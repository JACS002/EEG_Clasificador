{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa9d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Usando dispositivo: cuda\n",
      "🧠 INICIANDO EXPERIMENTO Parallel-EEGNet + S-TCN + MHSA + VAT\n",
      "🔧 Config: 4c, 8 canales, ventana 3s, VAT=ON\n",
      "⚙️  FT: epochs=30, base_lr=5e-05, head_lr=0.001, L2SP=0.0001, patience=5, CV=4\n",
      "Sujetos elegibles: 103 → [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|██████████| 103/103 [00:44<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=8652 | T=480 | C=8 | clases=4 | sujetos únicos=103\n",
      "Listo para entrenar: N=8652 | T=480 | C=8 | clases=4 | sujetos=103\n",
      "\n",
      "[Fold 1/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n",
      "  Época   1 | train_acc=0.4072 | val_acc=0.3956 | LR=0.01000\n",
      "  Época   5 | train_acc=0.5002 | val_acc=0.4130 | LR=0.00250\n",
      "  Época  10 | train_acc=0.3463 | val_acc=0.3214 | LR=0.00854\n",
      "  Época  15 | train_acc=0.5547 | val_acc=0.4405 | LR=0.00250\n",
      "  Época  20 | train_acc=0.5328 | val_acc=0.4222 | LR=0.00996\n",
      "  Época  25 | train_acc=0.5488 | val_acc=0.4350 | LR=0.00854\n",
      "  Early stopping en época 25 (mejor val_acc=0.4405)\n",
      "[Fold 1/5] Global acc=0.4552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5225    0.5261    0.5243       441\n",
      "       Right     0.4331    0.5578    0.4876       441\n",
      "  Both Fists     0.3918    0.3447    0.3667       441\n",
      "   Both Feet     0.4753    0.3923    0.4298       441\n",
      "\n",
      "    accuracy                         0.4552      1764\n",
      "   macro avg     0.4557    0.4552    0.4521      1764\n",
      "weighted avg     0.4557    0.4552    0.4521      1764\n",
      "\n",
      "  Fine-tuning (por sujeto) acc=0.4898 | Δ(FT-Global)=+0.0346 | sujetos=21\n",
      "\n",
      "[Fold 2/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n",
      "  Época   1 | train_acc=0.4172 | val_acc=0.3846 | LR=0.01000\n",
      "  Época   5 | train_acc=0.4795 | val_acc=0.4377 | LR=0.00250\n",
      "  Época  10 | train_acc=0.4805 | val_acc=0.4194 | LR=0.00854\n",
      "  Época  15 | train_acc=0.5162 | val_acc=0.4533 | LR=0.00250\n",
      "  Época  20 | train_acc=0.4910 | val_acc=0.4148 | LR=0.00996\n",
      "  Época  25 | train_acc=0.5274 | val_acc=0.4496 | LR=0.00854\n",
      "  Early stopping en época 29 (mejor val_acc=0.4744)\n",
      "[Fold 2/5] Global acc=0.5232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6034    0.5692    0.5858       441\n",
      "       Right     0.5970    0.5374    0.5656       441\n",
      "  Both Fists     0.4389    0.4966    0.4660       441\n",
      "   Both Feet     0.4779    0.4898    0.4838       441\n",
      "\n",
      "    accuracy                         0.5232      1764\n",
      "   macro avg     0.5293    0.5232    0.5253      1764\n",
      "weighted avg     0.5293    0.5232    0.5253      1764\n",
      "\n",
      "  Fine-tuning (por sujeto) acc=0.5431 | Δ(FT-Global)=+0.0198 | sujetos=21\n",
      "\n",
      "[Fold 3/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n",
      "  Época   1 | train_acc=0.4143 | val_acc=0.4194 | LR=0.01000\n",
      "  Época   5 | train_acc=0.4974 | val_acc=0.4734 | LR=0.00250\n",
      "  Época  10 | train_acc=0.4834 | val_acc=0.4606 | LR=0.00854\n",
      "  Época  15 | train_acc=0.5079 | val_acc=0.4863 | LR=0.00250\n",
      "  Época  20 | train_acc=0.4974 | val_acc=0.4505 | LR=0.00996\n",
      "  Época  25 | train_acc=0.5392 | val_acc=0.4789 | LR=0.00854\n",
      "  Época  30 | train_acc=0.5585 | val_acc=0.4918 | LR=0.00565\n",
      "  Época  35 | train_acc=0.5883 | val_acc=0.4890 | LR=0.00250\n",
      "  Época  40 | train_acc=0.6280 | val_acc=0.4863 | LR=0.00038\n",
      "  Early stopping en época 43 (mejor val_acc=0.5027)\n",
      "[Fold 3/5] Global acc=0.4739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.4845    0.5329    0.5076       441\n",
      "       Right     0.5170    0.5170    0.5170       441\n",
      "  Both Fists     0.4128    0.4399    0.4259       441\n",
      "   Both Feet     0.4864    0.4059    0.4425       441\n",
      "\n",
      "    accuracy                         0.4739      1764\n",
      "   macro avg     0.4752    0.4739    0.4732      1764\n",
      "weighted avg     0.4752    0.4739    0.4732      1764\n",
      "\n",
      "  Fine-tuning (por sujeto) acc=0.4677 | Δ(FT-Global)=-0.0062 | sujetos=21\n",
      "\n",
      "[Fold 4/5] Entrenando modelo global... (n_train=5880 | n_val=1092 | n_test=1680)\n",
      "  Época   1 | train_acc=0.3964 | val_acc=0.3810 | LR=0.01000\n",
      "  Época   5 | train_acc=0.4905 | val_acc=0.4679 | LR=0.00250\n",
      "  Época  10 | train_acc=0.4825 | val_acc=0.4560 | LR=0.00854\n",
      "  Época  15 | train_acc=0.5211 | val_acc=0.4515 | LR=0.00250\n",
      "  Época  20 | train_acc=0.4957 | val_acc=0.4414 | LR=0.00996\n",
      "  Época  25 | train_acc=0.5461 | val_acc=0.4615 | LR=0.00854\n",
      "  Early stopping en época 27 (mejor val_acc=0.4808)\n",
      "[Fold 4/5] Global acc=0.4839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6192    0.4452    0.5180       420\n",
      "       Right     0.5209    0.5048    0.5127       420\n",
      "  Both Fists     0.4097    0.5452    0.4678       420\n",
      "   Both Feet     0.4490    0.4405    0.4447       420\n",
      "\n",
      "    accuracy                         0.4839      1680\n",
      "   macro avg     0.4997    0.4839    0.4858      1680\n",
      "weighted avg     0.4997    0.4839    0.4858      1680\n",
      "\n",
      "  Fine-tuning (por sujeto) acc=0.5190 | Δ(FT-Global)=+0.0351 | sujetos=20\n",
      "\n",
      "[Fold 5/5] Entrenando modelo global... (n_train=5880 | n_val=1092 | n_test=1680)\n",
      "  Época   1 | train_acc=0.4051 | val_acc=0.3819 | LR=0.01000\n",
      "  Época   5 | train_acc=0.4670 | val_acc=0.4414 | LR=0.00250\n",
      "  Época  10 | train_acc=0.4447 | val_acc=0.4267 | LR=0.00854\n",
      "  Época  15 | train_acc=0.5131 | val_acc=0.4725 | LR=0.00250\n",
      "  Época  20 | train_acc=0.4850 | val_acc=0.4478 | LR=0.00996\n",
      "  Época  25 | train_acc=0.5121 | val_acc=0.4515 | LR=0.00854\n",
      "  Early stopping en época 28 (mejor val_acc=0.4881)\n",
      "[Fold 5/5] Global acc=0.5173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6057    0.5524    0.5778       420\n",
      "       Right     0.5415    0.5595    0.5504       420\n",
      "  Both Fists     0.4439    0.4048    0.4234       420\n",
      "   Both Feet     0.4833    0.5524    0.5156       420\n",
      "\n",
      "    accuracy                         0.5173      1680\n",
      "   macro avg     0.5186    0.5173    0.5168      1680\n",
      "weighted avg     0.5186    0.5173    0.5168      1680\n",
      "\n",
      "  Fine-tuning (por sujeto) acc=0.5452 | Δ(FT-Global)=+0.0280 | sujetos=20\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds: ['0.4552', '0.5232', '0.4739', '0.4839', '0.5173']\n",
      "Global mean: 0.4907\n",
      "Fine-tune folds: ['0.4898', '0.5431', '0.4677', '0.5190', '0.5452']\n",
      "Fine-tune mean: 0.5130\n",
      "Δ(FT-Global) mean: +0.0223\n",
      "↳ Matriz de confusión guardada: confusion_parallel_stcn_mhsa_vat_global_allfolds.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Parallel-EEGNet + S-TCN + MHSA con VAT (global) + fine-tuning por sujeto\n",
    "# - Misma construcción de dataset que EEGNet (6s, 8 canales, sujetos excluidos)\n",
    "# - Cross-subject global (5 folds) + FT por sujeto como etapa secundaria\n",
    "# - Notch adaptativo 50/60 Hz\n",
    "# - VAT durante entrenamiento global (opcional)\n",
    "\n",
    "import os, re, math, json, copy, random, itertools\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# RUTAS / CONFIG GENERAL\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Datos\n",
    "FS = 160.0\n",
    "WINDOW_MODE = '3s'   # [-1, +5] seg\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "# Escenario\n",
    "CLASS_SCENARIO = '4c'\n",
    "CLASS_NAMES_4C = ['Left', 'Right', 'Both Fists', 'Both Feet']\n",
    "N_CLASSES = 4\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Entrenamiento global\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_GLOBAL = 100\n",
    "LR_INIT = 1e-2\n",
    "SGDR_T0 = 6\n",
    "SGDR_Tmult = 2\n",
    "GLOBAL_VAL_SPLIT = 0.15\n",
    "GLOBAL_PATIENCE = 10\n",
    "LOG_EVERY = 5\n",
    "\n",
    "# Fine-tuning por sujeto\n",
    "CALIB_CV_FOLDS = 4\n",
    "FT_EPOCHS = 30\n",
    "FT_BASE_LR = 5e-5\n",
    "FT_HEAD_LR = 1e-3\n",
    "FT_L2SP = 1e-4\n",
    "FT_PATIENCE = 5\n",
    "FT_VAL_RATIO = 0.2\n",
    "\n",
    "# VAT (Virtual Adversarial Training)\n",
    "USE_VAT = True\n",
    "VAT_XI = 1e-6     # tamaño de paso para power-iteration\n",
    "VAT_EPS = 1.5     # radio de perturbación adversaria\n",
    "VAT_IP = 1        # iteraciones de potencia (1 suele bastar)\n",
    "\n",
    "# Augments ligeros\n",
    "USE_MIXUP = False\n",
    "MIXUP_ALPHA = 0.2\n",
    "\n",
    "# Runs (mismo set tuyo)\n",
    "MI_RUNS_LR = [4, 8, 12]\n",
    "MI_RUNS_OF = [6, 10, 14]\n",
    "BASELINE_RUNS_EO = [1]\n",
    "\n",
    "# =========================\n",
    "# CANALES / LECTURA EDF\n",
    "# =========================\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"[WARN] faltan canales {missing} en archivo {getattr(raw,'filenames', [''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    if run_id in BASELINE_RUNS_EO: return 'EO'\n",
    "    return None\n",
    "\n",
    "# --- Notch por SNR (50/60) ---\n",
    "_SNR_TABLE = None\n",
    "def _load_snr_table():\n",
    "    global _SNR_TABLE\n",
    "    if _SNR_TABLE is not None:\n",
    "        return _SNR_TABLE\n",
    "    csv_path = PROJ / 'reports' / 'psd_mains' / 'psd_mains_summary.csv'\n",
    "    if csv_path.exists():\n",
    "        try:\n",
    "            _SNR_TABLE = pd.read_csv(csv_path)\n",
    "        except:\n",
    "            _SNR_TABLE = None\n",
    "    return _SNR_TABLE\n",
    "\n",
    "def _decide_notch(subject, run, th_db=10.0):\n",
    "    df = _load_snr_table()\n",
    "    if df is None:\n",
    "        return 60.0\n",
    "    row = df[(df['subject']==subject) & (df['run']==run)]\n",
    "    if row.empty:\n",
    "        return 60.0\n",
    "    snr50 = float(row['snr50_db'].iloc[0]); snr60 = float(row['snr60_db'].iloc[0])\n",
    "    if snr60 >= th_db and snr60 >= snr50: return 60.0\n",
    "    if snr50 >= th_db and snr50 >  snr60: return 50.0\n",
    "    return None\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None:\n",
    "        return None\n",
    "    sid, rid = parse_subject_run(path)\n",
    "    notch = _decide_notch(sid, rid)\n",
    "    if notch is not None:\n",
    "        raw.notch_filter(freqs=[float(notch)], picks='eeg', method='spectrum_fit', phase='zero')\n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return []\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ', '')\n",
    "    res = []\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'):\n",
    "            res.append((float(onset), tag))\n",
    "    res.sort()\n",
    "    # de-dup mínimo por clase\n",
    "    dedup = []; last_t1 = last_t2 = -1e9\n",
    "    for t, tag in res:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# =========================\n",
    "# DATASET (MISMA LÓGICA 6s)\n",
    "# =========================\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR + MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "def extract_trials_from_run(edf_path: Path, scenario: str, window_mode: str):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF','EO'):\n",
    "        return ([], [])\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        return ([], [])\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    assert abs(fs - FS) < 1e-6\n",
    "    out = []\n",
    "    if kind in ('LR','OF'):\n",
    "        events = collect_events_T1T2(raw)\n",
    "        if window_mode == '3s':\n",
    "            rel_start, rel_end = 0.0, 3.0\n",
    "        else:\n",
    "            rel_start, rel_end = -1.0, 5.0  # 6 s\n",
    "        for onset_sec, tag in events:\n",
    "            if kind == 'LR':\n",
    "                label = 0 if tag=='T1' else 1 if tag=='T2' else None\n",
    "            else:\n",
    "                label = 2 if tag=='T1' else 3 if tag=='T2' else None\n",
    "            if label is None: continue\n",
    "            if scenario == '2c' and label not in (0,1): continue\n",
    "            if scenario == '3c' and label not in (0,1,2): continue\n",
    "            s = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "            e = int(round((raw.first_time + onset_sec + rel_end)   * fs))\n",
    "            if s < 0 or e > data.shape[1]: continue\n",
    "            seg = data[:, s:e].T.astype(np.float32)  # (T,C)\n",
    "            # z-score por época canal-a-canal\n",
    "            seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "            out.append((seg, label, subj))\n",
    "    elif kind == 'EO':\n",
    "        return ([], raw.ch_names)\n",
    "    return out, raw.ch_names\n",
    "\n",
    "def build_dataset_all(subjects, scenario='4c', window_mode='6s'):\n",
    "    X, y, groups = [], [], []\n",
    "    ch_template = None\n",
    "    for s in tqdm(subjects, desc=\"Construyendo dataset (RAW)\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "        trials = []\n",
    "        for r in (MI_RUNS_LR + MI_RUNS_OF):\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            trials.extend(outs)\n",
    "        # balanceo a 21 por clase/sujeto\n",
    "        per_class = {0:[],1:[],2:[],3:[]}\n",
    "        for seg, lab, _ in trials: per_class[lab].append(seg)\n",
    "        need = 21\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        valid = all(len(per_class[c])>0 for c in range(4))\n",
    "        if not valid: continue\n",
    "        def pick(arr):\n",
    "            if len(arr) >= need:\n",
    "                rng.shuffle(arr); return arr[:need]\n",
    "            idx = rng.choice(len(arr), size=need, replace=True)\n",
    "            return [arr[i] for i in idx]\n",
    "        for c in range(4):\n",
    "            segs = pick(per_class[c])\n",
    "            for seg in segs:\n",
    "                X.append(seg); y.append(c); groups.append(s)\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    groups = np.asarray(groups, dtype=np.int64)\n",
    "    n, T, C = X.shape\n",
    "    print(f\"Dataset construido: N={n} | T={T} | C={C} | clases={len(np.unique(y))} | sujetos únicos={len(np.unique(groups))}\")\n",
    "    return X, y, groups, ch_template\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS + VAT\n",
    "# =========================\n",
    "def do_time_jitter(x, max_ms=50, fs=160.0):\n",
    "    B,_,T,C = x.shape\n",
    "    max_shift = int(round(max_ms/1000.0 * fs))\n",
    "    if max_shift <= 0: return x\n",
    "    shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=x.device)\n",
    "    out = torch.empty_like(x)\n",
    "    for i,s in enumerate(shifts):\n",
    "        if s==0: out[i] = x[i]; continue\n",
    "        if s>0:\n",
    "            out[i,:,s:,:] = x[i,:,:T-s,:]; out[i,:,:s,:] = 0\n",
    "        else:\n",
    "            s = -s\n",
    "            out[i,:,:T-s,:] = x[i,:,s:,:]; out[i,:,T-s:,:] = 0\n",
    "    return out\n",
    "\n",
    "def do_gaussian_noise(x, sigma=0.01):\n",
    "    if sigma<=0: return x\n",
    "    return x + sigma*torch.randn_like(x)\n",
    "\n",
    "def do_temporal_cutout_masked(x, y, classes_mask={2,3}, min_ms=30, max_ms=60, fs=160.0):\n",
    "    B,_,T,C = x.shape\n",
    "    Lmin = int(round(min_ms/1000.0*fs)); Lmax = int(round(max_ms/1000.0*fs))\n",
    "    if Lmin<=0 or Lmax<=0 or Lmin>Lmax: return x\n",
    "    out = x.clone(); y_np = y.detach().cpu().numpy()\n",
    "    for i in range(B):\n",
    "        if int(y_np[i]) not in classes_mask: continue\n",
    "        L = random.randint(Lmin, Lmax)\n",
    "        if L>=T: continue\n",
    "        s = random.randint(0, T-L)\n",
    "        out[i,:,s:s+L,:] = 0\n",
    "    return out\n",
    "\n",
    "def mixup_batch(x, y, n_classes, alpha=0.2):\n",
    "    if alpha<=0:\n",
    "        y_onehot = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "        return x, y_onehot, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    perm = torch.randperm(x.size(0), device=x.device)\n",
    "    x_mix = lam*x + (1-lam)*x[perm]\n",
    "    y_a = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "    y_b = y_a[perm]\n",
    "    y_mix = lam*y_a + (1-lam)*y_b\n",
    "    return x_mix, y_mix, lam\n",
    "\n",
    "@torch.no_grad()\n",
    "def _normalize_like(x, ref):\n",
    "    # normaliza vector perturbación como ref (L2 sobre todo el tensor de entrada)\n",
    "    eps = 1e-6\n",
    "    r = x.view(x.size(0), -1)\n",
    "    n = torch.norm(r, p=2, dim=1, keepdim=True) + eps\n",
    "    r = (r / n) * ref\n",
    "    return r.view_as(x)\n",
    "\n",
    "def kl_div_with_logits(p_logits, q_logits):\n",
    "    p = torch.log_softmax(p_logits, dim=1)\n",
    "    q = torch.softmax(q_logits, dim=1)\n",
    "    return torch.mean(torch.sum(q * (torch.log(q + 1e-8) - p), dim=1))\n",
    "\n",
    "def virtual_adversarial_loss(model, x, logits=None, xi=1e-6, eps=1.5, ip=1):\n",
    "    # x: (B,1,T,C)\n",
    "    with torch.no_grad():\n",
    "        if logits is None:\n",
    "            logits = model(x)\n",
    "        p = logits.detach()\n",
    "    # d inicial aleatorio\n",
    "    d = torch.randn_like(x)\n",
    "    d = _normalize_like(d, ref=xi)\n",
    "    for _ in range(ip):\n",
    "        d.requires_grad_()\n",
    "        q = model(x + d)\n",
    "        adv_kl = kl_div_with_logits(p, q)\n",
    "        adv_kl.backward()\n",
    "        g = d.grad.detach()\n",
    "        d = _normalize_like(g, ref=xi)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "    # perturb final\n",
    "    r_adv = _normalize_like(d, ref=eps)\n",
    "    q = model(x + r_adv)\n",
    "    vat_loss = kl_div_with_logits(p, q)\n",
    "    return vat_loss\n",
    "\n",
    "# =========================\n",
    "# DATASET TORCH\n",
    "# =========================\n",
    "class EEGTrials(Dataset):\n",
    "    def __init__(self, X, y, groups):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]  # (T,C)\n",
    "        x = np.expand_dims(x, 0)  # (1,T,C)\n",
    "        return torch.from_numpy(x), torch.tensor(self.y[idx]), torch.tensor(self.g[idx])\n",
    "\n",
    "# =========================\n",
    "# MODELO: Parallel-EEGNet + S-TCN + MHSA\n",
    "# =========================\n",
    "class ChannelDropout(nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__(); self.p = p\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p<=0: return x\n",
    "        B,_,T,C = x.shape\n",
    "        mask = (torch.rand(B,1,1,C, device=x.device) > self.p).float()\n",
    "        return x * mask\n",
    "\n",
    "class SeparableTemporal(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.depth = nn.Conv2d(in_ch, in_ch, kernel_size=(k,1), groups=in_ch, padding=(k//2,0), bias=False)\n",
    "        self.point = nn.Conv2d(in_ch, out_ch, kernel_size=(1,1), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    def forward(self, x):\n",
    "        z = self.depth(x); z = self.point(z)\n",
    "        z = self.bn(z); z = self.act(z)\n",
    "        z = self.drop(z)\n",
    "        return z\n",
    "\n",
    "class ParallelEEGStem(nn.Module):\n",
    "    \"\"\"\n",
    "    Dos ramas temporales (kernels distintos) + depthwise espacial y separable temporal.\n",
    "    Entrada (B,1,T,C) -> Salida (B, F2_total, T', 1)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, F1=16, D=2, k_t_short=32, k_t_long=96,\n",
    "                 pool1_t=4, pool2_t=6, drop1=0.25, drop2=0.5, chdrop=0.1):\n",
    "        super().__init__()\n",
    "        self.chdrop = ChannelDropout(p=chdrop)\n",
    "\n",
    "        # Rama A (temporal corto)\n",
    "        self.convA = nn.Conv2d(1, F1, kernel_size=(k_t_short,1), padding=(k_t_short//2,0), bias=False)\n",
    "        self.bnA = nn.BatchNorm2d(F1); self.act = nn.ELU()\n",
    "\n",
    "        # Rama B (temporal largo)\n",
    "        self.convB = nn.Conv2d(1, F1, kernel_size=(k_t_long,1), padding=(k_t_long//2,0), bias=False)\n",
    "        self.bnB = nn.BatchNorm2d(F1)\n",
    "\n",
    "        # Depthwise espacial por rama\n",
    "        self.dwA = nn.Conv2d(F1, F1*D, kernel_size=(1,n_ch), groups=F1, bias=False)\n",
    "        self.dwB = nn.Conv2d(F1, F1*D, kernel_size=(1,n_ch), groups=F1, bias=False)\n",
    "        self.bn_dwA = nn.BatchNorm2d(F1*D)\n",
    "        self.bn_dwB = nn.BatchNorm2d(F1*D)\n",
    "        self.pool1A = nn.AvgPool2d(kernel_size=(pool1_t,1), stride=(pool1_t,1))\n",
    "        self.pool1B = nn.AvgPool2d(kernel_size=(pool1_t,1), stride=(pool1_t,1))\n",
    "        self.drop1A = nn.Dropout(drop1); self.drop1B = nn.Dropout(drop1)\n",
    "\n",
    "        # Separable temporal por rama\n",
    "        self.sepA = SeparableTemporal(F1*D, F1*D, k=16, p_drop=drop2)\n",
    "        self.sepB = SeparableTemporal(F1*D, F1*D, k=32, p_drop=drop2)\n",
    "        self.pool2A = nn.AvgPool2d(kernel_size=(pool2_t,1), stride=(pool2_t,1))\n",
    "        self.pool2B = nn.AvgPool2d(kernel_size=(pool2_t,1), stride=(pool2_t,1))\n",
    "\n",
    "        self.Fout = 2 * (F1*D)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,1,T,C)\n",
    "        x = self.chdrop(x)\n",
    "\n",
    "        a = self.convA(x); a = self.bnA(a); a = self.act(a)\n",
    "        b = self.convB(x); b = self.bnB(b); b = self.act(b)\n",
    "\n",
    "        a = self.dwA(a); a = self.bn_dwA(a); a = self.act(a)\n",
    "        b = self.dwB(b); b = self.bn_dwB(b); b = self.act(b)\n",
    "        a = self.pool1A(a); a = self.drop1A(a)\n",
    "        b = self.pool1B(b); b = self.drop1B(b)\n",
    "\n",
    "        a = self.sepA(a); a = self.pool2A(a)   # (B, F, T', 1)\n",
    "        b = self.sepB(b); b = self.pool2B(b)\n",
    "        z = torch.cat([a, b], dim=1)           # concat canales\n",
    "        return z  # (B, F_total, T', 1)\n",
    "\n",
    "class STCNBlock(nn.Module):\n",
    "    def __init__(self, d_model, k=7, dilation=1, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(d_model, d_model, kernel_size=k, padding=dilation*(k//2), dilation=dilation, groups=d_model)\n",
    "        self.bn1 = nn.BatchNorm1d(d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.conv2 = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "        self.bn2 = nn.BatchNorm1d(d_model)\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    def forward(self, x):  # x: (B, D, T)\n",
    "        y = self.conv1(x); y = self.bn1(y); y = self.act(y)\n",
    "        y = self.conv2(y); y = self.bn2(y); y = self.drop(y)\n",
    "        return x + y\n",
    "\n",
    "class MHSA1D(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=4, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.mha = nn.MultiheadAttention(d_model, n_heads, dropout=p_drop, batch_first=True)\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    def forward(self, x):  # x: (B,T,D)\n",
    "        y = self.ln(x)\n",
    "        y,_ = self.mha(y,y,y, need_weights=False)\n",
    "        return x + self.drop(y)\n",
    "\n",
    "class EEG_Parallel_STCN_MHSA(nn.Module):\n",
    "    \"\"\"\n",
    "    Entrada: (B,1,T,C)\n",
    "    1) Parallel EEG stem -> (B, F, T', 1)\n",
    "    2) Reordenar a (B, T', F)\n",
    "    3) S-TCN (dilations 1-2-4)\n",
    "    4) MHSA sobre T'\n",
    "    5) MeanPool + Head\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_classes=4,\n",
    "                 F1=16, D=2, k_t_short=32, k_t_long=96,\n",
    "                 pool1_t=4, pool2_t=6, drop1=0.25, drop2=0.5, chdrop=0.1,\n",
    "                 d_model=None, n_heads=4, stcn_k=7, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.stem = ParallelEEGStem(n_ch=n_ch, F1=F1, D=D, k_t_short=k_t_short, k_t_long=k_t_long,\n",
    "                                    pool1_t=pool1_t, pool2_t=pool2_t, drop1=drop1, drop2=drop2, chdrop=chdrop)\n",
    "        D_in = self.stem.Fout\n",
    "        self.proj = nn.Conv1d(D_in, D_in, kernel_size=1)  # opcional\n",
    "        self.stcn1 = STCNBlock(D_in, k=stcn_k, dilation=1, p_drop=p_drop)\n",
    "        self.stcn2 = STCNBlock(D_in, k=stcn_k, dilation=2, p_drop=p_drop)\n",
    "        self.stcn3 = STCNBlock(D_in, k=stcn_k, dilation=4, p_drop=p_drop)\n",
    "        self.mhsa = MHSA1D(D_in, n_heads=n_heads, p_drop=p_drop)\n",
    "        self.ln = nn.LayerNorm(D_in)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(D_in, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,1,T,C)\n",
    "        z = self.stem(x)                # (B, F, T', 1)\n",
    "        z = z.squeeze(-1)               # (B, F, T')\n",
    "        z = self.proj(z)                # (B, F, T')\n",
    "        z = self.stcn1(z); z = self.stcn2(z); z = self.stcn3(z)\n",
    "        z = z.transpose(1,2)            # (B, T', F)\n",
    "        z = self.mhsa(z)\n",
    "        z = self.ln(z)\n",
    "        z = z.mean(dim=1)               # (B, F)\n",
    "        logits = self.head(z)\n",
    "        return logits\n",
    "\n",
    "# =========================\n",
    "# ENTRENAMIENTO / EVAL\n",
    "# =========================\n",
    "def build_weighted_sampler(y, groups):\n",
    "    y = np.asarray(y); groups = np.asarray(groups)\n",
    "    class_counts = np.bincount(y, minlength=len(np.unique(y))).astype(float)\n",
    "    class_w = 1.0 / class_counts[y]\n",
    "    subj_vals, subj_counts = np.unique(groups, return_counts=True)\n",
    "    subj_map = {s:c for s,c in zip(subj_vals, subj_counts)}\n",
    "    subj_w = np.array([1.0/subj_map[g] for g in groups], dtype=float)\n",
    "    w = class_w * subj_w\n",
    "    w = w / w.mean()\n",
    "    return WeightedRandomSampler(weights=torch.from_numpy(w).float(), num_samples=len(w), replacement=True)\n",
    "\n",
    "def make_class_weight_tensor(y_indices, n_classes):\n",
    "    counts = np.bincount(y_indices, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    w = counts.sum() / counts\n",
    "    w = w / w.mean()\n",
    "    return torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def train_one_epoch(model, loader, opt, criterion, epoch, n_classes=N_CLASSES,\n",
    "                    use_vat=True, vat_xi=VAT_XI, vat_eps=VAT_EPS, vat_ip=VAT_IP):\n",
    "    model.train()\n",
    "    for xb, yb, _ in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "        # Augments ligeros\n",
    "        xb = do_time_jitter(xb, max_ms=50, fs=FS)\n",
    "        xb = do_gaussian_noise(xb, sigma=0.01)\n",
    "        xb = do_temporal_cutout_masked(xb, yb, classes_mask={2,3}, min_ms=30, max_ms=60, fs=FS)\n",
    "\n",
    "        if USE_MIXUP:\n",
    "            xb, yt, _ = mixup_batch(xb, yb, n_classes=n_classes, alpha=MIXUP_ALPHA)\n",
    "            logits = model(xb)\n",
    "            loss_sup = -(yt * torch.log_softmax(logits, dim=1)).sum(dim=1).mean()\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "            loss_sup = criterion(logits, yb)\n",
    "\n",
    "        loss = loss_sup\n",
    "        if use_vat:\n",
    "            vat_loss = virtual_adversarial_loss(model, xb, logits=logits, xi=vat_xi, eps=vat_eps, ip=vat_ip)\n",
    "            loss = loss + 0.5 * vat_loss  # peso VAT (ajústalo si quieres)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, use_tta=True, tta_n=5):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for xb, yb, _ in loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        if use_tta:\n",
    "            outs = []\n",
    "            for _ in range(tta_n):\n",
    "                outs.append(model(do_time_jitter(xb, max_ms=25, fs=FS)))\n",
    "            logits = torch.stack(outs, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "        pred = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        y_pred.extend(pred); y_true.extend(yb.numpy().tolist())\n",
    "    y_true = np.asarray(y_true, dtype=int); y_pred = np.asarray(y_pred, dtype=int)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    return y_true, y_pred, float(acc)\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45, ha='right'); plt.yticks(ticks, classes)\n",
    "    fmt = '.2f'; thresh = cm_norm.max()/2.\n",
    "    for i,j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i, format(cm_norm[i,j], fmt), ha=\"center\",\n",
    "                 color=\"white\" if cm_norm[i,j] > thresh else \"black\")\n",
    "    plt.ylabel('True'); plt.xlabel('Pred')\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150, bbox_inches='tight'); plt.close()\n",
    "\n",
    "def print_report(y_true, y_pred, classes):\n",
    "    print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n",
    "\n",
    "# =========================\n",
    "# FINE-TUNING POR SUJETO (mismo estilo que tuyo)\n",
    "# =========================\n",
    "def _freeze_all(m):\n",
    "    for p in m.parameters(): p.requires_grad = False\n",
    "\n",
    "def subject_cv_finetune_predict_progressive(model_global, Xs, ys, n_classes=4):\n",
    "    # Dos etapas: (1) head; (2) last blocks (stcn+mhsa) + head con L2-SP\n",
    "    y_true_full = np.empty_like(ys); y_pred_full = np.empty_like(ys)\n",
    "    # CV adaptativo\n",
    "    ys_np = np.asarray(ys)\n",
    "    counts = np.bincount(ys_np, minlength=n_classes)\n",
    "    min_class = counts[counts>0].min() if counts.sum()>0 else 0\n",
    "    splits = min(CALIB_CV_FOLDS, max(2, int(min_class))) if min_class>0 else 2\n",
    "    splitter = StratifiedKFold(n_splits=splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    for tr_idx, te_idx in splitter.split(Xs, ys):\n",
    "        Xcal, ycal = Xs[tr_idx], ys[tr_idx]\n",
    "        Xho,  yho  = Xs[te_idx], ys[te_idx]\n",
    "\n",
    "        # split interno\n",
    "        if len(np.unique(ycal)) >= 2 and len(ycal) >= 5:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=FT_VAL_RATIO, random_state=RANDOM_STATE)\n",
    "            (tr2, va2), = sss.split(Xcal, ycal)\n",
    "        else:\n",
    "            idx = np.arange(len(ycal)); np.random.shuffle(idx)\n",
    "            cut = max(1, int(0.85*len(idx)))\n",
    "            tr2, va2 = idx[:cut], idx[cut:]\n",
    "\n",
    "        ds_tr2 = torch.utils.data.TensorDataset(torch.from_numpy(Xcal[tr2]).float().unsqueeze(1), torch.from_numpy(ycal[tr2]).long())\n",
    "        ds_va2 = torch.utils.data.TensorDataset(torch.from_numpy(Xcal[va2]).float().unsqueeze(1), torch.from_numpy(ycal[va2]).long())\n",
    "        dl_tr2 = DataLoader(ds_tr2, batch_size=32, shuffle=True)\n",
    "        dl_va2 = DataLoader(ds_va2, batch_size=64, shuffle=False)\n",
    "        ds_te  = torch.utils.data.TensorDataset(torch.from_numpy(Xho).float().unsqueeze(1), torch.from_numpy(yho).long())\n",
    "        dl_te  = DataLoader(ds_te, batch_size=64, shuffle=False)\n",
    "\n",
    "        # ========== (1) HEAD ==========\n",
    "        m = copy.deepcopy(model_global).to(DEVICE)\n",
    "        _freeze_all(m)\n",
    "        # habilitar solo la head\n",
    "        for p in m.head.parameters(): p.requires_grad = True\n",
    "        opt = optim.Adam(m.head.parameters(), lr=FT_HEAD_LR)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "\n",
    "        best = copy.deepcopy(m.state_dict()); best_va = 1e9; bad=0\n",
    "        for _ in range(FT_EPOCHS):\n",
    "            m.train()\n",
    "            for xb, yb in dl_tr2:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                loss = crit(m(xb), yb); loss.backward(); opt.step()\n",
    "            # val\n",
    "            m.eval(); val_loss=0.0; n=0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in dl_va2:\n",
    "                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                    val_loss += crit(m(xb), yb).item()*xb.size(0); n+=xb.size(0)\n",
    "            val_loss/=max(1,n)\n",
    "            if val_loss < best_va-1e-7:\n",
    "                best_va = val_loss; best=copy.deepcopy(m.state_dict()); bad=0\n",
    "            else:\n",
    "                bad+=1\n",
    "                if bad>=FT_PATIENCE: break\n",
    "        m.load_state_dict(best)\n",
    "\n",
    "        # ========== (2) Último bloque (stcn3 + mhsa + ln + head) con L2-SP ==========\n",
    "        _freeze_all(m)\n",
    "        train_params = []\n",
    "        for p in m.stcn3.parameters(): p.requires_grad = True; train_params.append(p)\n",
    "        for p in m.mhsa.parameters():  p.requires_grad = True; train_params.append(p)\n",
    "        for p in m.ln.parameters():    p.requires_grad = True; train_params.append(p)\n",
    "        for p in m.head.parameters():  p.requires_grad = True; train_params.append(p)\n",
    "\n",
    "        ref = [p.detach().clone() for p in train_params]\n",
    "        opt = optim.Adam([\n",
    "            {\"params\": list(m.stcn3.parameters()) + list(m.mhsa.parameters()) + list(m.ln.parameters()), \"lr\": FT_BASE_LR},\n",
    "            {\"params\": m.head.parameters(), \"lr\": FT_HEAD_LR},\n",
    "        ])\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "\n",
    "        best = copy.deepcopy(m.state_dict()); best_va = 1e9; bad=0\n",
    "        for _ in range(FT_EPOCHS):\n",
    "            m.train()\n",
    "            for xb, yb in dl_tr2:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                logits = m(xb)\n",
    "                loss = crit(logits, yb)\n",
    "                # L2-SP\n",
    "                reg = 0.0\n",
    "                for p_cur, p_ref in zip(train_params, ref):\n",
    "                    reg = reg + torch.sum((p_cur - p_ref)**2)\n",
    "                loss = loss + FT_L2SP * reg\n",
    "                loss.backward(); opt.step()\n",
    "            # val\n",
    "            m.eval(); val_loss=0.0; n=0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in dl_va2:\n",
    "                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                    val_loss += crit(m(xb), yb).item()*xb.size(0); n+=xb.size(0)\n",
    "            val_loss/=max(1,n)\n",
    "            if val_loss < best_va-1e-7:\n",
    "                best_va = val_loss; best=copy.deepcopy(m.state_dict()); bad=0\n",
    "            else:\n",
    "                bad+=1\n",
    "                if bad>=FT_PATIENCE: break\n",
    "        m.load_state_dict(best)\n",
    "\n",
    "        # test hold-out del CV interno\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            preds=[]\n",
    "            for xb, _ in dl_te:\n",
    "                xb = xb.to(DEVICE)\n",
    "                logits = m(xb)\n",
    "                preds.extend(logits.argmax(1).cpu().numpy().tolist())\n",
    "        y_pred_full[te_idx] = np.asarray(preds); y_true_full[te_idx] = yho\n",
    "\n",
    "    return y_true_full, y_pred_full\n",
    "\n",
    "# =========================\n",
    "# HELPERS FOLDS JSON\n",
    "# =========================\n",
    "def save_group_folds_json_with_indices(subject_ids_str, groups_array, n_splits, out_json_path,\n",
    "                                       created_by=\"ParallelEEG_STCN_MHSA\", description=None):\n",
    "    out_json_path = Path(out_json_path)\n",
    "    unique_subjects_int = sorted(np.unique(groups_array).tolist())\n",
    "    subject_ids = [f\"S{sid:03d}\" for sid in unique_subjects_int]\n",
    "    if len(subject_ids) < n_splits:\n",
    "        raise ValueError(f\"n_splits={n_splits} mayor que número de sujetos={len(subject_ids)}\")\n",
    "    groups = np.arange(len(subject_ids))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    folds = []\n",
    "    fold_i = 0\n",
    "    for train_idx_grp, test_idx_grp in gkf.split(groups, groups, groups):\n",
    "        fold_i += 1\n",
    "        train_sids = [subject_ids[int(i)] for i in train_idx_grp]\n",
    "        test_sids  = [subject_ids[int(i)] for i in test_idx_grp]\n",
    "        train_sids_int = [int(s[1:]) for s in train_sids]\n",
    "        test_sids_int  = [int(s[1:]) for s in test_sids]\n",
    "        tr_idx = np.where(np.isin(groups_array, train_sids_int))[0].tolist()\n",
    "        te_idx = np.where(np.isin(groups_array, test_sids_int))[0].tolist()\n",
    "        folds.append({\n",
    "            \"fold\": int(fold_i),\n",
    "            \"train\": train_sids,\n",
    "            \"test\": test_sids,\n",
    "            \"tr_idx\": tr_idx,\n",
    "            \"te_idx\": te_idx\n",
    "        })\n",
    "    payload = {\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"created_by\": created_by,\n",
    "        \"description\": description if description is not None else \"\",\n",
    "        \"n_splits\": int(n_splits),\n",
    "        \"n_subjects\": len(subject_ids),\n",
    "        \"subject_ids\": subject_ids,\n",
    "        \"folds\": folds\n",
    "    }\n",
    "    out_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Folds JSON con índices guardado → {out_json_path}\")\n",
    "    return out_json_path\n",
    "\n",
    "def load_group_folds_json(path_json, expected_subject_ids=None, strict_check=True):\n",
    "    path_json = Path(path_json)\n",
    "    if not path_json.exists():\n",
    "        raise FileNotFoundError(f\"No existe {path_json}\")\n",
    "    with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "    subj_json = payload.get(\"subject_ids\", [])\n",
    "    if expected_subject_ids is not None:\n",
    "        expected = sorted(list(expected_subject_ids))\n",
    "        if subj_json != expected:\n",
    "            msg = (\"Los subject_ids del JSON no coinciden con expected_subject_ids.\\n\"\n",
    "                   f\"JSON has {len(subj_json)} subjects, expected {len(expected)}.\\n\"\n",
    "                   f\"First 10 JSON: {subj_json[:10]}\\nFirst 10 expected: {expected[:10]}\")\n",
    "            if strict_check:\n",
    "                raise ValueError(msg)\n",
    "            else:\n",
    "                print(\"WARNING: \" + msg)\n",
    "    return payload\n",
    "\n",
    "# =========================\n",
    "# EXPERIMENTO\n",
    "# =========================\n",
    "def run_experiment(save_folds_json=True, folds_json_path=FOLDS_DIR,\n",
    "                   folds_json_description=\"GroupKFold folds for ParallelEEG_STCN_MHSA + VAT\"):\n",
    "    mne.set_log_level('WARNING')\n",
    "\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos elegibles: {len(subs)} → {subs[:10]}{'...' if len(subs)>10 else ''}\")\n",
    "\n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Listo para entrenar: N={N} | T={T} | C={C} | clases={n_classes} | sujetos={len(np.unique(groups))}\")\n",
    "\n",
    "    ds = EEGTrials(X, y, groups)\n",
    "\n",
    "    # Folds JSON\n",
    "    if folds_json_path is None:\n",
    "        folds_json_path = Path(\"folds\") / f\"group_folds_{N_FOLDS}splits.json\"\n",
    "    else:\n",
    "        folds_json_path = Path(folds_json_path)\n",
    "    folds_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    unique_subs = sorted(np.unique(groups).tolist())\n",
    "    subject_ids_str = [f\"S{s:03d}\" for s in unique_subs]\n",
    "    if not folds_json_path.exists():\n",
    "        if not save_folds_json:\n",
    "            raise FileNotFoundError(f\"Folds JSON no encontrado en {folds_json_path} y save_folds_json=False.\")\n",
    "        save_group_folds_json_with_indices(subject_ids_str, groups, n_splits=N_FOLDS,\n",
    "                                           out_json_path=folds_json_path,\n",
    "                                           created_by=\"ParallelEEG_STCN_MHSA\",\n",
    "                                           description=f\"{folds_json_description}\")\n",
    "    payload = load_group_folds_json(folds_json_path, expected_subject_ids=subject_ids_str, strict_check=False)\n",
    "    folds = payload[\"folds\"]\n",
    "\n",
    "    global_folds = []\n",
    "    ft_prog_folds = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    for f in folds:\n",
    "        fold = f[\"fold\"]\n",
    "        tr_idx = np.asarray(f.get(\"tr_idx\", []), dtype=int)\n",
    "        te_idx = np.asarray(f.get(\"te_idx\", []), dtype=int)\n",
    "        if tr_idx.size == 0 or te_idx.size == 0:\n",
    "            print(f\"[WARN] fold {fold} sin índices tr/te válidos. Saltando.\")\n",
    "            continue\n",
    "\n",
    "        # split de validación por sujetos\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=GLOBAL_VAL_SPLIT, random_state=RANDOM_STATE)\n",
    "        tr_subj_idx, va_subj_idx = next(gss.split(tr_idx, groups[tr_idx], groups[tr_idx]))\n",
    "        tr_sub_idx = tr_idx[tr_subj_idx]\n",
    "        va_idx     = tr_idx[va_subj_idx]\n",
    "\n",
    "        sampler = build_weighted_sampler(y[tr_sub_idx], groups[tr_sub_idx])\n",
    "        tr_loader = DataLoader(Subset(ds, tr_sub_idx), batch_size=BATCH_SIZE, sampler=sampler, drop_last=False)\n",
    "        va_loader = DataLoader(Subset(ds, va_idx),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        te_loader = DataLoader(Subset(ds, te_idx),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "        # modelo\n",
    "        model = EEG_Parallel_STCN_MHSA(n_ch=C, n_classes=n_classes,\n",
    "                                       F1=16, D=2, k_t_short=32, k_t_long=96,\n",
    "                                       pool1_t=4, pool2_t=6,\n",
    "                                       drop1=0.25, drop2=0.5, chdrop=0.1,\n",
    "                                       n_heads=4, stcn_k=7, p_drop=0.2).to(DEVICE)\n",
    "\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_INIT, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=SGDR_T0, T_mult=SGDR_Tmult)\n",
    "        class_weights = make_class_weight_tensor(y[tr_sub_idx], n_classes)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        best_val = -1.0; bad = 0\n",
    "\n",
    "        print(f\"\\n[Fold {fold}/{N_FOLDS}] Entrenando modelo global...\"\n",
    "              f\" (n_train={len(tr_sub_idx)} | n_val={len(va_idx)} | n_test={len(te_idx)})\")\n",
    "\n",
    "        for epoch in range(1, EPOCHS_GLOBAL + 1):\n",
    "            train_one_epoch(model, tr_loader, opt, criterion, epoch,\n",
    "                            n_classes=n_classes, use_vat=USE_VAT,\n",
    "                            vat_xi=VAT_XI, vat_eps=VAT_EPS, vat_ip=VAT_IP)\n",
    "            scheduler.step(epoch-1 + 1e-8)\n",
    "\n",
    "            _, _, tr_acc = evaluate(model, tr_loader, use_tta=True, tta_n=5)\n",
    "            _, _, va_acc = evaluate(model, va_loader, use_tta=True, tta_n=5)\n",
    "\n",
    "            if (epoch % LOG_EVERY == 0) or epoch in (1, 10, 20, 50, 100):\n",
    "                cur_lr = opt.param_groups[0]['lr']\n",
    "                print(f\"  Época {epoch:3d} | train_acc={tr_acc:.4f} | val_acc={va_acc:.4f} | LR={cur_lr:.5f}\")\n",
    "\n",
    "            if va_acc > best_val + 1e-4:\n",
    "                best_val = va_acc; best_state = copy.deepcopy(model.state_dict()); bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= GLOBAL_PATIENCE:\n",
    "                    print(f\"  Early stopping en época {epoch} (mejor val_acc={best_val:.4f})\")\n",
    "                    break\n",
    "\n",
    "        # eval global\n",
    "        model.load_state_dict(best_state)\n",
    "        y_true, y_pred, acc_global = evaluate(model, te_loader, use_tta=True, tta_n=5)\n",
    "        global_folds.append(acc_global); all_true.append(y_true); all_pred.append(y_pred)\n",
    "        print(f\"[Fold {fold}/{N_FOLDS}] Global acc={acc_global:.4f}\")\n",
    "        print_report(y_true, y_pred, CLASS_NAMES_4C)\n",
    "\n",
    "        # ---------- Fine-tuning por sujeto (secundario) ----------\n",
    "        X_te, y_te, g_te = X[te_idx], y[te_idx], groups[te_idx]\n",
    "        y_true_ft_all, y_pred_ft_all = [], []\n",
    "        used_subjects = 0\n",
    "        for sid in np.unique(g_te):\n",
    "            idx = np.where(g_te == sid)[0]\n",
    "            Xs, ys = X_te[idx], y_te[idx]\n",
    "            if len(np.unique(ys)) < 2:\n",
    "                continue\n",
    "            y_true_subj, y_pred_subj = subject_cv_finetune_predict_progressive(model, Xs, ys, n_classes=n_classes)\n",
    "            y_true_ft_all.append(y_true_subj); y_pred_ft_all.append(y_pred_subj); used_subjects += 1\n",
    "        if len(y_true_ft_all) > 0:\n",
    "            y_true_ft_all = np.concatenate(y_true_ft_all)\n",
    "            y_pred_ft_all = np.concatenate(y_pred_ft_all)\n",
    "            acc_ft = (y_true_ft_all == y_pred_ft_all).mean()\n",
    "            print(f\"  Fine-tuning (por sujeto) acc={acc_ft:.4f} | Δ(FT-Global)={acc_ft - acc_global:+.4f} | sujetos={used_subjects}\")\n",
    "        else:\n",
    "            acc_ft = np.nan\n",
    "            print(\"  Fine-tuning no ejecutado (sujeto(s) con muestras insuficientes).\")\n",
    "        ft_prog_folds.append(acc_ft)\n",
    "\n",
    "    # ---------- resultados finales ----------\n",
    "    if len(all_true) > 0:\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "    else:\n",
    "        all_true = np.array([], dtype=int)\n",
    "        all_pred = np.array([], dtype=int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Global folds:\", [f\"{a:.4f}\" for a in global_folds])\n",
    "    if len(global_folds) > 0:\n",
    "        print(f\"Global mean: {np.mean(global_folds):.4f}\")\n",
    "    print(\"Fine-tune folds:\", [(\"nan\" if (a is None or np.isnan(a)) else f\"{a:.4f}\") for a in ft_prog_folds])\n",
    "    if len(ft_prog_folds) > 0:\n",
    "        print(f\"Fine-tune mean: {np.nanmean(ft_prog_folds):.4f}\")\n",
    "        print(f\"Δ(FT-Global) mean: {np.nanmean(ft_prog_folds) - np.mean(global_folds):+.4f}\")\n",
    "\n",
    "    if all_true.size > 0:\n",
    "        plot_confusion(all_true, all_pred, CLASS_NAMES_4C,\n",
    "                       title=\"Confusion Matrix - Global (ParallelEEG+STCN+MHSA+VAT)\",\n",
    "                       fname=\"confusion_parallel_stcn_mhsa_vat_global_allfolds.png\")\n",
    "        print(\"↳ Matriz de confusión guardada: confusion_parallel_stcn_mhsa_vat_global_allfolds.png\")\n",
    "\n",
    "    return {\n",
    "        \"global_folds\": global_folds,\n",
    "        \"ft_prog_folds\": ft_prog_folds,\n",
    "        \"all_true\": all_true,\n",
    "        \"all_pred\": all_pred,\n",
    "        \"folds_json_path\": str(folds_json_path)\n",
    "    }\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🧠 INICIANDO EXPERIMENTO Parallel-EEGNet + S-TCN + MHSA + VAT\")\n",
    "    print(f\"🔧 Config: {CLASS_SCENARIO}, 8 canales, ventana {WINDOW_MODE}, VAT={'ON' if USE_VAT else 'OFF'}\")\n",
    "    print(f\"⚙️  FT: epochs={FT_EPOCHS}, base_lr={FT_BASE_LR}, head_lr={FT_HEAD_LR}, L2SP={FT_L2SP}, patience={FT_PATIENCE}, CV={CALIB_CV_FOLDS}\")\n",
    "    run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e117844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Usando dispositivo: cuda\n",
      "🧠 INICIANDO EXPERIMENTO TWO-STAGE TRANSFORMER ARCHITECTURE\n",
      "📖 Basado en: 'A two-stage transformer based network for motor imagery classification'\n",
      "Sujetos disponibles: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   1%|          | 1/103 [00:00<00:17,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   2%|▏         | 2/103 [00:00<00:16,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   3%|▎         | 3/103 [00:00<00:16,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   4%|▍         | 4/103 [00:00<00:16,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   5%|▍         | 5/103 [00:00<00:15,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   6%|▌         | 6/103 [00:00<00:15,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   7%|▋         | 7/103 [00:01<00:16,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   8%|▊         | 8/103 [00:01<00:17,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   9%|▊         | 9/103 [00:01<00:17,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  10%|▉         | 10/103 [00:01<00:17,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  11%|█         | 11/103 [00:01<00:17,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  12%|█▏        | 12/103 [00:02<00:17,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  13%|█▎        | 13/103 [00:02<00:17,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  14%|█▎        | 14/103 [00:02<00:17,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  15%|█▍        | 15/103 [00:02<00:17,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  16%|█▌        | 16/103 [00:03<00:21,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  17%|█▋        | 17/103 [00:03<00:20,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  17%|█▋        | 18/103 [00:03<00:19,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  18%|█▊        | 19/103 [00:03<00:18,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  19%|█▉        | 20/103 [00:03<00:17,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  20%|██        | 21/103 [00:04<00:16,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  21%|██▏       | 22/103 [00:04<00:16,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  22%|██▏       | 23/103 [00:04<00:16,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  23%|██▎       | 24/103 [00:04<00:15,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  24%|██▍       | 25/103 [00:04<00:15,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  25%|██▌       | 26/103 [00:05<00:15,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  26%|██▌       | 27/103 [00:05<00:15,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  27%|██▋       | 28/103 [00:05<00:14,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  28%|██▊       | 29/103 [00:05<00:14,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  29%|██▉       | 30/103 [00:05<00:14,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  30%|███       | 31/103 [00:06<00:14,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  31%|███       | 32/103 [00:06<00:14,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  32%|███▏      | 33/103 [00:06<00:13,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  33%|███▎      | 34/103 [00:06<00:13,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  34%|███▍      | 35/103 [00:06<00:13,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  35%|███▍      | 36/103 [00:07<00:13,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  36%|███▌      | 37/103 [00:07<00:13,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  37%|███▋      | 38/103 [00:07<00:12,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  38%|███▊      | 39/103 [00:07<00:12,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  39%|███▉      | 40/103 [00:07<00:12,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  40%|███▉      | 41/103 [00:08<00:12,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  41%|████      | 42/103 [00:08<00:11,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  42%|████▏     | 43/103 [00:08<00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  43%|████▎     | 44/103 [00:08<00:11,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  44%|████▎     | 45/103 [00:08<00:11,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  45%|████▍     | 46/103 [00:09<00:11,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  46%|████▌     | 47/103 [00:09<00:10,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  47%|████▋     | 48/103 [00:09<00:10,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  48%|████▊     | 49/103 [00:09<00:10,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  49%|████▊     | 50/103 [00:09<00:10,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  50%|████▉     | 51/103 [00:10<00:10,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  50%|█████     | 52/103 [00:10<00:10,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  51%|█████▏    | 53/103 [00:10<00:09,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  52%|█████▏    | 54/103 [00:10<00:09,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  53%|█████▎    | 55/103 [00:10<00:09,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  54%|█████▍    | 56/103 [00:11<00:09,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  55%|█████▌    | 57/103 [00:11<00:09,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  56%|█████▋    | 58/103 [00:11<00:09,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  57%|█████▋    | 59/103 [00:11<00:09,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  58%|█████▊    | 60/103 [00:11<00:09,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  59%|█████▉    | 61/103 [00:12<00:09,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  60%|██████    | 62/103 [00:12<00:09,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  61%|██████    | 63/103 [00:12<00:08,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  62%|██████▏   | 64/103 [00:12<00:08,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  63%|██████▎   | 65/103 [00:13<00:08,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  64%|██████▍   | 66/103 [00:13<00:08,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  65%|██████▌   | 67/103 [00:13<00:08,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  66%|██████▌   | 68/103 [00:13<00:07,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  67%|██████▋   | 69/103 [00:14<00:07,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  68%|██████▊   | 70/103 [00:14<00:07,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  69%|██████▉   | 71/103 [00:14<00:07,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  70%|██████▉   | 72/103 [00:14<00:07,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  71%|███████   | 73/103 [00:14<00:06,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  72%|███████▏  | 74/103 [00:15<00:06,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  73%|███████▎  | 75/103 [00:15<00:07,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  74%|███████▍  | 76/103 [00:15<00:06,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  75%|███████▍  | 77/103 [00:15<00:06,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  76%|███████▌  | 78/103 [00:16<00:05,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  77%|███████▋  | 79/103 [00:16<00:05,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  78%|███████▊  | 80/103 [00:16<00:05,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  79%|███████▊  | 81/103 [00:16<00:05,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  80%|███████▉  | 82/103 [00:17<00:04,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  81%|████████  | 83/103 [00:17<00:04,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  82%|████████▏ | 84/103 [00:17<00:04,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  83%|████████▎ | 85/103 [00:17<00:04,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  83%|████████▎ | 86/103 [00:18<00:03,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  84%|████████▍ | 87/103 [00:18<00:03,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  85%|████████▌ | 88/103 [00:18<00:03,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  86%|████████▋ | 89/103 [00:18<00:03,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  87%|████████▋ | 90/103 [00:18<00:02,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  88%|████████▊ | 91/103 [00:19<00:03,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  89%|████████▉ | 92/103 [00:19<00:02,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  90%|█████████ | 93/103 [00:19<00:02,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  91%|█████████▏| 94/103 [00:19<00:02,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  92%|█████████▏| 95/103 [00:20<00:01,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  93%|█████████▎| 96/103 [00:20<00:01,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  94%|█████████▍| 97/103 [00:20<00:01,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  95%|█████████▌| 98/103 [00:20<00:01,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  96%|█████████▌| 99/103 [00:21<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  97%|█████████▋| 100/103 [00:21<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  98%|█████████▊| 101/103 [00:21<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  99%|█████████▉| 102/103 [00:21<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|██████████| 103/103 [00:22<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=6180 | T=960 | C=8 | clases=4 | sujetos únicos=103\n",
      "Datos cargados: N=6180, T=960, C=8, Clases=4\n",
      "Aplicando aumento de datos simplificado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aumento completado: 80 muestras añadidas\n",
      "Extrayendo características PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6260 [00:00<?, ?it/s]<ipython-input-4-d7304824e483>:638: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  band_power = np.trapz(psd[band_mask], freqs[band_mask])\n",
      "100%|██████████| 6260/6260 [00:03<00:00, 1600.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FOLD 1/5 ===\n",
      "Entrenando Stage 1...\n",
      "Error en el fold 1: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size\n",
      "\n",
      "=== FOLD 2/5 ===\n",
      "Entrenando Stage 1...\n",
      "Error en el fold 2: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size\n",
      "\n",
      "=== FOLD 3/5 ===\n",
      "Entrenando Stage 1...\n",
      "Error en el fold 3: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size\n",
      "\n",
      "=== FOLD 4/5 ===\n",
      "Entrenando Stage 1...\n",
      "Error en el fold 4: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size\n",
      "\n",
      "=== FOLD 5/5 ===\n",
      "Entrenando Stage 1...\n",
      "Error en el fold 5: Calculated padded input size per channel: (3). Kernel size: (4). Kernel size can't be greater than actual input size\n",
      "No se completó ningún fold exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Two-Stage Transformer Architecture for Physionet 2099 - 4-class MI\n",
    "# Versión corregida - Dimensiones compatibles\n",
    "\n",
    "import os, re, math, random, json, itertools, copy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# CONFIGURACIÓN GENERAL\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dispositivo y semilla\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Escenario y ventana\n",
    "CLASS_SCENARIO = '4c'\n",
    "WINDOW_MODE = '6s'\n",
    "FS = 160.0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Arquitectura Two-Stage\n",
    "BATCH_SIZE = 16  # Reducido para evitar problemas de memoria\n",
    "EPOCHS_STAGE1 = 50\n",
    "EPOCHS_STAGE2 = 30\n",
    "LR_STAGE1 = 1e-3\n",
    "LR_STAGE2 = 1e-4\n",
    "\n",
    "# Parámetros Transformer\n",
    "N_HEADS = 2\n",
    "D_MODEL = 64  # Dimensión del modelo para atención\n",
    "DROPOUT_ATTN = 0.3\n",
    "TCN_FILTERS = 32\n",
    "TCN_KERNEL_SIZE = 4\n",
    "TCN_N_BLOCKS = 2\n",
    "TIME_SLICES = 3  # Reducido para simplificar\n",
    "\n",
    "# TabNet\n",
    "TABNET_N_D = 16\n",
    "TABNET_N_A = 16\n",
    "TABNET_N_HIDDEN = 64\n",
    "\n",
    "# Data Augmentation\n",
    "N_CLUSTERS = 3\n",
    "AUG_SAMPLES_PER_CLASS = 20  # Reducido para prueba\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES DE CANALES (MANTENIDAS)\n",
    "# =========================\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "# Canales (8 con FCz)\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"Warning: faltan canales {missing} en archivo {getattr(raw,'filenames', [''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "# =========================\n",
    "# LECTURA DE EDF y EVENTOS (MANTENIDAS)\n",
    "# =========================\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "# Runs MI\n",
    "MI_RUNS_LR = [4, 8, 12]\n",
    "MI_RUNS_OF = [6, 10, 14]\n",
    "BASELINE_RUNS_EO = [1]\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    if run_id in BASELINE_RUNS_EO: return 'EO'\n",
    "    return None\n",
    "\n",
    "# Sujetos excluidos\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrado básico\n",
    "    raw.filter(4.0, 40.0, method='iir', verbose=False)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return []\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ', '')\n",
    "    res = []\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'):\n",
    "            res.append((float(onset), tag))\n",
    "    res.sort()\n",
    "    dedup = []\n",
    "    last_t1 = last_t2 = -1e9\n",
    "    for t, tag in res:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# =========================\n",
    "# CONSTRUCCIÓN DE DATASETS (MANTENIDAS)\n",
    "# =========================\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR + MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "def extract_trials_from_run(edf_path: Path, scenario: str, window_mode: str):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF','EO'):\n",
    "        return ([], [])\n",
    "\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        return ([], [])\n",
    "\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    assert abs(fs - FS) < 1e-6\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if kind in ('LR','OF'):\n",
    "        events = collect_events_T1T2(raw)\n",
    "        if window_mode == '3s':\n",
    "            rel_start, rel_end = 0.0, 3.0\n",
    "        else:  # 6s\n",
    "            rel_start, rel_end = -1.0, 5.0\n",
    "\n",
    "        for onset_sec, tag in events:\n",
    "            if kind == 'LR':\n",
    "                if tag == 'T1': label = 'L'\n",
    "                elif tag == 'T2': label = 'R'\n",
    "                else: continue\n",
    "            else:\n",
    "                if tag == 'T1': label = 'BFISTS'\n",
    "                elif tag == 'T2': label = 'BFEET'\n",
    "                else: continue\n",
    "\n",
    "            if scenario == '2c' and label not in ('L','R'): continue\n",
    "            if scenario == '3c' and label not in ('L','R','BFISTS'): continue\n",
    "            if scenario == '4c' and label not in ('L','R','BFISTS','BFEET'): continue\n",
    "\n",
    "            s = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "            e = int(round((raw.first_time + onset_sec + rel_end) * fs))\n",
    "            if s < 0 or e > data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            seg = data[:, s:e].T.astype(np.float32)\n",
    "            # Normalización z-score por canal\n",
    "            seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "\n",
    "            if label == 'L':       y = 0\n",
    "            elif label == 'R':     y = 1\n",
    "            elif label == 'BFISTS':y = 2\n",
    "            elif label == 'BFEET': y = 3\n",
    "            else: continue\n",
    "\n",
    "            out.append((seg, y, subj))\n",
    "\n",
    "    elif kind == 'EO':\n",
    "        return ([], raw.ch_names)\n",
    "\n",
    "    return out, raw.ch_names\n",
    "\n",
    "def build_dataset_all(subjects, scenario='4c', window_mode='3s'):\n",
    "    X, y, groups = [], [], []\n",
    "    ch_template = None\n",
    "\n",
    "    for s in tqdm(subjects, desc=\"Construyendo dataset (RAW)\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "\n",
    "        trials_L, trials_R, trials_FISTS, trials_FEET = [], [], [], []\n",
    "\n",
    "        for r in MI_RUNS_LR:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 0: trials_L.append(seg)\n",
    "                elif lab == 1: trials_R.append(seg)\n",
    "\n",
    "        for r in MI_RUNS_OF:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 2: trials_FISTS.append(seg)\n",
    "                elif lab == 3: trials_FEET.append(seg)\n",
    "\n",
    "        need_per_class = 15  # Reducido para prueba\n",
    "        def pick(trials, n, rng):\n",
    "            if len(trials) < n:\n",
    "                idx = rng.choice(len(trials), size=n, replace=True)\n",
    "                return [trials[i] for i in idx]\n",
    "            rng.shuffle(trials)\n",
    "            return trials[:n]\n",
    "\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        if len(trials_L)==0 or len(trials_R)==0 or len(trials_FISTS)==0 or len(trials_FEET)==0:\n",
    "            continue\n",
    "\n",
    "        Lp  = pick(trials_L,     need_per_class, rng)\n",
    "        Rp  = pick(trials_R,     need_per_class, rng)\n",
    "        FIp = pick(trials_FISTS, need_per_class, rng)\n",
    "        FEp = pick(trials_FEET,  need_per_class, rng)\n",
    "\n",
    "        pack = [(Lp, 0), (Rp, 1), (FIp, 2), (FEp, 3)]\n",
    "        for segs, lab in pack:\n",
    "            for seg in segs:\n",
    "                X.append(seg); y.append(lab); groups.append(s)\n",
    "\n",
    "    if len(X) == 0:\n",
    "        print(\"No se pudieron cargar datos. Verifica las rutas de archivos.\")\n",
    "        return None, None, None, None\n",
    "        \n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    groups = np.asarray(groups, dtype=np.int64)\n",
    "\n",
    "    n, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Dataset construido: N={n} | T={T} | C={C} | clases={n_classes} | sujetos únicos={len(np.unique(groups))}\")\n",
    "    return X, y, groups, ch_template\n",
    "\n",
    "# =========================\n",
    "# ARQUITECTURA TWO-STAGE TRANSFORMER - CORREGIDA\n",
    "# =========================\n",
    "\n",
    "class SimpleEEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGNet simplificado y estable\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, F1=16, D=2, T=960):\n",
    "        super().__init__()\n",
    "        self.F1 = F1\n",
    "        self.F2 = F1 * D\n",
    "        \n",
    "        # Bloque 1: Temporal + Espacial\n",
    "        self.conv1 = nn.Conv2d(1, F1, (64, 1), padding=(32, 0), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # Bloque 2: Depthwise\n",
    "        self.conv2 = nn.Conv2d(F1, self.F2, (1, n_ch), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F2)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool1 = nn.AvgPool2d((8, 1))\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Bloque 3: Separable\n",
    "        self.conv3 = nn.Conv2d(self.F2, self.F2, (16, 1), groups=self.F2, padding=(8, 0), bias=False)\n",
    "        self.conv4 = nn.Conv2d(self.F2, self.F2, (1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool2d((8, 1))\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        # Calcular dimensión de salida\n",
    "        self.output_dim = self._get_output_dim(n_ch, T)\n",
    "        \n",
    "    def _get_output_dim(self, n_ch, T):\n",
    "        # Pasar un tensor dummy para calcular la dimensión de salida\n",
    "        x = torch.randn(1, 1, T, n_ch)\n",
    "        with torch.no_grad():\n",
    "            x = self.forward_features(x)\n",
    "        return x.view(1, -1).size(1)\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        # Bloque 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        # Bloque 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Bloque 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        return x.flatten(1)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Mecanismo de atención multi-cabeza simplificado\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        # Proyecciones lineales\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, d_model = x.shape\n",
    "        \n",
    "        # Proyecciones Q, K, V\n",
    "        Q = self.w_q(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.w_k(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.w_v(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Atención escalada\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Aplicar atención\n",
    "        context = torch.matmul(attn_weights, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, self.d_model)\n",
    "        \n",
    "        # Proyección final\n",
    "        output = self.w_o(context)\n",
    "        return output, attn_weights\n",
    "\n",
    "class TemporalConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bloque convolucional temporal simple\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, \n",
    "                              padding=(kernel_size-1)*dilation//2, \n",
    "                              dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, \n",
    "                              padding=(kernel_size-1)*dilation//2, \n",
    "                              dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = F.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        return F.elu(x + residual)\n",
    "\n",
    "class Stage1Architecture(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura Stage 1 simplificada y estable\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_classes=4, T=960, time_slices=3):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.n_classes = n_classes\n",
    "        self.T = T\n",
    "        self.time_slices = time_slices\n",
    "        \n",
    "        # EEGNet base\n",
    "        self.eegnet = SimpleEEGNet(n_ch=n_ch, T=T)\n",
    "        eegnet_output_dim = self.eegnet.output_dim\n",
    "        \n",
    "        # Proyección para atención\n",
    "        self.projection = nn.Linear(eegnet_output_dim, D_MODEL)\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        self.attention = MultiHeadAttention(d_model=D_MODEL, n_heads=N_HEADS, dropout=DROPOUT_ATTN)\n",
    "        \n",
    "        # Bloques temporales\n",
    "        self.temporal_blocks = nn.ModuleList()\n",
    "        for i in range(TCN_N_BLOCKS):\n",
    "            block = TemporalConvBlock(D_MODEL, D_MODEL, kernel_size=TCN_KERNEL_SIZE, dilation=2**i)\n",
    "            self.temporal_blocks.append(block)\n",
    "        \n",
    "        # Capa de salida\n",
    "        self.output_dim = D_MODEL * time_slices\n",
    "        self.classifier = nn.Linear(self.output_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, _, T, C = x.shape\n",
    "        \n",
    "        # 1. EEGNet features\n",
    "        eeg_features = self.eegnet(x)  # (B, eegnet_output_dim)\n",
    "        \n",
    "        # 2. Proyección para time slicing\n",
    "        projected = self.projection(eeg_features).view(B, -1, D_MODEL)  # (B, seq_len, D_MODEL)\n",
    "        \n",
    "        # 3. Time slicing simple\n",
    "        seq_len = projected.shape[1]\n",
    "        slice_length = max(1, seq_len // self.time_slices)\n",
    "        \n",
    "        slice_embeddings = []\n",
    "        for i in range(self.time_slices):\n",
    "            start_idx = i * slice_length\n",
    "            end_idx = min((i + 1) * slice_length, seq_len)\n",
    "            \n",
    "            if start_idx < seq_len:\n",
    "                slice_data = projected[:, start_idx:end_idx, :]\n",
    "                \n",
    "                # Aplicar atención\n",
    "                attended, _ = self.attention(slice_data)\n",
    "                \n",
    "                # Aplicar bloques temporales\n",
    "                temporal_feat = attended.transpose(1, 2)  # (B, D_MODEL, T_slice)\n",
    "                for block in self.temporal_blocks:\n",
    "                    temporal_feat = block(temporal_feat)\n",
    "                \n",
    "                # Pooling global\n",
    "                slice_embed = temporal_feat.mean(dim=-1)  # (B, D_MODEL)\n",
    "                slice_embeddings.append(slice_embed)\n",
    "        \n",
    "        # Concatenar embeddings\n",
    "        if slice_embeddings:\n",
    "            embeddings = torch.cat(slice_embeddings, dim=1)  # (B, D_MODEL * n_slices)\n",
    "        else:\n",
    "            embeddings = eeg_features  # Fallback\n",
    "        \n",
    "        # Clasificación\n",
    "        logits = self.classifier(embeddings)\n",
    "        \n",
    "        return logits, embeddings\n",
    "\n",
    "class SimpleTabNet(nn.Module):\n",
    "    \"\"\"\n",
    "    TabNet simplificado para Stage 2\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, n_classes=4, n_d=16, n_steps=3):\n",
    "        super().__init__()\n",
    "        self.n_d = n_d\n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        # Batch normalization inicial\n",
    "        self.bn = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        # Transformadores de características\n",
    "        self.feature_transformers = nn.ModuleList()\n",
    "        for i in range(n_steps):\n",
    "            transformer = nn.Sequential(\n",
    "                nn.Linear(input_dim, n_d * 2),\n",
    "                nn.BatchNorm1d(n_d * 2),\n",
    "                nn.GLU(dim=1)\n",
    "            )\n",
    "            self.feature_transformers.append(transformer)\n",
    "        \n",
    "        # Atención por pasos\n",
    "        self.attentive_transformers = nn.ModuleList()\n",
    "        for i in range(n_steps):\n",
    "            attention = nn.Sequential(\n",
    "                nn.Linear(n_d, input_dim),\n",
    "                nn.BatchNorm1d(input_dim)\n",
    "            )\n",
    "            self.attentive_transformers.append(attention)\n",
    "        \n",
    "        # Clasificador final\n",
    "        self.classifier = nn.Linear(n_d * n_steps, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        \n",
    "        decision_outputs = []\n",
    "        total_attention = torch.zeros(x.size(0), x.size(1), device=x.device)\n",
    "        \n",
    "        for step in range(self.n_steps):\n",
    "            # Aplicar máscara de atención\n",
    "            mask = torch.softmax(self.attentive_transformers[step](x), dim=1)\n",
    "            total_attention = total_attention + mask\n",
    "            \n",
    "            # Transformar características\n",
    "            masked_x = x * mask\n",
    "            transformed = self.feature_transformers[step](masked_x)\n",
    "            \n",
    "            decision_outputs.append(transformed)\n",
    "        \n",
    "        # Combinar decisiones\n",
    "        final_decision = torch.cat(decision_outputs, dim=1)\n",
    "        logits = self.classifier(final_decision)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class TwoStageTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura completa de dos etapas - CORREGIDA\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_classes=4, T=960, time_slices=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stage 1\n",
    "        self.stage1 = Stage1Architecture(n_ch, n_classes, T, time_slices)\n",
    "        stage1_output_dim = self.stage1.output_dim\n",
    "        \n",
    "        # Stage 2 - TabNet\n",
    "        # Características PSD: 8 canales * 5 bandas = 40\n",
    "        psd_feature_dim = 40\n",
    "        tabnet_input_dim = stage1_output_dim + psd_feature_dim\n",
    "        \n",
    "        self.stage2 = SimpleTabNet(tabnet_input_dim, n_classes, n_d=TABNET_N_D)\n",
    "        \n",
    "    def forward(self, x, psd_features=None):\n",
    "        # Stage 1\n",
    "        logits_stage1, embeddings_stage1 = self.stage1(x)\n",
    "        \n",
    "        # Si no hay características PSD, retornar solo Stage 1\n",
    "        if psd_features is None:\n",
    "            return logits_stage1, embeddings_stage1\n",
    "        \n",
    "        # Stage 2: Combinar embeddings con características PSD\n",
    "        combined_features = torch.cat([embeddings_stage1, psd_features], dim=1)\n",
    "        logits_stage2 = self.stage2(combined_features)\n",
    "        \n",
    "        return logits_stage1, logits_stage2, embeddings_stage1\n",
    "\n",
    "# =========================\n",
    "# EXTRACCIÓN DE CARACTERÍSTICAS PSD\n",
    "# =========================\n",
    "def extract_psd_features(X, fs=160.0):\n",
    "    \"\"\"\n",
    "    Extraer características de densidad espectral de potencia (PSD)\n",
    "    \"\"\"\n",
    "    print(\"Extrayendo características PSD...\")\n",
    "    \n",
    "    n_trials, T, n_channels = X.shape\n",
    "    n_bands = 5\n",
    "    psd_features = np.zeros((n_trials, n_channels * n_bands))\n",
    "    \n",
    "    # Bandas de frecuencia\n",
    "    freq_bands = [(1, 4), (4, 8), (8, 14), (14, 31), (31, 49)]\n",
    "    \n",
    "    for i in tqdm(range(n_trials)):\n",
    "        trial_psd = []\n",
    "        for ch in range(n_channels):\n",
    "            signal = X[i, :, ch]\n",
    "            \n",
    "            # Calcular PSD usando FFT\n",
    "            fft_vals = np.fft.rfft(signal)\n",
    "            freqs = np.fft.rfftfreq(len(signal), 1/fs)\n",
    "            psd = np.abs(fft_vals) ** 2\n",
    "            \n",
    "            for f_low, f_high in freq_bands:\n",
    "                band_mask = (freqs >= f_low) & (freqs <= f_high)\n",
    "                if np.any(band_mask):\n",
    "                    band_power = np.trapz(psd[band_mask], freqs[band_mask])\n",
    "                else:\n",
    "                    band_power = 0.0\n",
    "                trial_psd.append(band_power)\n",
    "        \n",
    "        psd_features[i] = np.array(trial_psd)\n",
    "    \n",
    "    # Normalizar características PSD\n",
    "    psd_features = (psd_features - psd_features.mean(axis=0)) / (psd_features.std(axis=0) + 1e-8)\n",
    "    \n",
    "    return psd_features.astype(np.float32)\n",
    "\n",
    "# =========================\n",
    "# DATA AUGMENTATION SIMPLIFICADA\n",
    "# =========================\n",
    "def simple_augmentation(X, y, groups, n_augmented_per_class=20):\n",
    "    \"\"\"\n",
    "    Aumento de datos simplificado para prueba\n",
    "    \"\"\"\n",
    "    print(\"Aplicando aumento de datos simplificado...\")\n",
    "    \n",
    "    X_aug, y_aug, groups_aug = [], [], []\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    for class_idx in range(n_classes):\n",
    "        class_mask = (y == class_idx)\n",
    "        X_class = X[class_mask]\n",
    "        groups_class = groups[class_mask]\n",
    "        \n",
    "        if len(X_class) == 0:\n",
    "            continue\n",
    "            \n",
    "        n_generated = 0\n",
    "        while n_generated < n_augmented_per_class:\n",
    "            # Seleccionar trial aleatorio\n",
    "            idx = np.random.randint(len(X_class))\n",
    "            original_trial = X_class[idx]\n",
    "            \n",
    "            # Aplicar transformaciones simples\n",
    "            # 1. Ruido gaussiano\n",
    "            noise = np.random.normal(0, 0.01, original_trial.shape)\n",
    "            augmented_trial = original_trial + noise\n",
    "            \n",
    "            X_aug.append(augmented_trial)\n",
    "            y_aug.append(class_idx)\n",
    "            groups_aug.append(groups_class[idx])\n",
    "            n_generated += 1\n",
    "    \n",
    "    if X_aug:\n",
    "        X_aug = np.stack(X_aug, axis=0)\n",
    "        y_aug = np.array(y_aug, dtype=np.int64)\n",
    "        groups_aug = np.array(groups_aug, dtype=np.int64)\n",
    "        \n",
    "        # Combinar con datos originales\n",
    "        X_combined = np.concatenate([X, X_aug], axis=0)\n",
    "        y_combined = np.concatenate([y, y_aug], axis=0)\n",
    "        groups_combined = np.concatenate([groups, groups_aug], axis=0)\n",
    "        \n",
    "        print(f\"Aumento completado: {len(X_aug)} muestras añadidas\")\n",
    "        return X_combined, y_combined, groups_combined\n",
    "    \n",
    "    return X, y, groups\n",
    "\n",
    "# =========================\n",
    "# DATASET Y ENTRENAMIENTO\n",
    "# =========================\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y, groups, psd_features=None):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "        self.psd_features = psd_features.astype(np.float32) if psd_features is not None else None\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        x = np.expand_dims(x, 0)  # (1, T, C)\n",
    "        \n",
    "        if self.psd_features is not None:\n",
    "            return (torch.from_numpy(x), \n",
    "                    torch.from_numpy(self.psd_features[idx]), \n",
    "                    torch.tensor(self.y[idx]), \n",
    "                    torch.tensor(self.g[idx]))\n",
    "        else:\n",
    "            return (torch.from_numpy(x), \n",
    "                    torch.tensor(self.y[idx]), \n",
    "                    torch.tensor(self.g[idx]))\n",
    "\n",
    "def train_stage1(model, train_loader, val_loader, epochs=50, lr=1e-3):\n",
    "    \"\"\"Entrenamiento de la Etapa 1\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            if len(batch) == 4:  # Con PSD features\n",
    "                x, _, y, _ = batch\n",
    "            else:  # Sin PSD features\n",
    "                x, y, _ = batch\n",
    "                \n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validación\n",
    "        val_acc = evaluate_stage1(model, val_loader)\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_stage1.pth')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: Train Loss = {train_loss/len(train_loader):.4f}, Val Acc = {val_acc:.4f}')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "def train_stage2(model, train_loader, val_loader, epochs=30, lr=1e-4):\n",
    "    \"\"\"Entrenamiento de la Etapa 2 (TabNet)\"\"\"\n",
    "    optimizer = optim.Adam(model.stage2.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            x, psd, y, _ = batch\n",
    "            x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            _, logits_stage2, _ = model(x, psd)\n",
    "            loss = criterion(logits_stage2, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validación\n",
    "        val_acc = evaluate_stage2(model, val_loader)\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_stage2.pth')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: Train Loss = {train_loss/len(train_loader):.4f}, Val Acc = {val_acc:.4f}')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_stage1(model, loader):\n",
    "    \"\"\"Evaluación de la Etapa 1\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        if len(batch) == 4:  # Con PSD features\n",
    "            x, _, y, _ = batch\n",
    "        else:  # Sin PSD features\n",
    "            x, y, _ = batch\n",
    "            \n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits, _ = model(x)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_stage2(model, loader):\n",
    "    \"\"\"Evaluación de la Etapa 2\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        x, psd, y, _ = batch\n",
    "        x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "        _, logits_stage2, _ = model(x, psd)\n",
    "        pred = logits_stage2.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "# =========================\n",
    "# EXPERIMENTO PRINCIPAL\n",
    "# =========================\n",
    "def run_two_stage_experiment():\n",
    "    print(\"🧠 INICIANDO EXPERIMENTO TWO-STAGE TRANSFORMER ARCHITECTURE\")\n",
    "    print(\"📖 Basado en: 'A two-stage transformer based network for motor imagery classification'\")\n",
    "    \n",
    "    # Cargar datos\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos disponibles: {len(subs)}\")\n",
    "    \n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    \n",
    "    if X is None:\n",
    "        print(\"Error: No se pudieron cargar los datos. Verifica las rutas.\")\n",
    "        return None\n",
    "        \n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    print(f\"Datos cargados: N={N}, T={T}, C={C}, Clases={n_classes}\")\n",
    "    \n",
    "    # Aumento de datos simplificado\n",
    "    X_aug, y_aug, groups_aug = simple_augmentation(\n",
    "        X, y, groups, n_augmented_per_class=AUG_SAMPLES_PER_CLASS\n",
    "    )\n",
    "    \n",
    "    # Extraer características PSD\n",
    "    psd_features = extract_psd_features(X_aug, fs=FS)\n",
    "    \n",
    "    # Crear dataset\n",
    "    dataset = EEGDataset(X_aug, y_aug, groups_aug, psd_features)\n",
    "    \n",
    "    # Evaluación inter-sujeto con GroupKFold\n",
    "    unique_subjects = np.unique(groups_aug)\n",
    "    gkf = GroupKFold(n_splits=min(N_FOLDS, len(unique_subjects)))\n",
    "    \n",
    "    fold_results = {'stage1': [], 'stage2': []}\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X_aug, y_aug, groups_aug)):\n",
    "        print(f\"\\n=== FOLD {fold + 1}/{min(N_FOLDS, len(unique_subjects))} ===\")\n",
    "        \n",
    "        # Split train/val\n",
    "        train_subjects = np.unique(groups_aug[train_idx])\n",
    "        val_size = max(1, int(0.15 * len(train_subjects)))\n",
    "        val_subjects = np.random.choice(train_subjects, val_size, replace=False)\n",
    "        \n",
    "        val_mask = np.isin(groups_aug[train_idx], val_subjects)\n",
    "        val_idx = train_idx[val_mask]\n",
    "        train_idx_fold = train_idx[~val_mask]\n",
    "        \n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(Subset(dataset, train_idx_fold), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(Subset(dataset, test_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        # Modelo\n",
    "        model = TwoStageTransformer(n_ch=C, n_classes=n_classes, T=T, time_slices=TIME_SLICES).to(DEVICE)\n",
    "        \n",
    "        # Entrenamiento Stage 1\n",
    "        print(\"Entrenando Stage 1...\")\n",
    "        try:\n",
    "            history_stage1, best_stage1 = train_stage1(\n",
    "                model, train_loader, val_loader, epochs=EPOCHS_STAGE1, lr=LR_STAGE1\n",
    "            )\n",
    "            \n",
    "            # Evaluación Stage 1 en test\n",
    "            test_acc_stage1 = evaluate_stage1(model, test_loader)\n",
    "            fold_results['stage1'].append(test_acc_stage1)\n",
    "            print(f\"Stage 1 Test Accuracy: {test_acc_stage1:.4f}\")\n",
    "            \n",
    "            # Entrenamiento Stage 2\n",
    "            print(\"Entrenando Stage 2 (TabNet)...\")\n",
    "            history_stage2, best_stage2 = train_stage2(\n",
    "                model, train_loader, val_loader, epochs=EPOCHS_STAGE2, lr=LR_STAGE2\n",
    "            )\n",
    "            \n",
    "            # Evaluación Stage 2 en test\n",
    "            test_acc_stage2 = evaluate_stage2(model, test_loader)\n",
    "            fold_results['stage2'].append(test_acc_stage2)\n",
    "            print(f\"Stage 2 Test Accuracy: {test_acc_stage2:.4f}\")\n",
    "            print(f\"Improvement: +{(test_acc_stage2 - test_acc_stage1)*100:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en el fold {fold + 1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Resultados finales\n",
    "    if fold_results['stage1']:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RESULTADOS FINALES - TWO-STAGE TRANSFORMER ARCHITECTURE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        stage1_mean = np.mean(fold_results['stage1'])\n",
    "        stage1_std = np.std(fold_results['stage1'])\n",
    "        stage2_mean = np.mean(fold_results['stage2'])\n",
    "        stage2_std = np.std(fold_results['stage2'])\n",
    "        \n",
    "        print(f\"Stage 1 (EEGNet+Attention+TCN): {stage1_mean:.4f} ± {stage1_std:.4f}\")\n",
    "        print(f\"Stage 2 (TabNet): {stage2_mean:.4f} ± {stage2_std:.4f}\")\n",
    "        print(f\"Overall Improvement: +{(stage2_mean - stage1_mean)*100:.2f}%\")\n",
    "        \n",
    "        return {\n",
    "            'stage1_results': fold_results['stage1'],\n",
    "            'stage2_results': fold_results['stage2'],\n",
    "            'stage1_mean': stage1_mean,\n",
    "            'stage2_mean': stage2_mean,\n",
    "            'improvement': stage2_mean - stage1_mean\n",
    "        }\n",
    "    else:\n",
    "        print(\"No se completó ningún fold exitosamente.\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# EJECUCIÓN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_two_stage_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd230555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Usando dispositivo: cuda\n",
      "🧠 INICIANDO TWO-STAGE TRANSFORMER - VERSIÓN FINAL\n",
      "Sujetos disponibles: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   1%|          | 1/103 [00:00<00:17,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   2%|▏         | 2/103 [00:00<00:16,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   3%|▎         | 3/103 [00:00<00:18,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   4%|▍         | 4/103 [00:00<00:17,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   5%|▍         | 5/103 [00:00<00:16,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   6%|▌         | 6/103 [00:01<00:17,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   7%|▋         | 7/103 [00:01<00:17,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   8%|▊         | 8/103 [00:01<00:17,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   9%|▊         | 9/103 [00:01<00:18,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  10%|▉         | 10/103 [00:01<00:18,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  11%|█         | 11/103 [00:02<00:18,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  12%|█▏        | 12/103 [00:02<00:17,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  13%|█▎        | 13/103 [00:02<00:17,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  14%|█▎        | 14/103 [00:02<00:17,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  15%|█▍        | 15/103 [00:02<00:17,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  16%|█▌        | 16/103 [00:03<00:17,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  17%|█▋        | 17/103 [00:03<00:17,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  17%|█▋        | 18/103 [00:03<00:17,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  18%|█▊        | 19/103 [00:03<00:16,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  19%|█▉        | 20/103 [00:03<00:16,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  20%|██        | 21/103 [00:04<00:17,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  21%|██▏       | 22/103 [00:04<00:17,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  22%|██▏       | 23/103 [00:04<00:17,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  23%|██▎       | 24/103 [00:04<00:17,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  24%|██▍       | 25/103 [00:04<00:17,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  25%|██▌       | 26/103 [00:05<00:16,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  26%|██▌       | 27/103 [00:05<00:16,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  27%|██▋       | 28/103 [00:05<00:16,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  28%|██▊       | 29/103 [00:05<00:16,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  29%|██▉       | 30/103 [00:06<00:16,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  30%|███       | 31/103 [00:06<00:16,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  31%|███       | 32/103 [00:06<00:16,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  32%|███▏      | 33/103 [00:06<00:15,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  33%|███▎      | 34/103 [00:06<00:15,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  34%|███▍      | 35/103 [00:07<00:16,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  35%|███▍      | 36/103 [00:07<00:16,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  36%|███▌      | 37/103 [00:07<00:17,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  37%|███▋      | 38/103 [00:08<00:16,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  38%|███▊      | 39/103 [00:08<00:15,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  39%|███▉      | 40/103 [00:08<00:14,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  40%|███▉      | 41/103 [00:08<00:14,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  41%|████      | 42/103 [00:08<00:13,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  42%|████▏     | 43/103 [00:09<00:13,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  43%|████▎     | 44/103 [00:09<00:13,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  44%|████▎     | 45/103 [00:09<00:12,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  45%|████▍     | 46/103 [00:09<00:12,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  46%|████▌     | 47/103 [00:10<00:12,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  47%|████▋     | 48/103 [00:10<00:11,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  48%|████▊     | 49/103 [00:10<00:11,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  49%|████▊     | 50/103 [00:10<00:11,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  50%|████▉     | 51/103 [00:10<00:11,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  50%|█████     | 52/103 [00:11<00:11,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  51%|█████▏    | 53/103 [00:11<00:10,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  52%|█████▏    | 54/103 [00:11<00:10,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  53%|█████▎    | 55/103 [00:11<00:10,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  54%|█████▍    | 56/103 [00:11<00:10,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  55%|█████▌    | 57/103 [00:12<00:10,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  56%|█████▋    | 58/103 [00:12<00:09,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  57%|█████▋    | 59/103 [00:12<00:09,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  58%|█████▊    | 60/103 [00:12<00:09,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  59%|█████▉    | 61/103 [00:13<00:09,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  60%|██████    | 62/103 [00:13<00:09,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  61%|██████    | 63/103 [00:13<00:08,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  62%|██████▏   | 64/103 [00:13<00:08,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  63%|██████▎   | 65/103 [00:13<00:08,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  64%|██████▍   | 66/103 [00:14<00:08,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  65%|██████▌   | 67/103 [00:14<00:07,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  66%|██████▌   | 68/103 [00:14<00:07,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  67%|██████▋   | 69/103 [00:14<00:07,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  68%|██████▊   | 70/103 [00:15<00:07,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  69%|██████▉   | 71/103 [00:15<00:07,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  70%|██████▉   | 72/103 [00:15<00:06,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  71%|███████   | 73/103 [00:15<00:06,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  72%|███████▏  | 74/103 [00:15<00:06,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  73%|███████▎  | 75/103 [00:16<00:06,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  74%|███████▍  | 76/103 [00:16<00:05,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  75%|███████▍  | 77/103 [00:16<00:05,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  76%|███████▌  | 78/103 [00:16<00:05,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  77%|███████▋  | 79/103 [00:17<00:05,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  78%|███████▊  | 80/103 [00:17<00:05,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  79%|███████▊  | 81/103 [00:17<00:04,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  80%|███████▉  | 82/103 [00:17<00:05,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  81%|████████  | 83/103 [00:17<00:04,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  82%|████████▏ | 84/103 [00:18<00:04,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  83%|████████▎ | 85/103 [00:18<00:04,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  83%|████████▎ | 86/103 [00:18<00:03,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  84%|████████▍ | 87/103 [00:18<00:03,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  85%|████████▌ | 88/103 [00:19<00:03,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  86%|████████▋ | 89/103 [00:19<00:03,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  87%|████████▋ | 90/103 [00:19<00:03,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  88%|████████▊ | 91/103 [00:19<00:02,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  89%|████████▉ | 92/103 [00:20<00:02,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  90%|█████████ | 93/103 [00:20<00:02,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  91%|█████████▏| 94/103 [00:20<00:02,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  92%|█████████▏| 95/103 [00:20<00:01,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  93%|█████████▎| 96/103 [00:20<00:01,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  94%|█████████▍| 97/103 [00:21<00:01,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  95%|█████████▌| 98/103 [00:21<00:01,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  96%|█████████▌| 99/103 [00:21<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  97%|█████████▋| 100/103 [00:21<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  98%|█████████▊| 101/103 [00:22<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  99%|█████████▉| 102/103 [00:22<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|██████████| 103/103 [00:22<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=6180 | T=960 | C=8 | clases=4 | sujetos únicos=103\n",
      "Datos: N=6180, T=960, C=8, Clases=4\n",
      "Aplicando Channel Cluster Swapping Augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aumento completado: 120 muestras añadidas\n",
      "Extrayendo características PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6300 [00:00<?, ?it/s]<ipython-input-7-5e8bb7b585cb>:406: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  band_power = np.trapz(psd[band_mask], freqs[band_mask])\n",
      "100%|██████████| 6300/6300 [00:03<00:00, 1601.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FOLD 1/5 ===\n",
      "Train: 4286, Val: 730, Test: 1284\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "Entrenando Stage 1...\n",
      "Epoch 0: Loss = 1.4512, Val Acc = 0.2479, LR = 0.001000\n",
      "Epoch 10: Loss = 1.0990, Val Acc = 0.3836, LR = 0.000954\n",
      "Epoch 20: Loss = 0.5335, Val Acc = 0.3781, LR = 0.000839\n",
      "Epoch 30: Loss = 0.2989, Val Acc = 0.3438, LR = 0.000673\n",
      "Epoch 40: Loss = 0.1885, Val Acc = 0.3658, LR = 0.000480\n",
      "Epoch 50: Loss = 0.1234, Val Acc = 0.3644, LR = 0.000291\n",
      "Epoch 60: Loss = 0.1007, Val Acc = 0.3699, LR = 0.000133\n",
      "Epoch 70: Loss = 0.0667, Val Acc = 0.3685, LR = 0.000031\n",
      "✅ Stage 1 Test Acc: 0.3621\n",
      "Entrenando Stage 2...\n",
      "❌ Error en fold 1: The size of tensor a (32) must match the size of tensor b (296) at non-singleton dimension 1\n",
      "\n",
      "=== FOLD 2/5 ===\n",
      "Train: 4282, Val: 734, Test: 1284\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "Entrenando Stage 1...\n",
      "Epoch 0: Loss = 1.4432, Val Acc = 0.2548, LR = 0.001000\n",
      "Epoch 10: Loss = 1.0591, Val Acc = 0.3120, LR = 0.000954\n",
      "Epoch 20: Loss = 0.5662, Val Acc = 0.2820, LR = 0.000839\n",
      "Epoch 30: Loss = 0.2858, Val Acc = 0.2820, LR = 0.000673\n",
      "Epoch 40: Loss = 0.1863, Val Acc = 0.2916, LR = 0.000480\n",
      "Epoch 50: Loss = 0.1327, Val Acc = 0.3025, LR = 0.000291\n",
      "Epoch 60: Loss = 0.1074, Val Acc = 0.2861, LR = 0.000133\n",
      "Epoch 70: Loss = 0.0953, Val Acc = 0.2943, LR = 0.000031\n",
      "✅ Stage 1 Test Acc: 0.3287\n",
      "Entrenando Stage 2...\n",
      "❌ Error en fold 2: The size of tensor a (32) must match the size of tensor b (296) at non-singleton dimension 1\n",
      "\n",
      "=== FOLD 3/5 ===\n",
      "Train: 4280, Val: 736, Test: 1284\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "Entrenando Stage 1...\n",
      "Epoch 0: Loss = 1.4452, Val Acc = 0.2147, LR = 0.001000\n",
      "Epoch 10: Loss = 1.0659, Val Acc = 0.3179, LR = 0.000954\n",
      "Epoch 20: Loss = 0.4923, Val Acc = 0.3152, LR = 0.000839\n",
      "Epoch 30: Loss = 0.2855, Val Acc = 0.3071, LR = 0.000673\n",
      "Epoch 40: Loss = 0.1716, Val Acc = 0.3193, LR = 0.000480\n",
      "Epoch 50: Loss = 0.1242, Val Acc = 0.3288, LR = 0.000291\n",
      "Epoch 60: Loss = 0.0826, Val Acc = 0.3274, LR = 0.000133\n",
      "Epoch 70: Loss = 0.0993, Val Acc = 0.3234, LR = 0.000031\n",
      "✅ Stage 1 Test Acc: 0.3349\n",
      "Entrenando Stage 2...\n",
      "❌ Error en fold 3: The size of tensor a (32) must match the size of tensor b (296) at non-singleton dimension 1\n",
      "\n",
      "=== FOLD 4/5 ===\n",
      "Train: 4342, Val: 734, Test: 1224\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "Entrenando Stage 1...\n",
      "Epoch 0: Loss = 1.4403, Val Acc = 0.2316, LR = 0.001000\n",
      "Epoch 10: Loss = 1.0800, Val Acc = 0.3433, LR = 0.000954\n",
      "Epoch 20: Loss = 0.5198, Val Acc = 0.3011, LR = 0.000839\n",
      "Epoch 30: Loss = 0.2898, Val Acc = 0.3093, LR = 0.000673\n",
      "Epoch 40: Loss = 0.1803, Val Acc = 0.3147, LR = 0.000480\n",
      "Epoch 50: Loss = 0.1229, Val Acc = 0.2875, LR = 0.000291\n",
      "Epoch 60: Loss = 0.0872, Val Acc = 0.2997, LR = 0.000133\n",
      "Epoch 70: Loss = 0.0607, Val Acc = 0.3065, LR = 0.000031\n",
      "✅ Stage 1 Test Acc: 0.3317\n",
      "Entrenando Stage 2...\n",
      "❌ Error en fold 4: The size of tensor a (32) must match the size of tensor b (296) at non-singleton dimension 1\n",
      "\n",
      "=== FOLD 5/5 ===\n",
      "Train: 4339, Val: 737, Test: 1224\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "Entrenando Stage 1...\n",
      "Epoch 0: Loss = 1.4557, Val Acc = 0.2524, LR = 0.001000\n",
      "Epoch 10: Loss = 1.1003, Val Acc = 0.3460, LR = 0.000954\n",
      "Epoch 20: Loss = 0.5705, Val Acc = 0.3256, LR = 0.000839\n",
      "Epoch 30: Loss = 0.2942, Val Acc = 0.3460, LR = 0.000673\n",
      "Epoch 40: Loss = 0.1969, Val Acc = 0.3419, LR = 0.000480\n",
      "Epoch 50: Loss = 0.1412, Val Acc = 0.3596, LR = 0.000291\n",
      "Epoch 60: Loss = 0.1015, Val Acc = 0.3324, LR = 0.000133\n",
      "Epoch 70: Loss = 0.0717, Val Acc = 0.3446, LR = 0.000031\n",
      "✅ Stage 1 Test Acc: 0.3529\n",
      "Entrenando Stage 2...\n",
      "❌ Error en fold 5: The size of tensor a (32) must match the size of tensor b (296) at non-singleton dimension 1\n",
      "\n",
      "============================================================\n",
      "🎯 RESULTADOS FINALES\n",
      "============================================================\n",
      "Stage 1: 0.3421 ± 0.0131\n",
      "Stage 2: nan ± nan\n",
      "Mejora: +nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:218: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Two-Stage Transformer Architecture for Physionet 2099 - 4-class MI\n",
    "# Versión FINAL - Dimensiones corregidas\n",
    "\n",
    "import os, re, math, random, json, itertools, copy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# CONFIGURACIÓN GENERAL\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dispositivo y semilla\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Escenario y ventana\n",
    "CLASS_SCENARIO = '4c'\n",
    "WINDOW_MODE = '6s'\n",
    "FS = 160.0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Arquitectura Two-Stage\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_STAGE1 = 80\n",
    "EPOCHS_STAGE2 = 40\n",
    "LR_STAGE1 = 1e-3\n",
    "LR_STAGE2 = 5e-4\n",
    "\n",
    "# Parámetros Transformer\n",
    "N_HEADS = 4\n",
    "D_MODEL = 64\n",
    "DROPOUT_ATTN = 0.2\n",
    "TCN_FILTERS = 64\n",
    "TCN_KERNEL_SIZE = 3  # Reducido\n",
    "TCN_N_BLOCKS = 2\n",
    "TIME_SLICES = 4\n",
    "\n",
    "# TabNet\n",
    "TABNET_N_D = 32\n",
    "TABNET_N_A = 32\n",
    "TABNET_N_HIDDEN = 128\n",
    "\n",
    "# Data Augmentation\n",
    "N_CLUSTERS = 3\n",
    "AUG_SAMPLES_PER_CLASS = 30\n",
    "\n",
    "# =========================\n",
    "# ARQUITECTURA CORREGIDA - DIMENSIONES COMPATIBLES\n",
    "# =========================\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RobustEEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGNet robusto con dimensiones compatibles\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, F1=32, D=2, T=960):\n",
    "        super().__init__()\n",
    "        self.F1 = F1\n",
    "        self.F2 = F1 * D\n",
    "        \n",
    "        # Bloque 1: Temporal - kernel más pequeño\n",
    "        self.conv1 = nn.Conv2d(1, F1, (32, 1), padding=(16, 0), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # Bloque 2: Depthwise\n",
    "        self.conv2 = nn.Conv2d(F1, self.F2, (1, n_ch), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F2)\n",
    "        \n",
    "        # Pooling más conservador\n",
    "        self.pool1 = nn.AvgPool2d((4, 1))  # Reducido\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Bloque 3: Separable con kernel más pequeño\n",
    "        self.conv3 = nn.Conv2d(self.F2, self.F2, (8, 1), groups=self.F2, padding=(4, 0), bias=False)\n",
    "        self.conv4 = nn.Conv2d(self.F2, self.F2, (1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool2d((4, 1))  # Reducido\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        # Calcular dimensión de salida\n",
    "        self.output_dim = self._get_output_dim(n_ch, T)\n",
    "        \n",
    "    def _get_output_dim(self, n_ch, T):\n",
    "        # Calcular dimensión de salida\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 1, T, n_ch)\n",
    "            x = F.elu(self.bn1(self.conv1(x)))\n",
    "            x = F.elu(self.bn2(self.conv2(x)))\n",
    "            x = self.pool1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.elu(self.bn3(self.conv4(self.conv3(x))))\n",
    "            x = self.pool2(x)\n",
    "            x = self.dropout2(x)\n",
    "            return x.view(1, -1).size(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Bloque 1\n",
    "        x = F.elu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Bloque 2\n",
    "        x = F.elu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Bloque 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.elu(self.bn3(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        return x.flatten(1)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Atención multi-cabeza con dimensiones robustas\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, d_model = x.shape\n",
    "        \n",
    "        # Proyecciones Q, K, V\n",
    "        Q = self.w_q(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.w_k(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.w_v(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Atención escalada\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Aplicar atención\n",
    "        context = torch.matmul(attn_weights, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, self.d_model)\n",
    "        \n",
    "        return self.w_o(context), attn_weights\n",
    "\n",
    "class AdaptiveTemporalBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bloque temporal adaptativo que se ajusta al tamaño de entrada\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Usar kernel size 1 si la entrada es muy pequeña\n",
    "        effective_ks = kernel_size if kernel_size > 1 else 1\n",
    "        padding = (effective_ks - 1) // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, effective_ks, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, effective_ks, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        self.activation = nn.ELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        \n",
    "        x = self.activation(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        \n",
    "        return self.activation(x + residual)\n",
    "\n",
    "class Stage1Architecture(nn.Module):\n",
    "    \"\"\"\n",
    "    Stage 1 con manejo robusto de dimensiones\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_classes=4, T=960, time_slices=4):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.n_classes = n_classes\n",
    "        self.time_slices = time_slices\n",
    "        \n",
    "        # EEGNet base\n",
    "        self.eegnet = RobustEEGNet(n_ch=n_ch, T=T)\n",
    "        eegnet_output_dim = self.eegnet.output_dim\n",
    "        \n",
    "        print(f\"EEGNet output dimension: {eegnet_output_dim}\")\n",
    "        \n",
    "        # Proyección para atención\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(eegnet_output_dim, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, D_MODEL * time_slices)\n",
    "        )\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        self.attention = MultiHeadAttention(d_model=D_MODEL, n_heads=N_HEADS, dropout=DROPOUT_ATTN)\n",
    "        \n",
    "        # Bloques temporales adaptativos\n",
    "        self.temporal_blocks = nn.ModuleList()\n",
    "        for i in range(TCN_N_BLOCKS):\n",
    "            block = AdaptiveTemporalBlock(D_MODEL, TCN_FILTERS, kernel_size=TCN_KERNEL_SIZE)\n",
    "            self.temporal_blocks.append(block)\n",
    "        \n",
    "        # Capa de salida\n",
    "        self.output_dim = TCN_FILTERS * time_slices\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.output_dim, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, _, T, C = x.shape\n",
    "        \n",
    "        # 1. EEGNet features\n",
    "        eeg_features = self.eegnet(x)  # (B, eegnet_output_dim)\n",
    "        \n",
    "        # 2. Proyección y reshaping para time slicing\n",
    "        projected = self.projection(eeg_features)  # (B, D_MODEL * time_slices)\n",
    "        projected = projected.view(B, self.time_slices, D_MODEL)  # (B, time_slices, D_MODEL)\n",
    "        \n",
    "        # 3. Aplicar atención a cada \"slice temporal\"\n",
    "        attended, _ = self.attention(projected)  # (B, time_slices, D_MODEL)\n",
    "        \n",
    "        # 4. Procesar con bloques temporales\n",
    "        temporal_feat = attended.transpose(1, 2)  # (B, D_MODEL, time_slices)\n",
    "        \n",
    "        for block in self.temporal_blocks:\n",
    "            temporal_feat = block(temporal_feat)\n",
    "        \n",
    "        # 5. Flatten y clasificar\n",
    "        embeddings = temporal_feat.flatten(1)  # (B, TCN_FILTERS * time_slices)\n",
    "        logits = self.classifier(embeddings)\n",
    "        \n",
    "        return logits, embeddings\n",
    "\n",
    "class TabNetClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    TabNet simplificado pero efectivo\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, n_classes=4, n_d=32, n_steps=4):\n",
    "        super().__init__()\n",
    "        self.n_d = n_d\n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        # Capa inicial\n",
    "        self.initial_bn = nn.BatchNorm1d(input_dim)\n",
    "        self.initial_fc = nn.Linear(input_dim, n_d * 2)\n",
    "        self.initial_glu = nn.GLU(dim=1)\n",
    "        \n",
    "        # Bloques de decisión\n",
    "        self.decision_blocks = nn.ModuleList()\n",
    "        for i in range(n_steps):\n",
    "            block = nn.Sequential(\n",
    "                nn.Linear(n_d, n_d * 2),\n",
    "                nn.BatchNorm1d(n_d * 2),\n",
    "                nn.GLU(dim=1),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "            self.decision_blocks.append(block)\n",
    "        \n",
    "        # Capa de atención (simplificada)\n",
    "        self.attention_layers = nn.ModuleList()\n",
    "        for i in range(n_steps):\n",
    "            attention = nn.Sequential(\n",
    "                nn.Linear(n_d, input_dim),\n",
    "                nn.BatchNorm1d(input_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "            self.attention_layers.append(attention)\n",
    "        \n",
    "        # Clasificador final\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_d * n_steps, TABNET_N_HIDDEN),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(TABNET_N_HIDDEN, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.initial_glu(self.initial_fc(x))\n",
    "        \n",
    "        decision_outputs = []\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            # Aplicar atención\n",
    "            attention_weights = self.attention_layers[i](x)\n",
    "            attended_x = x * attention_weights\n",
    "            \n",
    "            # Transformar características\n",
    "            transformed = self.decision_blocks[i](attended_x)\n",
    "            decision_outputs.append(transformed)\n",
    "            \n",
    "            # Actualizar x para siguiente paso\n",
    "            x = x + transformed  # Conexión residual\n",
    "        \n",
    "        # Combinar todas las decisiones\n",
    "        final_features = torch.cat(decision_outputs, dim=1)\n",
    "        return self.classifier(final_features)\n",
    "\n",
    "class TwoStageTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura final de dos etapas\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_classes=4, T=960, time_slices=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stage 1\n",
    "        self.stage1 = Stage1Architecture(n_ch, n_classes, T, time_slices)\n",
    "        stage1_output_dim = self.stage1.output_dim\n",
    "        \n",
    "        # Stage 2 - TabNet\n",
    "        psd_feature_dim = 40  # 8 canales * 5 bandas\n",
    "        tabnet_input_dim = stage1_output_dim + psd_feature_dim\n",
    "        \n",
    "        self.stage2 = TabNetClassifier(tabnet_input_dim, n_classes, TABNET_N_D)\n",
    "        \n",
    "        print(f\"Stage 1 output dim: {stage1_output_dim}\")\n",
    "        print(f\"TabNet input dim: {tabnet_input_dim}\")\n",
    "        \n",
    "    def forward(self, x, psd_features=None):\n",
    "        # Stage 1\n",
    "        logits_stage1, embeddings_stage1 = self.stage1(x)\n",
    "        \n",
    "        if psd_features is None:\n",
    "            return logits_stage1, embeddings_stage1\n",
    "        \n",
    "        # Stage 2\n",
    "        combined_features = torch.cat([embeddings_stage1, psd_features], dim=1)\n",
    "        logits_stage2 = self.stage2(combined_features)\n",
    "        \n",
    "        return logits_stage1, logits_stage2, embeddings_stage1\n",
    "\n",
    "# =========================\n",
    "# MANTENER EL RESTO DEL CÓDIGO IGUAL PERO ACTUALIZAR FUNCIONES DE ENTRENAMIENTO\n",
    "# =========================\n",
    "\n",
    "# [MANTENER TODAS LAS FUNCIONES DE UTILIDAD, DATASET, Y PREPROCESAMIENTO DEL CÓDIGO ANTERIOR]\n",
    "\n",
    "def extract_psd_features(X, fs=160.0):\n",
    "    \"\"\"\n",
    "    Extraer características PSD corregida\n",
    "    \"\"\"\n",
    "    print(\"Extrayendo características PSD...\")\n",
    "    \n",
    "    n_trials, T, n_channels = X.shape\n",
    "    n_bands = 5\n",
    "    psd_features = np.zeros((n_trials, n_channels * n_bands))\n",
    "    \n",
    "    freq_bands = [(1, 4), (4, 8), (8, 14), (14, 31), (31, 49)]\n",
    "    \n",
    "    for i in tqdm(range(n_trials)):\n",
    "        trial_psd = []\n",
    "        for ch in range(n_channels):\n",
    "            signal = X[i, :, ch]\n",
    "            \n",
    "            # Calcular PSD usando FFT\n",
    "            fft_vals = np.fft.rfft(signal)\n",
    "            freqs = np.fft.rfftfreq(len(signal), 1/fs)\n",
    "            psd = np.abs(fft_vals) ** 2\n",
    "            \n",
    "            for f_low, f_high in freq_bands:\n",
    "                band_mask = (freqs >= f_low) & (freqs <= f_high)\n",
    "                if np.any(band_mask):\n",
    "                    band_power = np.trapz(psd[band_mask], freqs[band_mask])\n",
    "                else:\n",
    "                    band_power = 0.0\n",
    "                trial_psd.append(band_power)\n",
    "        \n",
    "        psd_features[i] = np.array(trial_psd)\n",
    "    \n",
    "    # Normalizar\n",
    "    psd_features = (psd_features - psd_features.mean(axis=0)) / (psd_features.std(axis=0) + 1e-8)\n",
    "    \n",
    "    return psd_features.astype(np.float32)\n",
    "\n",
    "def channel_cluster_swapping_augmentation(X, y, groups, n_clusters=3, n_augmented_per_class=30):\n",
    "    \"\"\"\n",
    "    Data augmentation del paper original\n",
    "    \"\"\"\n",
    "    print(\"Aplicando Channel Cluster Swapping Augmentation...\")\n",
    "    \n",
    "    X_aug, y_aug, groups_aug = [], [], []\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    for class_idx in range(n_classes):\n",
    "        class_mask = (y == class_idx)\n",
    "        X_class = X[class_mask]\n",
    "        groups_class = groups[class_mask]\n",
    "        \n",
    "        if len(X_class) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calcular matriz de correlación\n",
    "        corr_matrix = np.zeros((X_class.shape[2], X_class.shape[2]))\n",
    "        for i in range(len(X_class)):\n",
    "            trial_corr = np.corrcoef(X_class[i].T)\n",
    "            corr_matrix += np.nan_to_num(trial_corr)\n",
    "        corr_matrix /= len(X_class)\n",
    "        \n",
    "        # K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=10)\n",
    "        channel_labels = kmeans.fit_predict(corr_matrix)\n",
    "        \n",
    "        # Generar muestras aumentadas\n",
    "        n_generated = 0\n",
    "        while n_generated < n_augmented_per_class:\n",
    "            idx1, idx2 = np.random.choice(len(X_class), 2, replace=False)\n",
    "            \n",
    "            new_trial = X_class[idx1].copy()\n",
    "            for cluster_id in range(n_clusters):\n",
    "                cluster_channels = np.where(channel_labels == cluster_id)[0]\n",
    "                if len(cluster_channels) > 0:\n",
    "                    swap_channel = np.random.choice(cluster_channels)\n",
    "                    new_trial[:, swap_channel] = X_class[idx2][:, swap_channel]\n",
    "            \n",
    "            X_aug.append(new_trial)\n",
    "            y_aug.append(class_idx)\n",
    "            groups_aug.append(groups_class[idx1])\n",
    "            n_generated += 1\n",
    "    \n",
    "    if X_aug:\n",
    "        X_aug = np.stack(X_aug, axis=0)\n",
    "        y_aug = np.array(y_aug, dtype=np.int64)\n",
    "        groups_aug = np.array(groups_aug, dtype=np.int64)\n",
    "        \n",
    "        X_combined = np.concatenate([X, X_aug], axis=0)\n",
    "        y_combined = np.concatenate([y, y_aug], axis=0)\n",
    "        groups_combined = np.concatenate([groups, groups_aug], axis=0)\n",
    "        \n",
    "        print(f\"Aumento completado: {len(X_aug)} muestras añadidas\")\n",
    "        return X_combined, y_combined, groups_combined\n",
    "    \n",
    "    return X, y, groups\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y, groups, psd_features=None):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "        self.psd_features = psd_features.astype(np.float32) if psd_features is not None else None\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        x = np.expand_dims(x, 0)  # (1, T, C)\n",
    "        \n",
    "        if self.psd_features is not None:\n",
    "            return (torch.from_numpy(x), \n",
    "                    torch.from_numpy(self.psd_features[idx]), \n",
    "                    torch.tensor(self.y[idx]), \n",
    "                    torch.tensor(self.g[idx]))\n",
    "        else:\n",
    "            return (torch.from_numpy(x), \n",
    "                    torch.tensor(self.y[idx]), \n",
    "                    torch.tensor(self.g[idx]))\n",
    "\n",
    "def train_stage1(model, train_loader, val_loader, epochs=80, lr=1e-3):\n",
    "    \"\"\"Entrenamiento Stage 1 mejorado\"\"\"\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            if len(batch) == 4:\n",
    "                x, _, y, _ = batch\n",
    "            else:\n",
    "                x, y, _ = batch\n",
    "                \n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validación\n",
    "        val_acc = evaluate_stage1(model, val_loader)\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_stage1.pth')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f'Epoch {epoch}: Loss = {train_loss/len(train_loader):.4f}, Val Acc = {val_acc:.4f}, LR = {current_lr:.6f}')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "def train_stage2(model, train_loader, val_loader, epochs=40, lr=5e-4):\n",
    "    \"\"\"Entrenamiento Stage 2 mejorado\"\"\"\n",
    "    optimizer = optim.AdamW(model.stage2.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            x, psd, y, _ = batch\n",
    "            x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            _, logits_stage2, _ = model(x, psd)\n",
    "            loss = criterion(logits_stage2, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validación\n",
    "        val_acc = evaluate_stage2(model, val_loader)\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_stage2.pth')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {train_loss/len(train_loader):.4f}, Val Acc = {val_acc:.4f}')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_stage1(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        if len(batch) == 4:\n",
    "            x, _, y, _ = batch\n",
    "        else:\n",
    "            x, y, _ = batch\n",
    "            \n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits, _ = model(x)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_stage2(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        x, psd, y, _ = batch\n",
    "        x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "        _, logits_stage2, _ = model(x, psd)\n",
    "        pred = logits_stage2.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "# =========================\n",
    "# EXPERIMENTO PRINCIPAL MEJORADO\n",
    "# =========================\n",
    "def run_two_stage_experiment():\n",
    "    print(\"🧠 INICIANDO TWO-STAGE TRANSFORMER - VERSIÓN FINAL\")\n",
    "    \n",
    "    # Cargar datos (usar tus funciones existentes)\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos disponibles: {len(subs)}\")\n",
    "    \n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    \n",
    "    if X is None:\n",
    "        print(\"Error: No se pudieron cargar los datos.\")\n",
    "        return None\n",
    "        \n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    print(f\"Datos: N={N}, T={T}, C={C}, Clases={n_classes}\")\n",
    "    \n",
    "    # Data augmentation\n",
    "    X_aug, y_aug, groups_aug = channel_cluster_swapping_augmentation(\n",
    "        X, y, groups, n_clusters=N_CLUSTERS, n_augmented_per_class=AUG_SAMPLES_PER_CLASS\n",
    "    )\n",
    "    \n",
    "    # Extraer PSD\n",
    "    psd_features = extract_psd_features(X_aug, fs=FS)\n",
    "    \n",
    "    # Dataset\n",
    "    dataset = EEGDataset(X_aug, y_aug, groups_aug, psd_features)\n",
    "    \n",
    "    # Cross-validation\n",
    "    unique_subjects = np.unique(groups_aug)\n",
    "    gkf = GroupKFold(n_splits=min(N_FOLDS, len(unique_subjects)))\n",
    "    \n",
    "    fold_results = {'stage1': [], 'stage2': []}\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X_aug, y_aug, groups_aug)):\n",
    "        print(f\"\\n=== FOLD {fold + 1}/{min(N_FOLDS, len(unique_subjects))} ===\")\n",
    "        \n",
    "        # Split train/val\n",
    "        train_subjects = np.unique(groups_aug[train_idx])\n",
    "        val_size = max(1, int(0.15 * len(train_subjects)))\n",
    "        val_subjects = np.random.choice(train_subjects, val_size, replace=False)\n",
    "        \n",
    "        val_mask = np.isin(groups_aug[train_idx], val_subjects)\n",
    "        val_idx = train_idx[val_mask]\n",
    "        train_idx_fold = train_idx[~val_mask]\n",
    "        \n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(Subset(dataset, train_idx_fold), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(Subset(dataset, test_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        print(f\"Train: {len(train_idx_fold)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "        \n",
    "        # Modelo\n",
    "        model = TwoStageTransformer(n_ch=C, n_classes=n_classes, T=T, time_slices=TIME_SLICES).to(DEVICE)\n",
    "        \n",
    "        try:\n",
    "            # Stage 1\n",
    "            print(\"Entrenando Stage 1...\")\n",
    "            history_stage1, best_stage1 = train_stage1(\n",
    "                model, train_loader, val_loader, EPOCHS_STAGE1, LR_STAGE1\n",
    "            )\n",
    "            \n",
    "            test_acc_stage1 = evaluate_stage1(model, test_loader)\n",
    "            fold_results['stage1'].append(test_acc_stage1)\n",
    "            print(f\"✅ Stage 1 Test Acc: {test_acc_stage1:.4f}\")\n",
    "            \n",
    "            # Stage 2\n",
    "            print(\"Entrenando Stage 2...\")\n",
    "            history_stage2, best_stage2 = train_stage2(\n",
    "                model, train_loader, val_loader, EPOCHS_STAGE2, LR_STAGE2\n",
    "            )\n",
    "            \n",
    "            test_acc_stage2 = evaluate_stage2(model, test_loader)\n",
    "            fold_results['stage2'].append(test_acc_stage2)\n",
    "            print(f\"✅ Stage 2 Test Acc: {test_acc_stage2:.4f}\")\n",
    "            print(f\"📈 Improvement: +{(test_acc_stage2 - test_acc_stage1)*100:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error en fold {fold + 1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Resultados\n",
    "    if fold_results['stage1']:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🎯 RESULTADOS FINALES\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        stage1_mean = np.mean(fold_results['stage1'])\n",
    "        stage1_std = np.std(fold_results['stage1'])\n",
    "        stage2_mean = np.mean(fold_results['stage2'])\n",
    "        stage2_std = np.std(fold_results['stage2'])\n",
    "        \n",
    "        print(f\"Stage 1: {stage1_mean:.4f} ± {stage1_std:.4f}\")\n",
    "        print(f\"Stage 2: {stage2_mean:.4f} ± {stage2_std:.4f}\")\n",
    "        print(f\"Mejora: +{(stage2_mean - stage1_mean)*100:.2f}%\")\n",
    "        \n",
    "        return {\n",
    "            'stage1_results': fold_results['stage1'],\n",
    "            'stage2_results': fold_results['stage2'],\n",
    "            'stage1_mean': stage1_mean,\n",
    "            'stage2_mean': stage2_mean,\n",
    "            'improvement': stage2_mean - stage1_mean\n",
    "        }\n",
    "    else:\n",
    "        print(\"No se completaron folds exitosamente.\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_two_stage_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcadafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Usando dispositivo: cuda\n",
      "🧠 TWO-STAGE TRANSFORMER - VERSIÓN COMPLETA AUTO-CONTENIDA\n",
      "Sujetos disponibles: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   1%|          | 1/103 [00:00<00:20,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   2%|▏         | 2/103 [00:00<00:20,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   3%|▎         | 3/103 [00:00<00:20,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   4%|▍         | 4/103 [00:00<00:19,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   5%|▍         | 5/103 [00:01<00:19,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   6%|▌         | 6/103 [00:01<00:19,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   7%|▋         | 7/103 [00:01<00:19,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   8%|▊         | 8/103 [00:01<00:19,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   9%|▊         | 9/103 [00:01<00:19,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  10%|▉         | 10/103 [00:02<00:18,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  11%|█         | 11/103 [00:02<00:18,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  12%|█▏        | 12/103 [00:02<00:18,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  13%|█▎        | 13/103 [00:02<00:18,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  14%|█▎        | 14/103 [00:02<00:18,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  15%|█▍        | 15/103 [00:03<00:18,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  16%|█▌        | 16/103 [00:03<00:17,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  17%|█▋        | 17/103 [00:03<00:17,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  17%|█▋        | 18/103 [00:03<00:17,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  18%|█▊        | 19/103 [00:03<00:17,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  19%|█▉        | 20/103 [00:04<00:16,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  20%|██        | 21/103 [00:04<00:16,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  21%|██▏       | 22/103 [00:04<00:16,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  22%|██▏       | 23/103 [00:04<00:16,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  23%|██▎       | 24/103 [00:04<00:16,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  24%|██▍       | 25/103 [00:05<00:15,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  25%|██▌       | 26/103 [00:05<00:15,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  26%|██▌       | 27/103 [00:05<00:15,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  27%|██▋       | 28/103 [00:05<00:15,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  28%|██▊       | 29/103 [00:05<00:15,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  29%|██▉       | 30/103 [00:06<00:14,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  30%|███       | 31/103 [00:06<00:14,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  31%|███       | 32/103 [00:06<00:14,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  32%|███▏      | 33/103 [00:06<00:14,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  33%|███▎      | 34/103 [00:06<00:14,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  34%|███▍      | 35/103 [00:07<00:13,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  35%|███▍      | 36/103 [00:07<00:13,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  36%|███▌      | 37/103 [00:07<00:13,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  37%|███▋      | 38/103 [00:07<00:13,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  38%|███▊      | 39/103 [00:07<00:13,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  39%|███▉      | 40/103 [00:08<00:12,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  40%|███▉      | 41/103 [00:08<00:12,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  41%|████      | 42/103 [00:08<00:12,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  42%|████▏     | 43/103 [00:08<00:12,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  43%|████▎     | 44/103 [00:08<00:12,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  44%|████▎     | 45/103 [00:09<00:11,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  45%|████▍     | 46/103 [00:09<00:11,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  46%|████▌     | 47/103 [00:09<00:11,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  47%|████▋     | 48/103 [00:09<00:11,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  48%|████▊     | 49/103 [00:09<00:11,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  49%|████▊     | 50/103 [00:10<00:10,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  50%|████▉     | 51/103 [00:10<00:10,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  50%|█████     | 52/103 [00:10<00:10,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  51%|█████▏    | 53/103 [00:10<00:10,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  52%|█████▏    | 54/103 [00:11<00:10,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  53%|█████▎    | 55/103 [00:11<00:09,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  54%|█████▍    | 56/103 [00:11<00:09,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  55%|█████▌    | 57/103 [00:11<00:09,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  56%|█████▋    | 58/103 [00:11<00:09,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  57%|█████▋    | 59/103 [00:12<00:08,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  58%|█████▊    | 60/103 [00:12<00:08,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  59%|█████▉    | 61/103 [00:12<00:08,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  60%|██████    | 62/103 [00:12<00:08,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  61%|██████    | 63/103 [00:12<00:08,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  62%|██████▏   | 64/103 [00:13<00:07,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  63%|██████▎   | 65/103 [00:13<00:07,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  64%|██████▍   | 66/103 [00:13<00:07,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  65%|██████▌   | 67/103 [00:13<00:07,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  66%|██████▌   | 68/103 [00:13<00:07,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  67%|██████▋   | 69/103 [00:14<00:06,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  68%|██████▊   | 70/103 [00:14<00:06,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  69%|██████▉   | 71/103 [00:14<00:06,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  70%|██████▉   | 72/103 [00:14<00:06,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  71%|███████   | 73/103 [00:14<00:06,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  72%|███████▏  | 74/103 [00:15<00:05,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  73%|███████▎  | 75/103 [00:15<00:05,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  74%|███████▍  | 76/103 [00:15<00:05,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  75%|███████▍  | 77/103 [00:15<00:05,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  76%|███████▌  | 78/103 [00:15<00:05,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  77%|███████▋  | 79/103 [00:16<00:04,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  78%|███████▊  | 80/103 [00:16<00:04,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  79%|███████▊  | 81/103 [00:16<00:04,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  80%|███████▉  | 82/103 [00:16<00:04,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  81%|████████  | 83/103 [00:16<00:04,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  82%|████████▏ | 84/103 [00:17<00:03,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  83%|████████▎ | 85/103 [00:17<00:03,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  83%|████████▎ | 86/103 [00:17<00:03,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  84%|████████▍ | 87/103 [00:17<00:03,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  85%|████████▌ | 88/103 [00:17<00:03,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  86%|████████▋ | 89/103 [00:18<00:02,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  87%|████████▋ | 90/103 [00:18<00:02,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  88%|████████▊ | 91/103 [00:18<00:02,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  89%|████████▉ | 92/103 [00:18<00:02,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  90%|█████████ | 93/103 [00:18<00:02,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  91%|█████████▏| 94/103 [00:19<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  92%|█████████▏| 95/103 [00:19<00:01,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  93%|█████████▎| 96/103 [00:19<00:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  94%|█████████▍| 97/103 [00:19<00:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  95%|█████████▌| 98/103 [00:20<00:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  96%|█████████▌| 99/103 [00:20<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  97%|█████████▋| 100/103 [00:20<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  98%|█████████▊| 101/103 [00:20<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):  99%|█████████▉| 102/103 [00:20<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|██████████| 103/103 [00:21<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=8652 | T=960 | C=8 | clases=4 | sujetos únicos=103\n",
      "Datos cargados: N=8652, T=960, C=8, Clases=4\n",
      "Aplicando Channel Cluster Swapping Augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aumento completado: 120 muestras añadidas\n",
      "Extrayendo características PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8772 [00:00<?, ?it/s]<ipython-input-9-e22fa1ddfae2>:575: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  band_power = np.trapz(psd[band_mask], freqs[band_mask])\n",
      "100%|██████████| 8772/8772 [00:04<00:00, 1860.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "=== FOLD 1/5 ===\n",
      "============================================================\n",
      "📊 Dataset sizes: Train: 5966, Val: 1018, Test: 1788\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "TabNet n_d: 64\n",
      "\n",
      "🎯 STAGE 1 TRAINING\n",
      "Epoch   0: Train Loss: 1.4421, Train Acc: 0.2524 | Val Loss: 1.3998, Val Acc: 0.2579 | LR: 0.001000\n",
      "Epoch  10: Train Loss: 1.0575, Train Acc: 0.5432 | Val Loss: 1.5017, Val Acc: 0.3338 | LR: 0.000954\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  20: Train Loss: 0.5647, Train Acc: 0.7851 | Val Loss: 2.1539, Val Acc: 0.3389 | LR: 0.000839\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  30: Train Loss: 0.3190, Train Acc: 0.8857 | Val Loss: 2.4607, Val Acc: 0.3514 | LR: 0.000673\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  40: Train Loss: 0.2117, Train Acc: 0.9264 | Val Loss: 2.9458, Val Acc: 0.3377 | LR: 0.000480\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  50: Train Loss: 0.1370, Train Acc: 0.9575 | Val Loss: 3.3939, Val Acc: 0.3307 | LR: 0.000291\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  60: Train Loss: 0.1066, Train Acc: 0.9639 | Val Loss: 3.6054, Val Acc: 0.3463 | LR: 0.000133\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  70: Train Loss: 0.0991, Train Acc: 0.9670 | Val Loss: 3.6391, Val Acc: 0.3473 | LR: 0.000031\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  79: Train Loss: 0.0814, Train Acc: 0.9706 | Val Loss: 3.6916, Val Acc: 0.3375 | LR: 0.000000\n",
      "⚠️  Posible overfitting detectado!\n",
      "✅ Stage 1 Final - Train: 0.9706, Val: 0.3375, Test: 0.3361\n",
      "\n",
      "🎯 STAGE 2 TRAINING\n",
      "❌ Error en fold 1: The size of tensor a (64) must match the size of tensor b (296) at non-singleton dimension 1\n",
      "\n",
      "============================================================\n",
      "=== FOLD 2/5 ===\n",
      "============================================================\n",
      "📊 Dataset sizes: Train: 5961, Val: 1023, Test: 1788\n",
      "EEGNet output dimension: 3840\n",
      "Stage 1 output dim: 256\n",
      "TabNet input dim: 296\n",
      "TabNet n_d: 64\n",
      "\n",
      "🎯 STAGE 1 TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-e22fa1ddfae2>\", line 989, in run_two_stage_experiment\n",
      "    history_stage2, best_val_stage2 = train_stage2_with_metrics(\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-9-e22fa1ddfae2>\", line 788, in train_stage2_with_metrics\n",
      "    _, logits_stage2, _ = model(x, psd)\n",
      "                          ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-9-e22fa1ddfae2>\", line 546, in forward\n",
      "    logits_stage2 = self.stage2(combined_features)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-9-e22fa1ddfae2>\", line 513, in forward\n",
      "    attended_x = x * attention_weights\n",
      "                 ~~^~~~~~~~~~~~~~~~~~~\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (296) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Train Loss: 1.4439, Train Acc: 0.2482 | Val Loss: 1.4022, Val Acc: 0.2598 | LR: 0.001000\n",
      "Epoch  10: Train Loss: 1.0932, Train Acc: 0.5215 | Val Loss: 1.3784, Val Acc: 0.3598 | LR: 0.000954\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  20: Train Loss: 0.6109, Train Acc: 0.7632 | Val Loss: 2.0457, Val Acc: 0.3423 | LR: 0.000839\n",
      "⚠️  Posible overfitting detectado!\n",
      "Epoch  30: Train Loss: 0.3448, Train Acc: 0.8786 | Val Loss: 2.4451, Val Acc: 0.3433 | LR: 0.000673\n",
      "⚠️  Posible overfitting detectado!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e22fa1ddfae2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_two_stage_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e22fa1ddfae2>\u001b[0m in \u001b[0;36mrun_two_stage_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;31m# Stage 1 con métricas completas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n🎯 STAGE 1 TRAINING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             history_stage1, best_val_stage1 = train_stage1_with_metrics(\n\u001b[0m\u001b[1;32m    970\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_STAGE1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR_STAGE1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             )\n",
      "\u001b[0;32m<ipython-input-9-e22fa1ddfae2>\u001b[0m in \u001b[0;36mtrain_stage1_with_metrics\u001b[0;34m(model, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m                 \u001b[0mset_skip_guard_eval_unsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_skip_guard_eval_unsafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_maybe_set_eval_frame\u001b[0;34m(callback)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjustknobs_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pytorch/compiler:enable_compiler_set_eval_frame\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         torch._dynamo.utils.warn_once(\n\u001b[1;32m    117\u001b[0m             \u001b[0;34m\"Dynamo disabled by Justknob: enable_compiler_set_eval_frame, skipping set_eval_frame\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\u001b[0m in \u001b[0;36mjustknobs_check\u001b[0;34m(name, default)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mjustknobs_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkillswitch\u001b[0m \u001b[0mfunctionality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFB\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Two-Stage Transformer Architecture - VERSIÓN COMPLETA AUTO-CONTENIDA\n",
    "\n",
    "import os, re, math, random, json, itertools, copy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# CONFIGURACIÓN GENERAL\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dispositivo y semilla\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Escenario y ventana\n",
    "CLASS_SCENARIO = '4c'\n",
    "WINDOW_MODE = '6s'\n",
    "FS = 160.0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Arquitectura Two-Stage\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_STAGE1 = 80\n",
    "EPOCHS_STAGE2 = 40\n",
    "LR_STAGE1 = 1e-3\n",
    "LR_STAGE2 = 5e-4\n",
    "\n",
    "# Parámetros Transformer\n",
    "N_HEADS = 4\n",
    "D_MODEL = 64\n",
    "DROPOUT_ATTN = 0.2\n",
    "TCN_FILTERS = 64\n",
    "TCN_KERNEL_SIZE = 3\n",
    "TCN_N_BLOCKS = 2\n",
    "TIME_SLICES = 4\n",
    "\n",
    "# TabNet\n",
    "TABNET_N_D = 64\n",
    "TABNET_N_A = 64\n",
    "TABNET_N_HIDDEN = 128\n",
    "TABNET_N_STEPS = 3\n",
    "\n",
    "# Data Augmentation\n",
    "N_CLUSTERS = 3\n",
    "AUG_SAMPLES_PER_CLASS = 30\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES DE CANALES\n",
    "# =========================\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "# Canales (8 con FCz)\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"Warning: faltan canales {missing} en archivo {getattr(raw,'filenames', [''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "# =========================\n",
    "# LECTURA DE EDF y EVENTOS\n",
    "# =========================\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "# Runs MI\n",
    "MI_RUNS_LR = [4, 8, 12]\n",
    "MI_RUNS_OF = [6, 10, 14]\n",
    "BASELINE_RUNS_EO = [1]\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    if run_id in BASELINE_RUNS_EO: return 'EO'\n",
    "    return None\n",
    "\n",
    "# Sujetos excluidos\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrado básico\n",
    "    raw.filter(4.0, 40.0, method='iir', verbose=False)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return []\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ', '')\n",
    "    res = []\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'):\n",
    "            res.append((float(onset), tag))\n",
    "    res.sort()\n",
    "    dedup = []\n",
    "    last_t1 = last_t2 = -1e9\n",
    "    for t, tag in res:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# =========================\n",
    "# CONSTRUCCIÓN DE DATASETS\n",
    "# =========================\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR + MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "def extract_trials_from_run(edf_path: Path, scenario: str, window_mode: str):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF','EO'):\n",
    "        return ([], [])\n",
    "\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        return ([], [])\n",
    "\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    assert abs(fs - FS) < 1e-6\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if kind in ('LR','OF'):\n",
    "        events = collect_events_T1T2(raw)\n",
    "        if window_mode == '3s':\n",
    "            rel_start, rel_end = 0.0, 3.0\n",
    "        else:  # 6s\n",
    "            rel_start, rel_end = -1.0, 5.0\n",
    "\n",
    "        for onset_sec, tag in events:\n",
    "            if kind == 'LR':\n",
    "                if tag == 'T1': label = 'L'\n",
    "                elif tag == 'T2': label = 'R'\n",
    "                else: continue\n",
    "            else:\n",
    "                if tag == 'T1': label = 'BFISTS'\n",
    "                elif tag == 'T2': label = 'BFEET'\n",
    "                else: continue\n",
    "\n",
    "            if scenario == '2c' and label not in ('L','R'): continue\n",
    "            if scenario == '3c' and label not in ('L','R','BFISTS'): continue\n",
    "            if scenario == '4c' and label not in ('L','R','BFISTS','BFEET'): continue\n",
    "\n",
    "            s = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "            e = int(round((raw.first_time + onset_sec + rel_end) * fs))\n",
    "            if s < 0 or e > data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            seg = data[:, s:e].T.astype(np.float32)\n",
    "            # Normalización z-score por canal\n",
    "            seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "\n",
    "            if label == 'L':       y = 0\n",
    "            elif label == 'R':     y = 1\n",
    "            elif label == 'BFISTS':y = 2\n",
    "            elif label == 'BFEET': y = 3\n",
    "            else: continue\n",
    "\n",
    "            out.append((seg, y, subj))\n",
    "\n",
    "    elif kind == 'EO':\n",
    "        return ([], raw.ch_names)\n",
    "\n",
    "    return out, raw.ch_names\n",
    "\n",
    "def build_dataset_all(subjects, scenario='4c', window_mode='3s'):\n",
    "    X, y, groups = [], [], []\n",
    "    ch_template = None\n",
    "\n",
    "    for s in tqdm(subjects, desc=\"Construyendo dataset (RAW)\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "\n",
    "        trials_L, trials_R, trials_FISTS, trials_FEET = [], [], [], []\n",
    "\n",
    "        for r in MI_RUNS_LR:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 0: trials_L.append(seg)\n",
    "                elif lab == 1: trials_R.append(seg)\n",
    "\n",
    "        for r in MI_RUNS_OF:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 2: trials_FISTS.append(seg)\n",
    "                elif lab == 3: trials_FEET.append(seg)\n",
    "\n",
    "        need_per_class = 21\n",
    "        def pick(trials, n, rng):\n",
    "            if len(trials) < n:\n",
    "                idx = rng.choice(len(trials), size=n, replace=True)\n",
    "                return [trials[i] for i in idx]\n",
    "            rng.shuffle(trials)\n",
    "            return trials[:n]\n",
    "\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        if len(trials_L)==0 or len(trials_R)==0 or len(trials_FISTS)==0 or len(trials_FEET)==0:\n",
    "            continue\n",
    "\n",
    "        Lp  = pick(trials_L,     need_per_class, rng)\n",
    "        Rp  = pick(trials_R,     need_per_class, rng)\n",
    "        FIp = pick(trials_FISTS, need_per_class, rng)\n",
    "        FEp = pick(trials_FEET,  need_per_class, rng)\n",
    "\n",
    "        pack = [(Lp, 0), (Rp, 1), (FIp, 2), (FEp, 3)]\n",
    "        for segs, lab in pack:\n",
    "            for seg in segs:\n",
    "                X.append(seg); y.append(lab); groups.append(s)\n",
    "\n",
    "    if len(X) == 0:\n",
    "        print(\"No se pudieron cargar datos. Verifica las rutas de archivos.\")\n",
    "        return None, None, None, None\n",
    "        \n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    groups = np.asarray(groups, dtype=np.int64)\n",
    "\n",
    "    n, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Dataset construido: N={n} | T={T} | C={C} | clases={n_classes} | sujetos únicos={len(np.unique(groups))}\")\n",
    "    return X, y, groups, ch_template\n",
    "\n",
    "# =========================\n",
    "# ARQUITECTURA TWO-STAGE TRANSFORMER\n",
    "# =========================\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RobustEEGNet(nn.Module):\n",
    "    def __init__(self, n_ch=8, F1=32, D=2, T=960):\n",
    "        super().__init__()\n",
    "        self.F1 = F1\n",
    "        self.F2 = F1 * D\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, F1, (32, 1), padding=(16, 0), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(F1, self.F2, (1, n_ch), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F2)\n",
    "        \n",
    "        self.pool1 = nn.AvgPool2d((4, 1))\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(self.F2, self.F2, (8, 1), groups=self.F2, padding=(4, 0), bias=False)\n",
    "        self.conv4 = nn.Conv2d(self.F2, self.F2, (1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool2d((4, 1))\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.output_dim = self._get_output_dim(n_ch, T)\n",
    "        \n",
    "    def _get_output_dim(self, n_ch, T):\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 1, T, n_ch)\n",
    "            x = F.elu(self.bn1(self.conv1(x)))\n",
    "            x = F.elu(self.bn2(self.conv2(x)))\n",
    "            x = self.pool1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.elu(self.bn3(self.conv4(self.conv3(x))))\n",
    "            x = self.pool2(x)\n",
    "            x = self.dropout2(x)\n",
    "            return x.view(1, -1).size(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.bn1(self.conv1(x)))\n",
    "        x = F.elu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.elu(self.bn3(self.conv4(self.conv3(x))))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return x.flatten(1)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, d_model = x.shape\n",
    "        \n",
    "        Q = self.w_q(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.w_k(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.w_v(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context = torch.matmul(attn_weights, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, self.d_model)\n",
    "        \n",
    "        return self.w_o(context), attn_weights\n",
    "\n",
    "class AdaptiveTemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        effective_ks = kernel_size if kernel_size > 1 else 1\n",
    "        padding = (effective_ks - 1) // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, effective_ks, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, effective_ks, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        self.activation = nn.ELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.activation(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        return self.activation(x + residual)\n",
    "\n",
    "class Stage1Architecture(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_classes=4, T=960, time_slices=4):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.n_classes = n_classes\n",
    "        self.time_slices = time_slices\n",
    "        \n",
    "        self.eegnet = RobustEEGNet(n_ch=n_ch, T=T)\n",
    "        eegnet_output_dim = self.eegnet.output_dim\n",
    "        \n",
    "        print(f\"EEGNet output dimension: {eegnet_output_dim}\")\n",
    "        \n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(eegnet_output_dim, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, D_MODEL * time_slices)\n",
    "        )\n",
    "        \n",
    "        self.attention = MultiHeadAttention(d_model=D_MODEL, n_heads=N_HEADS, dropout=DROPOUT_ATTN)\n",
    "        \n",
    "        self.temporal_blocks = nn.ModuleList()\n",
    "        for i in range(TCN_N_BLOCKS):\n",
    "            block = AdaptiveTemporalBlock(D_MODEL, TCN_FILTERS, kernel_size=TCN_KERNEL_SIZE)\n",
    "            self.temporal_blocks.append(block)\n",
    "        \n",
    "        self.output_dim = TCN_FILTERS * time_slices\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.output_dim, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, _, T, C = x.shape\n",
    "        \n",
    "        eeg_features = self.eegnet(x)\n",
    "        projected = self.projection(eeg_features)\n",
    "        projected = projected.view(B, self.time_slices, D_MODEL)\n",
    "        \n",
    "        attended, _ = self.attention(projected)\n",
    "        temporal_feat = attended.transpose(1, 2)\n",
    "        \n",
    "        for block in self.temporal_blocks:\n",
    "            temporal_feat = block(temporal_feat)\n",
    "        \n",
    "        embeddings = temporal_feat.flatten(1)\n",
    "        logits = self.classifier(embeddings)\n",
    "        \n",
    "        return logits, embeddings\n",
    "\n",
    "class TabNetClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes=4, n_d=64, n_steps=3):\n",
    "        super().__init__()\n",
    "        self.n_d = n_d\n",
    "        self.n_steps = n_steps\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.initial_bn = nn.BatchNorm1d(input_dim)\n",
    "        self.initial_fc = nn.Linear(input_dim, n_d * 2)\n",
    "        \n",
    "        self.decision_blocks = nn.ModuleList()\n",
    "        for i in range(n_steps):\n",
    "            block = nn.Sequential(\n",
    "                nn.Linear(n_d, n_d * 2),\n",
    "                nn.BatchNorm1d(n_d * 2),\n",
    "                nn.GLU(dim=1),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "            self.decision_blocks.append(block)\n",
    "        \n",
    "        self.attention_layers = nn.ModuleList()\n",
    "        for i in range(n_steps):\n",
    "            attention = nn.Sequential(\n",
    "                nn.Linear(n_d, input_dim),\n",
    "                nn.BatchNorm1d(input_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "            self.attention_layers.append(attention)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_d * n_steps, TABNET_N_HIDDEN),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(TABNET_N_HIDDEN, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.initial_fc(x)\n",
    "        x = F.glu(x, dim=1)\n",
    "        \n",
    "        decision_outputs = []\n",
    "        current_x = x\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            attention_weights = self.attention_layers[i](current_x)\n",
    "            attended_x = x * attention_weights\n",
    "            \n",
    "            transformed = self.decision_blocks[i](attended_x)\n",
    "            decision_outputs.append(transformed)\n",
    "            \n",
    "            current_x = current_x + transformed\n",
    "        \n",
    "        final_features = torch.cat(decision_outputs, dim=1)\n",
    "        return self.classifier(final_features)\n",
    "\n",
    "class TwoStageTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_classes=4, T=960, time_slices=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stage1 = Stage1Architecture(n_ch, n_classes, T, time_slices)\n",
    "        stage1_output_dim = self.stage1.output_dim\n",
    "        \n",
    "        psd_feature_dim = 40\n",
    "        tabnet_input_dim = stage1_output_dim + psd_feature_dim\n",
    "        \n",
    "        self.stage2 = TabNetClassifier(tabnet_input_dim, n_classes, TABNET_N_D, TABNET_N_STEPS)\n",
    "        \n",
    "        print(f\"Stage 1 output dim: {stage1_output_dim}\")\n",
    "        print(f\"TabNet input dim: {tabnet_input_dim}\")\n",
    "        print(f\"TabNet n_d: {TABNET_N_D}\")\n",
    "        \n",
    "    def forward(self, x, psd_features=None):\n",
    "        logits_stage1, embeddings_stage1 = self.stage1(x)\n",
    "        \n",
    "        if psd_features is None:\n",
    "            return logits_stage1, embeddings_stage1\n",
    "        \n",
    "        combined_features = torch.cat([embeddings_stage1, psd_features], dim=1)\n",
    "        logits_stage2 = self.stage2(combined_features)\n",
    "        \n",
    "        return logits_stage1, logits_stage2, embeddings_stage1\n",
    "\n",
    "# =========================\n",
    "# DATA AUGMENTATION Y PREPROCESAMIENTO\n",
    "# =========================\n",
    "\n",
    "def extract_psd_features(X, fs=160.0):\n",
    "    print(\"Extrayendo características PSD...\")\n",
    "    \n",
    "    n_trials, T, n_channels = X.shape\n",
    "    n_bands = 5\n",
    "    psd_features = np.zeros((n_trials, n_channels * n_bands))\n",
    "    \n",
    "    freq_bands = [(1, 4), (4, 8), (8, 14), (14, 31), (31, 49)]\n",
    "    \n",
    "    for i in tqdm(range(n_trials)):\n",
    "        trial_psd = []\n",
    "        for ch in range(n_channels):\n",
    "            signal = X[i, :, ch]\n",
    "            \n",
    "            fft_vals = np.fft.rfft(signal)\n",
    "            freqs = np.fft.rfftfreq(len(signal), 1/fs)\n",
    "            psd = np.abs(fft_vals) ** 2\n",
    "            \n",
    "            for f_low, f_high in freq_bands:\n",
    "                band_mask = (freqs >= f_low) & (freqs <= f_high)\n",
    "                if np.any(band_mask):\n",
    "                    band_power = np.trapz(psd[band_mask], freqs[band_mask])\n",
    "                else:\n",
    "                    band_power = 0.0\n",
    "                trial_psd.append(band_power)\n",
    "        \n",
    "        psd_features[i] = np.array(trial_psd)\n",
    "    \n",
    "    psd_features = (psd_features - psd_features.mean(axis=0)) / (psd_features.std(axis=0) + 1e-8)\n",
    "    \n",
    "    return psd_features.astype(np.float32)\n",
    "\n",
    "def channel_cluster_swapping_augmentation(X, y, groups, n_clusters=3, n_augmented_per_class=30):\n",
    "    print(\"Aplicando Channel Cluster Swapping Augmentation...\")\n",
    "    \n",
    "    X_aug, y_aug, groups_aug = [], [], []\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    for class_idx in range(n_classes):\n",
    "        class_mask = (y == class_idx)\n",
    "        X_class = X[class_mask]\n",
    "        groups_class = groups[class_mask]\n",
    "        \n",
    "        if len(X_class) < 2:\n",
    "            continue\n",
    "            \n",
    "        corr_matrix = np.zeros((X_class.shape[2], X_class.shape[2]))\n",
    "        for i in range(len(X_class)):\n",
    "            trial_corr = np.corrcoef(X_class[i].T)\n",
    "            corr_matrix += np.nan_to_num(trial_corr)\n",
    "        corr_matrix /= len(X_class)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=10)\n",
    "        channel_labels = kmeans.fit_predict(corr_matrix)\n",
    "        \n",
    "        n_generated = 0\n",
    "        while n_generated < n_augmented_per_class:\n",
    "            idx1, idx2 = np.random.choice(len(X_class), 2, replace=False)\n",
    "            \n",
    "            new_trial = X_class[idx1].copy()\n",
    "            for cluster_id in range(n_clusters):\n",
    "                cluster_channels = np.where(channel_labels == cluster_id)[0]\n",
    "                if len(cluster_channels) > 0:\n",
    "                    swap_channel = np.random.choice(cluster_channels)\n",
    "                    new_trial[:, swap_channel] = X_class[idx2][:, swap_channel]\n",
    "            \n",
    "            X_aug.append(new_trial)\n",
    "            y_aug.append(class_idx)\n",
    "            groups_aug.append(groups_class[idx1])\n",
    "            n_generated += 1\n",
    "    \n",
    "    if X_aug:\n",
    "        X_aug = np.stack(X_aug, axis=0)\n",
    "        y_aug = np.array(y_aug, dtype=np.int64)\n",
    "        groups_aug = np.array(groups_aug, dtype=np.int64)\n",
    "        \n",
    "        X_combined = np.concatenate([X, X_aug], axis=0)\n",
    "        y_combined = np.concatenate([y, y_aug], axis=0)\n",
    "        groups_combined = np.concatenate([groups, groups_aug], axis=0)\n",
    "        \n",
    "        print(f\"Aumento completado: {len(X_aug)} muestras añadidas\")\n",
    "        return X_combined, y_combined, groups_combined\n",
    "    \n",
    "    return X, y, groups\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y, groups, psd_features=None):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "        self.psd_features = psd_features.astype(np.float32) if psd_features is not None else None\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        x = np.expand_dims(x, 0)\n",
    "        \n",
    "        if self.psd_features is not None:\n",
    "            return (torch.from_numpy(x), \n",
    "                    torch.from_numpy(self.psd_features[idx]), \n",
    "                    torch.tensor(self.y[idx]), \n",
    "                    torch.tensor(self.g[idx]))\n",
    "        else:\n",
    "            return (torch.from_numpy(x), \n",
    "                    torch.tensor(self.y[idx]), \n",
    "                    torch.tensor(self.g[idx]))\n",
    "\n",
    "# =========================\n",
    "# FUNCIONES DE ENTRENAMIENTO CON MÉTRICAS COMPLETAS\n",
    "# =========================\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    pred = output.argmax(dim=1)\n",
    "    correct = (pred == target).sum().item()\n",
    "    return correct / target.size(0)\n",
    "\n",
    "def train_stage1_with_metrics(model, train_loader, val_loader, epochs=80, lr=1e-3):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Fase de entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            if len(batch) == 4:\n",
    "                x, _, y, _ = batch\n",
    "            else:\n",
    "                x, y, _ = batch\n",
    "                \n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += calculate_accuracy(logits, y)\n",
    "            train_batches += 1\n",
    "        \n",
    "        # Fase de validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                if len(batch) == 4:\n",
    "                    x, _, y, _ = batch\n",
    "                else:\n",
    "                    x, y, _ = batch\n",
    "                    \n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                logits, _ = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_acc += calculate_accuracy(logits, y)\n",
    "                val_batches += 1\n",
    "        \n",
    "        # Calcular promedios\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        avg_train_acc = train_acc / train_batches\n",
    "        avg_val_loss = val_loss / val_batches\n",
    "        avg_val_acc = val_acc / val_batches\n",
    "        \n",
    "        # Actualizar historial\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(avg_train_acc)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(avg_val_acc)\n",
    "        history['lr'].append(scheduler.get_last_lr()[0])\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            best_val_acc = avg_val_acc\n",
    "            torch.save(model.state_dict(), 'best_stage1.pth')\n",
    "        \n",
    "        # Log cada 10 épocas\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f'Epoch {epoch:3d}: '\n",
    "                  f'Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | '\n",
    "                  f'Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f} | '\n",
    "                  f'LR: {current_lr:.6f}')\n",
    "            \n",
    "            # Detectar overfitting\n",
    "            if avg_train_acc - avg_val_acc > 0.15:\n",
    "                print('⚠️  Posible overfitting detectado!')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "def train_stage2_with_metrics(model, train_loader, val_loader, epochs=40, lr=5e-4):\n",
    "    optimizer = optim.AdamW(model.stage2.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Fase de entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            x, psd, y, _ = batch\n",
    "            x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            _, logits_stage2, _ = model(x, psd)\n",
    "            loss = criterion(logits_stage2, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += calculate_accuracy(logits_stage2, y)\n",
    "            train_batches += 1\n",
    "        \n",
    "        # Fase de validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x, psd, y, _ = batch\n",
    "                x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "                _, logits_stage2, _ = model(x, psd)\n",
    "                loss = criterion(logits_stage2, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_acc += calculate_accuracy(logits_stage2, y)\n",
    "                val_batches += 1\n",
    "        \n",
    "        # Calcular promedios\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        avg_train_acc = train_acc / train_batches\n",
    "        avg_val_loss = val_loss / val_batches\n",
    "        avg_val_acc = val_acc / val_batches\n",
    "        \n",
    "        # Actualizar historial\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(avg_train_acc)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(avg_val_acc)\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            best_val_acc = avg_val_acc\n",
    "            torch.save(model.state_dict(), 'best_stage2.pth')\n",
    "        \n",
    "        # Log cada 10 épocas\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f'Epoch {epoch:3d}: '\n",
    "                  f'Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | '\n",
    "                  f'Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "            \n",
    "            if avg_train_acc - avg_val_acc > 0.15:\n",
    "                print('⚠️  Posible overfitting detectado en Stage 2!')\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_stage1(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        if len(batch) == 4:\n",
    "            x, _, y, _ = batch\n",
    "        else:\n",
    "            x, y, _ = batch\n",
    "            \n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits, _ = model(x)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_stage2(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        x, psd, y, _ = batch\n",
    "        x, psd, y = x.to(DEVICE), psd.to(DEVICE), y.to(DEVICE)\n",
    "        _, logits_stage2, _ = model(x, psd)\n",
    "        pred = logits_stage2.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "def plot_training_curves(history, fold, stage):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'Fold {fold} - Stage {stage} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.title(f'Fold {fold} - Stage {stage} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'training_curves_fold{fold}_stage{stage}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# EXPERIMENTO PRINCIPAL COMPLETO\n",
    "# =========================\n",
    "def run_two_stage_experiment():\n",
    "    print(\"🧠 TWO-STAGE TRANSFORMER - VERSIÓN COMPLETA AUTO-CONTENIDA\")\n",
    "    \n",
    "    # Cargar datos\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos disponibles: {len(subs)}\")\n",
    "    \n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    \n",
    "    if X is None:\n",
    "        print(\"Error: No se pudieron cargar los datos.\")\n",
    "        return None\n",
    "        \n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    print(f\"Datos cargados: N={N}, T={T}, C={C}, Clases={n_classes}\")\n",
    "    \n",
    "    # Data augmentation\n",
    "    X_aug, y_aug, groups_aug = channel_cluster_swapping_augmentation(\n",
    "        X, y, groups, n_clusters=N_CLUSTERS, n_augmented_per_class=AUG_SAMPLES_PER_CLASS\n",
    "    )\n",
    "    \n",
    "    # Extraer características PSD\n",
    "    psd_features = extract_psd_features(X_aug, fs=FS)\n",
    "    \n",
    "    # Crear dataset\n",
    "    dataset = EEGDataset(X_aug, y_aug, groups_aug, psd_features)\n",
    "    \n",
    "    # Cross-validation con métricas completas\n",
    "    unique_subjects = np.unique(groups_aug)\n",
    "    gkf = GroupKFold(n_splits=min(N_FOLDS, len(unique_subjects)))\n",
    "    \n",
    "    fold_results = {\n",
    "        'stage1': {'train_acc': [], 'val_acc': [], 'test_acc': []},\n",
    "        'stage2': {'train_acc': [], 'val_acc': [], 'test_acc': []}\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X_aug, y_aug, groups_aug)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"=== FOLD {fold + 1}/{min(N_FOLDS, len(unique_subjects))} ===\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Split train/val\n",
    "        train_subjects = np.unique(groups_aug[train_idx])\n",
    "        val_size = max(1, int(0.15 * len(train_subjects)))\n",
    "        val_subjects = np.random.choice(train_subjects, val_size, replace=False)\n",
    "        \n",
    "        val_mask = np.isin(groups_aug[train_idx], val_subjects)\n",
    "        val_idx = train_idx[val_mask]\n",
    "        train_idx_fold = train_idx[~val_mask]\n",
    "        \n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(Subset(dataset, train_idx_fold), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(Subset(dataset, test_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        print(f\"📊 Dataset sizes: Train: {len(train_idx_fold)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "        \n",
    "        # Modelo\n",
    "        model = TwoStageTransformer(n_ch=C, n_classes=n_classes, T=T, time_slices=TIME_SLICES).to(DEVICE)\n",
    "        \n",
    "        try:\n",
    "            # Stage 1 con métricas completas\n",
    "            print(\"\\n🎯 STAGE 1 TRAINING\")\n",
    "            history_stage1, best_val_stage1 = train_stage1_with_metrics(\n",
    "                model, train_loader, val_loader, EPOCHS_STAGE1, LR_STAGE1\n",
    "            )\n",
    "            \n",
    "            # Evaluar en test\n",
    "            test_acc_stage1 = evaluate_stage1(model, test_loader)\n",
    "            train_acc_stage1 = history_stage1['train_acc'][-1]\n",
    "            val_acc_stage1 = history_stage1['val_acc'][-1]\n",
    "            \n",
    "            fold_results['stage1']['train_acc'].append(train_acc_stage1)\n",
    "            fold_results['stage1']['val_acc'].append(val_acc_stage1)\n",
    "            fold_results['stage1']['test_acc'].append(test_acc_stage1)\n",
    "            \n",
    "            print(f\"✅ Stage 1 Final - Train: {train_acc_stage1:.4f}, Val: {val_acc_stage1:.4f}, Test: {test_acc_stage1:.4f}\")\n",
    "            \n",
    "            # Graficar curvas\n",
    "            plot_training_curves(history_stage1, fold + 1, 1)\n",
    "            \n",
    "            # Stage 2 con métricas completas\n",
    "            print(\"\\n🎯 STAGE 2 TRAINING\")\n",
    "            history_stage2, best_val_stage2 = train_stage2_with_metrics(\n",
    "                model, train_loader, val_loader, EPOCHS_STAGE2, LR_STAGE2\n",
    "            )\n",
    "            \n",
    "            # Evaluar en test\n",
    "            test_acc_stage2 = evaluate_stage2(model, test_loader)\n",
    "            train_acc_stage2 = history_stage2['train_acc'][-1]\n",
    "            val_acc_stage2 = history_stage2['val_acc'][-1]\n",
    "            \n",
    "            fold_results['stage2']['train_acc'].append(train_acc_stage2)\n",
    "            fold_results['stage2']['val_acc'].append(val_acc_stage2)\n",
    "            fold_results['stage2']['test_acc'].append(test_acc_stage2)\n",
    "            \n",
    "            print(f\"✅ Stage 2 Final - Train: {train_acc_stage2:.4f}, Val: {val_acc_stage2:.4f}, Test: {test_acc_stage2:.4f}\")\n",
    "            print(f\"📈 Improvement: +{(test_acc_stage2 - test_acc_stage1)*100:.2f}%\")\n",
    "            \n",
    "            # Graficar curvas\n",
    "            plot_training_curves(history_stage2, fold + 1, 2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error en fold {fold + 1}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Resultados finales detallados\n",
    "    if fold_results['stage1']['test_acc']:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"🎯 RESULTADOS FINALES DETALLADOS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for stage in ['stage1', 'stage2']:\n",
    "            train_mean = np.mean(fold_results[stage]['train_acc'])\n",
    "            train_std = np.std(fold_results[stage]['train_acc'])\n",
    "            val_mean = np.mean(fold_results[stage]['val_acc'])\n",
    "            val_std = np.std(fold_results[stage]['val_acc'])\n",
    "            test_mean = np.mean(fold_results[stage]['test_acc'])\n",
    "            test_std = np.std(fold_results[stage]['test_acc'])\n",
    "            \n",
    "            print(f\"\\n{stage.upper()}:\")\n",
    "            print(f\"  Train: {train_mean:.4f} ± {train_std:.4f}\")\n",
    "            print(f\"  Val:   {val_mean:.4f} ± {val_std:.4f}\")\n",
    "            print(f\"  Test:  {test_mean:.4f} ± {test_std:.4f}\")\n",
    "            print(f\"  Overfitting (Train-Val): {(train_mean - val_mean)*100:.2f}%\")\n",
    "        \n",
    "        improvement = (np.mean(fold_results['stage2']['test_acc']) - \n",
    "                     np.mean(fold_results['stage1']['test_acc'])) * 100\n",
    "        print(f\"\\n📈 MEJORA TOTAL Stage 2 vs Stage 1: +{improvement:.2f}%\")\n",
    "        \n",
    "        return fold_results\n",
    "    else:\n",
    "        print(\"❌ No se completaron folds exitosamente.\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# EJECUCIÓN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_two_stage_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11843f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Dispositivo: cuda\n",
      "🧠 MI-EEG — CNN+Transformer (21/cls/subj) + Sliding Window + FT progresivo\n",
      "🔧 Escenario: 4c | rango ensayo=(0.0, 4.0) s | subventana=2.0s | stride=0.5s | subwins/ensayo=5 | band-pass=ON [4.0-38.0 Hz]\n",
      "⚙️  Balance: 21 ensayos por clase y por sujeto (con reemplazo si falta)\n",
      "⚙️  FT (sin fuga): GroupKFold por ensayo + GroupShuffleSplit en validación interna\n",
      "Sujetos elegibles: 103 → [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recolectando y balanceando ensayos base por sujeto: 100%|██████████| 103/103 [00:39<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensayos base balanceados: 8652  (~ #sujetos_utiles * 84)\n",
      "Sujetos con ensayos balanceados: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 1/5] Entrenando global (VAL por ensayo)...\n",
      "  Época   1 | train(ensayo)=0.2879 | val(ensayo)=0.2688\n",
      "  Época   5 | train(ensayo)=0.3847 | val(ensayo)=0.3313\n",
      "  Época  10 | train(ensayo)=0.5178 | val(ensayo)=0.3403\n",
      "  Época  15 | train(ensayo)=0.6275 | val(ensayo)=0.3700\n",
      "  Época  20 | train(ensayo)=0.6860 | val(ensayo)=0.3750\n",
      "  Época  25 | train(ensayo)=0.7478 | val(ensayo)=0.3472\n",
      "  Early stopping @ epoch 28 (best val ensayo=0.3869)\n",
      "↳ Curva: training_curve_cnnTrans_subjFolds_fold1.png\n",
      "[Fold 1] Ensayo acc=0.2914\n",
      "\n",
      "=== Reporte por ENSAYO (agregado) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.3232    0.1202    0.1752       441\n",
      "       Right     0.2875    0.3129    0.2997       441\n",
      "  Both Fists     0.2755    0.5941    0.3764       441\n",
      "   Both Feet     0.3609    0.1383    0.2000       441\n",
      "\n",
      "    accuracy                         0.2914      1764\n",
      "   macro avg     0.3118    0.2914    0.2628      1764\n",
      "weighted avg     0.3118    0.2914    0.2628      1764\n",
      "\n",
      "F1-macro: 0.2628 | Kappa: 0.0552\n",
      "  FT progresivo por ENSAYO acc=0.2619 | sujetos=84\n",
      "  Δ(FT-Ensayo - Global-Ensayo) = -0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 2/5] Entrenando global (VAL por ensayo)...\n",
      "  Época   1 | train(ensayo)=0.3022 | val(ensayo)=0.2917\n",
      "  Época   5 | train(ensayo)=0.3604 | val(ensayo)=0.3165\n",
      "  Época  10 | train(ensayo)=0.5625 | val(ensayo)=0.3244\n",
      "  Época  15 | train(ensayo)=0.6230 | val(ensayo)=0.3185\n",
      "  Época  20 | train(ensayo)=0.7325 | val(ensayo)=0.3313\n",
      "  Early stopping @ epoch 23 (best val ensayo=0.3522)\n",
      "↳ Curva: training_curve_cnnTrans_subjFolds_fold2.png\n",
      "[Fold 2] Ensayo acc=0.3316\n",
      "\n",
      "=== Reporte por ENSAYO (agregado) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.3186    0.5215    0.3955       441\n",
      "       Right     0.3562    0.1882    0.2463       441\n",
      "  Both Fists     0.3160    0.3855    0.3473       441\n",
      "   Both Feet     0.3764    0.2313    0.2865       441\n",
      "\n",
      "    accuracy                         0.3316      1764\n",
      "   macro avg     0.3418    0.3316    0.3189      1764\n",
      "weighted avg     0.3418    0.3316    0.3189      1764\n",
      "\n",
      "F1-macro: 0.3189 | Kappa: 0.1088\n",
      "  FT progresivo por ENSAYO acc=0.2920 | sujetos=84\n",
      "  Δ(FT-Ensayo - Global-Ensayo) = -0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 3/5] Entrenando global (VAL por ensayo)...\n",
      "  Época   1 | train(ensayo)=0.2892 | val(ensayo)=0.2579\n",
      "  Época   5 | train(ensayo)=0.4379 | val(ensayo)=0.3065\n",
      "  Época  10 | train(ensayo)=0.5562 | val(ensayo)=0.2897\n",
      "  Época  15 | train(ensayo)=0.6463 | val(ensayo)=0.2827\n",
      "  Early stopping @ epoch 16 (best val ensayo=0.3165)\n",
      "↳ Curva: training_curve_cnnTrans_subjFolds_fold3.png\n",
      "[Fold 3] Ensayo acc=0.3413\n",
      "\n",
      "=== Reporte por ENSAYO (agregado) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.3236    0.2268    0.2667       441\n",
      "       Right     0.3617    0.3469    0.3542       441\n",
      "  Both Fists     0.3053    0.4036    0.3477       441\n",
      "   Both Feet     0.3808    0.3878    0.3843       441\n",
      "\n",
      "    accuracy                         0.3413      1764\n",
      "   macro avg     0.3429    0.3413    0.3382      1764\n",
      "weighted avg     0.3429    0.3413    0.3382      1764\n",
      "\n",
      "F1-macro: 0.3382 | Kappa: 0.1217\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3f35d2b49b3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"⚙️  Balance: 21 ensayos por clase y por sujeto (con reemplazo si falta)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"⚙️  FT (sin fuga): GroupKFold por ensayo + GroupShuffleSplit en validación interna\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c3f35d2b49b3>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m    780\u001b[0m                 \u001b[0mXho\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0myho\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtho\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mho_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mho_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mho_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                 m_head = finetune_l2sp(model, Xcal, ycal, tcal,\n\u001b[0m\u001b[1;32m    783\u001b[0m                                        \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFT_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFT_BASE_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFT_HEAD_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c3f35d2b49b3>\u001b[0m in \u001b[0;36mfinetune_l2sp\u001b[0;34m(model_global, Xcal, ycal, trial_ids_cal, n_classes, mode, epochs, batch_size, base_lr, head_lr, l2sp_lambda, val_ratio, seed, device)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl_va\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                 \u001b[0mnval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c3f35d2b49b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mcls_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cls\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c3f35d2b49b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    885\u001b[0m                     \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                 )\n\u001b[0;32m--> 887\u001b[0;31m                 return torch._transformer_encoder_layer_fwd(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ===========================================\n",
    "# MI-EEG (PhysioNet eegmmidb) — CNN+Transformer (Balanced 21/cls/subj) + Sliding Window\n",
    "# Patch: usar Kfold5.json SOLO para sujetos por fold (ignorar tr_idx/te_idx)\n",
    "# Split por sujeto/ensayo -> luego windowing (sin fuga). Métrica por ENSAYO.\n",
    "# FT por sujeto (L2-SP) agrupando por ensayo (sin fuga).\n",
    "# ===========================================\n",
    "\n",
    "import os, re, math, json, copy, random, itertools, collections\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, cohen_kappa_score\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'           # .../S###/S###R##.edf\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "print(f\"🚀 Dispositivo: {DEVICE}\")\n",
    "\n",
    "FS = 160.0\n",
    "\n",
    "# Escenario y rango base por ensayo\n",
    "CLASS_SCENARIO = '4c'            # '2c','3c','4c'\n",
    "WINDOW_GLOBAL = (0.0, 4.0)       # segundos rel. T1/T2 (ensayo base)\n",
    "\n",
    "# Sliding window (mismo nº por ensayo)\n",
    "WIN_LEN_SEC = 2.0\n",
    "WIN_STRIDE_SEC = 0.5\n",
    "N_SUBWINS = int(math.floor((WINDOW_GLOBAL[1]-WINDOW_GLOBAL[0]-WIN_LEN_SEC)/WIN_STRIDE_SEC) + 1)\n",
    "\n",
    "# Balance 21 por clase/sujeto\n",
    "N_PER_CLASS_PER_SUBJECT = 21\n",
    "\n",
    "# CV\n",
    "N_FOLDS = 5\n",
    "GLOBAL_VAL_SPLIT = 0.15\n",
    "GLOBAL_PATIENCE  = 10\n",
    "\n",
    "# Entrenamiento\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_GLOBAL = 80\n",
    "LR_INIT = 1e-3\n",
    "\n",
    "# FT por sujeto\n",
    "CALIB_CV_FOLDS = 4\n",
    "FT_EPOCHS = 30\n",
    "FT_BASE_LR = 5e-5\n",
    "FT_HEAD_LR = 1e-3\n",
    "FT_L2SP = 1e-4\n",
    "FT_PATIENCE = 5\n",
    "FT_VAL_RATIO = 0.2\n",
    "\n",
    "# Band-pass\n",
    "USE_BANDPASS = True\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "BP_METHOD, BP_PHASE = 'fir', 'zero'\n",
    "\n",
    "# Dataset\n",
    "EXCLUDE_SUBJECTS = {38,88,89,92,100,104}\n",
    "MI_RUNS_LR = [4,8,12]            # Left/Right\n",
    "MI_RUNS_OF = [6,10,14]           # Both Fists / Both Feet\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "\n",
    "CLASS_NAMES = ['Left', 'Right', 'Both Fists', 'Both Feet']\n",
    "\n",
    "# =========================\n",
    "# UTIL: canales/edf\n",
    "# =========================\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"[WARN] faltan canales {missing} en {getattr(raw,'filenames',[''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    return None\n",
    "\n",
    "_SNR_TABLE = None\n",
    "def _load_snr_table():\n",
    "    global _SNR_TABLE\n",
    "    if _SNR_TABLE is not None: return _SNR_TABLE\n",
    "    csv_path = PROJ / 'reports' / 'psd_mains' / 'psd_mains_summary.csv'\n",
    "    if csv_path.exists():\n",
    "        try: _SNR_TABLE = pd.read_csv(csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[SNR] No se pudo leer {csv_path}: {e}\")\n",
    "            _SNR_TABLE = None\n",
    "    return _SNR_TABLE\n",
    "\n",
    "def _decide_notch(subject, run, th_db=10.0):\n",
    "    df = _load_snr_table()\n",
    "    if df is None:  return 60.0\n",
    "    row = df[(df['subject']==subject) & (df['run']==run)]\n",
    "    if row.empty:   return 60.0\n",
    "    snr50 = float(row['snr50_db'].iloc[0]); snr60 = float(row['snr60_db'].iloc[0])\n",
    "    if snr60 >= th_db and snr60 >= snr50: return 60.0\n",
    "    if snr50 >= th_db and snr50 >  snr60: return 50.0\n",
    "    return None\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None: return None\n",
    "\n",
    "    sid, rid = parse_subject_run(path)\n",
    "    notch = _decide_notch(sid, rid)\n",
    "    if notch is not None:\n",
    "        raw.notch_filter(freqs=[float(notch)], picks='eeg', method='spectrum_fit', phase='zero')\n",
    "\n",
    "    if USE_BANDPASS and (BP_LO is not None) and (BP_HI is not None):\n",
    "        raw.filter(l_freq=float(BP_LO), h_freq=float(BP_HI),\n",
    "                   picks='eeg', method=BP_METHOD, phase=BP_PHASE, verbose=False)\n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    out = []\n",
    "    if raw.annotations is None or len(raw.annotations) == 0: return out\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ','')\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'): out.append((float(onset), tag))\n",
    "    out.sort()\n",
    "    dedup = []; last_t1 = last_t2 = -1e9\n",
    "    for t, tag in out:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# =========================\n",
    "# Dataset helpers\n",
    "# =========================\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR+MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "def extract_base_trials_from_run(edf_path: Path, scenario: str, window_global=(0.0,4.0)):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF'): return []\n",
    "\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None: return []\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    out = []\n",
    "    events = collect_events_T1T2(raw)\n",
    "    rel_start, rel_end = window_global\n",
    "    ev_idx = 0\n",
    "    for onset_sec, tag in events:\n",
    "        ev_idx += 1\n",
    "        if kind == 'LR':\n",
    "            label = 0 if tag=='T1' else 1\n",
    "        else:\n",
    "            label = 2 if tag=='T1' else 3\n",
    "        if   scenario == '2c' and label not in (0,1): continue\n",
    "        elif scenario == '3c' and label not in (0,1,2): continue\n",
    "        elif scenario == '4c' and label not in (0,1,2,3): continue\n",
    "\n",
    "        s0 = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "        e0 = int(round((raw.first_time + onset_sec + rel_end)   * fs))\n",
    "        if s0 < 0 or e0 > data.shape[1] or e0 <= s0: continue\n",
    "\n",
    "        seg = data[:, s0:e0].T.astype(np.float32)  # (T_base, C)\n",
    "        seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "        trial_key = f\"S{subj:03d}_R{run:02d}_E{ev_idx:03d}\"\n",
    "        out.append((seg, label, subj, trial_key))\n",
    "    return out\n",
    "\n",
    "def build_balanced_trials(subjects, scenario='4c', window_global=(0.0,4.0), n_per_class=N_PER_CLASS_PER_SUBJECT):\n",
    "    trials_balanced = []\n",
    "    for s in tqdm(subjects, desc=\"Recolectando y balanceando ensayos base por sujeto\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "        bins = {0:[],1:[],2:[],3:[]}\n",
    "        for r in (MI_RUNS_LR + MI_RUNS_OF):\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            for t in extract_base_trials_from_run(p, scenario, window_global):\n",
    "                bins[t[1]].append(t)\n",
    "        # descarta sujeto si no tiene todas las clases\n",
    "        if any(len(bins[c]) == 0 for c in (0,1,2,3)): continue\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        for c in (0,1,2,3):\n",
    "            pool = bins[c]\n",
    "            if len(pool) >= n_per_class:\n",
    "                rng.shuffle(pool); take = pool[:n_per_class]\n",
    "            else:\n",
    "                idx = rng.choice(len(pool), size=n_per_class, replace=True)\n",
    "                take = [pool[i] for i in idx]\n",
    "            trials_balanced.extend(take)\n",
    "    print(f\"Ensayos base balanceados: {len(trials_balanced)}  (~ #sujetos_utiles * {n_per_class*4})\")\n",
    "    return trials_balanced\n",
    "\n",
    "def window_trials(trials, win_len_sec=2.0, win_stride_sec=0.5, fs=160.0):\n",
    "    \"\"\"Windowing para una lista de ensayos (de un split). Retorna X,y,subj,trial_ids.\"\"\"\n",
    "    X, y, g, tkeys = [], [], [], []\n",
    "    win_len = int(round(win_len_sec * fs))\n",
    "    stride  = int(round(win_stride_sec * fs))\n",
    "    for seg, lab, subj, tkey in trials:\n",
    "        T = seg.shape[0]\n",
    "        starts = [i for i in range(0, T - win_len + 1, stride)]\n",
    "        # asegura N_SUBWINS por ensayo\n",
    "        if len(starts) > N_SUBWINS: starts = starts[:N_SUBWINS]\n",
    "        while len(starts) < N_SUBWINS and (T - win_len) >= 0:\n",
    "            starts.append(T - win_len)\n",
    "        for s in starts:\n",
    "            e = s + win_len\n",
    "            sub = seg[s:e, :].astype(np.float32)\n",
    "            sub = (sub - sub.mean(axis=0, keepdims=True)) / (sub.std(axis=0, keepdims=True) + 1e-6)\n",
    "            X.append(sub); y.append(lab); g.append(subj); tkeys.append(tkey)\n",
    "    uniq = {k:i for i,k in enumerate(sorted(set(tkeys)))}\n",
    "    trial_ids = np.asarray([uniq[k] for k in tkeys], dtype=np.int64)\n",
    "    X = np.stack(X, axis=0).astype(np.float32)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    g = np.asarray(g, dtype=np.int64)\n",
    "    return X, y, g, trial_ids, uniq\n",
    "\n",
    "# =========================\n",
    "# Dataset torch\n",
    "# =========================\n",
    "class EEGTrials(Dataset):\n",
    "    def __init__(self, X, y, groups, trial_ids):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "        self.t = trial_ids.astype(np.int64)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]; x = np.expand_dims(x, 0)  # (1,Tw,C)\n",
    "        return torch.from_numpy(x), torch.tensor(self.y[idx]), torch.tensor(self.g[idx]), torch.tensor(self.t[idx])\n",
    "\n",
    "def build_weighted_sampler(y, groups):\n",
    "    y = np.asarray(y); groups = np.asarray(groups)\n",
    "    class_counts = np.bincount(y, minlength=len(np.unique(y))).astype(float)\n",
    "    class_w = 1.0 / class_counts[y]\n",
    "    subj_vals, subj_counts = np.unique(groups, return_counts=True)\n",
    "    subj_map = {s:c for s,c in zip(subj_vals, subj_counts)}\n",
    "    subj_w = np.array([1.0/subj_map[g] for g in groups], dtype=float)\n",
    "    w = class_w * subj_w; w = w / w.mean()\n",
    "    return WeightedRandomSampler(weights=torch.from_numpy(w).float(), num_samples=len(w), replacement=True)\n",
    "\n",
    "# =========================\n",
    "# Modelo: CNN + Transformer\n",
    "# =========================\n",
    "class ChannelDropout(nn.Module):\n",
    "    def __init__(self, p=0.1): super().__init__(); self.p = p\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p<=0: return x\n",
    "        B,_,T,C = x.shape\n",
    "        mask = (torch.rand(B,1,1,C, device=x.device) > self.p).float()\n",
    "        return x * mask\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_max_norm(model, max_value=2.0, p=2.0):\n",
    "    for m in model.modules():\n",
    "        if hasattr(m,'weight') and isinstance(m,(nn.Conv2d, nn.Linear)):\n",
    "            w = m.weight.data\n",
    "            norms = w.view(w.size(0), -1).norm(p=p, dim=1, keepdim=True)\n",
    "            desired = torch.clamp(norms, max=max_value)\n",
    "            w.view(w.size(0), -1).mul_(desired / (1e-8 + norms))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 4000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)\n",
    "    def forward(self, x):\n",
    "        T = x.size(1); return x + self.pe[:, :T, :]\n",
    "\n",
    "class CNNTokenizer(nn.Module):\n",
    "    def __init__(self, n_ch: int, d_feat: int = 128, k_temporal: int = 128, stride_t: int = 4, chdrop_p: float = 0.1, drop_p: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.chdrop = ChannelDropout(chdrop_p)\n",
    "        self.conv_t = nn.Conv2d(1, d_feat, kernel_size=(k_temporal,1), stride=(stride_t,1), padding=(k_temporal//2,0), bias=False)\n",
    "        self.bn_t   = nn.BatchNorm2d(d_feat, momentum=0.99, eps=1e-3)\n",
    "        self.act    = nn.ELU()\n",
    "        self.conv_sp_dw = nn.Conv2d(d_feat, d_feat, kernel_size=(1,n_ch), groups=d_feat, bias=False)\n",
    "        self.bn_sp      = nn.BatchNorm2d(d_feat, momentum=0.99, eps=1e-3)\n",
    "        self.conv_pw = nn.Conv2d(d_feat, d_feat, kernel_size=(1,1), bias=False)\n",
    "        self.bn_pw   = nn.BatchNorm2d(d_feat, momentum=0.99, eps=1e-3)\n",
    "        self.drop    = nn.Dropout(drop_p)\n",
    "    def forward(self, x):\n",
    "        z = self.chdrop(x)\n",
    "        z = self.conv_t(z); z = self.bn_t(z); z = self.act(z)         # (B,D,T',C)\n",
    "        z = self.conv_sp_dw(z); z = self.bn_sp(z); z = self.act(z)    # (B,D,T',1)\n",
    "        z = self.conv_pw(z); z = self.bn_pw(z); z = self.act(z)\n",
    "        z = self.drop(z)\n",
    "        z = z.squeeze(-1).transpose(1,2)  # (B,T',D)\n",
    "        return z\n",
    "\n",
    "def _enc_layer(d_model=128, nhead=4, dim_ff=256, drop=0.2):\n",
    "    return nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_ff,\n",
    "                                      dropout=drop, activation='gelu', batch_first=True, norm_first=True)\n",
    "\n",
    "class TemporalTransformer(nn.Module):\n",
    "    def __init__(self, d_model=128, nhead=4, dim_ff=256, depth=3, drop=0.2):\n",
    "        super().__init__()\n",
    "        self.pe = PositionalEncoding(d_model)\n",
    "        layer = _enc_layer(d_model, nhead, dim_ff, drop)\n",
    "        self.enc = nn.TransformerEncoder(layer, num_layers=depth)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.pe(x)\n",
    "        x = self.enc(x)\n",
    "        return self.norm(x)\n",
    "\n",
    "class HybridCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch: int, n_classes: int, seq_len: int,\n",
    "                 d_model: int = 128, nhead: int = 4, depth: int = 3,\n",
    "                 dim_ff: int = 256, k_temporal: int = 128, stride_t: int = 4,\n",
    "                 drop: float = 0.2, chdrop_p: float = 0.1, use_cls_token: bool = False):\n",
    "        super().__init__()\n",
    "        self.use_cls = use_cls_token\n",
    "        self.tokenizer = CNNTokenizer(n_ch, d_model, k_temporal, stride_t, chdrop_p, drop)\n",
    "        self.cls = nn.Parameter(torch.zeros(1,1,d_model)) if use_cls_token else None\n",
    "        self.transformer = TemporalTransformer(d_model, nhead, dim_ff, depth, drop)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(d_model, n_classes)\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        tok = self.tokenizer(x)                   # (B,T',D)\n",
    "        if self.use_cls:\n",
    "            B = tok.size(0); cls_tok = self.cls.expand(B,-1,-1)\n",
    "            tok = torch.cat([cls_tok, tok], dim=1)\n",
    "        z = self.transformer(tok)\n",
    "        feat = z[:,0,:] if self.use_cls else z.mean(dim=1)\n",
    "        return self.head(feat)\n",
    "\n",
    "# =========================\n",
    "# Entrenamiento / Eval\n",
    "# =========================\n",
    "class SoftCE(nn.Module):\n",
    "    def __init__(self, n_classes: int, label_smoothing: float = 0.05, class_weights: torch.Tensor | None = None):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.ls = float(label_smoothing)\n",
    "        self.register_buffer('w', class_weights if class_weights is not None else None)\n",
    "    def forward(self, logits, targets_idx):\n",
    "        B, C = logits.size()\n",
    "        yt = F.one_hot(targets_idx, num_classes=C).float()\n",
    "        if self.ls > 0: yt = (1 - self.ls) * yt + self.ls * (1.0 / C)\n",
    "        logp = F.log_softmax(logits, dim=1)\n",
    "        loss = -(yt * logp)\n",
    "        if self.w is not None: loss = loss * self.w.unsqueeze(0)\n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def _predict_tta(model, xb, n=5, fs=160.0):\n",
    "    def time_jitter(x, max_ms=25):\n",
    "        max_shift = int(round(max_ms/1000.0 * fs))\n",
    "        if max_shift <= 0: return x\n",
    "        B,_,T,C = x.shape\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=x.device)\n",
    "        out = torch.zeros_like(x)\n",
    "        for i,s in enumerate(shifts):\n",
    "            if s >= 0: out[i,:,s:,:] = x[i,:,:T-s,:]\n",
    "            else: s=-s; out[i,:,:T-s,:] = x[i,:,s:,:]\n",
    "        return out\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        outs.append(model(time_jitter(xb,25)))\n",
    "    return torch.stack(outs, dim=0).mean(dim=0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_per_trial(model, loader, use_tta=True, tta_n=5, n_classes=4):\n",
    "    model.eval()\n",
    "    sums, counts, labels = {}, {}, {}\n",
    "    for xb, yb, _, tb in loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        logits = _predict_tta(model, xb, n=tta_n) if use_tta else model(xb)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        yb = yb.numpy(); tb = tb.numpy()\n",
    "        for i in range(xb.size(0)):\n",
    "            t = int(tb[i])\n",
    "            if t not in sums:\n",
    "                sums[t] = np.zeros((n_classes,), dtype=np.float64)\n",
    "                counts[t] = 0\n",
    "                labels[t] = int(yb[i])\n",
    "            sums[t] += logits[i]; counts[t] += 1\n",
    "    ids = sorted(sums.keys())\n",
    "    y_true_trial = np.asarray([labels[t] for t in ids], dtype=int)\n",
    "    y_pred_trial = np.asarray([int((sums[t]/max(1,counts[t])).argmax()) for t in ids], dtype=int)\n",
    "    acc = (y_true_trial == y_pred_trial).mean()\n",
    "    return y_true_trial, y_pred_trial, float(acc)\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45, ha='right'); plt.yticks(ticks, classes)\n",
    "    fmt = '.2f'; thresh = cm_norm.max()/2.\n",
    "    for i,j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j,i,format(cm_norm[i,j],fmt),ha=\"center\", color=\"white\" if cm_norm[i,j]>thresh else \"black\")\n",
    "    plt.ylabel('True'); plt.xlabel('Pred'); plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "def print_report(y_true, y_pred, classes, tag=\"\"):\n",
    "    print(f\"\\n=== Reporte {tag} ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n",
    "    print(f\"F1-macro: {f1_score(y_true, y_pred, average='macro'):.4f} | Kappa: {cohen_kappa_score(y_true,y_pred):.4f}\")\n",
    "\n",
    "# =========================\n",
    "# FT (L2-SP), SIN fuga (agrupa por ensayo)\n",
    "# =========================\n",
    "def _freeze_for_mode(model: HybridCNNTransformer, mode: str):\n",
    "    for p in model.parameters(): p.requires_grad = False\n",
    "    if   mode=='out':\n",
    "        for p in model.head[-1].parameters(): p.requires_grad = True\n",
    "    elif mode=='head':\n",
    "        for p in model.head.parameters(): p.requires_grad = True\n",
    "    elif mode=='cnn+trans+head':\n",
    "        for p in model.tokenizer.parameters():   p.requires_grad = True\n",
    "        for p in model.transformer.parameters(): p.requires_grad = True\n",
    "        for p in model.head.parameters():        p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "def _param_groups(model: HybridCNNTransformer, mode: str):\n",
    "    if   mode=='out': return list(model.head[-1].parameters())\n",
    "    elif mode=='head': return list(model.head.parameters())\n",
    "    elif mode=='cnn+trans+head': \n",
    "        return list(model.tokenizer.parameters()) + list(model.transformer.parameters()) + list(model.head.parameters())\n",
    "\n",
    "def finetune_l2sp(model_global: HybridCNNTransformer, Xcal, ycal, trial_ids_cal,\n",
    "                  n_classes: int, mode='head', epochs=FT_EPOCHS, batch_size=32,\n",
    "                  base_lr=FT_BASE_LR, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                  val_ratio=FT_VAL_RATIO, seed=RANDOM_STATE, device=DEVICE):\n",
    "    # split interno sin fuga: por ensayo (GroupShuffleSplit)\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=val_ratio, random_state=seed)\n",
    "    (tr_idx, va_idx), = gss.split(Xcal, ycal, groups=trial_ids_cal)\n",
    "    Xtr, ytr = Xcal[tr_idx], ycal[tr_idx]\n",
    "    Xva, yva = Xcal[va_idx], ycal[va_idx]\n",
    "\n",
    "    ds_tr = torch.utils.data.TensorDataset(torch.from_numpy(Xtr).float().unsqueeze(1),\n",
    "                                           torch.from_numpy(ytr).long())\n",
    "    ds_va = torch.utils.data.TensorDataset(torch.from_numpy(Xva).float().unsqueeze(1),\n",
    "                                           torch.from_numpy(yva).long())\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = copy.deepcopy(model_global).to(device)\n",
    "    _freeze_for_mode(model, mode)\n",
    "    params = _param_groups(model, mode)\n",
    "\n",
    "    if mode=='cnn+trans+head':\n",
    "        tok_params = list(model.tokenizer.parameters()) + list(model.transformer.parameters())\n",
    "        head_params = list(model.head.parameters())\n",
    "        opt = torch.optim.Adam([\n",
    "            {'params': tok_params,  'lr': base_lr},\n",
    "            {'params': head_params, 'lr': head_lr},\n",
    "        ])\n",
    "        train_params = tok_params + head_params\n",
    "    else:\n",
    "        opt = torch.optim.Adam(params, lr=head_lr)\n",
    "        train_params = params\n",
    "\n",
    "    ref = [p.detach().clone().to(device) for p in train_params]   # L2-SP ref\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_state, best_val, bad = copy.deepcopy(model.state_dict()), float('inf'), 0\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in dl_tr:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            reg = 0.0\n",
    "            for p_cur, p_ref in zip(train_params, ref):\n",
    "                reg = reg + torch.sum((p_cur - p_ref)**2)\n",
    "            (loss + l2sp_lambda*reg).backward(); opt.step()\n",
    "            apply_max_norm(model, 2.0, p=2.0)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, nval = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_va:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                val_loss += F.cross_entropy(model(xb), yb).item() * xb.size(0)\n",
    "                nval += xb.size(0)\n",
    "        val_loss /= max(1,nval)\n",
    "        if val_loss + 1e-7 < best_val: best_val, bad, best_state = val_loss, 0, copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= FT_PATIENCE: break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# Folds JSON: SOLO sujetos (ignora índices)\n",
    "# =========================\n",
    "def read_folds_subjects_only(json_path, current_subjects):\n",
    "    \"\"\"\n",
    "    Lee Kfold5.json y devuelve lista de folds con train_subjects/test_subjects (enteros).\n",
    "    Ignora por completo tr_idx/te_idx si existen.\n",
    "    Valida que los sujetos existan en el dataset actual.\n",
    "    \"\"\"\n",
    "    p = Path(json_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"No existe {p}. Debes proporcionar un JSON con sujetos por fold.\")\n",
    "    with open(p, 'r', encoding='utf-8') as f:\n",
    "        payload = json.load(f)\n",
    "    folds_raw = payload.get('folds', [])\n",
    "    if not folds_raw:\n",
    "        raise ValueError(\"JSON no contiene 'folds'.\")\n",
    "\n",
    "    cur_set = set(current_subjects)\n",
    "    folds = []\n",
    "    for fr in folds_raw:\n",
    "        train_s = fr.get('train_subjects', fr.get('train', []))\n",
    "        test_s  = fr.get('test_subjects',  fr.get('test',  []))\n",
    "        if not train_s or not test_s:\n",
    "            raise ValueError(\"Cada fold debe tener 'train_subjects' y 'test_subjects' (o 'train'/'test').\")\n",
    "\n",
    "        def to_int_list(lst):\n",
    "            out = []\n",
    "            for s in lst:\n",
    "                if isinstance(s, int): out.append(s)\n",
    "                elif isinstance(s, str) and s.upper().startswith('S') and s[1:].isdigit():\n",
    "                    out.append(int(s[1:]))\n",
    "                elif isinstance(s, str) and s.isdigit():\n",
    "                    out.append(int(s))\n",
    "                else:\n",
    "                    raise ValueError(f\"Sujeto inválido en JSON: {s}\")\n",
    "            return out\n",
    "\n",
    "        tr_int = to_int_list(train_s)\n",
    "        te_int = to_int_list(test_s)\n",
    "\n",
    "        # validación: sujetos del JSON deben existir\n",
    "        miss_tr = [s for s in tr_int if s not in cur_set]\n",
    "        miss_te = [s for s in te_int if s not in cur_set]\n",
    "        if miss_tr or miss_te:\n",
    "            raise ValueError(f\"Fold con sujetos no presentes en dataset actual. \"\n",
    "                             f\"Faltan en TRAIN: {miss_tr}, Faltan en TEST: {miss_te}\")\n",
    "\n",
    "        folds.append({'fold': fr.get('fold', len(folds)+1),\n",
    "                      'train_subjects': tr_int, 'test_subjects': te_int})\n",
    "    return folds\n",
    "\n",
    "# =========================\n",
    "# Experimento\n",
    "# =========================\n",
    "def plot_training_curves(history, fname):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history['train_acc'], label='train_acc')\n",
    "    plt.plot(history['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Training curve'); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "def run_experiment():\n",
    "    mne.set_log_level('WARNING')\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos elegibles: {len(subs)} → {subs[:10]}{'...' if len(subs)>10 else ''}\")\n",
    "\n",
    "    # 1) Ensayos balanceados (21/clase/sujeto) sobre TODOS los sujetos elegibles\n",
    "    trials_bal = build_balanced_trials(subs, scenario=CLASS_SCENARIO, window_global=WINDOW_GLOBAL,\n",
    "                                       n_per_class=N_PER_CLASS_PER_SUBJECT)\n",
    "\n",
    "    # Sujetos presentes tras balanceo\n",
    "    subj_in_trials = sorted({t[2] for t in trials_bal})\n",
    "    print(f\"Sujetos con ensayos balanceados: {len(subj_in_trials)}\")\n",
    "\n",
    "    # 2) Leer folds SOLO por sujetos\n",
    "    folds = read_folds_subjects_only(FOLDS_JSON, current_subjects=subj_in_trials)\n",
    "\n",
    "    # 3) Loop de folds\n",
    "    global_folds_trial, all_true_trial, all_pred_trial, ft_prog_folds = [], [], [], []\n",
    "\n",
    "    for f in folds:\n",
    "        fold = f['fold']\n",
    "        train_subs = set(f['train_subjects'])\n",
    "        test_subs  = set(f['test_subjects'])\n",
    "\n",
    "        # Split por sujeto (antes de windowing): seleccionamos ensayos (trial-level)\n",
    "        tr_trials = [t for t in trials_bal if t[2] in train_subs]\n",
    "        te_trials = [t for t in trials_bal if t[2] in test_subs]\n",
    "\n",
    "        # Sanity: cada clase presente en TEST por ensayo (antes de windowing)\n",
    "        lbl_te = [t[1] for t in te_trials]\n",
    "        present = {0,1,2,3}.intersection(set(lbl_te))\n",
    "        if present != {0,1,2,3}:\n",
    "            print(f\"[WARN] Fold {fold}: clases en TEST (trial-level) = {sorted(present)}; se salta este fold.\")\n",
    "            continue\n",
    "\n",
    "        # 3a) Split interno de VALID por sujeto dentro de TRAIN (sin fuga de sujetos)\n",
    "        train_subs_list = sorted(list(train_subs))\n",
    "        rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "        rng.shuffle(train_subs_list)\n",
    "        n_va = max(1, int(round(GLOBAL_VAL_SPLIT * len(train_subs_list))))\n",
    "        val_subs = set(train_subs_list[:n_va])\n",
    "        real_train_subs = set(train_subs_list[n_va:])\n",
    "\n",
    "        tr_trials_main = [t for t in tr_trials if t[2] in real_train_subs]\n",
    "        va_trials      = [t for t in tr_trials if t[2] in val_subs]\n",
    "\n",
    "        # 4) Windowing por split (sin fuga entre ensayos)\n",
    "        Xtr, ytr, gtr, ttr, _ = window_trials(trials=tr_trials_main, win_len_sec=WIN_LEN_SEC, win_stride_sec=WIN_STRIDE_SEC, fs=FS)\n",
    "        Xva, yva, gva, tva, _ = window_trials(trials=va_trials,      win_len_sec=WIN_LEN_SEC, win_stride_sec=WIN_STRIDE_SEC, fs=FS)\n",
    "        Xte, yte, gte, tte, _ = window_trials(trials=te_trials,      win_len_sec=WIN_LEN_SEC, win_stride_sec=WIN_STRIDE_SEC, fs=FS)\n",
    "\n",
    "        # DataLoaders\n",
    "        ds_tr = EEGTrials(Xtr, ytr, gtr, ttr)\n",
    "        ds_va = EEGTrials(Xva, yva, gva, tva)\n",
    "        ds_te = EEGTrials(Xte, yte, gte, tte)\n",
    "\n",
    "        tr_loader = DataLoader(ds_tr, batch_size=BATCH_SIZE,\n",
    "                               sampler=build_weighted_sampler(ytr, gtr), drop_last=False)\n",
    "        va_loader = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        te_loader = DataLoader(ds_te, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "        # 5) Modelo\n",
    "        Tw, C = Xtr.shape[1], Xtr.shape[2]\n",
    "        n_classes = len(set(ytr.tolist()) | set(yva.tolist()) | set(yte.tolist()))\n",
    "        model = HybridCNNTransformer(\n",
    "            n_ch=C, n_classes=n_classes, seq_len=Tw,\n",
    "            d_model=128, nhead=4, depth=3, dim_ff=256,\n",
    "            k_temporal=128, stride_t=4, drop=0.2, chdrop_p=0.10, use_cls_token=False\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=LR_INIT)\n",
    "        criterion = SoftCE(n_classes=n_classes, label_smoothing=0.05, class_weights=None)\n",
    "\n",
    "        def _acc_trial(loader): return evaluate_per_trial(model, loader, use_tta=False, n_classes=n_classes)[2]\n",
    "\n",
    "        # 6) Entrenamiento (early stopping por ENSAYO)\n",
    "        history = {'train_acc': [], 'val_acc': []}\n",
    "        print(f\"\\n[Fold {fold}/{len(folds)}] Entrenando global (VAL por ensayo)...\")\n",
    "        best_state = copy.deepcopy(model.state_dict()); best_val = -1.0; bad = 0\n",
    "\n",
    "        for epoch in range(1, EPOCHS_GLOBAL+1):\n",
    "            model.train()\n",
    "            for xb, yb, _, _ in tr_loader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                loss = criterion(model(xb), yb)\n",
    "                opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
    "                apply_max_norm(model, 2.0, p=2.0)\n",
    "\n",
    "            tr_acc = _acc_trial(tr_loader)\n",
    "            va_acc = _acc_trial(va_loader)\n",
    "            history['train_acc'].append(tr_acc); history['val_acc'].append(va_acc)\n",
    "\n",
    "            if epoch % 5 == 0 or epoch in (1,10,20,50,80):\n",
    "                print(f\"  Época {epoch:3d} | train(ensayo)={tr_acc:.4f} | val(ensayo)={va_acc:.4f}\")\n",
    "\n",
    "            if va_acc > best_val + 1e-4:\n",
    "                best_val, bad = va_acc, 0\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= GLOBAL_PATIENCE:\n",
    "                    print(f\"  Early stopping @ epoch {epoch} (best val ensayo={best_val:.4f})\")\n",
    "                    break\n",
    "\n",
    "        plot_training_curves(history, f\"training_curve_cnnTrans_subjFolds_fold{fold}.png\")\n",
    "        print(f\"↳ Curva: training_curve_cnnTrans_subjFolds_fold{fold}.png\")\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # 7) Test por ENSAYO (TTA)\n",
    "        y_true_tr, y_pred_tr, acc_tr = evaluate_per_trial(model, te_loader, use_tta=True, tta_n=5, n_classes=n_classes)\n",
    "        global_folds_trial.append(acc_tr)\n",
    "        all_true_trial.append(y_true_tr); all_pred_trial.append(y_pred_tr)\n",
    "        print(f\"[Fold {fold}] Ensayo acc={acc_tr:.4f}\")\n",
    "        print_report(y_true_tr, y_pred_tr, CLASS_NAMES, tag=\"por ENSAYO (agregado)\")\n",
    "\n",
    "        # 8) FT por sujeto (sin fuga, agrupando por ensayo)\n",
    "        #    Trabajamos dentro del set de TEST (por cada sujeto en test_subs)\n",
    "        y_true_ft_all, y_pred_ft_all, used_subjects = [], [], 0\n",
    "\n",
    "        # Para comodidad, indices por sujeto dentro de Xte\n",
    "        trial_to_label = {}\n",
    "        for idx in range(len(Xte)):\n",
    "            trial_to_label[int(tte[idx])] = int(yte[idx])\n",
    "\n",
    "        for sid in sorted(test_subs):\n",
    "            mask_sid = (gte == sid)\n",
    "            if mask_sid.sum() == 0: continue\n",
    "            Xs, ys, ts = Xte[mask_sid], yte[mask_sid], tte[mask_sid]\n",
    "\n",
    "            # GroupKFold por ensayo (sin fuga)\n",
    "            if len(np.unique(ts)) < CALIB_CV_FOLDS:\n",
    "                continue\n",
    "            gkf = GroupKFold(n_splits=CALIB_CV_FOLDS)\n",
    "            for tr_i, ho_i in gkf.split(Xs, ys, groups=ts):\n",
    "                Xcal, ycal, tcal = Xs[tr_i], ys[tr_i], ts[tr_i]\n",
    "                Xho,  yho,  tho  = Xs[ho_i], ys[ho_i], ts[ho_i]\n",
    "\n",
    "                m_head = finetune_l2sp(model, Xcal, ycal, tcal,\n",
    "                                       n_classes=n_classes, mode='head',\n",
    "                                       epochs=FT_EPOCHS, base_lr=FT_BASE_LR, head_lr=FT_HEAD_LR,\n",
    "                                       l2sp_lambda=FT_L2SP, val_ratio=FT_VAL_RATIO, device=DEVICE)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    xb = torch.from_numpy(Xho).float().unsqueeze(1).to(DEVICE)\n",
    "                    logits = m_head(xb).cpu().numpy()\n",
    "\n",
    "                sums = collections.defaultdict(lambda: np.zeros((n_classes,), dtype=np.float64))\n",
    "                counts = collections.defaultdict(int)\n",
    "                labels = {}\n",
    "                for i in range(len(Xho)):\n",
    "                    t = int(tho[i]); sums[t] += logits[i]; counts[t] += 1; labels[t] = int(yho[i])\n",
    "                for t in sums.keys():\n",
    "                    y_pred_ft_all.append(int((sums[t]/max(1,counts[t])).argmax()))\n",
    "                    y_true_ft_all.append(labels[t])\n",
    "                used_subjects += 1\n",
    "\n",
    "        if len(y_true_ft_all) > 0:\n",
    "            y_true_ft_all = np.asarray(y_true_ft_all, dtype=int)\n",
    "            y_pred_ft_all = np.asarray(y_pred_ft_all, dtype=int)\n",
    "            acc_ft = (y_true_ft_all == y_pred_ft_all).mean()\n",
    "            print(f\"  FT progresivo por ENSAYO acc={acc_ft:.4f} | sujetos={used_subjects}\")\n",
    "            print(f\"  Δ(FT-Ensayo - Global-Ensayo) = {acc_ft - acc_tr:+.4f}\")\n",
    "        else:\n",
    "            acc_ft = np.nan\n",
    "            print(\"  FT no ejecutado (fold sin sujetos aptos).\")\n",
    "        ft_prog_folds.append(acc_ft)\n",
    "\n",
    "    # ----- resultados globales -----\n",
    "    if len(all_true_trial)>0: all_true_trial = np.concatenate(all_true_trial); all_pred_trial = np.concatenate(all_pred_trial)\n",
    "    else: all_true_trial = np.array([],dtype=int); all_pred_trial = np.array([],dtype=int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADOS FINALES — CNN+Transformer (21/cls/subj) + Sliding Window + Kfold SUBJECTS-only\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Ensayo folds:\", [f\"{a:.4f}\" for a in global_folds_trial])\n",
    "    if len(global_folds_trial) > 0:\n",
    "        print(f\"Ensayo mean: {np.mean(global_folds_trial):.4f}\")\n",
    "    print(\"FT prog (ensayo) folds:\", [(\"nan\" if (a is None or np.isnan(a)) else f\"{a:.4f}\") for a in ft_prog_folds])\n",
    "    if len(ft_prog_folds) > 0:\n",
    "        print(f\"FT (ensayo) mean: {np.nanmean(ft_prog_folds):.4f}\")\n",
    "        print(f\"Δ(FT-Ensayo - Global-Ensayo) mean: {np.nanmean(ft_prog_folds) - np.mean(global_folds_trial):+.4f}\")\n",
    "\n",
    "    if all_true_trial.size > 0:\n",
    "        plot_confusion(all_true_trial, all_pred_trial, CLASS_NAMES,\n",
    "                       title=\"Confusion Matrix - Global Model (Per Trial, All Folds)\",\n",
    "                       fname=\"confusion_cnnTrans_subjectFolds_trial_allfolds.png\")\n",
    "        print(\"↳ Matriz de confusión (ensayo): confusion_cnnTrans_subjectFolds_trial_allfolds.png\")\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    bp_status = f\"ON [{BP_LO}-{BP_HI} Hz]\" if USE_BANDPASS and (BP_LO is not None) and (BP_HI is not None) else \"OFF\"\n",
    "    print(\"🧠 MI-EEG — CNN+Transformer (21/cls/subj) + Sliding Window + FT progresivo\")\n",
    "    print(f\"🔧 Escenario: {CLASS_SCENARIO} | rango ensayo={WINDOW_GLOBAL} s | subventana={WIN_LEN_SEC}s | stride={WIN_STRIDE_SEC}s | subwins/ensayo={N_SUBWINS} | band-pass={bp_status}\")\n",
    "    print(f\"⚙️  Balance: 21 ensayos por clase y por sujeto (con reemplazo si falta)\")\n",
    "    print(f\"⚙️  FT (sin fuga): GroupKFold por ensayo + GroupShuffleSplit en validación interna\")\n",
    "    run_experiment()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
