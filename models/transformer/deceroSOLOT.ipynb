{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ec3bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸš€ INICIANDO ENTRENAMIENTO CON WINDOW SLIDING ACTIVADO\n",
      "ðŸ”§ ConfiguraciÃ³n Window Sliding: SW_LEN=2.5s, SW_STRIDE=0.3s\n",
      "ðŸŽ¯ Modo: tta\n",
      "\n",
      "============================================================\n",
      "PROCESANDO FOLD 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1:   0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  7.96it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  7.72it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] n_train=5628 | n_val=1260 | n_test=1764\n",
      "ðŸ“Š DistribuciÃ³n de clases - Train: [1407 1407 1407 1407]\n",
      "ðŸ“Š sfreq=160.0 Hz -> patch_size=16 | stride=8\n",
      "ðŸ“Š Pesos Focal Loss: [0.25 0.25 0.25 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2663 | train_acc=0.2562 | val_acc=0.2897 | val_f1m=0.2138\n",
      "  Ã‰poca   2 | train_loss=0.2554 | train_acc=0.2999 | val_acc=0.3595 | val_f1m=0.2781\n",
      "  Ã‰poca   3 | train_loss=0.2382 | train_acc=0.3849 | val_acc=0.4683 | val_f1m=0.4573\n",
      "  Ã‰poca   4 | train_loss=0.2207 | train_acc=0.4563 | val_acc=0.5270 | val_f1m=0.5256\n",
      "  Ã‰poca   5 | train_loss=0.2127 | train_acc=0.4796 | val_acc=0.4825 | val_f1m=0.4785\n",
      "  Ã‰poca   6 | train_loss=0.2063 | train_acc=0.5016 | val_acc=0.5405 | val_f1m=0.5365\n",
      "  Ã‰poca   7 | train_loss=0.2074 | train_acc=0.4915 | val_acc=0.5167 | val_f1m=0.5197\n",
      "  Ã‰poca   8 | train_loss=0.2001 | train_acc=0.5135 | val_acc=0.5071 | val_f1m=0.4783\n",
      "  Ã‰poca   9 | train_loss=0.1991 | train_acc=0.5176 | val_acc=0.5183 | val_f1m=0.5018\n",
      "  Ã‰poca  10 | train_loss=0.1997 | train_acc=0.5091 | val_acc=0.5262 | val_f1m=0.5219\n",
      "  Ã‰poca  11 | train_loss=0.1964 | train_acc=0.5229 | val_acc=0.5071 | val_f1m=0.5030\n",
      "  Ã‰poca  12 | train_loss=0.1945 | train_acc=0.5355 | val_acc=0.5103 | val_f1m=0.5039\n",
      "  Ã‰poca  13 | train_loss=0.1935 | train_acc=0.5350 | val_acc=0.5460 | val_f1m=0.5444\n",
      "  Ã‰poca  14 | train_loss=0.1913 | train_acc=0.5359 | val_acc=0.5190 | val_f1m=0.5162\n",
      "  Ã‰poca  15 | train_loss=0.1884 | train_acc=0.5485 | val_acc=0.5254 | val_f1m=0.5254\n",
      "  Ã‰poca  16 | train_loss=0.1862 | train_acc=0.5574 | val_acc=0.5103 | val_f1m=0.5057\n",
      "  Ã‰poca  17 | train_loss=0.1819 | train_acc=0.5666 | val_acc=0.5317 | val_f1m=0.5250\n",
      "  Ã‰poca  18 | train_loss=0.1849 | train_acc=0.5583 | val_acc=0.4825 | val_f1m=0.4716\n",
      "  Ã‰poca  19 | train_loss=0.1808 | train_acc=0.5665 | val_acc=0.5183 | val_f1m=0.5120\n",
      "  Ã‰poca  20 | train_loss=0.1786 | train_acc=0.5581 | val_acc=0.5206 | val_f1m=0.5188\n",
      "  Ã‰poca  21 | train_loss=0.1796 | train_acc=0.5608 | val_acc=0.5230 | val_f1m=0.5186\n",
      "  Ã‰poca  22 | train_loss=0.1789 | train_acc=0.5663 | val_acc=0.5151 | val_f1m=0.5036\n",
      "  Ã‰poca  23 | train_loss=0.1736 | train_acc=0.5798 | val_acc=0.5071 | val_f1m=0.4774\n",
      "  Ã‰poca  24 | train_loss=0.1715 | train_acc=0.5855 | val_acc=0.5278 | val_f1m=0.5262\n",
      "  Ã‰poca  25 | train_loss=0.1705 | train_acc=0.5878 | val_acc=0.5119 | val_f1m=0.5074\n",
      "  Ã‰poca  26 | train_loss=0.1681 | train_acc=0.5915 | val_acc=0.5373 | val_f1m=0.5221\n",
      "  Ã‰poca  27 | train_loss=0.1643 | train_acc=0.6034 | val_acc=0.5175 | val_f1m=0.5226\n",
      "  Ã‰poca  28 | train_loss=0.1635 | train_acc=0.6013 | val_acc=0.5183 | val_f1m=0.5104\n",
      "  Early stopping en Ã©poca 28 (mejor val_f1m=0.5444)\n",
      "ðŸŽ¯ Evaluando TEST con tta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1764/1764 [00:06<00:00, 253.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] TEST - acc=0.4796, F1-macro=0.4811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5597    0.5850    0.5721       441\n",
      "       right     0.5746    0.4104    0.4788       441\n",
      "  both fists     0.3694    0.4490    0.4053       441\n",
      "   both feet     0.4624    0.4739    0.4681       441\n",
      "\n",
      "    accuracy                         0.4796      1764\n",
      "   macro avg     0.4915    0.4796    0.4811      1764\n",
      "weighted avg     0.4915    0.4796    0.4811      1764\n",
      "\n",
      "Confusion matrix:\n",
      "[[258  32  83  68]\n",
      " [ 48 181 129  83]\n",
      " [ 94  57 198  92]\n",
      " [ 61  45 126 209]]\n",
      "\n",
      "============================================================\n",
      "PROCESANDO FOLD 2/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.18it/s]\n",
      "Cargando val fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.40it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] n_train=5628 | n_val=1260 | n_test=1764\n",
      "ðŸ“Š DistribuciÃ³n de clases - Train: [1407 1407 1407 1407]\n",
      "ðŸ“Š sfreq=160.0 Hz -> patch_size=16 | stride=8\n",
      "ðŸ“Š Pesos Focal Loss: [0.25 0.25 0.25 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2652 | train_acc=0.2596 | val_acc=0.2746 | val_f1m=0.1936\n",
      "  Ã‰poca   2 | train_loss=0.2556 | train_acc=0.3070 | val_acc=0.3857 | val_f1m=0.3809\n",
      "  Ã‰poca   3 | train_loss=0.2313 | train_acc=0.4128 | val_acc=0.4016 | val_f1m=0.3556\n",
      "  Ã‰poca   4 | train_loss=0.2241 | train_acc=0.4387 | val_acc=0.4754 | val_f1m=0.4741\n",
      "  Ã‰poca   5 | train_loss=0.2137 | train_acc=0.4753 | val_acc=0.4603 | val_f1m=0.4314\n",
      "  Ã‰poca   6 | train_loss=0.2130 | train_acc=0.4707 | val_acc=0.4452 | val_f1m=0.4335\n",
      "  Ã‰poca   7 | train_loss=0.2101 | train_acc=0.4801 | val_acc=0.4794 | val_f1m=0.4782\n",
      "  Ã‰poca   8 | train_loss=0.2083 | train_acc=0.4849 | val_acc=0.4571 | val_f1m=0.4328\n",
      "  Ã‰poca   9 | train_loss=0.2048 | train_acc=0.4925 | val_acc=0.4865 | val_f1m=0.4840\n",
      "  Ã‰poca  10 | train_loss=0.2011 | train_acc=0.5050 | val_acc=0.4905 | val_f1m=0.4897\n",
      "  Ã‰poca  11 | train_loss=0.1979 | train_acc=0.5210 | val_acc=0.5262 | val_f1m=0.5183\n",
      "  Ã‰poca  12 | train_loss=0.1947 | train_acc=0.5277 | val_acc=0.5063 | val_f1m=0.5087\n",
      "  Ã‰poca  13 | train_loss=0.1966 | train_acc=0.5258 | val_acc=0.5127 | val_f1m=0.5105\n",
      "  Ã‰poca  14 | train_loss=0.1934 | train_acc=0.5290 | val_acc=0.4651 | val_f1m=0.4574\n",
      "  Ã‰poca  15 | train_loss=0.1920 | train_acc=0.5274 | val_acc=0.4659 | val_f1m=0.4564\n",
      "  Ã‰poca  16 | train_loss=0.1904 | train_acc=0.5295 | val_acc=0.4913 | val_f1m=0.4844\n",
      "  Ã‰poca  17 | train_loss=0.1924 | train_acc=0.5323 | val_acc=0.4794 | val_f1m=0.4675\n",
      "  Ã‰poca  18 | train_loss=0.1869 | train_acc=0.5412 | val_acc=0.4651 | val_f1m=0.4217\n",
      "  Ã‰poca  19 | train_loss=0.1869 | train_acc=0.5386 | val_acc=0.4897 | val_f1m=0.4757\n",
      "  Ã‰poca  20 | train_loss=0.1829 | train_acc=0.5540 | val_acc=0.5063 | val_f1m=0.5087\n",
      "  Ã‰poca  21 | train_loss=0.1775 | train_acc=0.5577 | val_acc=0.4944 | val_f1m=0.4965\n",
      "  Ã‰poca  22 | train_loss=0.1800 | train_acc=0.5613 | val_acc=0.4833 | val_f1m=0.4836\n",
      "  Ã‰poca  23 | train_loss=0.1745 | train_acc=0.5736 | val_acc=0.5008 | val_f1m=0.4905\n",
      "  Ã‰poca  24 | train_loss=0.1755 | train_acc=0.5760 | val_acc=0.4873 | val_f1m=0.4820\n",
      "  Ã‰poca  25 | train_loss=0.1733 | train_acc=0.5789 | val_acc=0.5127 | val_f1m=0.5059\n",
      "  Ã‰poca  26 | train_loss=0.1705 | train_acc=0.5824 | val_acc=0.4944 | val_f1m=0.4913\n",
      "  Early stopping en Ã©poca 26 (mejor val_f1m=0.5183)\n",
      "ðŸŽ¯ Evaluando TEST con tta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1764/1764 [00:07<00:00, 251.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] TEST - acc=0.5204, F1-macro=0.5058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5127    0.7778    0.6180       441\n",
      "       right     0.5768    0.5873    0.5820       441\n",
      "  both fists     0.4539    0.4127    0.4323       441\n",
      "   both feet     0.5469    0.3039    0.3907       441\n",
      "\n",
      "    accuracy                         0.5204      1764\n",
      "   macro avg     0.5226    0.5204    0.5058      1764\n",
      "weighted avg     0.5226    0.5204    0.5058      1764\n",
      "\n",
      "Confusion matrix:\n",
      "[[343  26  49  23]\n",
      " [ 61 259  76  45]\n",
      " [152  64 182  43]\n",
      " [113 100  94 134]]\n",
      "\n",
      "============================================================\n",
      "PROCESANDO FOLD 3/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  8.38it/s]\n",
      "Cargando val fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.39it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] n_train=5628 | n_val=1260 | n_test=1764\n",
      "ðŸ“Š DistribuciÃ³n de clases - Train: [1407 1407 1407 1407]\n",
      "ðŸ“Š sfreq=160.0 Hz -> patch_size=16 | stride=8\n",
      "ðŸ“Š Pesos Focal Loss: [0.25 0.25 0.25 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2663 | train_acc=0.2496 | val_acc=0.2635 | val_f1m=0.1613\n",
      "  Ã‰poca   2 | train_loss=0.2494 | train_acc=0.3351 | val_acc=0.3524 | val_f1m=0.3445\n",
      "  Ã‰poca   3 | train_loss=0.2290 | train_acc=0.4275 | val_acc=0.4048 | val_f1m=0.3895\n",
      "  Ã‰poca   4 | train_loss=0.2179 | train_acc=0.4598 | val_acc=0.4111 | val_f1m=0.4035\n",
      "  Ã‰poca   5 | train_loss=0.2136 | train_acc=0.4783 | val_acc=0.4365 | val_f1m=0.4378\n",
      "  Ã‰poca   6 | train_loss=0.2064 | train_acc=0.4998 | val_acc=0.4381 | val_f1m=0.4213\n",
      "  Ã‰poca   7 | train_loss=0.2024 | train_acc=0.5046 | val_acc=0.4468 | val_f1m=0.4404\n",
      "  Ã‰poca   8 | train_loss=0.1977 | train_acc=0.5194 | val_acc=0.4429 | val_f1m=0.4369\n",
      "  Ã‰poca   9 | train_loss=0.1922 | train_acc=0.5275 | val_acc=0.4286 | val_f1m=0.4148\n",
      "  Ã‰poca  10 | train_loss=0.1926 | train_acc=0.5299 | val_acc=0.4698 | val_f1m=0.4618\n",
      "  Ã‰poca  11 | train_loss=0.1881 | train_acc=0.5462 | val_acc=0.4619 | val_f1m=0.4527\n",
      "  Ã‰poca  12 | train_loss=0.1835 | train_acc=0.5574 | val_acc=0.4278 | val_f1m=0.4215\n",
      "  Ã‰poca  13 | train_loss=0.1838 | train_acc=0.5517 | val_acc=0.4429 | val_f1m=0.4413\n",
      "  Ã‰poca  14 | train_loss=0.1841 | train_acc=0.5558 | val_acc=0.4159 | val_f1m=0.4059\n",
      "  Ã‰poca  15 | train_loss=0.1775 | train_acc=0.5686 | val_acc=0.4476 | val_f1m=0.4502\n",
      "  Ã‰poca  16 | train_loss=0.1766 | train_acc=0.5737 | val_acc=0.4437 | val_f1m=0.4382\n",
      "  Ã‰poca  17 | train_loss=0.1771 | train_acc=0.5693 | val_acc=0.4270 | val_f1m=0.4264\n",
      "  Ã‰poca  18 | train_loss=0.1710 | train_acc=0.5908 | val_acc=0.4381 | val_f1m=0.4350\n",
      "  Ã‰poca  19 | train_loss=0.1694 | train_acc=0.5842 | val_acc=0.4413 | val_f1m=0.4325\n",
      "  Ã‰poca  20 | train_loss=0.1656 | train_acc=0.5997 | val_acc=0.4444 | val_f1m=0.4476\n",
      "  Ã‰poca  21 | train_loss=0.1628 | train_acc=0.6111 | val_acc=0.4254 | val_f1m=0.3996\n",
      "  Ã‰poca  22 | train_loss=0.1587 | train_acc=0.6173 | val_acc=0.4460 | val_f1m=0.4448\n",
      "  Ã‰poca  23 | train_loss=0.1573 | train_acc=0.6269 | val_acc=0.4349 | val_f1m=0.4371\n",
      "  Ã‰poca  24 | train_loss=0.1538 | train_acc=0.6340 | val_acc=0.4381 | val_f1m=0.4369\n",
      "  Ã‰poca  25 | train_loss=0.1464 | train_acc=0.6425 | val_acc=0.4563 | val_f1m=0.4589\n",
      "  Early stopping en Ã©poca 25 (mejor val_f1m=0.4618)\n",
      "ðŸŽ¯ Evaluando TEST con tta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1764/1764 [00:06<00:00, 253.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] TEST - acc=0.4705, F1-macro=0.4641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5021    0.5351    0.5181       441\n",
      "       right     0.5000    0.6213    0.5541       441\n",
      "  both fists     0.4387    0.3243    0.3729       441\n",
      "   both feet     0.4214    0.4014    0.4111       441\n",
      "\n",
      "    accuracy                         0.4705      1764\n",
      "   macro avg     0.4656    0.4705    0.4641      1764\n",
      "weighted avg     0.4656    0.4705    0.4641      1764\n",
      "\n",
      "Confusion matrix:\n",
      "[[236  62  75  68]\n",
      " [ 40 274  49  78]\n",
      " [102  99 143  97]\n",
      " [ 92 113  59 177]]\n",
      "\n",
      "============================================================\n",
      "PROCESANDO FOLD 4/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  8.41it/s]\n",
      "Cargando val fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.47it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] n_train=5712 | n_val=1260 | n_test=1680\n",
      "ðŸ“Š DistribuciÃ³n de clases - Train: [1428 1428 1428 1428]\n",
      "ðŸ“Š sfreq=160.0 Hz -> patch_size=16 | stride=8\n",
      "ðŸ“Š Pesos Focal Loss: [0.25 0.25 0.25 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2660 | train_acc=0.2544 | val_acc=0.2532 | val_f1m=0.1128\n",
      "  Ã‰poca   2 | train_loss=0.2522 | train_acc=0.3235 | val_acc=0.3825 | val_f1m=0.3818\n",
      "  Ã‰poca   3 | train_loss=0.2296 | train_acc=0.4205 | val_acc=0.4238 | val_f1m=0.4064\n",
      "  Ã‰poca   4 | train_loss=0.2139 | train_acc=0.4774 | val_acc=0.4286 | val_f1m=0.4276\n",
      "  Ã‰poca   5 | train_loss=0.2114 | train_acc=0.4834 | val_acc=0.4357 | val_f1m=0.4337\n",
      "  Ã‰poca   6 | train_loss=0.2087 | train_acc=0.4914 | val_acc=0.4373 | val_f1m=0.4306\n",
      "  Ã‰poca   7 | train_loss=0.2086 | train_acc=0.4970 | val_acc=0.4611 | val_f1m=0.4572\n",
      "  Ã‰poca   8 | train_loss=0.2026 | train_acc=0.5116 | val_acc=0.4548 | val_f1m=0.4378\n",
      "  Ã‰poca   9 | train_loss=0.2014 | train_acc=0.5165 | val_acc=0.4556 | val_f1m=0.4569\n",
      "  Ã‰poca  10 | train_loss=0.1970 | train_acc=0.5235 | val_acc=0.4698 | val_f1m=0.4693\n",
      "  Ã‰poca  11 | train_loss=0.1950 | train_acc=0.5221 | val_acc=0.4397 | val_f1m=0.4155\n",
      "  Ã‰poca  12 | train_loss=0.1925 | train_acc=0.5361 | val_acc=0.4611 | val_f1m=0.4596\n",
      "  Ã‰poca  13 | train_loss=0.1888 | train_acc=0.5488 | val_acc=0.4571 | val_f1m=0.4597\n",
      "  Ã‰poca  14 | train_loss=0.1905 | train_acc=0.5326 | val_acc=0.4794 | val_f1m=0.4739\n",
      "  Ã‰poca  15 | train_loss=0.1893 | train_acc=0.5520 | val_acc=0.4532 | val_f1m=0.4482\n",
      "  Ã‰poca  16 | train_loss=0.1890 | train_acc=0.5450 | val_acc=0.4746 | val_f1m=0.4712\n",
      "  Ã‰poca  17 | train_loss=0.1842 | train_acc=0.5523 | val_acc=0.4849 | val_f1m=0.4821\n",
      "  Ã‰poca  18 | train_loss=0.1841 | train_acc=0.5511 | val_acc=0.4651 | val_f1m=0.4654\n",
      "  Ã‰poca  19 | train_loss=0.1803 | train_acc=0.5669 | val_acc=0.4603 | val_f1m=0.4621\n",
      "  Ã‰poca  20 | train_loss=0.1759 | train_acc=0.5798 | val_acc=0.4571 | val_f1m=0.4545\n",
      "  Ã‰poca  21 | train_loss=0.1780 | train_acc=0.5728 | val_acc=0.4659 | val_f1m=0.4614\n",
      "  Ã‰poca  22 | train_loss=0.1723 | train_acc=0.5825 | val_acc=0.4444 | val_f1m=0.4301\n",
      "  Ã‰poca  23 | train_loss=0.1735 | train_acc=0.5760 | val_acc=0.4738 | val_f1m=0.4719\n",
      "  Ã‰poca  24 | train_loss=0.1691 | train_acc=0.5895 | val_acc=0.4810 | val_f1m=0.4806\n",
      "  Ã‰poca  25 | train_loss=0.1650 | train_acc=0.6050 | val_acc=0.4754 | val_f1m=0.4756\n",
      "  Ã‰poca  26 | train_loss=0.1633 | train_acc=0.6080 | val_acc=0.4532 | val_f1m=0.4272\n",
      "  Ã‰poca  27 | train_loss=0.1604 | train_acc=0.6171 | val_acc=0.4690 | val_f1m=0.4635\n",
      "  Ã‰poca  28 | train_loss=0.1578 | train_acc=0.6159 | val_acc=0.4651 | val_f1m=0.4645\n",
      "  Ã‰poca  29 | train_loss=0.1534 | train_acc=0.6343 | val_acc=0.4706 | val_f1m=0.4660\n",
      "  Ã‰poca  30 | train_loss=0.1521 | train_acc=0.6353 | val_acc=0.4770 | val_f1m=0.4756\n",
      "  Ã‰poca  31 | train_loss=0.1509 | train_acc=0.6359 | val_acc=0.4778 | val_f1m=0.4667\n",
      "  Ã‰poca  32 | train_loss=0.1447 | train_acc=0.6514 | val_acc=0.4516 | val_f1m=0.4401\n",
      "  Early stopping en Ã©poca 32 (mejor val_f1m=0.4821)\n",
      "ðŸŽ¯ Evaluando TEST con tta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1680/1680 [00:06<00:00, 253.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] TEST - acc=0.5155, F1-macro=0.5169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5986    0.6214    0.6098       420\n",
      "       right     0.6160    0.5310    0.5703       420\n",
      "  both fists     0.4254    0.4619    0.4429       420\n",
      "   both feet     0.4413    0.4476    0.4444       420\n",
      "\n",
      "    accuracy                         0.5155      1680\n",
      "   macro avg     0.5203    0.5155    0.5169      1680\n",
      "weighted avg     0.5203    0.5155    0.5169      1680\n",
      "\n",
      "Confusion matrix:\n",
      "[[261  23  73  63]\n",
      " [ 36 223  77  84]\n",
      " [ 77  58 194  91]\n",
      " [ 62  58 112 188]]\n",
      "\n",
      "============================================================\n",
      "PROCESANDO FOLD 5/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  8.48it/s]\n",
      "Cargando val fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.53it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] n_train=5712 | n_val=1260 | n_test=1680\n",
      "ðŸ“Š DistribuciÃ³n de clases - Train: [1428 1428 1428 1428]\n",
      "ðŸ“Š sfreq=160.0 Hz -> patch_size=16 | stride=8\n",
      "ðŸ“Š Pesos Focal Loss: [0.25 0.25 0.25 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2662 | train_acc=0.2512 | val_acc=0.2635 | val_f1m=0.1674\n",
      "  Ã‰poca   2 | train_loss=0.2598 | train_acc=0.2847 | val_acc=0.3413 | val_f1m=0.3144\n",
      "  Ã‰poca   3 | train_loss=0.2389 | train_acc=0.3972 | val_acc=0.5246 | val_f1m=0.5147\n",
      "  Ã‰poca   4 | train_loss=0.2215 | train_acc=0.4550 | val_acc=0.5317 | val_f1m=0.5047\n",
      "  Ã‰poca   5 | train_loss=0.2191 | train_acc=0.4582 | val_acc=0.5579 | val_f1m=0.5350\n",
      "  Ã‰poca   6 | train_loss=0.2199 | train_acc=0.4520 | val_acc=0.5730 | val_f1m=0.5713\n",
      "  Ã‰poca   7 | train_loss=0.2152 | train_acc=0.4662 | val_acc=0.5429 | val_f1m=0.5359\n",
      "  Ã‰poca   8 | train_loss=0.2126 | train_acc=0.4727 | val_acc=0.5556 | val_f1m=0.5337\n",
      "  Ã‰poca   9 | train_loss=0.2111 | train_acc=0.4781 | val_acc=0.5294 | val_f1m=0.5079\n",
      "  Ã‰poca  10 | train_loss=0.2058 | train_acc=0.4965 | val_acc=0.5460 | val_f1m=0.5239\n",
      "  Ã‰poca  11 | train_loss=0.2066 | train_acc=0.4907 | val_acc=0.5476 | val_f1m=0.5442\n",
      "  Ã‰poca  12 | train_loss=0.2016 | train_acc=0.5021 | val_acc=0.5230 | val_f1m=0.5147\n",
      "  Ã‰poca  13 | train_loss=0.2016 | train_acc=0.5014 | val_acc=0.5468 | val_f1m=0.5385\n",
      "  Ã‰poca  14 | train_loss=0.2019 | train_acc=0.5032 | val_acc=0.5571 | val_f1m=0.5589\n",
      "  Ã‰poca  15 | train_loss=0.2001 | train_acc=0.5105 | val_acc=0.5571 | val_f1m=0.5600\n",
      "  Ã‰poca  16 | train_loss=0.1935 | train_acc=0.5261 | val_acc=0.5484 | val_f1m=0.5345\n",
      "  Ã‰poca  17 | train_loss=0.1922 | train_acc=0.5327 | val_acc=0.5619 | val_f1m=0.5546\n",
      "  Ã‰poca  18 | train_loss=0.1883 | train_acc=0.5432 | val_acc=0.5389 | val_f1m=0.5334\n",
      "  Ã‰poca  19 | train_loss=0.1917 | train_acc=0.5278 | val_acc=0.5603 | val_f1m=0.5537\n",
      "  Ã‰poca  20 | train_loss=0.1852 | train_acc=0.5557 | val_acc=0.5722 | val_f1m=0.5695\n",
      "  Ã‰poca  21 | train_loss=0.1821 | train_acc=0.5546 | val_acc=0.5603 | val_f1m=0.5622\n",
      "  Early stopping en Ã©poca 21 (mejor val_f1m=0.5713)\n",
      "ðŸŽ¯ Evaluando TEST con tta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1680/1680 [00:06<00:00, 250.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] TEST - acc=0.5089, F1-macro=0.5025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6024    0.6095    0.6059       420\n",
      "       right     0.5396    0.6000    0.5682       420\n",
      "  both fists     0.4058    0.5333    0.4609       420\n",
      "   both feet     0.5212    0.2929    0.3750       420\n",
      "\n",
      "    accuracy                         0.5089      1680\n",
      "   macro avg     0.5172    0.5089    0.5025      1680\n",
      "weighted avg     0.5172    0.5089    0.5025      1680\n",
      "\n",
      "Confusion matrix:\n",
      "[[256  30  98  36]\n",
      " [ 29 252 101  38]\n",
      " [ 78  79 224  39]\n",
      " [ 62 106 129 123]]\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ RESULTADOS FINALES CON WINDOW SLIDING\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4796', '0.5204', '0.4705', '0.5155', '0.5089']\n",
      "Global mean ACC: 0.4990\n",
      "F1 folds (MACRO): ['0.4811', '0.5058', '0.4641', '0.5169', '0.5025']\n",
      "F1 mean (MACRO): 0.4941\n",
      "ðŸ”§ ConfiguraciÃ³n usada: SW_MODE=tta, SW_LEN=2.5, SW_STRIDE=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Transformer-only para MI (4 clases, 8 canales) - VERSIÃ“N FINAL CON WINDOW SLIDING\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG - CON WINDOW SLIDING ACTIVADO\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "BASE_LR = 1e-3\n",
    "WARMUP_EPOCHS = 8\n",
    "PATIENCE = 15\n",
    "\n",
    "# Split de validaciÃ³n por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18\n",
    "\n",
    "# Prepro\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Modelo (transformer-only)\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 4\n",
    "P_DROP = 0.2\n",
    "\n",
    "# Ventana temporal (epoch)\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA (sÃ³lo en TEST) - ACTIVADO CON CONFIGURACIÃ“N MEJORADA\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True     # Activado\n",
    "TTA_SHIFTS_S = [0.0]  # Solo shifts pequeÃ±os para empezar\n",
    "SW_LEN, SW_STRIDE = 2.5, 0.3  # ConfiguraciÃ³n mÃ¡s conservadora\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O (igual que antes)\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X[mask])\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel_consistent(train_X, other_X):\n",
    "    \"\"\"VersiÃ³n mejorada que asegura consistencia entre train y test\"\"\"\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    \n",
    "    # Calcular estadÃ­sticas globales del train\n",
    "    channel_means = train_X.mean(axis=(0, 2), keepdims=True)\n",
    "    channel_stds = train_X.std(axis=(0, 2), keepdims=True) + 1e-6\n",
    "    \n",
    "    # Aplicar a todos los conjuntos\n",
    "    train_X_std = (train_X - channel_means) / channel_stds\n",
    "    other_X_std = (other_X - channel_means) / channel_stds\n",
    "    \n",
    "    return train_X_std, other_X_std\n",
    "\n",
    "# =========================\n",
    "# MODELO (igual que antes)\n",
    "# =========================\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, n_ch, patch_size_samples, patch_stride_samples, d_model):\n",
    "        super().__init__()\n",
    "        assert patch_size_samples >= 1 and patch_stride_samples >= 1\n",
    "        self.n_ch = n_ch\n",
    "        self.p_size = int(patch_size_samples)\n",
    "        self.p_stride = int(patch_stride_samples)\n",
    "        self.proj = nn.Linear(n_ch * self.p_size, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, T = x.shape\n",
    "        if T < self.p_size:\n",
    "            pad = self.p_size - T\n",
    "            x = F.pad(x, (0, pad), mode='replicate')\n",
    "            T = x.shape[-1]\n",
    "        starts = list(range(0, T - self.p_size + 1, self.p_stride))\n",
    "        patches = []\n",
    "        for s in starts:\n",
    "            seg = x[:, :, s:s + self.p_size]\n",
    "            seg = seg.reshape(B, C * self.p_size)\n",
    "            patches.append(seg)\n",
    "        if len(patches) == 0:\n",
    "            seg = x[:, :, :self.p_size].reshape(B, C * self.p_size)\n",
    "            patches = [seg]\n",
    "        patches = torch.stack(patches, dim=1)\n",
    "        out = self.proj(patches)\n",
    "        return out\n",
    "\n",
    "class EEGTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=4, p_drop=0.2,\n",
    "                 patch_size_samples=16, patch_stride_samples=None):\n",
    "        super().__init__()\n",
    "        if patch_stride_samples is None:\n",
    "            patch_stride_samples = patch_size_samples\n",
    "        self.embed = PatchEmbedding(n_ch, patch_size_samples, patch_stride_samples, d_model)\n",
    "        self.dropout = nn.Dropout(p_drop)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=4*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=p_drop, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.pos_encoding = None\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.embed(x)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "        z = self.encoder(z)\n",
    "        cls = z[:, 0, :]\n",
    "        out = self.head(cls)\n",
    "        return out\n",
    "\n",
    "# =========================\n",
    "# FOCAL LOSS CORREGIDO\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor = None, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha / alpha.sum()\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            at = self.alpha[target]\n",
    "        else:\n",
    "            at = 1.0\n",
    "            \n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        \n",
    "        if self.reduction == 'mean': \n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':  \n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS (igual que antes)\n",
    "# =========================\n",
    "def augment_batch(\n",
    "    xb,\n",
    "    p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "    max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1\n",
    "):\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA CON WINDOW SLIDING CORREGIDA\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    \"\"\"Window sliding con preprocesamiento consistente\"\"\"\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1]))\n",
    "    st = max(1, st)\n",
    "    \n",
    "    print(f\"ðŸ”§ Window Sliding: len={wl}samples ({sw_len}s), stride={st}samples ({sw_stride}s), total_windows={max(1, (X.shape[-1]-wl+st)//st)}\")\n",
    "    \n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(X.shape[0]), desc=\"Processing windows\"):\n",
    "            x = X[i]\n",
    "            acc = []\n",
    "            \n",
    "            # Calcular estadÃ­sticas de normalizaciÃ³n para esta muestra\n",
    "            if not ZSCORE_PER_EPOCH:\n",
    "                x_mean = x.mean(axis=1, keepdims=True)\n",
    "                x_std = x.std(axis=1, keepdims=True) + 1e-6\n",
    "            \n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                \n",
    "                # Aplicar padding si es necesario\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='constant', constant_values=0)\n",
    "                \n",
    "                # âœ… NORMALIZACIÃ“N CONSISTENTE para cada ventana\n",
    "                if not ZSCORE_PER_EPOCH:\n",
    "                    seg = (seg - x_mean) / x_std\n",
    "                \n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            \n",
    "            # Promedio de logits de todas las ventanas\n",
    "            if len(acc) > 0:\n",
    "                avg_logits = np.mean(np.stack(acc, axis=0), axis=0)\n",
    "            else:\n",
    "                avg_logits = np.zeros(4, dtype=np.float32)\n",
    "            out.append(avg_logits)\n",
    "    \n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    \"\"\"TTA con preprocesamiento consistente\"\"\"\n",
    "    model.eval()\n",
    "    T = X.shape[-1]\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(X.shape[0]), desc=\"Processing TTA\"):\n",
    "            x0 = X[i]\n",
    "            acc = []\n",
    "            \n",
    "            # Calcular estadÃ­sticas de normalizaciÃ³n para esta muestra\n",
    "            if not ZSCORE_PER_EPOCH:\n",
    "                x0_mean = x0.mean(axis=1, keepdims=True)\n",
    "                x0_std = x0.std(axis=1, keepdims=True) + 1e-6\n",
    "            \n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='constant', constant_values=0)[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='constant', constant_values=0)[:, :T]\n",
    "                \n",
    "                # âœ… NORMALIZACIÃ“N CONSISTENTE\n",
    "                if not ZSCORE_PER_EPOCH:\n",
    "                    x = (x - x0_mean) / x0_std\n",
    "                \n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            \n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def standard_inference(model, X, device):\n",
    "    \"\"\"Inference estÃ¡ndar sin complicaciones\"\"\"\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor).cpu().numpy()\n",
    "    return logits\n",
    "\n",
    "def unified_inference(model, X, sfreq, device, mode='standard'):\n",
    "    \"\"\"FunciÃ³n unificada para inference con diferentes modos\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if mode == 'standard':\n",
    "        return standard_inference(model, X, device)\n",
    "    \n",
    "    elif mode == 'subwindow':\n",
    "        return subwindow_logits(model, X, sfreq, SW_LEN, SW_STRIDE, device)\n",
    "    \n",
    "    elif mode == 'tta':\n",
    "        return time_shift_tta_logits(model, X, sfreq, TTA_SHIFTS_S, device)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Modo desconocido: {mode}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL CON WINDOW SLIDING\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # Split de validaciÃ³n\n",
    "    rng = random.Random(RANDOM_STATE + fold)\n",
    "    tr_subjects = train_sub.copy()\n",
    "    rng.shuffle(tr_subjects)\n",
    "    n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "    val_subjects = sorted(tr_subjects[:n_val_subj])\n",
    "    train_subjects = sorted(tr_subjects[n_val_subj:])\n",
    "\n",
    "    # Carga de datos\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)}\")\n",
    "    print(f\"ðŸ“Š DistribuciÃ³n de clases - Train: {np.bincount(y_tr)}\")\n",
    "\n",
    "    if sfreq is None:\n",
    "        raise RuntimeError(\"No se pudo inferir sfreq.\")\n",
    "\n",
    "    # NormalizaciÃ³n\n",
    "    X_tr_std, X_val_std = standardize_per_channel_consistent(X_tr, X_val)\n",
    "    _, X_te_std = standardize_per_channel_consistent(X_tr, X_te)\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std), torch.tensor(y_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std), torch.tensor(y_te).long())\n",
    "\n",
    "    tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, worker_init_fn=seed_worker)\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # ConfiguraciÃ³n de patches\n",
    "    patch_duration_s = 0.100\n",
    "    patch_stride_fraction = 0.5\n",
    "\n",
    "    patch_size_samples = max(1, int(round(patch_duration_s * sfreq)))\n",
    "    patch_stride_samples = max(1, int(round(patch_size_samples * patch_stride_fraction)))\n",
    "\n",
    "    print(f\"ðŸ“Š sfreq={sfreq:.1f} Hz -> patch_size={patch_size_samples} | stride={patch_stride_samples}\")\n",
    "\n",
    "    # Modelo\n",
    "    model = EEGTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                           n_layers=N_LAYERS, p_drop=P_DROP,\n",
    "                           patch_size_samples=patch_size_samples,\n",
    "                           patch_stride_samples=patch_stride_samples).to(device)\n",
    "\n",
    "    # Optimizador\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "\n",
    "    # Focal Loss balanceado\n",
    "    class_counts = np.bincount(y_tr, minlength=4).astype(np.float32)\n",
    "    total = class_counts.sum()\n",
    "    alpha = torch.tensor([total / (4.0 * count) for count in class_counts], \n",
    "                         dtype=torch.float32, device=device)\n",
    "    alpha = alpha / alpha.sum()\n",
    "    \n",
    "    print(f\"ðŸ“Š Pesos Focal Loss: {alpha.cpu().numpy()}\")\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.0, reduction='mean')\n",
    "\n",
    "    # Scheduler\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    \n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    \n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # Entrenamiento\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"lr\": []}\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        \n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        \n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # Cargar mejor modelo\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # EvaluaciÃ³n en TEST CON WINDOW SLIDING\n",
    "    print(f\"ðŸŽ¯ Evaluando TEST con {SW_MODE}...\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Usar inference unificada\n",
    "    logits = unified_inference(model, X_te_std, sfreq, device, SW_MODE)\n",
    "    preds = logits.argmax(axis=1)\n",
    "    gts = y_te\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    \n",
    "    print(f\"[Fold {fold}/5] TEST - acc={acc:.4f}, F1-macro={f1m:.4f}\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(gts, preds, labels=[0,1,2,3]))\n",
    "\n",
    "    return acc, f1m\n",
    "\n",
    "# =========================\n",
    "# LOOP PRINCIPAL\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ INICIANDO ENTRENAMIENTO CON WINDOW SLIDING ACTIVADO\")\n",
    "    print(f\"ðŸ”§ ConfiguraciÃ³n Window Sliding: SW_LEN={SW_LEN}s, SW_STRIDE={SW_STRIDE}s\")\n",
    "    print(f\"ðŸŽ¯ Modo: {SW_MODE}\")\n",
    "    \n",
    "    acc_folds, f1_folds = [], []\n",
    "    for fold in range(1, 6):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESANDO FOLD {fold}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        acc, f1m = train_one_fold(fold, DEVICE)\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸŽ‰ RESULTADOS FINALES CON WINDOW SLIDING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n",
    "    print(f\"ðŸ”§ ConfiguraciÃ³n usada: SW_MODE={SW_MODE}, SW_LEN={SW_LEN}, SW_STRIDE={SW_STRIDE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
