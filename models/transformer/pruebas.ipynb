{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf227eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Usando dispositivo: cuda\n",
      "🧠 INICIANDO EXPERIMENTO TWO-STAGE (Encoder+Tabular)\n",
      "🔧 Configuración: 4c, 8 canales, 3s\n",
      "⚙️  Stage-1: epochs=70, lr=0.001, SGDR T0=6, Tmult=2\n",
      "⚙️  Stage-2: TabNet | epochs=400, patience=40\n",
      "Sujetos elegibles: 103 → [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|██████████| 103/103 [00:40<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=8652 | T=480 | C=8 | clases=4 | sujetos únicos=103\n",
      "Listo para entrenar: N=8652 | T=480 | C=8 | clases=4 | sujetos=103\n",
      "\n",
      "[Fold 1/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3606 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.5174 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5459 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Early stopping @ 13 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold1.png\n",
      "[Fold 1] Stage-1 acc(test) = 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.57781 | val_0_accuracy: 0.30311 |  0:00:00s\n",
      "epoch 1  | loss: 1.36085 | val_0_accuracy: 0.28938 |  0:00:01s\n",
      "epoch 2  | loss: 1.3195  | val_0_accuracy: 0.2674  |  0:00:01s\n",
      "epoch 3  | loss: 1.29776 | val_0_accuracy: 0.32234 |  0:00:01s\n",
      "epoch 4  | loss: 1.28598 | val_0_accuracy: 0.35073 |  0:00:02s\n",
      "epoch 5  | loss: 1.28318 | val_0_accuracy: 0.3544  |  0:00:02s\n",
      "epoch 6  | loss: 1.27581 | val_0_accuracy: 0.35531 |  0:00:03s\n",
      "epoch 7  | loss: 1.27677 | val_0_accuracy: 0.35348 |  0:00:03s\n",
      "epoch 8  | loss: 1.26668 | val_0_accuracy: 0.37363 |  0:00:04s\n",
      "epoch 9  | loss: 1.273   | val_0_accuracy: 0.34799 |  0:00:04s\n",
      "epoch 10 | loss: 1.25982 | val_0_accuracy: 0.3663  |  0:00:05s\n",
      "epoch 11 | loss: 1.26755 | val_0_accuracy: 0.35897 |  0:00:05s\n",
      "epoch 12 | loss: 1.25274 | val_0_accuracy: 0.35256 |  0:00:06s\n",
      "epoch 13 | loss: 1.25517 | val_0_accuracy: 0.37179 |  0:00:06s\n",
      "epoch 14 | loss: 1.25671 | val_0_accuracy: 0.35256 |  0:00:07s\n",
      "epoch 15 | loss: 1.23507 | val_0_accuracy: 0.35073 |  0:00:07s\n",
      "epoch 16 | loss: 1.22665 | val_0_accuracy: 0.36264 |  0:00:07s\n",
      "epoch 17 | loss: 1.22204 | val_0_accuracy: 0.37088 |  0:00:08s\n",
      "epoch 18 | loss: 1.21542 | val_0_accuracy: 0.36538 |  0:00:08s\n",
      "epoch 19 | loss: 1.21586 | val_0_accuracy: 0.37821 |  0:00:09s\n",
      "epoch 20 | loss: 1.20902 | val_0_accuracy: 0.36538 |  0:00:09s\n",
      "epoch 21 | loss: 1.20392 | val_0_accuracy: 0.35531 |  0:00:10s\n",
      "epoch 22 | loss: 1.19566 | val_0_accuracy: 0.36905 |  0:00:10s\n",
      "epoch 23 | loss: 1.19122 | val_0_accuracy: 0.37363 |  0:00:11s\n",
      "epoch 24 | loss: 1.19513 | val_0_accuracy: 0.35165 |  0:00:11s\n",
      "epoch 25 | loss: 1.19307 | val_0_accuracy: 0.36905 |  0:00:12s\n",
      "epoch 26 | loss: 1.18757 | val_0_accuracy: 0.35165 |  0:00:12s\n",
      "epoch 27 | loss: 1.19518 | val_0_accuracy: 0.38095 |  0:00:13s\n",
      "epoch 28 | loss: 1.18746 | val_0_accuracy: 0.36355 |  0:00:13s\n",
      "epoch 29 | loss: 1.15971 | val_0_accuracy: 0.36905 |  0:00:13s\n",
      "epoch 30 | loss: 1.14985 | val_0_accuracy: 0.34982 |  0:00:14s\n",
      "epoch 31 | loss: 1.14155 | val_0_accuracy: 0.3489  |  0:00:14s\n",
      "epoch 32 | loss: 1.16079 | val_0_accuracy: 0.35531 |  0:00:15s\n",
      "epoch 33 | loss: 1.15995 | val_0_accuracy: 0.37821 |  0:00:15s\n",
      "epoch 34 | loss: 1.14879 | val_0_accuracy: 0.36264 |  0:00:16s\n",
      "epoch 35 | loss: 1.13444 | val_0_accuracy: 0.37454 |  0:00:16s\n",
      "epoch 36 | loss: 1.1174  | val_0_accuracy: 0.36081 |  0:00:17s\n",
      "epoch 37 | loss: 1.09111 | val_0_accuracy: 0.36081 |  0:00:17s\n",
      "epoch 38 | loss: 1.10149 | val_0_accuracy: 0.35348 |  0:00:18s\n",
      "epoch 39 | loss: 1.10147 | val_0_accuracy: 0.32143 |  0:00:18s\n",
      "epoch 40 | loss: 1.11307 | val_0_accuracy: 0.3544  |  0:00:19s\n",
      "epoch 41 | loss: 1.09889 | val_0_accuracy: 0.34066 |  0:00:19s\n",
      "epoch 42 | loss: 1.08481 | val_0_accuracy: 0.3489  |  0:00:19s\n",
      "epoch 43 | loss: 1.06448 | val_0_accuracy: 0.33333 |  0:00:20s\n",
      "epoch 44 | loss: 1.04842 | val_0_accuracy: 0.34615 |  0:00:20s\n",
      "epoch 45 | loss: 1.06151 | val_0_accuracy: 0.35073 |  0:00:21s\n",
      "epoch 46 | loss: 1.05439 | val_0_accuracy: 0.33333 |  0:00:21s\n",
      "epoch 47 | loss: 1.01456 | val_0_accuracy: 0.35989 |  0:00:22s\n",
      "epoch 48 | loss: 1.03281 | val_0_accuracy: 0.35714 |  0:00:22s\n",
      "epoch 49 | loss: 1.02598 | val_0_accuracy: 0.36813 |  0:00:23s\n",
      "epoch 50 | loss: 1.00861 | val_0_accuracy: 0.35531 |  0:00:23s\n",
      "epoch 51 | loss: 0.99229 | val_0_accuracy: 0.36447 |  0:00:23s\n",
      "epoch 52 | loss: 0.98914 | val_0_accuracy: 0.34341 |  0:00:24s\n",
      "epoch 53 | loss: 0.99781 | val_0_accuracy: 0.34982 |  0:00:24s\n",
      "epoch 54 | loss: 0.9973  | val_0_accuracy: 0.35165 |  0:00:25s\n",
      "epoch 55 | loss: 0.99165 | val_0_accuracy: 0.34066 |  0:00:25s\n",
      "epoch 56 | loss: 1.0189  | val_0_accuracy: 0.35989 |  0:00:26s\n",
      "epoch 57 | loss: 0.97745 | val_0_accuracy: 0.33883 |  0:00:26s\n",
      "epoch 58 | loss: 0.98303 | val_0_accuracy: 0.34524 |  0:00:27s\n",
      "epoch 59 | loss: 0.98772 | val_0_accuracy: 0.35806 |  0:00:27s\n",
      "epoch 60 | loss: 0.93856 | val_0_accuracy: 0.36905 |  0:00:28s\n",
      "epoch 61 | loss: 0.95298 | val_0_accuracy: 0.35073 |  0:00:28s\n",
      "epoch 62 | loss: 0.95365 | val_0_accuracy: 0.35623 |  0:00:28s\n",
      "epoch 63 | loss: 0.94558 | val_0_accuracy: 0.35348 |  0:00:29s\n",
      "epoch 64 | loss: 0.94377 | val_0_accuracy: 0.3663  |  0:00:29s\n",
      "epoch 65 | loss: 0.91847 | val_0_accuracy: 0.37821 |  0:00:30s\n",
      "epoch 66 | loss: 0.88904 | val_0_accuracy: 0.37546 |  0:00:30s\n",
      "epoch 67 | loss: 0.90943 | val_0_accuracy: 0.36355 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 27 and best_val_0_accuracy = 0.38095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] BLEND acc(test) = 0.3730 (w=0.5) | Δ vs Stage-1 = +0.0204\n",
      "\n",
      "[Fold 2/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3447 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.5171 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5416 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Early stopping @ 13 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold2.png\n",
      "[Fold 2] Stage-1 acc(test) = 0.4223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.56595 | val_0_accuracy: 0.26557 |  0:00:00s\n",
      "epoch 1  | loss: 1.37343 | val_0_accuracy: 0.25    |  0:00:00s\n",
      "epoch 2  | loss: 1.31592 | val_0_accuracy: 0.27015 |  0:00:01s\n",
      "epoch 3  | loss: 1.29433 | val_0_accuracy: 0.26099 |  0:00:01s\n",
      "epoch 4  | loss: 1.28363 | val_0_accuracy: 0.28846 |  0:00:02s\n",
      "epoch 5  | loss: 1.26352 | val_0_accuracy: 0.33974 |  0:00:02s\n",
      "epoch 6  | loss: 1.26247 | val_0_accuracy: 0.3663  |  0:00:03s\n",
      "epoch 7  | loss: 1.26035 | val_0_accuracy: 0.36447 |  0:00:03s\n",
      "epoch 8  | loss: 1.25784 | val_0_accuracy: 0.37088 |  0:00:04s\n",
      "epoch 9  | loss: 1.26009 | val_0_accuracy: 0.36172 |  0:00:04s\n",
      "epoch 10 | loss: 1.2434  | val_0_accuracy: 0.37454 |  0:00:05s\n",
      "epoch 11 | loss: 1.2328  | val_0_accuracy: 0.37271 |  0:00:05s\n",
      "epoch 12 | loss: 1.2349  | val_0_accuracy: 0.36996 |  0:00:05s\n",
      "epoch 13 | loss: 1.22338 | val_0_accuracy: 0.36813 |  0:00:06s\n",
      "epoch 14 | loss: 1.21859 | val_0_accuracy: 0.36264 |  0:00:06s\n",
      "epoch 15 | loss: 1.20593 | val_0_accuracy: 0.37271 |  0:00:07s\n",
      "epoch 16 | loss: 1.19124 | val_0_accuracy: 0.36081 |  0:00:07s\n",
      "epoch 17 | loss: 1.18347 | val_0_accuracy: 0.35989 |  0:00:08s\n",
      "epoch 18 | loss: 1.1746  | val_0_accuracy: 0.36264 |  0:00:08s\n",
      "epoch 19 | loss: 1.17232 | val_0_accuracy: 0.34982 |  0:00:09s\n",
      "epoch 20 | loss: 1.16185 | val_0_accuracy: 0.37821 |  0:00:09s\n",
      "epoch 21 | loss: 1.16068 | val_0_accuracy: 0.35714 |  0:00:10s\n",
      "epoch 22 | loss: 1.17765 | val_0_accuracy: 0.38736 |  0:00:10s\n",
      "epoch 23 | loss: 1.17766 | val_0_accuracy: 0.34615 |  0:00:11s\n",
      "epoch 24 | loss: 1.17032 | val_0_accuracy: 0.36813 |  0:00:11s\n",
      "epoch 25 | loss: 1.14906 | val_0_accuracy: 0.36172 |  0:00:11s\n",
      "epoch 26 | loss: 1.12973 | val_0_accuracy: 0.34158 |  0:00:12s\n",
      "epoch 27 | loss: 1.17248 | val_0_accuracy: 0.36905 |  0:00:12s\n",
      "epoch 28 | loss: 1.1486  | val_0_accuracy: 0.38278 |  0:00:13s\n",
      "epoch 29 | loss: 1.13915 | val_0_accuracy: 0.37271 |  0:00:13s\n",
      "epoch 30 | loss: 1.14882 | val_0_accuracy: 0.35073 |  0:00:14s\n",
      "epoch 31 | loss: 1.13669 | val_0_accuracy: 0.35623 |  0:00:14s\n",
      "epoch 32 | loss: 1.12125 | val_0_accuracy: 0.35897 |  0:00:15s\n",
      "epoch 33 | loss: 1.09648 | val_0_accuracy: 0.37271 |  0:00:15s\n",
      "epoch 34 | loss: 1.10334 | val_0_accuracy: 0.35256 |  0:00:16s\n",
      "epoch 35 | loss: 1.10242 | val_0_accuracy: 0.37179 |  0:00:16s\n",
      "epoch 36 | loss: 1.09616 | val_0_accuracy: 0.35256 |  0:00:16s\n",
      "epoch 37 | loss: 1.12062 | val_0_accuracy: 0.34799 |  0:00:17s\n",
      "epoch 38 | loss: 1.11489 | val_0_accuracy: 0.36081 |  0:00:17s\n",
      "epoch 39 | loss: 1.10367 | val_0_accuracy: 0.35623 |  0:00:18s\n",
      "epoch 40 | loss: 1.07544 | val_0_accuracy: 0.337   |  0:00:18s\n",
      "epoch 41 | loss: 1.06704 | val_0_accuracy: 0.35073 |  0:00:19s\n",
      "epoch 42 | loss: 1.07534 | val_0_accuracy: 0.34982 |  0:00:19s\n",
      "epoch 43 | loss: 1.07658 | val_0_accuracy: 0.36264 |  0:00:20s\n",
      "epoch 44 | loss: 1.05015 | val_0_accuracy: 0.3489  |  0:00:20s\n",
      "epoch 45 | loss: 1.06152 | val_0_accuracy: 0.35531 |  0:00:21s\n",
      "epoch 46 | loss: 1.04481 | val_0_accuracy: 0.34707 |  0:00:21s\n",
      "epoch 47 | loss: 1.04341 | val_0_accuracy: 0.34341 |  0:00:22s\n",
      "epoch 48 | loss: 1.02838 | val_0_accuracy: 0.33974 |  0:00:22s\n",
      "epoch 49 | loss: 1.01792 | val_0_accuracy: 0.34524 |  0:00:22s\n",
      "epoch 50 | loss: 1.03387 | val_0_accuracy: 0.36264 |  0:00:23s\n",
      "epoch 51 | loss: 1.01051 | val_0_accuracy: 0.35256 |  0:00:23s\n",
      "epoch 52 | loss: 0.98381 | val_0_accuracy: 0.34799 |  0:00:24s\n",
      "epoch 53 | loss: 0.95346 | val_0_accuracy: 0.3315  |  0:00:24s\n",
      "epoch 54 | loss: 0.95175 | val_0_accuracy: 0.34432 |  0:00:25s\n",
      "epoch 55 | loss: 0.96492 | val_0_accuracy: 0.36081 |  0:00:25s\n",
      "epoch 56 | loss: 0.95365 | val_0_accuracy: 0.35806 |  0:00:26s\n",
      "epoch 57 | loss: 0.96339 | val_0_accuracy: 0.34524 |  0:00:26s\n",
      "epoch 58 | loss: 1.00274 | val_0_accuracy: 0.35623 |  0:00:27s\n",
      "epoch 59 | loss: 0.9618  | val_0_accuracy: 0.34432 |  0:00:27s\n",
      "epoch 60 | loss: 0.9315  | val_0_accuracy: 0.34524 |  0:00:27s\n",
      "epoch 61 | loss: 0.89899 | val_0_accuracy: 0.35348 |  0:00:28s\n",
      "epoch 62 | loss: 0.89488 | val_0_accuracy: 0.34707 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 22 and best_val_0_accuracy = 0.38736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] BLEND acc(test) = 0.4331 (w=0.5) | Δ vs Stage-1 = +0.0108\n",
      "\n",
      "[Fold 3/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3651 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.5162 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5492 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Early stopping @ 13 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold3.png\n",
      "[Fold 3] Stage-1 acc(test) = 0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.56814 | val_0_accuracy: 0.28938 |  0:00:00s\n",
      "epoch 1  | loss: 1.37503 | val_0_accuracy: 0.25641 |  0:00:00s\n",
      "epoch 2  | loss: 1.32627 | val_0_accuracy: 0.25458 |  0:00:01s\n",
      "epoch 3  | loss: 1.2972  | val_0_accuracy: 0.28205 |  0:00:01s\n",
      "epoch 4  | loss: 1.30162 | val_0_accuracy: 0.30769 |  0:00:02s\n",
      "epoch 5  | loss: 1.28396 | val_0_accuracy: 0.32967 |  0:00:02s\n",
      "epoch 6  | loss: 1.27343 | val_0_accuracy: 0.33883 |  0:00:03s\n",
      "epoch 7  | loss: 1.27326 | val_0_accuracy: 0.34524 |  0:00:03s\n",
      "epoch 8  | loss: 1.26439 | val_0_accuracy: 0.36355 |  0:00:04s\n",
      "epoch 9  | loss: 1.25808 | val_0_accuracy: 0.38553 |  0:00:04s\n",
      "epoch 10 | loss: 1.25545 | val_0_accuracy: 0.35806 |  0:00:05s\n",
      "epoch 11 | loss: 1.25803 | val_0_accuracy: 0.39652 |  0:00:05s\n",
      "epoch 12 | loss: 1.25404 | val_0_accuracy: 0.38828 |  0:00:05s\n",
      "epoch 13 | loss: 1.24225 | val_0_accuracy: 0.37821 |  0:00:06s\n",
      "epoch 14 | loss: 1.24355 | val_0_accuracy: 0.39652 |  0:00:06s\n",
      "epoch 15 | loss: 1.24173 | val_0_accuracy: 0.37179 |  0:00:07s\n",
      "epoch 16 | loss: 1.23556 | val_0_accuracy: 0.38278 |  0:00:07s\n",
      "epoch 17 | loss: 1.22784 | val_0_accuracy: 0.3956  |  0:00:08s\n",
      "epoch 18 | loss: 1.23046 | val_0_accuracy: 0.36905 |  0:00:08s\n",
      "epoch 19 | loss: 1.2234  | val_0_accuracy: 0.36722 |  0:00:09s\n",
      "epoch 20 | loss: 1.21407 | val_0_accuracy: 0.38553 |  0:00:09s\n",
      "epoch 21 | loss: 1.21489 | val_0_accuracy: 0.37729 |  0:00:10s\n",
      "epoch 22 | loss: 1.21115 | val_0_accuracy: 0.37912 |  0:00:10s\n",
      "epoch 23 | loss: 1.20887 | val_0_accuracy: 0.39377 |  0:00:10s\n",
      "epoch 24 | loss: 1.21097 | val_0_accuracy: 0.37454 |  0:00:11s\n",
      "epoch 25 | loss: 1.21745 | val_0_accuracy: 0.40476 |  0:00:11s\n",
      "epoch 26 | loss: 1.21109 | val_0_accuracy: 0.39927 |  0:00:12s\n",
      "epoch 27 | loss: 1.2194  | val_0_accuracy: 0.39194 |  0:00:12s\n",
      "epoch 28 | loss: 1.22023 | val_0_accuracy: 0.40018 |  0:00:13s\n",
      "epoch 29 | loss: 1.21617 | val_0_accuracy: 0.36172 |  0:00:13s\n",
      "epoch 30 | loss: 1.20518 | val_0_accuracy: 0.38645 |  0:00:14s\n",
      "epoch 31 | loss: 1.19883 | val_0_accuracy: 0.40568 |  0:00:14s\n",
      "epoch 32 | loss: 1.1962  | val_0_accuracy: 0.37637 |  0:00:15s\n",
      "epoch 33 | loss: 1.19284 | val_0_accuracy: 0.38004 |  0:00:15s\n",
      "epoch 34 | loss: 1.18132 | val_0_accuracy: 0.37088 |  0:00:15s\n",
      "epoch 35 | loss: 1.17481 | val_0_accuracy: 0.35714 |  0:00:16s\n",
      "epoch 36 | loss: 1.18053 | val_0_accuracy: 0.36447 |  0:00:16s\n",
      "epoch 37 | loss: 1.17024 | val_0_accuracy: 0.35897 |  0:00:17s\n",
      "epoch 38 | loss: 1.17247 | val_0_accuracy: 0.3663  |  0:00:17s\n",
      "epoch 39 | loss: 1.17098 | val_0_accuracy: 0.38828 |  0:00:18s\n",
      "epoch 40 | loss: 1.15654 | val_0_accuracy: 0.38462 |  0:00:18s\n",
      "epoch 41 | loss: 1.16531 | val_0_accuracy: 0.40476 |  0:00:19s\n",
      "epoch 42 | loss: 1.17027 | val_0_accuracy: 0.40385 |  0:00:19s\n",
      "epoch 43 | loss: 1.16846 | val_0_accuracy: 0.3956  |  0:00:20s\n",
      "epoch 44 | loss: 1.16203 | val_0_accuracy: 0.41117 |  0:00:20s\n",
      "epoch 45 | loss: 1.13727 | val_0_accuracy: 0.40751 |  0:00:20s\n",
      "epoch 46 | loss: 1.14032 | val_0_accuracy: 0.39927 |  0:00:21s\n",
      "epoch 47 | loss: 1.15299 | val_0_accuracy: 0.38736 |  0:00:21s\n",
      "epoch 48 | loss: 1.15377 | val_0_accuracy: 0.37637 |  0:00:22s\n",
      "epoch 49 | loss: 1.16365 | val_0_accuracy: 0.39011 |  0:00:22s\n",
      "epoch 50 | loss: 1.15444 | val_0_accuracy: 0.39927 |  0:00:23s\n",
      "epoch 51 | loss: 1.15292 | val_0_accuracy: 0.37271 |  0:00:23s\n",
      "epoch 52 | loss: 1.1497  | val_0_accuracy: 0.40018 |  0:00:24s\n",
      "epoch 53 | loss: 1.14834 | val_0_accuracy: 0.37637 |  0:00:24s\n",
      "epoch 54 | loss: 1.16362 | val_0_accuracy: 0.38919 |  0:00:25s\n",
      "epoch 55 | loss: 1.15097 | val_0_accuracy: 0.37454 |  0:00:25s\n",
      "epoch 56 | loss: 1.14237 | val_0_accuracy: 0.37546 |  0:00:25s\n",
      "epoch 57 | loss: 1.14534 | val_0_accuracy: 0.38004 |  0:00:26s\n",
      "epoch 58 | loss: 1.13824 | val_0_accuracy: 0.38828 |  0:00:26s\n",
      "epoch 59 | loss: 1.14425 | val_0_accuracy: 0.38736 |  0:00:27s\n",
      "epoch 60 | loss: 1.12558 | val_0_accuracy: 0.37821 |  0:00:27s\n",
      "epoch 61 | loss: 1.11254 | val_0_accuracy: 0.37454 |  0:00:28s\n",
      "epoch 62 | loss: 1.1124  | val_0_accuracy: 0.36996 |  0:00:28s\n",
      "epoch 63 | loss: 1.08607 | val_0_accuracy: 0.38004 |  0:00:29s\n",
      "epoch 64 | loss: 1.06333 | val_0_accuracy: 0.37912 |  0:00:29s\n",
      "epoch 65 | loss: 1.06614 | val_0_accuracy: 0.37088 |  0:00:30s\n",
      "epoch 66 | loss: 1.05724 | val_0_accuracy: 0.36264 |  0:00:30s\n",
      "epoch 67 | loss: 1.04944 | val_0_accuracy: 0.39011 |  0:00:30s\n",
      "epoch 68 | loss: 1.06139 | val_0_accuracy: 0.36081 |  0:00:31s\n",
      "epoch 69 | loss: 1.05938 | val_0_accuracy: 0.37454 |  0:00:31s\n",
      "epoch 70 | loss: 1.0729  | val_0_accuracy: 0.36264 |  0:00:32s\n",
      "epoch 71 | loss: 1.05674 | val_0_accuracy: 0.38095 |  0:00:32s\n",
      "epoch 72 | loss: 1.01733 | val_0_accuracy: 0.36996 |  0:00:33s\n",
      "epoch 73 | loss: 1.01088 | val_0_accuracy: 0.37179 |  0:00:33s\n",
      "epoch 74 | loss: 0.99264 | val_0_accuracy: 0.37729 |  0:00:34s\n",
      "epoch 75 | loss: 0.99559 | val_0_accuracy: 0.38553 |  0:00:34s\n",
      "epoch 76 | loss: 0.9925  | val_0_accuracy: 0.36813 |  0:00:35s\n",
      "epoch 77 | loss: 0.98047 | val_0_accuracy: 0.37454 |  0:00:35s\n",
      "epoch 78 | loss: 0.97571 | val_0_accuracy: 0.37729 |  0:00:36s\n",
      "epoch 79 | loss: 0.97706 | val_0_accuracy: 0.39194 |  0:00:36s\n",
      "epoch 80 | loss: 0.97351 | val_0_accuracy: 0.38736 |  0:00:36s\n",
      "epoch 81 | loss: 0.95759 | val_0_accuracy: 0.37821 |  0:00:37s\n",
      "epoch 82 | loss: 0.96788 | val_0_accuracy: 0.38095 |  0:00:37s\n",
      "epoch 83 | loss: 0.93713 | val_0_accuracy: 0.36264 |  0:00:38s\n",
      "epoch 84 | loss: 0.94092 | val_0_accuracy: 0.38095 |  0:00:38s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 44 and best_val_0_accuracy = 0.41117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] BLEND acc(test) = 0.3889 (w=0.5) | Δ vs Stage-1 = +0.0045\n",
      "\n",
      "[Fold 4/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3522 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.5078 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5337 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Early stopping @ 13 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold4.png\n",
      "[Fold 4] Stage-1 acc(test) = 0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.56813 | val_0_accuracy: 0.27839 |  0:00:00s\n",
      "epoch 1  | loss: 1.35981 | val_0_accuracy: 0.3141  |  0:00:00s\n",
      "epoch 2  | loss: 1.32926 | val_0_accuracy: 0.32234 |  0:00:01s\n",
      "epoch 3  | loss: 1.30819 | val_0_accuracy: 0.34982 |  0:00:01s\n",
      "epoch 4  | loss: 1.30547 | val_0_accuracy: 0.34615 |  0:00:02s\n",
      "epoch 5  | loss: 1.29807 | val_0_accuracy: 0.34799 |  0:00:02s\n",
      "epoch 6  | loss: 1.28665 | val_0_accuracy: 0.3489  |  0:00:03s\n",
      "epoch 7  | loss: 1.26928 | val_0_accuracy: 0.37637 |  0:00:03s\n",
      "epoch 8  | loss: 1.26966 | val_0_accuracy: 0.36813 |  0:00:04s\n",
      "epoch 9  | loss: 1.26733 | val_0_accuracy: 0.37088 |  0:00:04s\n",
      "epoch 10 | loss: 1.26133 | val_0_accuracy: 0.35623 |  0:00:04s\n",
      "epoch 11 | loss: 1.25938 | val_0_accuracy: 0.36813 |  0:00:05s\n",
      "epoch 12 | loss: 1.24944 | val_0_accuracy: 0.37729 |  0:00:05s\n",
      "epoch 13 | loss: 1.24751 | val_0_accuracy: 0.38736 |  0:00:06s\n",
      "epoch 14 | loss: 1.25004 | val_0_accuracy: 0.38553 |  0:00:06s\n",
      "epoch 15 | loss: 1.2489  | val_0_accuracy: 0.37729 |  0:00:07s\n",
      "epoch 16 | loss: 1.24132 | val_0_accuracy: 0.38462 |  0:00:07s\n",
      "epoch 17 | loss: 1.2322  | val_0_accuracy: 0.39377 |  0:00:08s\n",
      "epoch 18 | loss: 1.23044 | val_0_accuracy: 0.4011  |  0:00:08s\n",
      "epoch 19 | loss: 1.22325 | val_0_accuracy: 0.39377 |  0:00:08s\n",
      "epoch 20 | loss: 1.22746 | val_0_accuracy: 0.38095 |  0:00:09s\n",
      "epoch 21 | loss: 1.2161  | val_0_accuracy: 0.38553 |  0:00:09s\n",
      "epoch 22 | loss: 1.21505 | val_0_accuracy: 0.40842 |  0:00:10s\n",
      "epoch 23 | loss: 1.21561 | val_0_accuracy: 0.38736 |  0:00:10s\n",
      "epoch 24 | loss: 1.20024 | val_0_accuracy: 0.36447 |  0:00:11s\n",
      "epoch 25 | loss: 1.20953 | val_0_accuracy: 0.38004 |  0:00:11s\n",
      "epoch 26 | loss: 1.2064  | val_0_accuracy: 0.37271 |  0:00:12s\n",
      "epoch 27 | loss: 1.20515 | val_0_accuracy: 0.37454 |  0:00:12s\n",
      "epoch 28 | loss: 1.1873  | val_0_accuracy: 0.38553 |  0:00:13s\n",
      "epoch 29 | loss: 1.2062  | val_0_accuracy: 0.38187 |  0:00:13s\n",
      "epoch 30 | loss: 1.22366 | val_0_accuracy: 0.36813 |  0:00:13s\n",
      "epoch 31 | loss: 1.20996 | val_0_accuracy: 0.38004 |  0:00:14s\n",
      "epoch 32 | loss: 1.19783 | val_0_accuracy: 0.37546 |  0:00:14s\n",
      "epoch 33 | loss: 1.20788 | val_0_accuracy: 0.38645 |  0:00:15s\n",
      "epoch 34 | loss: 1.20364 | val_0_accuracy: 0.38828 |  0:00:15s\n",
      "epoch 35 | loss: 1.20756 | val_0_accuracy: 0.36081 |  0:00:16s\n",
      "epoch 36 | loss: 1.22774 | val_0_accuracy: 0.37271 |  0:00:16s\n",
      "epoch 37 | loss: 1.2039  | val_0_accuracy: 0.37637 |  0:00:17s\n",
      "epoch 38 | loss: 1.21116 | val_0_accuracy: 0.36264 |  0:00:17s\n",
      "epoch 39 | loss: 1.20473 | val_0_accuracy: 0.38828 |  0:00:18s\n",
      "epoch 40 | loss: 1.18975 | val_0_accuracy: 0.37821 |  0:00:18s\n",
      "epoch 41 | loss: 1.18721 | val_0_accuracy: 0.39377 |  0:00:18s\n",
      "epoch 42 | loss: 1.16522 | val_0_accuracy: 0.37821 |  0:00:19s\n",
      "epoch 43 | loss: 1.15024 | val_0_accuracy: 0.38919 |  0:00:19s\n",
      "epoch 44 | loss: 1.14255 | val_0_accuracy: 0.39652 |  0:00:20s\n",
      "epoch 45 | loss: 1.12122 | val_0_accuracy: 0.38095 |  0:00:20s\n",
      "epoch 46 | loss: 1.14127 | val_0_accuracy: 0.38919 |  0:00:21s\n",
      "epoch 47 | loss: 1.13688 | val_0_accuracy: 0.39011 |  0:00:21s\n",
      "epoch 48 | loss: 1.16625 | val_0_accuracy: 0.38828 |  0:00:22s\n",
      "epoch 49 | loss: 1.17692 | val_0_accuracy: 0.37546 |  0:00:22s\n",
      "epoch 50 | loss: 1.15629 | val_0_accuracy: 0.36996 |  0:00:23s\n",
      "epoch 51 | loss: 1.1448  | val_0_accuracy: 0.3956  |  0:00:23s\n",
      "epoch 52 | loss: 1.12771 | val_0_accuracy: 0.37912 |  0:00:23s\n",
      "epoch 53 | loss: 1.11684 | val_0_accuracy: 0.37729 |  0:00:24s\n",
      "epoch 54 | loss: 1.09213 | val_0_accuracy: 0.38828 |  0:00:24s\n",
      "epoch 55 | loss: 1.09326 | val_0_accuracy: 0.37912 |  0:00:25s\n",
      "epoch 56 | loss: 1.08409 | val_0_accuracy: 0.38462 |  0:00:25s\n",
      "epoch 57 | loss: 1.06867 | val_0_accuracy: 0.39469 |  0:00:26s\n",
      "epoch 58 | loss: 1.07415 | val_0_accuracy: 0.37363 |  0:00:26s\n",
      "epoch 59 | loss: 1.07662 | val_0_accuracy: 0.37912 |  0:00:27s\n",
      "epoch 60 | loss: 1.11854 | val_0_accuracy: 0.36172 |  0:00:27s\n",
      "epoch 61 | loss: 1.07413 | val_0_accuracy: 0.36722 |  0:00:28s\n",
      "epoch 62 | loss: 1.04585 | val_0_accuracy: 0.36355 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 22 and best_val_0_accuracy = 0.40842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] BLEND acc(test) = 0.4024 (w=0.5) | Δ vs Stage-1 = +0.0268\n",
      "\n",
      "[Fold 5/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3543 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.5065 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5313 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Early stopping @ 13 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold5.png\n",
      "[Fold 5] Stage-1 acc(test) = 0.4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.60815 | val_0_accuracy: 0.23352 |  0:00:00s\n",
      "epoch 1  | loss: 1.36743 | val_0_accuracy: 0.25641 |  0:00:00s\n",
      "epoch 2  | loss: 1.3148  | val_0_accuracy: 0.28755 |  0:00:01s\n",
      "epoch 3  | loss: 1.30859 | val_0_accuracy: 0.35073 |  0:00:01s\n",
      "epoch 4  | loss: 1.29575 | val_0_accuracy: 0.35256 |  0:00:02s\n",
      "epoch 5  | loss: 1.28065 | val_0_accuracy: 0.37454 |  0:00:02s\n",
      "epoch 6  | loss: 1.27686 | val_0_accuracy: 0.36447 |  0:00:03s\n",
      "epoch 7  | loss: 1.26341 | val_0_accuracy: 0.37088 |  0:00:03s\n",
      "epoch 8  | loss: 1.25136 | val_0_accuracy: 0.39286 |  0:00:04s\n",
      "epoch 9  | loss: 1.26418 | val_0_accuracy: 0.38187 |  0:00:04s\n",
      "epoch 10 | loss: 1.26114 | val_0_accuracy: 0.39194 |  0:00:04s\n",
      "epoch 11 | loss: 1.25717 | val_0_accuracy: 0.39927 |  0:00:05s\n",
      "epoch 12 | loss: 1.2527  | val_0_accuracy: 0.41026 |  0:00:05s\n",
      "epoch 13 | loss: 1.25438 | val_0_accuracy: 0.39927 |  0:00:06s\n",
      "epoch 14 | loss: 1.23913 | val_0_accuracy: 0.413   |  0:00:06s\n",
      "epoch 15 | loss: 1.23412 | val_0_accuracy: 0.37363 |  0:00:07s\n",
      "epoch 16 | loss: 1.23935 | val_0_accuracy: 0.40659 |  0:00:07s\n",
      "epoch 17 | loss: 1.24697 | val_0_accuracy: 0.39011 |  0:00:08s\n",
      "epoch 18 | loss: 1.25129 | val_0_accuracy: 0.38553 |  0:00:08s\n",
      "epoch 19 | loss: 1.25892 | val_0_accuracy: 0.38919 |  0:00:09s\n",
      "epoch 20 | loss: 1.26206 | val_0_accuracy: 0.42308 |  0:00:09s\n",
      "epoch 21 | loss: 1.25386 | val_0_accuracy: 0.41575 |  0:00:09s\n",
      "epoch 22 | loss: 1.2469  | val_0_accuracy: 0.38462 |  0:00:10s\n",
      "epoch 23 | loss: 1.24297 | val_0_accuracy: 0.41209 |  0:00:10s\n",
      "epoch 24 | loss: 1.23849 | val_0_accuracy: 0.40293 |  0:00:11s\n",
      "epoch 25 | loss: 1.22642 | val_0_accuracy: 0.41117 |  0:00:11s\n",
      "epoch 26 | loss: 1.23041 | val_0_accuracy: 0.41209 |  0:00:12s\n",
      "epoch 27 | loss: 1.23172 | val_0_accuracy: 0.41758 |  0:00:12s\n",
      "epoch 28 | loss: 1.21691 | val_0_accuracy: 0.42674 |  0:00:13s\n",
      "epoch 29 | loss: 1.20079 | val_0_accuracy: 0.40018 |  0:00:13s\n",
      "epoch 30 | loss: 1.19619 | val_0_accuracy: 0.39927 |  0:00:14s\n",
      "epoch 31 | loss: 1.19255 | val_0_accuracy: 0.41026 |  0:00:14s\n",
      "epoch 32 | loss: 1.20733 | val_0_accuracy: 0.4185  |  0:00:14s\n",
      "epoch 33 | loss: 1.20867 | val_0_accuracy: 0.39194 |  0:00:15s\n",
      "epoch 34 | loss: 1.22109 | val_0_accuracy: 0.39927 |  0:00:15s\n",
      "epoch 35 | loss: 1.19976 | val_0_accuracy: 0.40201 |  0:00:16s\n",
      "epoch 36 | loss: 1.20019 | val_0_accuracy: 0.40842 |  0:00:16s\n",
      "epoch 37 | loss: 1.18658 | val_0_accuracy: 0.42216 |  0:00:17s\n",
      "epoch 38 | loss: 1.18383 | val_0_accuracy: 0.41941 |  0:00:17s\n",
      "epoch 39 | loss: 1.17493 | val_0_accuracy: 0.40018 |  0:00:18s\n",
      "epoch 40 | loss: 1.17451 | val_0_accuracy: 0.4011  |  0:00:18s\n",
      "epoch 41 | loss: 1.18992 | val_0_accuracy: 0.40659 |  0:00:19s\n",
      "epoch 42 | loss: 1.19147 | val_0_accuracy: 0.43132 |  0:00:19s\n",
      "epoch 43 | loss: 1.19051 | val_0_accuracy: 0.39927 |  0:00:19s\n",
      "epoch 44 | loss: 1.17577 | val_0_accuracy: 0.41117 |  0:00:20s\n",
      "epoch 45 | loss: 1.16722 | val_0_accuracy: 0.40934 |  0:00:20s\n",
      "epoch 46 | loss: 1.17827 | val_0_accuracy: 0.42491 |  0:00:21s\n",
      "epoch 47 | loss: 1.16861 | val_0_accuracy: 0.40201 |  0:00:21s\n",
      "epoch 48 | loss: 1.15579 | val_0_accuracy: 0.41575 |  0:00:22s\n",
      "epoch 49 | loss: 1.15526 | val_0_accuracy: 0.413   |  0:00:22s\n",
      "epoch 50 | loss: 1.16272 | val_0_accuracy: 0.42308 |  0:00:23s\n",
      "epoch 51 | loss: 1.15234 | val_0_accuracy: 0.40659 |  0:00:23s\n",
      "epoch 52 | loss: 1.16051 | val_0_accuracy: 0.41667 |  0:00:24s\n",
      "epoch 53 | loss: 1.17849 | val_0_accuracy: 0.4185  |  0:00:24s\n",
      "epoch 54 | loss: 1.17644 | val_0_accuracy: 0.41575 |  0:00:24s\n",
      "epoch 55 | loss: 1.1691  | val_0_accuracy: 0.41667 |  0:00:25s\n",
      "epoch 56 | loss: 1.1459  | val_0_accuracy: 0.40659 |  0:00:25s\n",
      "epoch 57 | loss: 1.17599 | val_0_accuracy: 0.40018 |  0:00:26s\n",
      "epoch 58 | loss: 1.16536 | val_0_accuracy: 0.43315 |  0:00:26s\n",
      "epoch 59 | loss: 1.16417 | val_0_accuracy: 0.4011  |  0:00:27s\n",
      "epoch 60 | loss: 1.15993 | val_0_accuracy: 0.40659 |  0:00:27s\n",
      "epoch 61 | loss: 1.14523 | val_0_accuracy: 0.41209 |  0:00:28s\n",
      "epoch 62 | loss: 1.13001 | val_0_accuracy: 0.42766 |  0:00:28s\n",
      "epoch 63 | loss: 1.1417  | val_0_accuracy: 0.39011 |  0:00:29s\n",
      "epoch 64 | loss: 1.1389  | val_0_accuracy: 0.40842 |  0:00:29s\n",
      "epoch 65 | loss: 1.12266 | val_0_accuracy: 0.39469 |  0:00:30s\n",
      "epoch 66 | loss: 1.11628 | val_0_accuracy: 0.39103 |  0:00:30s\n",
      "epoch 67 | loss: 1.10579 | val_0_accuracy: 0.41392 |  0:00:30s\n",
      "epoch 68 | loss: 1.09691 | val_0_accuracy: 0.40842 |  0:00:31s\n",
      "epoch 69 | loss: 1.10609 | val_0_accuracy: 0.39469 |  0:00:31s\n",
      "epoch 70 | loss: 1.09692 | val_0_accuracy: 0.4011  |  0:00:32s\n",
      "epoch 71 | loss: 1.10499 | val_0_accuracy: 0.40751 |  0:00:32s\n",
      "epoch 72 | loss: 1.08061 | val_0_accuracy: 0.39652 |  0:00:33s\n",
      "epoch 73 | loss: 1.08268 | val_0_accuracy: 0.40476 |  0:00:33s\n",
      "epoch 74 | loss: 1.07663 | val_0_accuracy: 0.40201 |  0:00:34s\n",
      "epoch 75 | loss: 1.07667 | val_0_accuracy: 0.40751 |  0:00:34s\n",
      "epoch 76 | loss: 1.06331 | val_0_accuracy: 0.41392 |  0:00:35s\n",
      "epoch 77 | loss: 1.06534 | val_0_accuracy: 0.42033 |  0:00:35s\n",
      "epoch 78 | loss: 1.06191 | val_0_accuracy: 0.39469 |  0:00:36s\n",
      "epoch 79 | loss: 1.077   | val_0_accuracy: 0.38645 |  0:00:36s\n",
      "epoch 80 | loss: 1.08019 | val_0_accuracy: 0.39652 |  0:00:36s\n",
      "epoch 81 | loss: 1.05383 | val_0_accuracy: 0.36905 |  0:00:37s\n",
      "epoch 82 | loss: 1.05728 | val_0_accuracy: 0.40385 |  0:00:37s\n",
      "epoch 83 | loss: 1.07466 | val_0_accuracy: 0.3956  |  0:00:38s\n",
      "epoch 84 | loss: 1.08603 | val_0_accuracy: 0.40842 |  0:00:38s\n",
      "epoch 85 | loss: 1.08243 | val_0_accuracy: 0.39103 |  0:00:39s\n",
      "epoch 86 | loss: 1.07433 | val_0_accuracy: 0.40934 |  0:00:39s\n",
      "epoch 87 | loss: 1.04868 | val_0_accuracy: 0.3837  |  0:00:40s\n",
      "epoch 88 | loss: 1.04009 | val_0_accuracy: 0.40018 |  0:00:40s\n",
      "epoch 89 | loss: 1.05164 | val_0_accuracy: 0.39194 |  0:00:41s\n",
      "epoch 90 | loss: 1.07813 | val_0_accuracy: 0.39835 |  0:00:41s\n",
      "epoch 91 | loss: 1.04913 | val_0_accuracy: 0.40476 |  0:00:41s\n",
      "epoch 92 | loss: 1.02159 | val_0_accuracy: 0.41209 |  0:00:42s\n",
      "epoch 93 | loss: 0.99382 | val_0_accuracy: 0.40201 |  0:00:42s\n",
      "epoch 94 | loss: 0.98377 | val_0_accuracy: 0.40293 |  0:00:43s\n",
      "epoch 95 | loss: 0.95819 | val_0_accuracy: 0.41117 |  0:00:43s\n",
      "epoch 96 | loss: 0.94178 | val_0_accuracy: 0.40842 |  0:00:44s\n",
      "epoch 97 | loss: 0.94693 | val_0_accuracy: 0.40842 |  0:00:44s\n",
      "epoch 98 | loss: 0.94507 | val_0_accuracy: 0.42308 |  0:00:45s\n",
      "\n",
      "Early stopping occurred at epoch 98 with best_epoch = 58 and best_val_0_accuracy = 0.43315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5] BLEND acc(test) = 0.4226 (w=0.5) | Δ vs Stage-1 = +0.0167\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES (Two-Stage)\n",
      "============================================================\n",
      "Stage-1 folds: ['0.3526', '0.4223', '0.3844', '0.3756', '0.4060']\n",
      "Stage-1 mean: 0.3882\n",
      "BLEND folds: ['0.3730', '0.4331', '0.3889', '0.4024', '0.4226']\n",
      "BLEND mean: 0.4040\n",
      "Δ(BLEND - Stage-1) mean: +0.0158\n",
      "↳ Matriz de confusión guardada: confusion_twostage_blend_allfolds.png\n",
      "✔️ Done.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Two-Stage MI-EEG (PhysioNet) — Standalone Notebook Block\n",
    "--------------------------------------------------------\n",
    "- Stage-1: EEGNet-parallel + MHA (temporal) + S-TCN + Time Slicing (feature-map)\n",
    "           → outputs (logits, emb128). Trained with CE (class-weighted), SGDR, logs train/val.\n",
    "- Stage-2: Tabular head over [emb] ⊕ [PSD] (Welch log-bandpower). Uses TabNet if available,\n",
    "           else an MLP fallback. Logs val accuracy for overfitting check.\n",
    "- Optional Blending: final_logits = w * logits_stage1 + (1-w) * logits_stage2.\n",
    "- Protocol: same paths and dataset construction patterns you use.\n",
    "\n",
    "Run: execute this cell as-is in a notebook. It shares the same directory layout:\n",
    "  PROJ/ data/raw  data/cache  models/folds/Kfold5.json\n",
    "\n",
    "Notes:\n",
    "- Uses only 8 MI channels you listed.\n",
    "- Keeps GroupKFold(5) and GroupSplit for val inside train, like your baseline.\n",
    "- WINDOW_MODE default changed to '3s' (0–3 s post-cue) for MI focus. You can switch back to '6s'.\n",
    "- Adds detailed logs each epoch: train_acc and val_acc for Stage-1; and val_acc for Stage-2.\n",
    "\"\"\"\n",
    "\n",
    "import os, re, math, random, json, itertools, copy, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Escenario y ventana\n",
    "CLASS_SCENARIO = '4c'\n",
    "WINDOW_MODE = '3s'   # recomendado para MI (0–3 s post-cue). Cambia a '6s' si quieres replicar.\n",
    "FS = 160.0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Entrenamiento Stage-1\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_STAGE1 = 70\n",
    "LR_STAGE1 = 1e-3\n",
    "WD_STAGE1 = 1e-5\n",
    "SGDR_T0 = 6\n",
    "SGDR_Tmult = 2\n",
    "PATIENCE_STAGE1 = 12\n",
    "LOG_EVERY = 5\n",
    "\n",
    "# Stage-2 (Tabular)\n",
    "USE_TABNET = True  # si no está instalado, cae a MLP automáticamente\n",
    "EPOCHS_STAGE2 = 400\n",
    "PATIENCE_STAGE2 = 40\n",
    "BLEND_W = 0.5      # peso de Stage-1 en el blend final\n",
    "\n",
    "# Fine-tuning por sujeto (opcional, simple)\n",
    "DO_SUBJECT_FT = False    # pon True si quieres hacer FT: adapta Stage-2 (+último bloque encoder)\n",
    "FT_EPOCHS = 10\n",
    "FT_LR_ENCODER_LAST = 1e-4\n",
    "\n",
    "# Normalización por época\n",
    "NORM_EPOCH_ZSCORE = True\n",
    "\n",
    "# Sujetos excluidos\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "# Runs\n",
    "MI_RUNS_LR = [4, 8, 12]\n",
    "MI_RUNS_OF = [6, 10, 14]\n",
    "BASELINE_RUNS_EO = [1]\n",
    "\n",
    "# Canales (8 con FCz)\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES_4C = ['Left', 'Right', 'Both Fists', 'Both Feet']\n",
    "\n",
    "# ============== UTIL CANALES/EDF (idéntico a tu base) ==============\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"Warning: faltan canales {missing} en archivo {getattr(raw,'filenames', [''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    if run_id in BASELINE_RUNS_EO: return 'EO'\n",
    "    return None\n",
    "\n",
    "_SNR_TABLE = None\n",
    "\n",
    "def _load_snr_table():\n",
    "    global _SNR_TABLE\n",
    "    if _SNR_TABLE is not None:\n",
    "        return _SNR_TABLE\n",
    "    csv_path = PROJ / 'reports' / 'psd_mains' / 'psd_mains_summary.csv'\n",
    "    if csv_path.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            _SNR_TABLE = df\n",
    "        except Exception as e:\n",
    "            print(f\"[SNR] No se pudo leer {csv_path}: {e}\")\n",
    "            _SNR_TABLE = None\n",
    "    return _SNR_TABLE\n",
    "\n",
    "def _decide_notch(subject, run, th_db=10.0):\n",
    "    df = _load_snr_table()\n",
    "    if df is None:  # default\n",
    "        return 60.0\n",
    "    row = df[(df['subject']==subject) & (df['run']==run)]\n",
    "    if row.empty:\n",
    "        return 60.0\n",
    "    snr50 = float(row['snr50_db'].iloc[0]); snr60 = float(row['snr60_db'].iloc[0])\n",
    "    if snr60 >= th_db and snr60 >= snr50: return 60.0\n",
    "    if snr50 >= th_db and snr50 >  snr60: return 50.0\n",
    "    return None  # no notch si no sobresale\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None:\n",
    "        return None\n",
    "    sid, rid = parse_subject_run(path)\n",
    "    notch = _decide_notch(sid, rid)\n",
    "    if notch is not None:\n",
    "        raw.notch_filter(freqs=[float(notch)], picks='eeg', method='spectrum_fit', phase='zero')\n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return []\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ', '')\n",
    "    res = []\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'):\n",
    "            res.append((float(onset), tag))\n",
    "    res.sort()\n",
    "    dedup = []\n",
    "    last_t1 = last_t2 = -1e9\n",
    "    for t, tag in res:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# ============== DATASET BUILD (como tu script) ==============\n",
    "\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR + MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "\n",
    "def extract_trials_from_run(edf_path: Path, scenario: str, window_mode: str):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF','EO'):\n",
    "        return ([], [])\n",
    "\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        return ([], [])\n",
    "\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    assert abs(fs - FS) < 1e-6\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if kind in ('LR','OF'):\n",
    "        events = collect_events_T1T2(raw)\n",
    "        if window_mode == '3s':\n",
    "            rel_start, rel_end = 0.0, 3.0\n",
    "        else:\n",
    "            rel_start, rel_end = -1.0, 5.0\n",
    "\n",
    "        for onset_sec, tag in events:\n",
    "            if kind == 'LR':\n",
    "                if tag == 'T1': label = 'L'\n",
    "                elif tag == 'T2': label = 'R'\n",
    "                else: continue\n",
    "            else:\n",
    "                if tag == 'T1': label = 'BFISTS'\n",
    "                elif tag == 'T2': label = 'BFEET'\n",
    "                else: continue\n",
    "\n",
    "            if scenario == '2c' and label not in ('L','R'): continue\n",
    "            if scenario == '3c' and label not in ('L','R','BFISTS'): continue\n",
    "            if scenario == '4c' and label not in ('L','R','BFISTS','BFEET'): continue\n",
    "\n",
    "            s = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "            e = int(round((raw.first_time + onset_sec + rel_end) * fs))\n",
    "            if s < 0 or e > data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            seg = data[:, s:e].T.astype(np.float32)  # (T,C)\n",
    "            if NORM_EPOCH_ZSCORE:\n",
    "                seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "\n",
    "            if label == 'L':       y = 0\n",
    "            elif label == 'R':     y = 1\n",
    "            elif label == 'BFISTS':y = 2\n",
    "            elif label == 'BFEET': y = 3\n",
    "            else: continue\n",
    "\n",
    "            out.append((seg, y, subj))\n",
    "\n",
    "    elif kind == 'EO':\n",
    "        return ([], raw.ch_names)\n",
    "\n",
    "    return out, raw.ch_names\n",
    "\n",
    "\n",
    "def build_dataset_all(subjects, scenario='4c', window_mode='3s'):\n",
    "    X, y, groups = [], [], []\n",
    "    ch_template = None\n",
    "\n",
    "    for s in tqdm(subjects, desc=\"Construyendo dataset (RAW)\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "\n",
    "        trials_L, trials_R, trials_FISTS, trials_FEET = [], [], [], []\n",
    "\n",
    "        for r in MI_RUNS_LR:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 0: trials_L.append(seg)\n",
    "                elif lab == 1: trials_R.append(seg)\n",
    "\n",
    "        for r in MI_RUNS_OF:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 2: trials_FISTS.append(seg)\n",
    "                elif lab == 3: trials_FEET.append(seg)\n",
    "\n",
    "        need_per_class = 21\n",
    "        def pick(trials, n, rng):\n",
    "            if len(trials) < n:\n",
    "                idx = rng.choice(len(trials), size=n, replace=True)\n",
    "                return [trials[i] for i in idx]\n",
    "            rng.shuffle(trials)\n",
    "            return trials[:n]\n",
    "\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        if len(trials_L)==0 or len(trials_R)==0 or len(trials_FISTS)==0 or len(trials_FEET)==0:\n",
    "            continue\n",
    "\n",
    "        Lp  = pick(trials_L,     need_per_class, rng)\n",
    "        Rp  = pick(trials_R,     need_per_class, rng)\n",
    "        FIp = pick(trials_FISTS, need_per_class, rng)\n",
    "        FEp = pick(trials_FEET,  need_per_class, rng)\n",
    "\n",
    "        pack = [(Lp, 0), (Rp, 1), (FIp, 2), (FEp, 3)]\n",
    "        for segs, lab in pack:\n",
    "            for seg in segs:\n",
    "                X.append(seg); y.append(lab); groups.append(s)\n",
    "\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    groups = np.asarray(groups, dtype=np.int64)\n",
    "\n",
    "    n, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Dataset construido: N={n} | T={T} | C={C} | clases={n_classes} | sujetos únicos={len(np.unique(groups))}\")\n",
    "    return X, y, groups, ch_template\n",
    "\n",
    "# ============== Dataset y utils torch ==============\n",
    "class EEGTrials(Dataset):\n",
    "    def __init__(self, X, y, groups):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        x = np.expand_dims(x, 0)                 # (1, T, C)\n",
    "        return torch.from_numpy(x), torch.tensor(self.y[idx]), torch.tensor(self.g[idx])\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_max_norm(layers, max_value=2.0, p=2.0):\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            w = layer.weight.data\n",
    "            norms = w.view(w.size(0), -1).norm(p=p, dim=1, keepdim=True)\n",
    "            desired = torch.clamp(norms, max=max_value)\n",
    "            w.view(w.size(0), -1).mul_(desired / (1e-8 + norms))\n",
    "\n",
    "# ============== Augments (ligeros) ==============\n",
    "\n",
    "def do_time_jitter(x, max_ms=50, fs=160.0):\n",
    "    max_shift = int(round(max_ms/1000.0 * fs))\n",
    "    if max_shift <= 0: return x\n",
    "    B,_,T,C = x.shape\n",
    "    shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=x.device)\n",
    "    out = torch.empty_like(x)\n",
    "    for i,s in enumerate(shifts):\n",
    "        if s==0: out[i] = x[i]; continue\n",
    "        if s>0:\n",
    "            out[i,:,s:,:] = x[i,:,:T-s,:]\n",
    "            out[i,:,:s,:] = 0\n",
    "        else:\n",
    "            s = -s\n",
    "            out[i,:,:T-s,:] = x[i,:,s:,:]\n",
    "            out[i,:,T-s:,:] = 0\n",
    "    return out\n",
    "\n",
    "def do_gaussian_noise(x, sigma=0.01):\n",
    "    if sigma<=0: return x\n",
    "    return x + sigma*torch.randn_like(x)\n",
    "\n",
    "def mixup_batch(x, y, n_classes, alpha=0.2):\n",
    "    if alpha<=0:\n",
    "        y_onehot = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "        return x, y_onehot, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    perm = torch.randperm(x.size(0), device=x.device)\n",
    "    x_mix = lam*x + (1-lam)*x[perm]\n",
    "    y_a = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "    y_b = y_a[perm]\n",
    "    y_mix = lam*y_a + (1-lam)*y_b\n",
    "    return x_mix, y_mix, lam\n",
    "\n",
    "class WeightedSoftCrossEntropy(nn.Module):\n",
    "    def __init__(self, class_weights=None, label_smoothing=0.05):\n",
    "        super().__init__()\n",
    "        self.register_buffer('w', None if class_weights is None else class_weights.clone().float())\n",
    "        self.ls = float(label_smoothing)\n",
    "    def forward(self, logits, target_probs):\n",
    "        if self.ls > 0:\n",
    "            K = logits.size(1)\n",
    "            target_probs = (1-self.ls)*target_probs + self.ls*(1.0/K)\n",
    "        logp = torch.log_softmax(logits, dim=1)\n",
    "        loss_per_class = -(target_probs * logp)\n",
    "        if self.w is not None:\n",
    "            loss_per_class = loss_per_class * self.w.unsqueeze(0)\n",
    "        loss = loss_per_class.sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "# ============== Stage-1: Encoder (EEGNet-parallel + MHA + S-TCN + Slicing) ==============\n",
    "class MHABlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 4, dim), nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = self.norm(x)\n",
    "        y, _ = self.attn(h, h, h, need_weights=False)\n",
    "        x = x + self.drop(y)\n",
    "        x = x + self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class DSConv1d(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, k: int = 4, dilation: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        pad = (k - 1) // 2 * dilation\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, groups=in_ch, padding=pad, dilation=dilation, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU(); self.drop = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x); x = self.act(x); x = self.drop(x); return x\n",
    "\n",
    "class STCN(nn.Module):\n",
    "    def __init__(self, dim: int, k: int = 4, dilations=(1,2,4), dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                DSConv1d(dim, dim, k=k, dilation=d, dropout=dropout),\n",
    "                nn.Conv1d(dim, dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm1d(dim), nn.ELU(), nn.Dropout(dropout)\n",
    "            ) for d in dilations\n",
    "        ])\n",
    "    def forward(self, x):  # (B,D,T)\n",
    "        for b in self.blocks:\n",
    "            res = x; x = b(x); x = x + res\n",
    "        return x\n",
    "\n",
    "class EEGNetParallel(nn.Module):\n",
    "    def __init__(self, n_ch: int, F1: int = 16, D: int = 2, k_t_list=(32,64,96), pool1_t=4, k_sep=16, pool2_t=4, drop=0.2):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.branches = nn.ModuleList()\n",
    "        for k_t in k_t_list:\n",
    "            self.branches.append(nn.Sequential(\n",
    "                nn.Conv2d(1, F1, kernel_size=(k_t, 1), padding=(k_t // 2, 0), bias=False),\n",
    "                nn.BatchNorm2d(F1), nn.ELU(),\n",
    "                nn.Conv2d(F1, F1*D, kernel_size=(1, n_ch), groups=F1, bias=False),\n",
    "                nn.BatchNorm2d(F1*D), nn.ELU(),\n",
    "                nn.AvgPool2d(kernel_size=(pool1_t,1), stride=(pool1_t,1)),\n",
    "                nn.Dropout(drop),\n",
    "                nn.Conv2d(F1*D, F1*D, kernel_size=(k_sep,1), groups=F1*D, padding=(k_sep//2,0), bias=False),\n",
    "                nn.Conv2d(F1*D, F1*D, kernel_size=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(F1*D), nn.ELU(),\n",
    "                nn.AvgPool2d(kernel_size=(pool2_t,1), stride=(pool2_t,1)),\n",
    "                nn.Dropout(drop),\n",
    "            ))\n",
    "        self.out_dim = len(k_t_list) * (F1*D)\n",
    "    def forward(self, x):\n",
    "        feats = [b(x) for b in self.branches]  # each: (B,F2,T',1)\n",
    "        return torch.cat(feats, dim=1)         # (B,Dsum,T',1)\n",
    "\n",
    "class TwoStageEncoder(nn.Module):\n",
    "    def __init__(self, n_ch: int, n_classes: int,\n",
    "                 F1=16, D=2, k_t_list=(32,64,96), attn_heads=2,\n",
    "                 stcn_k=4, stcn_dils=(1,2,4), emb_dim=128, drop=0.2,\n",
    "                 slice_len_steps=None, slice_stride_steps=None, avg_on='emb'):\n",
    "        super().__init__()\n",
    "        self.backbone = EEGNetParallel(n_ch=n_ch, F1=F1, D=D, k_t_list=k_t_list, drop=drop)\n",
    "        self.proj = nn.Conv2d(self.backbone.out_dim, emb_dim, kernel_size=(1,1), bias=False)\n",
    "        self.attn = MHABlock(dim=emb_dim, num_heads=attn_heads, dropout=drop)\n",
    "        self.stcn = STCN(dim=emb_dim, k=stcn_k, dilations=stcn_dils, dropout=drop)\n",
    "        self.cls_head = nn.Linear(emb_dim, n_classes)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.avg_on = avg_on\n",
    "        self.slice_len_steps = slice_len_steps\n",
    "        self.slice_stride_steps = slice_stride_steps\n",
    "\n",
    "    def _time_slices(self, T):\n",
    "        if self.slice_len_steps is None or self.slice_stride_steps is None:\n",
    "            k = 5; L = max(2, T // (k + 1)); S = max(1, (T - L) // max(1, (k - 1)))\n",
    "        else:\n",
    "            L, S = self.slice_len_steps, self.slice_stride_steps\n",
    "        slices, s = [], 0\n",
    "        while s + L <= T:\n",
    "            slices.append((s, s+L)); s += S\n",
    "        if not slices: slices = [(0,T)]\n",
    "        return slices\n",
    "\n",
    "    def forward(self, x):  # x: (B,1,T,C)\n",
    "        z = self.backbone(x)                      # (B,Dsum,T',1)\n",
    "        z = self.proj(z).squeeze(-1).transpose(1,2)  # (B,T',emb)\n",
    "        z = self.attn(z)\n",
    "        z = self.stcn(z.transpose(1,2)).transpose(1,2)  # (B,T',emb)\n",
    "        B,Tp,Demb = z.shape\n",
    "        idxs = self._time_slices(Tp)\n",
    "        slice_embs, slice_logits = [], []\n",
    "        for (a,b) in idxs:\n",
    "            seg = z[:,a:b,:]\n",
    "            e = seg.mean(dim=1)  # GAP over time\n",
    "            slice_embs.append(e)\n",
    "            slice_logits.append(self.cls_head(e))\n",
    "        if self.avg_on == 'logits':\n",
    "            logits = torch.stack(slice_logits, dim=0).mean(dim=0)\n",
    "            emb = torch.stack(slice_embs, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            emb = torch.stack(slice_embs, dim=0).mean(dim=0)\n",
    "            logits = self.cls_head(emb)\n",
    "        return logits, emb\n",
    "\n",
    "# ============== Stage-1 training & eval ==============\n",
    "\n",
    "def build_weighted_sampler(y, groups):\n",
    "    y = np.asarray(y); groups = np.asarray(groups)\n",
    "    class_counts = np.bincount(y, minlength=len(np.unique(y))).astype(float)\n",
    "    class_w = 1.0 / class_counts[y]\n",
    "    subj_vals, subj_counts = np.unique(groups, return_counts=True)\n",
    "    subj_map = {s:c for s,c in zip(subj_vals, subj_counts)}\n",
    "    subj_w = np.array([1.0/subj_map[g] for g in groups], dtype=float)\n",
    "    w = class_w * subj_w\n",
    "    w = w / w.mean()\n",
    "    w_t = torch.from_numpy(w).float()\n",
    "    sampler = WeightedRandomSampler(weights=w_t, num_samples=len(w_t), replacement=True)\n",
    "    return sampler\n",
    "\n",
    "class Stage1Trainer:\n",
    "    def __init__(self, device=DEVICE, lr=LR_STAGE1, wd=WD_STAGE1, label_smoothing=0.05, max_norm=2.0):\n",
    "        self.device = device; self.lr = lr; self.wd = wd\n",
    "        self.label_smoothing = label_smoothing; self.max_norm = max_norm\n",
    "    def _crit(self, n_classes, class_weights=None):\n",
    "        return nn.CrossEntropyLoss(weight=class_weights, label_smoothing=self.label_smoothing)\n",
    "    def fit(self, model, dl_train, dl_val, epochs=EPOCHS_STAGE1, class_weights=None):\n",
    "        model.to(self.device)\n",
    "        opt = optim.Adam(model.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        sched = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=SGDR_T0, T_mult=SGDR_Tmult)\n",
    "        crit = self._crit(n_classes=model.cls_head.out_features, class_weights=class_weights)\n",
    "        best_state = copy.deepcopy(model.state_dict()); best_val=-1.0; bad=0\n",
    "        history = {'train_acc':[], 'val_acc':[]}\n",
    "        for ep in range(1, epochs+1):\n",
    "            # ---- train epoch ----\n",
    "            model.train(); n_ok=0; n_tot=0\n",
    "            for xb,yb,_ in dl_train:\n",
    "                xb,yb = xb.to(self.device), yb.to(self.device)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                logits,_ = model(xb)\n",
    "                loss = crit(logits, yb)\n",
    "                loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 5.0); opt.step()\n",
    "                n_ok += (logits.argmax(1)==yb).sum().item(); n_tot += yb.numel()\n",
    "            sched.step(ep-1 + 1e-8)\n",
    "            train_acc = n_ok/max(1,n_tot)\n",
    "            # ---- val ----\n",
    "            val_acc = self.evaluate(model, dl_val)\n",
    "            history['train_acc'].append(train_acc); history['val_acc'].append(val_acc)\n",
    "            if (ep % LOG_EVERY == 0) or ep in (1, 10, 20, 50):\n",
    "                cur_lr = opt.param_groups[0]['lr']\n",
    "                print(f\"[Stage-1] Ep {ep:3d} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f} | LR={cur_lr:.5f}\")\n",
    "            if val_acc > best_val + 1e-4:\n",
    "                best_val = val_acc; best_state = copy.deepcopy(model.state_dict()); bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= PATIENCE_STAGE1:\n",
    "                    print(f\"[Stage-1] Early stopping @ {ep} (best val_acc={best_val:.4f})\")\n",
    "                    break\n",
    "        return best_state, history\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, model, dl):\n",
    "        model.eval(); n_ok=0; n=0\n",
    "        for xb,yb,_ in dl:\n",
    "            xb,yb = xb.to(self.device), yb.to(self.device)\n",
    "            logits,_ = model(xb)\n",
    "            n_ok += (logits.argmax(1)==yb).sum().item(); n += yb.numel()\n",
    "        return n/max(1,n)\n",
    "    @torch.no_grad()\n",
    "    def predict_logits(self, model, dl):\n",
    "        model.eval(); outs=[]\n",
    "        for xb,_,_ in dl:\n",
    "            xb = xb.to(self.device)\n",
    "            logits,_ = model(xb)\n",
    "            outs.append(logits.detach().cpu().numpy())\n",
    "        return np.vstack(outs)\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(model, dl, device=DEVICE):\n",
    "    model.eval().to(device)\n",
    "    embs, ys = [], []\n",
    "    for xb,yb,_ in dl:\n",
    "        xb = xb.to(device)\n",
    "        _, e = model(xb)\n",
    "        embs.append(e.detach().cpu().numpy()); ys.append(yb.numpy())\n",
    "    return np.vstack(embs), np.concatenate(ys)\n",
    "\n",
    "# ============== PSD features (Welch) ==============\n",
    "try:\n",
    "    from scipy.signal import welch\n",
    "except Exception:\n",
    "    welch = None\n",
    "    warnings.warn(\"scipy not found: PSD features disabled. Install scipy to enable.\")\n",
    "\n",
    "class PSDConfig:\n",
    "    def __init__(self, fs=160.0, nperseg_sec=1.0, noverlap=0.5, bands=((1,4),(4,8),(8,14),(14,31),(31,49))):\n",
    "        self.fs = fs; self.nperseg_sec = nperseg_sec; self.noverlap = noverlap; self.bands = bands\n",
    "\n",
    "def _bandpower(f, Pxx, band):\n",
    "    idx = (f >= band[0]) & (f < band[1])\n",
    "    return (Pxx[idx].mean() + 1e-12)\n",
    "\n",
    "def make_psd_features(X_np, cfg=PSDConfig()):\n",
    "    if welch is None:\n",
    "        raise RuntimeError(\"scipy.signal.welch not available.\")\n",
    "    N,T,C = X_np.shape\n",
    "    nperseg = int(round(cfg.nperseg_sec*cfg.fs))\n",
    "    noverlap = int(round(cfg.noverlap*nperseg))\n",
    "    feats = []\n",
    "    for i in range(N):\n",
    "        x = X_np[i]\n",
    "        ch_feats = []\n",
    "        for c in range(C):\n",
    "            f, P = welch(x[:,c], fs=cfg.fs, nperseg=nperseg, noverlap=noverlap)\n",
    "            bp = [np.log(_bandpower(f, P, b)) for b in cfg.bands]\n",
    "            ch_feats.extend(bp)\n",
    "        feats.append(ch_feats)\n",
    "    return np.asarray(feats, dtype=np.float32)\n",
    "\n",
    "# ============== Stage-2: Tabular head (TabNet or MLP) ==============\n",
    "class _MLPHead(nn.Module):\n",
    "    def __init__(self, d_in, n_classes, hidden=256, drop=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, hidden), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(hidden, hidden//2), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(hidden//2, n_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class TabularHead:\n",
    "    def __init__(self, input_dim, n_classes, use_tabnet=USE_TABNET, device=DEVICE, tabnet_params=None):\n",
    "        self.n_classes = n_classes; self.device = device\n",
    "        self.use_tabnet = False; self.tabnet=None\n",
    "        if use_tabnet:\n",
    "            try:\n",
    "                from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "                self.tabnet = TabNetClassifier(**(tabnet_params or dict(n_d=32, n_a=64, n_steps=3, gamma=1.5)))\n",
    "                self.use_tabnet = True\n",
    "            except Exception:\n",
    "                warnings.warn(\"pytorch_tabnet not found; using MLP fallback.\")\n",
    "        if not self.use_tabnet:\n",
    "            self.mlp = _MLPHead(input_dim, n_classes).to(self.device)\n",
    "            self.opt = optim.Adam(self.mlp.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            self.crit = nn.CrossEntropyLoss()\n",
    "            self.scaler_mean=None; self.scaler_std=None\n",
    "    def fit(self, X, y, X_val=None, y_val=None, epochs=EPOCHS_STAGE2, patience=PATIENCE_STAGE2):\n",
    "        if self.use_tabnet:\n",
    "            eval_set=[(X_val, y_val)] if X_val is not None else None\n",
    "            self.tabnet.fit(X, y, eval_set=eval_set, max_epochs=epochs, patience=patience,\n",
    "                            batch_size=256, virtual_batch_size=128)\n",
    "        else:\n",
    "            self.scaler_mean = X.mean(axis=0, keepdims=True); self.scaler_std = X.std(axis=0, keepdims=True)+1e-6\n",
    "            Xn = (X - self.scaler_mean)/self.scaler_std; Xn = torch.from_numpy(Xn).float().to(self.device)\n",
    "            y_t = torch.from_numpy(y).long().to(self.device)\n",
    "            dset = torch.utils.data.TensorDataset(Xn,y_t)\n",
    "            loader = DataLoader(dset, batch_size=256, shuffle=True)\n",
    "            if X_val is not None and y_val is not None:\n",
    "                Xv = (X_val - self.scaler_mean)/self.scaler_std\n",
    "                self.Xv_t = torch.from_numpy(Xv).float().to(self.device)\n",
    "                self.yv_t = torch.from_numpy(y_val).long().to(self.device)\n",
    "            else:\n",
    "                self.Xv_t=None; self.yv_t=None\n",
    "            best_state = copy.deepcopy(self.mlp.state_dict()); best=-1.0; bad=0\n",
    "            for ep in range(1, epochs+1):\n",
    "                self.mlp.train()\n",
    "                for xb,yb in loader:\n",
    "                    self.opt.zero_grad(set_to_none=True)\n",
    "                    logits = self.mlp(xb)\n",
    "                    loss = self.crit(logits, yb)\n",
    "                    loss.backward(); self.opt.step()\n",
    "                if self.Xv_t is not None:\n",
    "                    self.mlp.eval();\n",
    "                    with torch.no_grad():\n",
    "                        lv = self.mlp(self.Xv_t)\n",
    "                        acc = (lv.argmax(1)==self.yv_t).float().mean().item()\n",
    "                    if ep % 10 == 0:\n",
    "                        print(f\"[Stage-2] Ep {ep:3d} | val_acc={acc:.4f}\")\n",
    "                    if acc > best + 1e-4:\n",
    "                        best = acc; best_state = copy.deepcopy(self.mlp.state_dict()); bad=0\n",
    "                    else:\n",
    "                        bad += 1\n",
    "                        if bad >= patience:\n",
    "                            print(f\"[Stage-2] Early stopping @ {ep} (best val_acc={best:.4f})\"); break\n",
    "            self.mlp.load_state_dict(best_state)\n",
    "    def predict_logits(self, X):\n",
    "        if self.use_tabnet:\n",
    "            proba = self.tabnet.predict_proba(X)\n",
    "            return np.log(proba + 1e-9)\n",
    "        else:\n",
    "            Xn = (X - self.scaler_mean)/self.scaler_std\n",
    "            Xt = torch.from_numpy(Xn).float().to(self.device)\n",
    "            self.mlp.eval();\n",
    "            with torch.no_grad():\n",
    "                logits = self.mlp(Xt).cpu().numpy()\n",
    "            return logits\n",
    "\n",
    "def blend_logits(logits1, logits2, w=BLEND_W):\n",
    "    w = float(np.clip(w,0.0,1.0)); return w*logits1 + (1.0-w)*logits2\n",
    "\n",
    "# ============== Folds JSON helpers (como tu script) ==============\n",
    "\n",
    "def save_group_folds_json_with_indices(subject_ids_str, groups_array, n_splits, out_json_path,\n",
    "                                       created_by=\"TwoStage_Exp\", description=None):\n",
    "    out_json_path = Path(out_json_path)\n",
    "    unique_subjects_int = sorted(np.unique(groups_array).tolist())\n",
    "    subject_ids = [f\"S{sid:03d}\" for sid in unique_subjects_int]\n",
    "    if len(subject_ids) < n_splits:\n",
    "        raise ValueError(f\"n_splits={n_splits} mayor que número de sujetos={len(subject_ids)}\")\n",
    "    groups = np.arange(len(subject_ids))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    folds = []\n",
    "    fold_i = 0\n",
    "    for train_idx_grp, test_idx_grp in gkf.split(groups, groups, groups):\n",
    "        fold_i += 1\n",
    "        train_sids = [subject_ids[int(i)] for i in train_idx_grp]\n",
    "        test_sids  = [subject_ids[int(i)] for i in test_idx_grp]\n",
    "        train_sids_int = [int(s[1:]) for s in train_sids]\n",
    "        test_sids_int  = [int(s[1:]) for s in test_sids]\n",
    "        tr_idx = np.where(np.isin(groups_array, train_sids_int))[0].tolist()\n",
    "        te_idx = np.where(np.isin(groups_array, test_sids_int))[0].tolist()\n",
    "        folds.append({\"fold\": int(fold_i), \"train\": train_sids, \"test\": test_sids, \"tr_idx\": tr_idx, \"te_idx\": te_idx})\n",
    "    payload = {\"created_at\": datetime.now().isoformat(), \"created_by\": created_by,\n",
    "               \"description\": description if description is not None else \"\",\n",
    "               \"n_splits\": int(n_splits), \"n_subjects\": len(subject_ids),\n",
    "               \"subject_ids\": subject_ids, \"folds\": folds}\n",
    "    out_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Folds JSON con índices guardado → {out_json_path}\")\n",
    "    return out_json_path\n",
    "\n",
    "\n",
    "def load_group_folds_json(path_json, expected_subject_ids=None, strict_check=True):\n",
    "    path_json = Path(path_json)\n",
    "    if not path_json.exists():\n",
    "        raise FileNotFoundError(f\"No existe {path_json}\")\n",
    "    with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "    subj_json = payload.get(\"subject_ids\", [])\n",
    "    if expected_subject_ids is not None:\n",
    "        expected = sorted(list(expected_subject_ids))\n",
    "        if subj_json != expected:\n",
    "            msg = (\"Los subject_ids del JSON no coinciden con expected_subject_ids.\\n\"\n",
    "                   f\"JSON has {len(subj_json)} subjects, expected {len(expected)}.\\n\"\n",
    "                   f\"First 10 JSON: {subj_json[:10]}\\nFirst 10 expected: {expected[:10]}\")\n",
    "            if strict_check: raise ValueError(msg)\n",
    "            else: print(\"WARNING: \" + msg)\n",
    "    return payload\n",
    "\n",
    "# ============== Confusion + curves ==============\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, ha='right'); plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f'; thresh = cm_norm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i, format(cm_norm[i, j], fmt), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150, bbox_inches='tight'); plt.close()\n",
    "\n",
    "def plot_training_curves(history, fname, title='Stage-1 Training curve'):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history['train_acc'], label='train_acc')\n",
    "    plt.plot(history['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title(title); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "# ============== EXPERIMENTO PRINCIPAL ==============\n",
    "\n",
    "def run_experiment_two_stage():\n",
    "    mne.set_log_level('WARNING')\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos elegibles: {len(subs)} → {subs[:10]}{'...' if len(subs)>10 else ''}\")\n",
    "\n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Listo para entrenar: N={N} | T={T} | C={C} | clases={n_classes} | sujetos={len(np.unique(groups))}\")\n",
    "\n",
    "    ds = EEGTrials(X, y, groups)\n",
    "\n",
    "    # preparar JSON folds\n",
    "    folds_json_path = Path(FOLDS_DIR)\n",
    "    folds_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    unique_subs = sorted(np.unique(groups).tolist())\n",
    "    subject_ids_str = [f\"S{s:03d}\" for s in unique_subs]\n",
    "    if not folds_json_path.exists():\n",
    "        save_group_folds_json_with_indices(subject_ids_str, groups, n_splits=N_FOLDS,\n",
    "                                           out_json_path=folds_json_path,\n",
    "                                           created_by=\"TwoStage_Pipeline\",\n",
    "                                           description=\"Two-Stage GroupKFold\")\n",
    "    payload = load_group_folds_json(folds_json_path, expected_subject_ids=subject_ids_str, strict_check=False)\n",
    "    folds = payload[\"folds\"]\n",
    "\n",
    "    global_folds = []\n",
    "    blend_folds = []\n",
    "    all_true = []; all_pred = []\n",
    "\n",
    "    for f in folds:\n",
    "        fold = f[\"fold\"]\n",
    "        tr_idx = np.asarray(f.get(\"tr_idx\", []), dtype=int)\n",
    "        te_idx = np.asarray(f.get(\"te_idx\", []), dtype=int)\n",
    "        if tr_idx.size == 0 or te_idx.size == 0:\n",
    "            print(f\"Advertencia: fold {fold} sin índices tr/te válidos. Saltando.\")\n",
    "            continue\n",
    "        # Split de validación por sujetos\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=RANDOM_STATE)\n",
    "        tr_subj_idx, va_subj_idx = next(gss.split(tr_idx, groups[tr_idx], groups[tr_idx]))\n",
    "        tr_sub_idx = tr_idx[tr_subj_idx]\n",
    "        va_idx     = tr_idx[va_subj_idx]\n",
    "\n",
    "        tr_loader = DataLoader(Subset(ds, tr_sub_idx), batch_size=BATCH_SIZE,\n",
    "                               sampler=build_weighted_sampler(y[tr_sub_idx], groups[tr_sub_idx]), drop_last=False)\n",
    "        va_loader = DataLoader(Subset(ds, va_idx),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        te_loader = DataLoader(Subset(ds, te_idx),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "        # -------- Stage-1 --------\n",
    "        model = TwoStageEncoder(n_ch=C, n_classes=n_classes,\n",
    "                                F1=16, D=2, k_t_list=(32,64,96), attn_heads=2,\n",
    "                                stcn_k=3, stcn_dils=(1,2,4), emb_dim=128, drop=0.2,\n",
    "                                slice_len_steps=None, slice_stride_steps=None, avg_on='emb').to(DEVICE)\n",
    "\n",
    "        trainer = Stage1Trainer(device=DEVICE, lr=LR_STAGE1, wd=WD_STAGE1, label_smoothing=0.05)\n",
    "        class_counts = np.bincount(y[tr_sub_idx], minlength=n_classes).astype(np.float32)\n",
    "        class_counts[class_counts==0]=1.0\n",
    "        class_w = class_counts.sum()/class_counts\n",
    "        class_w = class_w / class_w.mean()\n",
    "        class_w = torch.tensor(class_w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        print(f\"\\n[Fold {fold}/{N_FOLDS}] Entrenando Stage-1 (encoder)...\")\n",
    "        best_state, hist = trainer.fit(model, tr_loader, va_loader, epochs=EPOCHS_STAGE1, class_weights=class_w)\n",
    "        plot_training_curves(hist, f\"stage1_curve_fold{fold}.png\", title='Stage-1 Train/Val Acc')\n",
    "        print(f\"↳ Curva Stage-1 guardada: stage1_curve_fold{fold}.png\")\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # Evaluación Stage-1 pura en test\n",
    "        logits_stage1 = trainer.predict_logits(model, te_loader)  # (Nte, C)\n",
    "        y_te = y[te_idx]\n",
    "        y_pred_stage1 = logits_stage1.argmax(1)\n",
    "        acc_stage1 = (y_pred_stage1 == y_te).mean()\n",
    "        print(f\"[Fold {fold}] Stage-1 acc(test) = {acc_stage1:.4f}\")\n",
    "\n",
    "        # -------- Extraer embeddings + PSD para Stage-2 --------\n",
    "        emb_tr, y_tr = extract_embeddings(model, tr_loader, DEVICE)\n",
    "        emb_va, y_va = extract_embeddings(model, va_loader, DEVICE)\n",
    "        emb_te, _    = extract_embeddings(model, te_loader, DEVICE)\n",
    "\n",
    "        # recolecta X bruto para PSD\n",
    "        def collect_numpy(dl):\n",
    "            Xs, ys = [], []\n",
    "            for xb,yb,_ in dl:\n",
    "                Xs.append(xb.squeeze(1).numpy()); ys.append(yb.numpy())\n",
    "            return np.concatenate(Xs, axis=0), np.concatenate(ys, axis=0)\n",
    "        X_tr_np, _ = collect_numpy(tr_loader)\n",
    "        X_va_np, _ = collect_numpy(va_loader)\n",
    "        X_te_np, _ = collect_numpy(te_loader)\n",
    "\n",
    "        if welch is None:\n",
    "            print(\"WARNING: scipy no disponible → Stage-2 usará SOLO embeddings (sin PSD).\")\n",
    "            psd_tr = np.zeros((emb_tr.shape[0], 0), dtype=np.float32)\n",
    "            psd_va = np.zeros((emb_va.shape[0], 0), dtype=np.float32)\n",
    "            psd_te = np.zeros((emb_te.shape[0], 0), dtype=np.float32)\n",
    "        else:\n",
    "            psd_tr = make_psd_features(X_tr_np, PSDConfig(fs=FS))\n",
    "            psd_va = make_psd_features(X_va_np, PSDConfig(fs=FS))\n",
    "            psd_te = make_psd_features(X_te_np, PSDConfig(fs=FS))\n",
    "\n",
    "        Xtr2 = np.hstack([emb_tr, psd_tr]); Xva2 = np.hstack([emb_va, psd_va]); Xte2 = np.hstack([emb_te, psd_te])\n",
    "\n",
    "        # -------- Stage-2 (TabNet/MLP) --------\n",
    "        head = TabularHead(input_dim=Xtr2.shape[1], n_classes=n_classes, use_tabnet=USE_TABNET, device=DEVICE)\n",
    "        print(f\"[Fold {fold}] Entrenando Stage-2 (tabular head)...\")\n",
    "        head.fit(Xtr2, y_tr, X_val=Xva2, y_val=y_va, epochs=EPOCHS_STAGE2, patience=PATIENCE_STAGE2)\n",
    "        logits_stage2 = head.predict_logits(Xte2)\n",
    "\n",
    "        # -------- Blend opcional --------\n",
    "        logits_blend = blend_logits(logits_stage1, logits_stage2, w=BLEND_W)\n",
    "        y_pred_blend = logits_blend.argmax(1)\n",
    "        acc_blend = (y_pred_blend == y_te).mean()\n",
    "        print(f\"[Fold {fold}] BLEND acc(test) = {acc_blend:.4f} (w={BLEND_W}) | Δ vs Stage-1 = {acc_blend-acc_stage1:+.4f}\")\n",
    "\n",
    "        global_folds.append(acc_stage1)\n",
    "        blend_folds.append(acc_blend)\n",
    "        all_true.append(y_te); all_pred.append(y_pred_blend)\n",
    "\n",
    "    if len(all_true)>0:\n",
    "        all_true = np.concatenate(all_true); all_pred = np.concatenate(all_pred)\n",
    "    else:\n",
    "        all_true = np.array([], dtype=int); all_pred = np.array([], dtype=int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADOS FINALES (Two-Stage)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Stage-1 folds:\", [f\"{a:.4f}\" for a in global_folds])\n",
    "    if global_folds:\n",
    "        print(f\"Stage-1 mean: {np.mean(global_folds):.4f}\")\n",
    "    print(\"BLEND folds:\", [f\"{a:.4f}\" for a in blend_folds])\n",
    "    if blend_folds:\n",
    "        print(f\"BLEND mean: {np.mean(blend_folds):.4f}\")\n",
    "        print(f\"Δ(BLEND - Stage-1) mean: {np.mean(blend_folds) - np.mean(global_folds):+.4f}\")\n",
    "\n",
    "    if all_true.size>0:\n",
    "        plot_confusion(all_true, all_pred, CLASS_NAMES_4C,\n",
    "                       title=\"Confusion Matrix - Two-Stage BLEND (All Folds)\",\n",
    "                       fname=\"confusion_twostage_blend_allfolds.png\")\n",
    "        print(\"↳ Matriz de confusión guardada: confusion_twostage_blend_allfolds.png\")\n",
    "\n",
    "    return {\n",
    "        \"stage1_folds\": global_folds,\n",
    "        \"blend_folds\": blend_folds,\n",
    "        \"all_true\": all_true,\n",
    "        \"all_pred\": all_pred,\n",
    "        \"folds_json_path\": str(FOLDS_DIR)\n",
    "    }\n",
    "\n",
    "# -------- MAIN --------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🧠 INICIANDO EXPERIMENTO TWO-STAGE (Encoder+Tabular)\")\n",
    "    print(f\"🔧 Configuración: {CLASS_SCENARIO}, {len(EXPECTED_8)} canales, {WINDOW_MODE}\")\n",
    "    print(f\"⚙️  Stage-1: epochs={EPOCHS_STAGE1}, lr={LR_STAGE1}, SGDR T0={SGDR_T0}, Tmult={SGDR_Tmult}\")\n",
    "    print(f\"⚙️  Stage-2: {'TabNet' if USE_TABNET else 'MLP'} | epochs={EPOCHS_STAGE2}, patience={PATIENCE_STAGE2}\")\n",
    "    out = run_experiment_two_stage()\n",
    "    print(\"✔️ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc20b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Usando dispositivo: cuda\n",
      "🧠 INICIANDO EXPERIMENTO TWO-STAGE (Encoder+Tabular, tuned)\n",
      "🔧 Configuración: 4c, 8 canales, 6s\n",
      "⚙️  Stage-1: epochs=80, lr=0.001, SGDR T0=6, Tmult=2, augments+TTA ✓\n",
      "⚙️  Stage-2: TabNet | epochs=400, patience=50\n",
      "Sujetos elegibles: 103 → [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW):   0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|██████████| 103/103 [00:36<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=8652 | T=640 | C=8 | clases=4 | sujetos únicos=103\n",
      "Listo para entrenar: N=8652 | T=640 | C=8 | clases=4 | sujetos=103\n",
      "[Fold 1] sujetos train=65, val=17, test=21\n",
      "  train subs: [1, 4, 5, 6, 7, 10, 11, 12, 14, 16]...\n",
      "  val   subs: [2, 9, 15, 21, 27, 34, 41, 47, 53, 60]...\n",
      "  test  subs: [3, 8, 13, 18, 23, 28, 33, 39, 44, 49]...\n",
      "[Fold 1] n_train=5460 | n_val=1428 | n_test=1764\n",
      "[Fold 1] val class dist: {0: 357, 1: 357, 2: 357, 3: 357}\n",
      "\n",
      "[Fold 1/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3837 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.5099 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5209 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Ep  15 | train_acc=0.6016 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Early stopping @ 16 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold1.png\n",
      "[Fold 1] Stage-1 acc(test) = 0.3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.72381 | val_0_accuracy: 0.2521  |  0:00:00s\n",
      "epoch 1  | loss: 1.39826 | val_0_accuracy: 0.28992 |  0:00:01s\n",
      "epoch 2  | loss: 1.34501 | val_0_accuracy: 0.30462 |  0:00:01s\n",
      "epoch 3  | loss: 1.3227  | val_0_accuracy: 0.29202 |  0:00:02s\n",
      "epoch 4  | loss: 1.3081  | val_0_accuracy: 0.32633 |  0:00:02s\n",
      "epoch 5  | loss: 1.3049  | val_0_accuracy: 0.34314 |  0:00:03s\n",
      "epoch 6  | loss: 1.30153 | val_0_accuracy: 0.37535 |  0:00:03s\n",
      "epoch 7  | loss: 1.303   | val_0_accuracy: 0.38375 |  0:00:04s\n",
      "epoch 8  | loss: 1.28378 | val_0_accuracy: 0.37185 |  0:00:04s\n",
      "epoch 9  | loss: 1.27604 | val_0_accuracy: 0.39216 |  0:00:05s\n",
      "epoch 10 | loss: 1.27567 | val_0_accuracy: 0.39216 |  0:00:06s\n",
      "epoch 11 | loss: 1.2724  | val_0_accuracy: 0.40126 |  0:00:06s\n",
      "epoch 12 | loss: 1.27616 | val_0_accuracy: 0.39636 |  0:00:07s\n",
      "epoch 13 | loss: 1.27536 | val_0_accuracy: 0.37815 |  0:00:07s\n",
      "epoch 14 | loss: 1.272   | val_0_accuracy: 0.39636 |  0:00:08s\n",
      "epoch 15 | loss: 1.26327 | val_0_accuracy: 0.38725 |  0:00:08s\n",
      "epoch 16 | loss: 1.26036 | val_0_accuracy: 0.39146 |  0:00:09s\n",
      "epoch 17 | loss: 1.25748 | val_0_accuracy: 0.38305 |  0:00:09s\n",
      "epoch 18 | loss: 1.24884 | val_0_accuracy: 0.41246 |  0:00:10s\n",
      "epoch 19 | loss: 1.25908 | val_0_accuracy: 0.36975 |  0:00:10s\n",
      "epoch 20 | loss: 1.2614  | val_0_accuracy: 0.39006 |  0:00:11s\n",
      "epoch 21 | loss: 1.25435 | val_0_accuracy: 0.38866 |  0:00:12s\n",
      "epoch 22 | loss: 1.25227 | val_0_accuracy: 0.40336 |  0:00:12s\n",
      "epoch 23 | loss: 1.2523  | val_0_accuracy: 0.42297 |  0:00:13s\n",
      "epoch 24 | loss: 1.25065 | val_0_accuracy: 0.40266 |  0:00:13s\n",
      "epoch 25 | loss: 1.24598 | val_0_accuracy: 0.41036 |  0:00:14s\n",
      "epoch 26 | loss: 1.25433 | val_0_accuracy: 0.41387 |  0:00:14s\n",
      "epoch 27 | loss: 1.24254 | val_0_accuracy: 0.41246 |  0:00:15s\n",
      "epoch 28 | loss: 1.23577 | val_0_accuracy: 0.40966 |  0:00:15s\n",
      "epoch 29 | loss: 1.24358 | val_0_accuracy: 0.39636 |  0:00:16s\n",
      "epoch 30 | loss: 1.24408 | val_0_accuracy: 0.40126 |  0:00:16s\n",
      "epoch 31 | loss: 1.24358 | val_0_accuracy: 0.41176 |  0:00:17s\n",
      "epoch 32 | loss: 1.23923 | val_0_accuracy: 0.40686 |  0:00:17s\n",
      "epoch 33 | loss: 1.23117 | val_0_accuracy: 0.40056 |  0:00:18s\n",
      "epoch 34 | loss: 1.22663 | val_0_accuracy: 0.40686 |  0:00:19s\n",
      "epoch 35 | loss: 1.23209 | val_0_accuracy: 0.39776 |  0:00:19s\n",
      "epoch 36 | loss: 1.22405 | val_0_accuracy: 0.40476 |  0:00:20s\n",
      "epoch 37 | loss: 1.22971 | val_0_accuracy: 0.38936 |  0:00:20s\n",
      "epoch 38 | loss: 1.22207 | val_0_accuracy: 0.40126 |  0:00:21s\n",
      "epoch 39 | loss: 1.22988 | val_0_accuracy: 0.40616 |  0:00:21s\n",
      "epoch 40 | loss: 1.22093 | val_0_accuracy: 0.39776 |  0:00:22s\n",
      "epoch 41 | loss: 1.2363  | val_0_accuracy: 0.39496 |  0:00:22s\n",
      "epoch 42 | loss: 1.22867 | val_0_accuracy: 0.41457 |  0:00:23s\n",
      "epoch 43 | loss: 1.22526 | val_0_accuracy: 0.40686 |  0:00:23s\n",
      "epoch 44 | loss: 1.24591 | val_0_accuracy: 0.39706 |  0:00:24s\n",
      "epoch 45 | loss: 1.24691 | val_0_accuracy: 0.41947 |  0:00:24s\n",
      "epoch 46 | loss: 1.24127 | val_0_accuracy: 0.41036 |  0:00:25s\n",
      "epoch 47 | loss: 1.23368 | val_0_accuracy: 0.43067 |  0:00:26s\n",
      "epoch 48 | loss: 1.22705 | val_0_accuracy: 0.42227 |  0:00:26s\n",
      "epoch 49 | loss: 1.21604 | val_0_accuracy: 0.41947 |  0:00:27s\n",
      "epoch 50 | loss: 1.21811 | val_0_accuracy: 0.41877 |  0:00:27s\n",
      "epoch 51 | loss: 1.22288 | val_0_accuracy: 0.41667 |  0:00:28s\n",
      "epoch 52 | loss: 1.21152 | val_0_accuracy: 0.41106 |  0:00:28s\n",
      "epoch 53 | loss: 1.21214 | val_0_accuracy: 0.41527 |  0:00:29s\n",
      "epoch 54 | loss: 1.21955 | val_0_accuracy: 0.41036 |  0:00:29s\n",
      "epoch 55 | loss: 1.22651 | val_0_accuracy: 0.41036 |  0:00:30s\n",
      "epoch 56 | loss: 1.21549 | val_0_accuracy: 0.40756 |  0:00:30s\n",
      "epoch 57 | loss: 1.21391 | val_0_accuracy: 0.41176 |  0:00:31s\n",
      "epoch 58 | loss: 1.2103  | val_0_accuracy: 0.41737 |  0:00:32s\n",
      "epoch 59 | loss: 1.21574 | val_0_accuracy: 0.41317 |  0:00:32s\n",
      "epoch 60 | loss: 1.21466 | val_0_accuracy: 0.41387 |  0:00:33s\n",
      "epoch 61 | loss: 1.209   | val_0_accuracy: 0.41176 |  0:00:33s\n",
      "epoch 62 | loss: 1.20653 | val_0_accuracy: 0.41246 |  0:00:34s\n",
      "epoch 63 | loss: 1.21122 | val_0_accuracy: 0.41527 |  0:00:34s\n",
      "epoch 64 | loss: 1.19676 | val_0_accuracy: 0.41036 |  0:00:35s\n",
      "epoch 65 | loss: 1.19951 | val_0_accuracy: 0.40546 |  0:00:35s\n",
      "epoch 66 | loss: 1.19808 | val_0_accuracy: 0.40546 |  0:00:36s\n",
      "epoch 67 | loss: 1.1964  | val_0_accuracy: 0.41807 |  0:00:36s\n",
      "epoch 68 | loss: 1.19197 | val_0_accuracy: 0.38936 |  0:00:37s\n",
      "epoch 69 | loss: 1.2237  | val_0_accuracy: 0.39916 |  0:00:37s\n",
      "epoch 70 | loss: 1.22054 | val_0_accuracy: 0.40056 |  0:00:38s\n",
      "epoch 71 | loss: 1.23358 | val_0_accuracy: 0.40196 |  0:00:39s\n",
      "epoch 72 | loss: 1.22967 | val_0_accuracy: 0.40056 |  0:00:39s\n",
      "epoch 73 | loss: 1.23035 | val_0_accuracy: 0.39076 |  0:00:40s\n",
      "epoch 74 | loss: 1.23623 | val_0_accuracy: 0.39916 |  0:00:40s\n",
      "epoch 75 | loss: 1.23004 | val_0_accuracy: 0.39986 |  0:00:41s\n",
      "epoch 76 | loss: 1.22426 | val_0_accuracy: 0.40616 |  0:00:41s\n",
      "epoch 77 | loss: 1.20984 | val_0_accuracy: 0.38936 |  0:00:42s\n",
      "epoch 78 | loss: 1.21482 | val_0_accuracy: 0.40546 |  0:00:42s\n",
      "epoch 79 | loss: 1.21021 | val_0_accuracy: 0.40686 |  0:00:43s\n",
      "epoch 80 | loss: 1.22344 | val_0_accuracy: 0.40756 |  0:00:43s\n",
      "epoch 81 | loss: 1.21519 | val_0_accuracy: 0.40476 |  0:00:44s\n",
      "epoch 82 | loss: 1.20462 | val_0_accuracy: 0.41036 |  0:00:44s\n",
      "epoch 83 | loss: 1.19719 | val_0_accuracy: 0.41246 |  0:00:45s\n",
      "epoch 84 | loss: 1.1942  | val_0_accuracy: 0.40126 |  0:00:45s\n",
      "epoch 85 | loss: 1.1908  | val_0_accuracy: 0.39636 |  0:00:46s\n",
      "epoch 86 | loss: 1.19417 | val_0_accuracy: 0.40686 |  0:00:47s\n",
      "epoch 87 | loss: 1.21473 | val_0_accuracy: 0.39286 |  0:00:47s\n",
      "epoch 88 | loss: 1.21559 | val_0_accuracy: 0.40056 |  0:00:48s\n",
      "epoch 89 | loss: 1.20899 | val_0_accuracy: 0.39636 |  0:00:48s\n",
      "epoch 90 | loss: 1.19412 | val_0_accuracy: 0.39706 |  0:00:49s\n",
      "epoch 91 | loss: 1.20284 | val_0_accuracy: 0.39216 |  0:00:49s\n",
      "epoch 92 | loss: 1.19991 | val_0_accuracy: 0.39636 |  0:00:50s\n",
      "epoch 93 | loss: 1.19592 | val_0_accuracy: 0.40616 |  0:00:50s\n",
      "epoch 94 | loss: 1.19323 | val_0_accuracy: 0.39706 |  0:00:51s\n",
      "epoch 95 | loss: 1.2298  | val_0_accuracy: 0.39636 |  0:00:51s\n",
      "epoch 96 | loss: 1.23161 | val_0_accuracy: 0.39566 |  0:00:52s\n",
      "epoch 97 | loss: 1.21438 | val_0_accuracy: 0.39496 |  0:00:52s\n",
      "\n",
      "Early stopping occurred at epoch 97 with best_epoch = 47 and best_val_0_accuracy = 0.43067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Mejor w (val) = 0.4 | val_acc_blend = 0.4286\n",
      "[Fold 1] BLEND acc(test) = 0.3622 (w=0.4) | Δ vs Stage-1 = -0.0142\n",
      "[Fold 2] sujetos train=65, val=17, test=21\n",
      "  train subs: [1, 4, 5, 6, 8, 10, 11, 13, 14, 16]...\n",
      "  val   subs: [3, 9, 15, 21, 28, 34, 41, 47, 54, 60]...\n",
      "  test  subs: [2, 7, 12, 17, 22, 27, 32, 37, 43, 48]...\n",
      "[Fold 2] n_train=5460 | n_val=1428 | n_test=1764\n",
      "[Fold 2] val class dist: {0: 357, 1: 357, 2: 357, 3: 357}\n",
      "\n",
      "[Fold 2/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3537 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.4716 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5007 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Ep  15 | train_acc=0.5570 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Early stopping @ 16 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold2.png\n",
      "[Fold 2] Stage-1 acc(test) = 0.4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.77574 | val_0_accuracy: 0.2507  |  0:00:00s\n",
      "epoch 1  | loss: 1.4198  | val_0_accuracy: 0.29342 |  0:00:01s\n",
      "epoch 2  | loss: 1.36164 | val_0_accuracy: 0.2423  |  0:00:01s\n",
      "epoch 3  | loss: 1.34384 | val_0_accuracy: 0.29132 |  0:00:02s\n",
      "epoch 4  | loss: 1.33698 | val_0_accuracy: 0.31653 |  0:00:02s\n",
      "epoch 5  | loss: 1.33277 | val_0_accuracy: 0.34524 |  0:00:03s\n",
      "epoch 6  | loss: 1.31691 | val_0_accuracy: 0.32003 |  0:00:03s\n",
      "epoch 7  | loss: 1.32441 | val_0_accuracy: 0.30952 |  0:00:04s\n",
      "epoch 8  | loss: 1.31943 | val_0_accuracy: 0.34804 |  0:00:04s\n",
      "epoch 9  | loss: 1.31435 | val_0_accuracy: 0.34174 |  0:00:05s\n",
      "epoch 10 | loss: 1.31102 | val_0_accuracy: 0.35154 |  0:00:06s\n",
      "epoch 11 | loss: 1.30184 | val_0_accuracy: 0.35224 |  0:00:06s\n",
      "epoch 12 | loss: 1.30103 | val_0_accuracy: 0.33754 |  0:00:07s\n",
      "epoch 13 | loss: 1.30214 | val_0_accuracy: 0.35714 |  0:00:07s\n",
      "epoch 14 | loss: 1.30027 | val_0_accuracy: 0.35224 |  0:00:08s\n",
      "epoch 15 | loss: 1.29892 | val_0_accuracy: 0.34524 |  0:00:08s\n",
      "epoch 16 | loss: 1.29707 | val_0_accuracy: 0.34384 |  0:00:09s\n",
      "epoch 17 | loss: 1.28687 | val_0_accuracy: 0.34874 |  0:00:09s\n",
      "epoch 18 | loss: 1.29259 | val_0_accuracy: 0.35084 |  0:00:10s\n",
      "epoch 19 | loss: 1.28854 | val_0_accuracy: 0.35714 |  0:00:11s\n",
      "epoch 20 | loss: 1.28613 | val_0_accuracy: 0.35434 |  0:00:11s\n",
      "epoch 21 | loss: 1.27737 | val_0_accuracy: 0.36345 |  0:00:12s\n",
      "epoch 22 | loss: 1.27483 | val_0_accuracy: 0.34944 |  0:00:12s\n",
      "epoch 23 | loss: 1.28194 | val_0_accuracy: 0.36555 |  0:00:13s\n",
      "epoch 24 | loss: 1.28407 | val_0_accuracy: 0.36975 |  0:00:13s\n",
      "epoch 25 | loss: 1.28653 | val_0_accuracy: 0.34594 |  0:00:14s\n",
      "epoch 26 | loss: 1.29758 | val_0_accuracy: 0.34944 |  0:00:14s\n",
      "epoch 27 | loss: 1.29301 | val_0_accuracy: 0.35084 |  0:00:15s\n",
      "epoch 28 | loss: 1.29507 | val_0_accuracy: 0.34244 |  0:00:15s\n",
      "epoch 29 | loss: 1.29175 | val_0_accuracy: 0.35084 |  0:00:16s\n",
      "epoch 30 | loss: 1.29119 | val_0_accuracy: 0.35644 |  0:00:17s\n",
      "epoch 31 | loss: 1.29531 | val_0_accuracy: 0.34804 |  0:00:17s\n",
      "epoch 32 | loss: 1.28948 | val_0_accuracy: 0.35014 |  0:00:18s\n",
      "epoch 33 | loss: 1.28441 | val_0_accuracy: 0.37815 |  0:00:18s\n",
      "epoch 34 | loss: 1.28976 | val_0_accuracy: 0.36275 |  0:00:19s\n",
      "epoch 35 | loss: 1.28037 | val_0_accuracy: 0.37185 |  0:00:19s\n",
      "epoch 36 | loss: 1.27975 | val_0_accuracy: 0.34524 |  0:00:20s\n",
      "epoch 37 | loss: 1.2851  | val_0_accuracy: 0.36765 |  0:00:20s\n",
      "epoch 38 | loss: 1.27896 | val_0_accuracy: 0.36134 |  0:00:21s\n",
      "epoch 39 | loss: 1.27724 | val_0_accuracy: 0.35364 |  0:00:21s\n",
      "epoch 40 | loss: 1.29058 | val_0_accuracy: 0.36415 |  0:00:22s\n",
      "epoch 41 | loss: 1.29391 | val_0_accuracy: 0.35714 |  0:00:22s\n",
      "epoch 42 | loss: 1.2959  | val_0_accuracy: 0.35924 |  0:00:23s\n",
      "epoch 43 | loss: 1.29023 | val_0_accuracy: 0.35084 |  0:00:23s\n",
      "epoch 44 | loss: 1.28397 | val_0_accuracy: 0.34034 |  0:00:24s\n",
      "epoch 45 | loss: 1.28128 | val_0_accuracy: 0.34664 |  0:00:25s\n",
      "epoch 46 | loss: 1.28151 | val_0_accuracy: 0.36485 |  0:00:25s\n",
      "epoch 47 | loss: 1.2873  | val_0_accuracy: 0.36555 |  0:00:26s\n",
      "epoch 48 | loss: 1.28256 | val_0_accuracy: 0.36134 |  0:00:26s\n",
      "epoch 49 | loss: 1.28823 | val_0_accuracy: 0.34244 |  0:00:27s\n",
      "epoch 50 | loss: 1.28596 | val_0_accuracy: 0.35364 |  0:00:27s\n",
      "epoch 51 | loss: 1.28884 | val_0_accuracy: 0.36835 |  0:00:28s\n",
      "epoch 52 | loss: 1.28699 | val_0_accuracy: 0.36275 |  0:00:28s\n",
      "epoch 53 | loss: 1.28792 | val_0_accuracy: 0.35644 |  0:00:29s\n",
      "epoch 54 | loss: 1.28259 | val_0_accuracy: 0.36275 |  0:00:30s\n",
      "epoch 55 | loss: 1.28633 | val_0_accuracy: 0.35924 |  0:00:30s\n",
      "epoch 56 | loss: 1.27782 | val_0_accuracy: 0.36134 |  0:00:31s\n",
      "epoch 57 | loss: 1.27637 | val_0_accuracy: 0.35224 |  0:00:31s\n",
      "epoch 58 | loss: 1.28215 | val_0_accuracy: 0.33543 |  0:00:32s\n",
      "epoch 59 | loss: 1.27976 | val_0_accuracy: 0.34734 |  0:00:32s\n",
      "epoch 60 | loss: 1.27968 | val_0_accuracy: 0.36835 |  0:00:33s\n",
      "epoch 61 | loss: 1.28606 | val_0_accuracy: 0.35014 |  0:00:33s\n",
      "epoch 62 | loss: 1.28927 | val_0_accuracy: 0.34944 |  0:00:34s\n",
      "epoch 63 | loss: 1.28568 | val_0_accuracy: 0.36134 |  0:00:34s\n",
      "epoch 64 | loss: 1.27877 | val_0_accuracy: 0.35714 |  0:00:35s\n",
      "epoch 65 | loss: 1.28018 | val_0_accuracy: 0.36204 |  0:00:36s\n",
      "epoch 66 | loss: 1.2811  | val_0_accuracy: 0.36345 |  0:00:36s\n",
      "epoch 67 | loss: 1.28102 | val_0_accuracy: 0.36975 |  0:00:37s\n",
      "epoch 68 | loss: 1.28001 | val_0_accuracy: 0.36275 |  0:00:37s\n",
      "epoch 69 | loss: 1.28342 | val_0_accuracy: 0.36485 |  0:00:38s\n",
      "epoch 70 | loss: 1.27973 | val_0_accuracy: 0.37115 |  0:00:38s\n",
      "epoch 71 | loss: 1.28148 | val_0_accuracy: 0.36695 |  0:00:39s\n",
      "epoch 72 | loss: 1.28189 | val_0_accuracy: 0.36765 |  0:00:39s\n",
      "epoch 73 | loss: 1.27686 | val_0_accuracy: 0.37885 |  0:00:40s\n",
      "epoch 74 | loss: 1.27665 | val_0_accuracy: 0.37605 |  0:00:40s\n",
      "epoch 75 | loss: 1.27463 | val_0_accuracy: 0.37045 |  0:00:41s\n",
      "epoch 76 | loss: 1.27468 | val_0_accuracy: 0.36835 |  0:00:42s\n",
      "epoch 77 | loss: 1.27734 | val_0_accuracy: 0.37325 |  0:00:42s\n",
      "epoch 78 | loss: 1.27355 | val_0_accuracy: 0.36835 |  0:00:43s\n",
      "epoch 79 | loss: 1.27548 | val_0_accuracy: 0.35784 |  0:00:43s\n",
      "epoch 80 | loss: 1.26816 | val_0_accuracy: 0.36765 |  0:00:44s\n",
      "epoch 81 | loss: 1.27007 | val_0_accuracy: 0.36134 |  0:00:44s\n",
      "epoch 82 | loss: 1.26852 | val_0_accuracy: 0.37605 |  0:00:45s\n",
      "epoch 83 | loss: 1.26741 | val_0_accuracy: 0.37535 |  0:00:45s\n",
      "epoch 84 | loss: 1.26927 | val_0_accuracy: 0.36975 |  0:00:46s\n",
      "epoch 85 | loss: 1.26565 | val_0_accuracy: 0.38025 |  0:00:46s\n",
      "epoch 86 | loss: 1.26474 | val_0_accuracy: 0.37115 |  0:00:47s\n",
      "epoch 87 | loss: 1.27026 | val_0_accuracy: 0.36134 |  0:00:47s\n",
      "epoch 88 | loss: 1.2614  | val_0_accuracy: 0.34594 |  0:00:48s\n",
      "epoch 89 | loss: 1.26266 | val_0_accuracy: 0.37395 |  0:00:48s\n",
      "epoch 90 | loss: 1.2612  | val_0_accuracy: 0.36625 |  0:00:49s\n",
      "epoch 91 | loss: 1.27178 | val_0_accuracy: 0.36625 |  0:00:50s\n",
      "epoch 92 | loss: 1.2683  | val_0_accuracy: 0.35714 |  0:00:50s\n",
      "epoch 93 | loss: 1.26584 | val_0_accuracy: 0.36345 |  0:00:51s\n",
      "epoch 94 | loss: 1.26354 | val_0_accuracy: 0.34664 |  0:00:51s\n",
      "epoch 95 | loss: 1.27337 | val_0_accuracy: 0.35574 |  0:00:52s\n",
      "epoch 96 | loss: 1.26758 | val_0_accuracy: 0.36345 |  0:00:52s\n",
      "epoch 97 | loss: 1.26593 | val_0_accuracy: 0.35784 |  0:00:53s\n",
      "epoch 98 | loss: 1.26203 | val_0_accuracy: 0.37535 |  0:00:53s\n",
      "epoch 99 | loss: 1.26109 | val_0_accuracy: 0.37815 |  0:00:54s\n",
      "epoch 100| loss: 1.26983 | val_0_accuracy: 0.35644 |  0:00:54s\n",
      "epoch 101| loss: 1.27313 | val_0_accuracy: 0.34104 |  0:00:55s\n",
      "epoch 102| loss: 1.26294 | val_0_accuracy: 0.35294 |  0:00:55s\n",
      "epoch 103| loss: 1.26202 | val_0_accuracy: 0.35924 |  0:00:56s\n",
      "epoch 104| loss: 1.26349 | val_0_accuracy: 0.35504 |  0:00:56s\n",
      "epoch 105| loss: 1.2628  | val_0_accuracy: 0.37185 |  0:00:57s\n",
      "epoch 106| loss: 1.2632  | val_0_accuracy: 0.36555 |  0:00:58s\n",
      "epoch 107| loss: 1.2556  | val_0_accuracy: 0.35784 |  0:00:58s\n",
      "epoch 108| loss: 1.25775 | val_0_accuracy: 0.35924 |  0:00:59s\n",
      "epoch 109| loss: 1.25892 | val_0_accuracy: 0.36415 |  0:00:59s\n",
      "epoch 110| loss: 1.27155 | val_0_accuracy: 0.35224 |  0:01:00s\n",
      "epoch 111| loss: 1.26405 | val_0_accuracy: 0.35784 |  0:01:00s\n",
      "epoch 112| loss: 1.26532 | val_0_accuracy: 0.35644 |  0:01:01s\n",
      "epoch 113| loss: 1.26711 | val_0_accuracy: 0.34944 |  0:01:01s\n",
      "epoch 114| loss: 1.25908 | val_0_accuracy: 0.35574 |  0:01:02s\n",
      "epoch 115| loss: 1.2588  | val_0_accuracy: 0.36695 |  0:01:02s\n",
      "epoch 116| loss: 1.26406 | val_0_accuracy: 0.35714 |  0:01:03s\n",
      "epoch 117| loss: 1.26645 | val_0_accuracy: 0.36695 |  0:01:04s\n",
      "epoch 118| loss: 1.26022 | val_0_accuracy: 0.36765 |  0:01:04s\n",
      "epoch 119| loss: 1.2564  | val_0_accuracy: 0.36835 |  0:01:05s\n",
      "epoch 120| loss: 1.25552 | val_0_accuracy: 0.36765 |  0:01:05s\n",
      "epoch 121| loss: 1.25053 | val_0_accuracy: 0.37045 |  0:01:06s\n",
      "epoch 122| loss: 1.25441 | val_0_accuracy: 0.36835 |  0:01:06s\n",
      "epoch 123| loss: 1.25924 | val_0_accuracy: 0.36765 |  0:01:07s\n",
      "epoch 124| loss: 1.25717 | val_0_accuracy: 0.36625 |  0:01:07s\n",
      "epoch 125| loss: 1.25476 | val_0_accuracy: 0.36555 |  0:01:08s\n",
      "epoch 126| loss: 1.25533 | val_0_accuracy: 0.37605 |  0:01:08s\n",
      "epoch 127| loss: 1.25358 | val_0_accuracy: 0.37325 |  0:01:09s\n",
      "epoch 128| loss: 1.262   | val_0_accuracy: 0.35504 |  0:01:10s\n",
      "epoch 129| loss: 1.25688 | val_0_accuracy: 0.37325 |  0:01:10s\n",
      "epoch 130| loss: 1.25109 | val_0_accuracy: 0.34174 |  0:01:11s\n",
      "epoch 131| loss: 1.24862 | val_0_accuracy: 0.35154 |  0:01:11s\n",
      "epoch 132| loss: 1.24873 | val_0_accuracy: 0.34594 |  0:01:12s\n",
      "epoch 133| loss: 1.24721 | val_0_accuracy: 0.35014 |  0:01:12s\n",
      "epoch 134| loss: 1.24507 | val_0_accuracy: 0.35434 |  0:01:13s\n",
      "epoch 135| loss: 1.24123 | val_0_accuracy: 0.34944 |  0:01:13s\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 85 and best_val_0_accuracy = 0.38025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] Mejor w (val) = 0.3 | val_acc_blend = 0.3873\n",
      "[Fold 2] BLEND acc(test) = 0.3963 (w=0.3) | Δ vs Stage-1 = -0.0057\n",
      "[Fold 3] sujetos train=65, val=17, test=21\n",
      "  train subs: [2, 4, 5, 7, 8, 10, 12, 13, 14, 17]...\n",
      "  val   subs: [3, 9, 15, 22, 28, 34, 41, 48, 54, 60]...\n",
      "  test  subs: [1, 6, 11, 16, 21, 26, 31, 36, 42, 47]...\n",
      "[Fold 3] n_train=5460 | n_val=1428 | n_test=1764\n",
      "[Fold 3] val class dist: {0: 357, 1: 357, 2: 357, 3: 357}\n",
      "\n",
      "[Fold 3/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3560 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.4813 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5071 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Ep  15 | train_acc=0.5885 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Early stopping @ 16 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold3.png\n",
      "[Fold 3] Stage-1 acc(test) = 0.3810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.73112 | val_0_accuracy: 0.23039 |  0:00:00s\n",
      "epoch 1  | loss: 1.41738 | val_0_accuracy: 0.2591  |  0:00:01s\n",
      "epoch 2  | loss: 1.36009 | val_0_accuracy: 0.30182 |  0:00:01s\n",
      "epoch 3  | loss: 1.33996 | val_0_accuracy: 0.35854 |  0:00:02s\n",
      "epoch 4  | loss: 1.32274 | val_0_accuracy: 0.34454 |  0:00:02s\n",
      "epoch 5  | loss: 1.32055 | val_0_accuracy: 0.37115 |  0:00:03s\n",
      "epoch 6  | loss: 1.31153 | val_0_accuracy: 0.38655 |  0:00:03s\n",
      "epoch 7  | loss: 1.30019 | val_0_accuracy: 0.39986 |  0:00:04s\n",
      "epoch 8  | loss: 1.29564 | val_0_accuracy: 0.38866 |  0:00:04s\n",
      "epoch 9  | loss: 1.29559 | val_0_accuracy: 0.39566 |  0:00:05s\n",
      "epoch 10 | loss: 1.3034  | val_0_accuracy: 0.36905 |  0:00:06s\n",
      "epoch 11 | loss: 1.29401 | val_0_accuracy: 0.41387 |  0:00:06s\n",
      "epoch 12 | loss: 1.28695 | val_0_accuracy: 0.40336 |  0:00:07s\n",
      "epoch 13 | loss: 1.29179 | val_0_accuracy: 0.40336 |  0:00:07s\n",
      "epoch 14 | loss: 1.28562 | val_0_accuracy: 0.40476 |  0:00:08s\n",
      "epoch 15 | loss: 1.28987 | val_0_accuracy: 0.39286 |  0:00:08s\n",
      "epoch 16 | loss: 1.28921 | val_0_accuracy: 0.40126 |  0:00:09s\n",
      "epoch 17 | loss: 1.28022 | val_0_accuracy: 0.39636 |  0:00:09s\n",
      "epoch 18 | loss: 1.27833 | val_0_accuracy: 0.41527 |  0:00:10s\n",
      "epoch 19 | loss: 1.27271 | val_0_accuracy: 0.41807 |  0:00:11s\n",
      "epoch 20 | loss: 1.26835 | val_0_accuracy: 0.41387 |  0:00:11s\n",
      "epoch 21 | loss: 1.26698 | val_0_accuracy: 0.41457 |  0:00:12s\n",
      "epoch 22 | loss: 1.25972 | val_0_accuracy: 0.40756 |  0:00:12s\n",
      "epoch 23 | loss: 1.26325 | val_0_accuracy: 0.40756 |  0:00:13s\n",
      "epoch 24 | loss: 1.26307 | val_0_accuracy: 0.41457 |  0:00:13s\n",
      "epoch 25 | loss: 1.26296 | val_0_accuracy: 0.40896 |  0:00:14s\n",
      "epoch 26 | loss: 1.25076 | val_0_accuracy: 0.40616 |  0:00:14s\n",
      "epoch 27 | loss: 1.25419 | val_0_accuracy: 0.39566 |  0:00:15s\n",
      "epoch 28 | loss: 1.25522 | val_0_accuracy: 0.37185 |  0:00:16s\n",
      "epoch 29 | loss: 1.25561 | val_0_accuracy: 0.39846 |  0:00:16s\n",
      "epoch 30 | loss: 1.26024 | val_0_accuracy: 0.39636 |  0:00:17s\n",
      "epoch 31 | loss: 1.26596 | val_0_accuracy: 0.40126 |  0:00:17s\n",
      "epoch 32 | loss: 1.25998 | val_0_accuracy: 0.42017 |  0:00:18s\n",
      "epoch 33 | loss: 1.25227 | val_0_accuracy: 0.42507 |  0:00:18s\n",
      "epoch 34 | loss: 1.25246 | val_0_accuracy: 0.42717 |  0:00:19s\n",
      "epoch 35 | loss: 1.24869 | val_0_accuracy: 0.41597 |  0:00:20s\n",
      "epoch 36 | loss: 1.24965 | val_0_accuracy: 0.40266 |  0:00:20s\n",
      "epoch 37 | loss: 1.2622  | val_0_accuracy: 0.39076 |  0:00:21s\n",
      "epoch 38 | loss: 1.2611  | val_0_accuracy: 0.41387 |  0:00:21s\n",
      "epoch 39 | loss: 1.25264 | val_0_accuracy: 0.41036 |  0:00:22s\n",
      "epoch 40 | loss: 1.2538  | val_0_accuracy: 0.42157 |  0:00:22s\n",
      "epoch 41 | loss: 1.26152 | val_0_accuracy: 0.41106 |  0:00:23s\n",
      "epoch 42 | loss: 1.2545  | val_0_accuracy: 0.40896 |  0:00:23s\n",
      "epoch 43 | loss: 1.27002 | val_0_accuracy: 0.39636 |  0:00:24s\n",
      "epoch 44 | loss: 1.25886 | val_0_accuracy: 0.38655 |  0:00:24s\n",
      "epoch 45 | loss: 1.25721 | val_0_accuracy: 0.38936 |  0:00:25s\n",
      "epoch 46 | loss: 1.25602 | val_0_accuracy: 0.40336 |  0:00:25s\n",
      "epoch 47 | loss: 1.25192 | val_0_accuracy: 0.39916 |  0:00:26s\n",
      "epoch 48 | loss: 1.25324 | val_0_accuracy: 0.40266 |  0:00:26s\n",
      "epoch 49 | loss: 1.25414 | val_0_accuracy: 0.40546 |  0:00:27s\n",
      "epoch 50 | loss: 1.25554 | val_0_accuracy: 0.40896 |  0:00:28s\n",
      "epoch 51 | loss: 1.24676 | val_0_accuracy: 0.40336 |  0:00:28s\n",
      "epoch 52 | loss: 1.25369 | val_0_accuracy: 0.40546 |  0:00:29s\n",
      "epoch 53 | loss: 1.24346 | val_0_accuracy: 0.41106 |  0:00:29s\n",
      "epoch 54 | loss: 1.24157 | val_0_accuracy: 0.41176 |  0:00:30s\n",
      "epoch 55 | loss: 1.24427 | val_0_accuracy: 0.41387 |  0:00:30s\n",
      "epoch 56 | loss: 1.2442  | val_0_accuracy: 0.41317 |  0:00:31s\n",
      "epoch 57 | loss: 1.24129 | val_0_accuracy: 0.40686 |  0:00:31s\n",
      "epoch 58 | loss: 1.23297 | val_0_accuracy: 0.41527 |  0:00:32s\n",
      "epoch 59 | loss: 1.23423 | val_0_accuracy: 0.40686 |  0:00:32s\n",
      "epoch 60 | loss: 1.23528 | val_0_accuracy: 0.42227 |  0:00:33s\n",
      "epoch 61 | loss: 1.24073 | val_0_accuracy: 0.41597 |  0:00:33s\n",
      "epoch 62 | loss: 1.23346 | val_0_accuracy: 0.42367 |  0:00:34s\n",
      "epoch 63 | loss: 1.22691 | val_0_accuracy: 0.40476 |  0:00:34s\n",
      "epoch 64 | loss: 1.22377 | val_0_accuracy: 0.40756 |  0:00:35s\n",
      "epoch 65 | loss: 1.23944 | val_0_accuracy: 0.41317 |  0:00:36s\n",
      "epoch 66 | loss: 1.24563 | val_0_accuracy: 0.42297 |  0:00:36s\n",
      "epoch 67 | loss: 1.24663 | val_0_accuracy: 0.41737 |  0:00:37s\n",
      "epoch 68 | loss: 1.23855 | val_0_accuracy: 0.41737 |  0:00:37s\n",
      "epoch 69 | loss: 1.2293  | val_0_accuracy: 0.41457 |  0:00:38s\n",
      "epoch 70 | loss: 1.22651 | val_0_accuracy: 0.40616 |  0:00:38s\n",
      "epoch 71 | loss: 1.2174  | val_0_accuracy: 0.41737 |  0:00:39s\n",
      "epoch 72 | loss: 1.22028 | val_0_accuracy: 0.42577 |  0:00:39s\n",
      "epoch 73 | loss: 1.21694 | val_0_accuracy: 0.42437 |  0:00:40s\n",
      "epoch 74 | loss: 1.21468 | val_0_accuracy: 0.41317 |  0:00:40s\n",
      "epoch 75 | loss: 1.2335  | val_0_accuracy: 0.39426 |  0:00:41s\n",
      "epoch 76 | loss: 1.23002 | val_0_accuracy: 0.38515 |  0:00:41s\n",
      "epoch 77 | loss: 1.23726 | val_0_accuracy: 0.40406 |  0:00:42s\n",
      "epoch 78 | loss: 1.23343 | val_0_accuracy: 0.42297 |  0:00:43s\n",
      "epoch 79 | loss: 1.22531 | val_0_accuracy: 0.40546 |  0:00:43s\n",
      "epoch 80 | loss: 1.22069 | val_0_accuracy: 0.41947 |  0:00:44s\n",
      "epoch 81 | loss: 1.23877 | val_0_accuracy: 0.41106 |  0:00:44s\n",
      "epoch 82 | loss: 1.24636 | val_0_accuracy: 0.41597 |  0:00:45s\n",
      "epoch 83 | loss: 1.23873 | val_0_accuracy: 0.42787 |  0:00:45s\n",
      "epoch 84 | loss: 1.23734 | val_0_accuracy: 0.41737 |  0:00:46s\n",
      "epoch 85 | loss: 1.23869 | val_0_accuracy: 0.43347 |  0:00:46s\n",
      "epoch 86 | loss: 1.23664 | val_0_accuracy: 0.41527 |  0:00:47s\n",
      "epoch 87 | loss: 1.23943 | val_0_accuracy: 0.41036 |  0:00:48s\n",
      "epoch 88 | loss: 1.24637 | val_0_accuracy: 0.38796 |  0:00:48s\n",
      "epoch 89 | loss: 1.24594 | val_0_accuracy: 0.41527 |  0:00:49s\n",
      "epoch 90 | loss: 1.23807 | val_0_accuracy: 0.41877 |  0:00:49s\n",
      "epoch 91 | loss: 1.23551 | val_0_accuracy: 0.41036 |  0:00:50s\n",
      "epoch 92 | loss: 1.23206 | val_0_accuracy: 0.41527 |  0:00:51s\n",
      "epoch 93 | loss: 1.23076 | val_0_accuracy: 0.42577 |  0:00:51s\n",
      "epoch 94 | loss: 1.2243  | val_0_accuracy: 0.42997 |  0:00:52s\n",
      "epoch 95 | loss: 1.23905 | val_0_accuracy: 0.41036 |  0:00:52s\n",
      "epoch 96 | loss: 1.23891 | val_0_accuracy: 0.41737 |  0:00:53s\n",
      "epoch 97 | loss: 1.23045 | val_0_accuracy: 0.41877 |  0:00:53s\n",
      "epoch 98 | loss: 1.23123 | val_0_accuracy: 0.39286 |  0:00:54s\n",
      "epoch 99 | loss: 1.24308 | val_0_accuracy: 0.39636 |  0:00:54s\n",
      "epoch 100| loss: 1.24735 | val_0_accuracy: 0.40126 |  0:00:55s\n",
      "epoch 101| loss: 1.23762 | val_0_accuracy: 0.40616 |  0:00:55s\n",
      "epoch 102| loss: 1.23334 | val_0_accuracy: 0.42157 |  0:00:56s\n",
      "epoch 103| loss: 1.2364  | val_0_accuracy: 0.41667 |  0:00:57s\n",
      "epoch 104| loss: 1.23094 | val_0_accuracy: 0.41246 |  0:00:57s\n",
      "epoch 105| loss: 1.2404  | val_0_accuracy: 0.41457 |  0:00:58s\n",
      "epoch 106| loss: 1.24741 | val_0_accuracy: 0.42507 |  0:00:58s\n",
      "epoch 107| loss: 1.2348  | val_0_accuracy: 0.41106 |  0:00:59s\n",
      "epoch 108| loss: 1.23496 | val_0_accuracy: 0.40966 |  0:00:59s\n",
      "epoch 109| loss: 1.23292 | val_0_accuracy: 0.41036 |  0:01:00s\n",
      "epoch 110| loss: 1.22152 | val_0_accuracy: 0.41317 |  0:01:00s\n",
      "epoch 111| loss: 1.22246 | val_0_accuracy: 0.42227 |  0:01:01s\n",
      "epoch 112| loss: 1.22067 | val_0_accuracy: 0.40266 |  0:01:01s\n",
      "epoch 113| loss: 1.22562 | val_0_accuracy: 0.40196 |  0:01:02s\n",
      "epoch 114| loss: 1.22488 | val_0_accuracy: 0.41877 |  0:01:03s\n",
      "epoch 115| loss: 1.21451 | val_0_accuracy: 0.40336 |  0:01:03s\n",
      "epoch 116| loss: 1.21007 | val_0_accuracy: 0.39496 |  0:01:04s\n",
      "epoch 117| loss: 1.22255 | val_0_accuracy: 0.39776 |  0:01:04s\n",
      "epoch 118| loss: 1.22451 | val_0_accuracy: 0.41036 |  0:01:05s\n",
      "epoch 119| loss: 1.2292  | val_0_accuracy: 0.41176 |  0:01:05s\n",
      "epoch 120| loss: 1.22383 | val_0_accuracy: 0.41106 |  0:01:06s\n",
      "epoch 121| loss: 1.22627 | val_0_accuracy: 0.41106 |  0:01:06s\n",
      "epoch 122| loss: 1.22666 | val_0_accuracy: 0.38375 |  0:01:07s\n",
      "epoch 123| loss: 1.23857 | val_0_accuracy: 0.39146 |  0:01:07s\n",
      "epoch 124| loss: 1.23588 | val_0_accuracy: 0.40056 |  0:01:08s\n",
      "epoch 125| loss: 1.24635 | val_0_accuracy: 0.37745 |  0:01:08s\n",
      "epoch 126| loss: 1.24686 | val_0_accuracy: 0.39356 |  0:01:09s\n",
      "epoch 127| loss: 1.23258 | val_0_accuracy: 0.39636 |  0:01:10s\n",
      "epoch 128| loss: 1.23372 | val_0_accuracy: 0.39636 |  0:01:10s\n",
      "epoch 129| loss: 1.24721 | val_0_accuracy: 0.39356 |  0:01:11s\n",
      "epoch 130| loss: 1.24101 | val_0_accuracy: 0.40126 |  0:01:11s\n",
      "epoch 131| loss: 1.23608 | val_0_accuracy: 0.40616 |  0:01:12s\n",
      "epoch 132| loss: 1.22986 | val_0_accuracy: 0.41176 |  0:01:12s\n",
      "epoch 133| loss: 1.2313  | val_0_accuracy: 0.40966 |  0:01:13s\n",
      "epoch 134| loss: 1.21818 | val_0_accuracy: 0.41947 |  0:01:13s\n",
      "epoch 135| loss: 1.21972 | val_0_accuracy: 0.42997 |  0:01:14s\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 85 and best_val_0_accuracy = 0.43347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] Mejor w (val) = 0.3 | val_acc_blend = 0.4328\n",
      "[Fold 3] BLEND acc(test) = 0.3968 (w=0.3) | Δ vs Stage-1 = +0.0159\n",
      "[Fold 4] sujetos train=66, val=17, test=20\n",
      "  train subs: [1, 2, 4, 6, 7, 8, 11, 12, 13, 14]...\n",
      "  val   subs: [3, 9, 16, 22, 28, 34, 42, 48, 54, 60]...\n",
      "  test  subs: [5, 10, 15, 20, 25, 30, 35, 41, 46, 51]...\n",
      "[Fold 4] n_train=5544 | n_val=1428 | n_test=1680\n",
      "[Fold 4] val class dist: {0: 357, 1: 357, 2: 357, 3: 357}\n",
      "\n",
      "[Fold 4/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3575 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.4829 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5090 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Ep  15 | train_acc=0.5785 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Early stopping @ 16 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold4.png\n",
      "[Fold 4] Stage-1 acc(test) = 0.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.74597 | val_0_accuracy: 0.26891 |  0:00:00s\n",
      "epoch 1  | loss: 1.40348 | val_0_accuracy: 0.28711 |  0:00:01s\n",
      "epoch 2  | loss: 1.34584 | val_0_accuracy: 0.34314 |  0:00:01s\n",
      "epoch 3  | loss: 1.31728 | val_0_accuracy: 0.34244 |  0:00:02s\n",
      "epoch 4  | loss: 1.31294 | val_0_accuracy: 0.36625 |  0:00:02s\n",
      "epoch 5  | loss: 1.30271 | val_0_accuracy: 0.37325 |  0:00:03s\n",
      "epoch 6  | loss: 1.30412 | val_0_accuracy: 0.36765 |  0:00:03s\n",
      "epoch 7  | loss: 1.30057 | val_0_accuracy: 0.38025 |  0:00:04s\n",
      "epoch 8  | loss: 1.29688 | val_0_accuracy: 0.40196 |  0:00:04s\n",
      "epoch 9  | loss: 1.29128 | val_0_accuracy: 0.40826 |  0:00:05s\n",
      "epoch 10 | loss: 1.28585 | val_0_accuracy: 0.39286 |  0:00:05s\n",
      "epoch 11 | loss: 1.27981 | val_0_accuracy: 0.38796 |  0:00:06s\n",
      "epoch 12 | loss: 1.27985 | val_0_accuracy: 0.35574 |  0:00:06s\n",
      "epoch 13 | loss: 1.27713 | val_0_accuracy: 0.38725 |  0:00:07s\n",
      "epoch 14 | loss: 1.28152 | val_0_accuracy: 0.40056 |  0:00:07s\n",
      "epoch 15 | loss: 1.27777 | val_0_accuracy: 0.39216 |  0:00:08s\n",
      "epoch 16 | loss: 1.2721  | val_0_accuracy: 0.38445 |  0:00:09s\n",
      "epoch 17 | loss: 1.2754  | val_0_accuracy: 0.39356 |  0:00:09s\n",
      "epoch 18 | loss: 1.27454 | val_0_accuracy: 0.38725 |  0:00:10s\n",
      "epoch 19 | loss: 1.26944 | val_0_accuracy: 0.39496 |  0:00:10s\n",
      "epoch 20 | loss: 1.27275 | val_0_accuracy: 0.39566 |  0:00:11s\n",
      "epoch 21 | loss: 1.27077 | val_0_accuracy: 0.38725 |  0:00:11s\n",
      "epoch 22 | loss: 1.26783 | val_0_accuracy: 0.38866 |  0:00:12s\n",
      "epoch 23 | loss: 1.27113 | val_0_accuracy: 0.38515 |  0:00:12s\n",
      "epoch 24 | loss: 1.27491 | val_0_accuracy: 0.40546 |  0:00:13s\n",
      "epoch 25 | loss: 1.2677  | val_0_accuracy: 0.40616 |  0:00:13s\n",
      "epoch 26 | loss: 1.26842 | val_0_accuracy: 0.40756 |  0:00:14s\n",
      "epoch 27 | loss: 1.26304 | val_0_accuracy: 0.41667 |  0:00:15s\n",
      "epoch 28 | loss: 1.26309 | val_0_accuracy: 0.41176 |  0:00:15s\n",
      "epoch 29 | loss: 1.26083 | val_0_accuracy: 0.40476 |  0:00:16s\n",
      "epoch 30 | loss: 1.26027 | val_0_accuracy: 0.39216 |  0:00:16s\n",
      "epoch 31 | loss: 1.24817 | val_0_accuracy: 0.39216 |  0:00:17s\n",
      "epoch 32 | loss: 1.26075 | val_0_accuracy: 0.40616 |  0:00:17s\n",
      "epoch 33 | loss: 1.25219 | val_0_accuracy: 0.39286 |  0:00:18s\n",
      "epoch 34 | loss: 1.26439 | val_0_accuracy: 0.38445 |  0:00:18s\n",
      "epoch 35 | loss: 1.25804 | val_0_accuracy: 0.38095 |  0:00:19s\n",
      "epoch 36 | loss: 1.25615 | val_0_accuracy: 0.40546 |  0:00:19s\n",
      "epoch 37 | loss: 1.26296 | val_0_accuracy: 0.40476 |  0:00:20s\n",
      "epoch 38 | loss: 1.26011 | val_0_accuracy: 0.39846 |  0:00:21s\n",
      "epoch 39 | loss: 1.25892 | val_0_accuracy: 0.39496 |  0:00:21s\n",
      "epoch 40 | loss: 1.25983 | val_0_accuracy: 0.38866 |  0:00:22s\n",
      "epoch 41 | loss: 1.26307 | val_0_accuracy: 0.40686 |  0:00:22s\n",
      "epoch 42 | loss: 1.25788 | val_0_accuracy: 0.39076 |  0:00:23s\n",
      "epoch 43 | loss: 1.26265 | val_0_accuracy: 0.39706 |  0:00:23s\n",
      "epoch 44 | loss: 1.25435 | val_0_accuracy: 0.41176 |  0:00:24s\n",
      "epoch 45 | loss: 1.25213 | val_0_accuracy: 0.39286 |  0:00:24s\n",
      "epoch 46 | loss: 1.25347 | val_0_accuracy: 0.40756 |  0:00:25s\n",
      "epoch 47 | loss: 1.26707 | val_0_accuracy: 0.39916 |  0:00:25s\n",
      "epoch 48 | loss: 1.25952 | val_0_accuracy: 0.40126 |  0:00:26s\n",
      "epoch 49 | loss: 1.2516  | val_0_accuracy: 0.39426 |  0:00:27s\n",
      "epoch 50 | loss: 1.24536 | val_0_accuracy: 0.39006 |  0:00:27s\n",
      "epoch 51 | loss: 1.24821 | val_0_accuracy: 0.39076 |  0:00:28s\n",
      "epoch 52 | loss: 1.25148 | val_0_accuracy: 0.38936 |  0:00:28s\n",
      "epoch 53 | loss: 1.25417 | val_0_accuracy: 0.37465 |  0:00:29s\n",
      "epoch 54 | loss: 1.25289 | val_0_accuracy: 0.38235 |  0:00:29s\n",
      "epoch 55 | loss: 1.24117 | val_0_accuracy: 0.38025 |  0:00:30s\n",
      "epoch 56 | loss: 1.25553 | val_0_accuracy: 0.37605 |  0:00:30s\n",
      "epoch 57 | loss: 1.25524 | val_0_accuracy: 0.39706 |  0:00:31s\n",
      "epoch 58 | loss: 1.25482 | val_0_accuracy: 0.39496 |  0:00:31s\n",
      "epoch 59 | loss: 1.25347 | val_0_accuracy: 0.39006 |  0:00:32s\n",
      "epoch 60 | loss: 1.25389 | val_0_accuracy: 0.40196 |  0:00:33s\n",
      "epoch 61 | loss: 1.25169 | val_0_accuracy: 0.38235 |  0:00:33s\n",
      "epoch 62 | loss: 1.25306 | val_0_accuracy: 0.39356 |  0:00:34s\n",
      "epoch 63 | loss: 1.24605 | val_0_accuracy: 0.37955 |  0:00:34s\n",
      "epoch 64 | loss: 1.25297 | val_0_accuracy: 0.38375 |  0:00:35s\n",
      "epoch 65 | loss: 1.2521  | val_0_accuracy: 0.39146 |  0:00:35s\n",
      "epoch 66 | loss: 1.25176 | val_0_accuracy: 0.39426 |  0:00:36s\n",
      "epoch 67 | loss: 1.25518 | val_0_accuracy: 0.39636 |  0:00:36s\n",
      "epoch 68 | loss: 1.24612 | val_0_accuracy: 0.40476 |  0:00:37s\n",
      "epoch 69 | loss: 1.24529 | val_0_accuracy: 0.38725 |  0:00:37s\n",
      "epoch 70 | loss: 1.24647 | val_0_accuracy: 0.40616 |  0:00:38s\n",
      "epoch 71 | loss: 1.24582 | val_0_accuracy: 0.41176 |  0:00:39s\n",
      "epoch 72 | loss: 1.24663 | val_0_accuracy: 0.41387 |  0:00:39s\n",
      "epoch 73 | loss: 1.23943 | val_0_accuracy: 0.40196 |  0:00:40s\n",
      "epoch 74 | loss: 1.25453 | val_0_accuracy: 0.38936 |  0:00:40s\n",
      "epoch 75 | loss: 1.25154 | val_0_accuracy: 0.40126 |  0:00:41s\n",
      "epoch 76 | loss: 1.24535 | val_0_accuracy: 0.40406 |  0:00:41s\n",
      "epoch 77 | loss: 1.24028 | val_0_accuracy: 0.41246 |  0:00:42s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 27 and best_val_0_accuracy = 0.41667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] Mejor w (val) = 0.3 | val_acc_blend = 0.4083\n",
      "[Fold 4] BLEND acc(test) = 0.3881 (w=0.3) | Δ vs Stage-1 = +0.0155\n",
      "[Fold 5] sujetos train=66, val=17, test=20\n",
      "  train subs: [1, 2, 5, 6, 7, 8, 11, 12, 13, 15]...\n",
      "  val   subs: [3, 10, 16, 22, 28, 35, 42, 48, 54, 61]...\n",
      "  test  subs: [4, 9, 14, 19, 24, 29, 34, 40, 45, 50]...\n",
      "[Fold 5] n_train=5544 | n_val=1428 | n_test=1680\n",
      "[Fold 5] val class dist: {0: 357, 1: 357, 2: 357, 3: 357}\n",
      "\n",
      "[Fold 5/5] Entrenando Stage-1 (encoder)...\n",
      "[Stage-1] Ep   1 | train_acc=0.3505 | val_acc=1.0000 | LR=0.00100\n",
      "[Stage-1] Ep   5 | train_acc=0.4697 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Ep  10 | train_acc=0.5023 | val_acc=1.0000 | LR=0.00085\n",
      "[Stage-1] Ep  15 | train_acc=0.5804 | val_acc=1.0000 | LR=0.00025\n",
      "[Stage-1] Early stopping @ 16 (best val_acc=1.0000)\n",
      "↳ Curva Stage-1 guardada: stage1_curve_fold5.png\n",
      "[Fold 5] Stage-1 acc(test) = 0.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5] Entrenando Stage-2 (tabular head)...\n",
      "epoch 0  | loss: 1.71778 | val_0_accuracy: 0.27381 |  0:00:00s\n",
      "epoch 1  | loss: 1.42375 | val_0_accuracy: 0.28431 |  0:00:01s\n",
      "epoch 2  | loss: 1.3542  | val_0_accuracy: 0.30392 |  0:00:01s\n",
      "epoch 3  | loss: 1.33522 | val_0_accuracy: 0.32773 |  0:00:02s\n",
      "epoch 4  | loss: 1.32554 | val_0_accuracy: 0.33263 |  0:00:02s\n",
      "epoch 5  | loss: 1.32158 | val_0_accuracy: 0.35854 |  0:00:03s\n",
      "epoch 6  | loss: 1.3097  | val_0_accuracy: 0.34244 |  0:00:03s\n",
      "epoch 7  | loss: 1.30535 | val_0_accuracy: 0.37465 |  0:00:04s\n",
      "epoch 8  | loss: 1.29372 | val_0_accuracy: 0.37535 |  0:00:05s\n",
      "epoch 9  | loss: 1.29652 | val_0_accuracy: 0.39146 |  0:00:05s\n",
      "epoch 10 | loss: 1.28764 | val_0_accuracy: 0.38936 |  0:00:06s\n",
      "epoch 11 | loss: 1.28833 | val_0_accuracy: 0.38025 |  0:00:06s\n",
      "epoch 12 | loss: 1.29755 | val_0_accuracy: 0.38655 |  0:00:07s\n",
      "epoch 13 | loss: 1.28871 | val_0_accuracy: 0.38725 |  0:00:07s\n",
      "epoch 14 | loss: 1.29046 | val_0_accuracy: 0.37325 |  0:00:08s\n",
      "epoch 15 | loss: 1.29919 | val_0_accuracy: 0.38655 |  0:00:08s\n",
      "epoch 16 | loss: 1.29601 | val_0_accuracy: 0.39496 |  0:00:09s\n",
      "epoch 17 | loss: 1.29871 | val_0_accuracy: 0.39636 |  0:00:09s\n",
      "epoch 18 | loss: 1.29096 | val_0_accuracy: 0.38936 |  0:00:10s\n",
      "epoch 19 | loss: 1.28737 | val_0_accuracy: 0.38165 |  0:00:10s\n",
      "epoch 20 | loss: 1.28488 | val_0_accuracy: 0.38235 |  0:00:11s\n",
      "epoch 21 | loss: 1.287   | val_0_accuracy: 0.39636 |  0:00:12s\n",
      "epoch 22 | loss: 1.28487 | val_0_accuracy: 0.37675 |  0:00:12s\n",
      "epoch 23 | loss: 1.28126 | val_0_accuracy: 0.39076 |  0:00:13s\n",
      "epoch 24 | loss: 1.27686 | val_0_accuracy: 0.39986 |  0:00:13s\n",
      "epoch 25 | loss: 1.28399 | val_0_accuracy: 0.39426 |  0:00:14s\n",
      "epoch 26 | loss: 1.27763 | val_0_accuracy: 0.39706 |  0:00:14s\n",
      "epoch 27 | loss: 1.27098 | val_0_accuracy: 0.40966 |  0:00:15s\n",
      "epoch 28 | loss: 1.28465 | val_0_accuracy: 0.38725 |  0:00:15s\n",
      "epoch 29 | loss: 1.2789  | val_0_accuracy: 0.38866 |  0:00:16s\n",
      "epoch 30 | loss: 1.28284 | val_0_accuracy: 0.40546 |  0:00:16s\n",
      "epoch 31 | loss: 1.27639 | val_0_accuracy: 0.40406 |  0:00:17s\n",
      "epoch 32 | loss: 1.27755 | val_0_accuracy: 0.41667 |  0:00:17s\n",
      "epoch 33 | loss: 1.27415 | val_0_accuracy: 0.40826 |  0:00:18s\n",
      "epoch 34 | loss: 1.27631 | val_0_accuracy: 0.39916 |  0:00:19s\n",
      "epoch 35 | loss: 1.28595 | val_0_accuracy: 0.38796 |  0:00:19s\n",
      "epoch 36 | loss: 1.28111 | val_0_accuracy: 0.39286 |  0:00:20s\n",
      "epoch 37 | loss: 1.28755 | val_0_accuracy: 0.38165 |  0:00:20s\n",
      "epoch 38 | loss: 1.28284 | val_0_accuracy: 0.36835 |  0:00:21s\n",
      "epoch 39 | loss: 1.27352 | val_0_accuracy: 0.36555 |  0:00:21s\n",
      "epoch 40 | loss: 1.2768  | val_0_accuracy: 0.36905 |  0:00:22s\n",
      "epoch 41 | loss: 1.27226 | val_0_accuracy: 0.39076 |  0:00:22s\n",
      "epoch 42 | loss: 1.272   | val_0_accuracy: 0.37815 |  0:00:23s\n",
      "epoch 43 | loss: 1.26875 | val_0_accuracy: 0.39216 |  0:00:23s\n",
      "epoch 44 | loss: 1.27613 | val_0_accuracy: 0.39636 |  0:00:24s\n",
      "epoch 45 | loss: 1.27069 | val_0_accuracy: 0.39216 |  0:00:25s\n",
      "epoch 46 | loss: 1.26523 | val_0_accuracy: 0.38165 |  0:00:25s\n",
      "epoch 47 | loss: 1.27358 | val_0_accuracy: 0.38936 |  0:00:26s\n",
      "epoch 48 | loss: 1.26864 | val_0_accuracy: 0.38725 |  0:00:27s\n",
      "epoch 49 | loss: 1.26834 | val_0_accuracy: 0.38165 |  0:00:27s\n",
      "epoch 50 | loss: 1.26711 | val_0_accuracy: 0.38515 |  0:00:28s\n",
      "epoch 51 | loss: 1.26849 | val_0_accuracy: 0.39076 |  0:00:29s\n",
      "epoch 52 | loss: 1.27358 | val_0_accuracy: 0.37815 |  0:00:29s\n",
      "epoch 53 | loss: 1.2718  | val_0_accuracy: 0.39146 |  0:00:30s\n",
      "epoch 54 | loss: 1.26787 | val_0_accuracy: 0.38375 |  0:00:31s\n",
      "epoch 55 | loss: 1.26551 | val_0_accuracy: 0.38936 |  0:00:31s\n",
      "epoch 56 | loss: 1.27104 | val_0_accuracy: 0.37675 |  0:00:32s\n",
      "epoch 57 | loss: 1.26588 | val_0_accuracy: 0.38725 |  0:00:33s\n",
      "epoch 58 | loss: 1.27105 | val_0_accuracy: 0.38796 |  0:00:33s\n",
      "epoch 59 | loss: 1.27552 | val_0_accuracy: 0.36975 |  0:00:34s\n",
      "epoch 60 | loss: 1.27213 | val_0_accuracy: 0.37465 |  0:00:35s\n",
      "epoch 61 | loss: 1.27181 | val_0_accuracy: 0.38655 |  0:00:35s\n",
      "epoch 62 | loss: 1.27134 | val_0_accuracy: 0.38936 |  0:00:36s\n",
      "epoch 63 | loss: 1.26568 | val_0_accuracy: 0.38095 |  0:00:36s\n",
      "epoch 64 | loss: 1.26436 | val_0_accuracy: 0.39636 |  0:00:37s\n",
      "epoch 65 | loss: 1.2644  | val_0_accuracy: 0.38165 |  0:00:38s\n",
      "epoch 66 | loss: 1.26744 | val_0_accuracy: 0.39146 |  0:00:38s\n",
      "epoch 67 | loss: 1.26368 | val_0_accuracy: 0.39076 |  0:00:39s\n",
      "epoch 68 | loss: 1.26036 | val_0_accuracy: 0.39566 |  0:00:40s\n",
      "epoch 69 | loss: 1.26611 | val_0_accuracy: 0.38235 |  0:00:40s\n",
      "epoch 70 | loss: 1.26528 | val_0_accuracy: 0.40616 |  0:00:41s\n",
      "epoch 71 | loss: 1.27076 | val_0_accuracy: 0.37325 |  0:00:42s\n",
      "epoch 72 | loss: 1.25539 | val_0_accuracy: 0.38866 |  0:00:42s\n",
      "epoch 73 | loss: 1.25294 | val_0_accuracy: 0.38515 |  0:00:43s\n",
      "epoch 74 | loss: 1.25507 | val_0_accuracy: 0.38235 |  0:00:44s\n",
      "epoch 75 | loss: 1.26225 | val_0_accuracy: 0.38375 |  0:00:44s\n",
      "epoch 76 | loss: 1.25925 | val_0_accuracy: 0.38796 |  0:00:45s\n",
      "epoch 77 | loss: 1.25512 | val_0_accuracy: 0.38095 |  0:00:46s\n",
      "epoch 78 | loss: 1.26243 | val_0_accuracy: 0.38025 |  0:00:46s\n",
      "epoch 79 | loss: 1.26132 | val_0_accuracy: 0.37815 |  0:00:47s\n",
      "epoch 80 | loss: 1.26582 | val_0_accuracy: 0.38866 |  0:00:48s\n",
      "epoch 81 | loss: 1.25952 | val_0_accuracy: 0.38445 |  0:00:48s\n",
      "epoch 82 | loss: 1.25605 | val_0_accuracy: 0.39916 |  0:00:49s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 32 and best_val_0_accuracy = 0.41667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5] Mejor w (val) = 0.5 | val_acc_blend = 0.4111\n",
      "[Fold 5] BLEND acc(test) = 0.4071 (w=0.5) | Δ vs Stage-1 = +0.0006\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES (Two-Stage, tuned)\n",
      "============================================================\n",
      "Stage-1 folds: ['0.3764', '0.4019', '0.3810', '0.3726', '0.4065']\n",
      "Stage-1 mean: 0.3877\n",
      "BLEND folds: ['0.3622', '0.3963', '0.3968', '0.3881', '0.4071']\n",
      "BLEND mean: 0.3901\n",
      "Δ(BLEND - Stage-1) mean: +0.0024\n",
      "↳ Matriz de confusión guardada: confusion_twostage_blend_allfolds.png\n",
      "✔️ Done.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Two-Stage MI-EEG (PhysioNet) — Standalone, tuned\n",
    "- Stage-1: EEGNet-parallel + MHA temporal + S-TCN + Time Slicing (por logits)\n",
    "           con augments + TTA, mayor capacidad (F1=24, emb=160, heads=4).\n",
    "- Stage-2: TabNet (si disponible) con hiperparámetros afinados; fallback MLP.\n",
    "- Blend: selecciona w por validación y lo aplica en test.\n",
    "- Mismas rutas/estructura que tu baseline, 8 canales MI, exclusiones y GroupKFold(5).\n",
    "\n",
    "Archivos generados:\n",
    "- stage1_curve_foldX.png por fold\n",
    "- confusion_twostage_blend_allfolds.png\n",
    "\"\"\"\n",
    "\n",
    "import os, re, math, random, json, itertools, copy, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Escenario y ventana\n",
    "CLASS_SCENARIO = '4c'\n",
    "WINDOW_MODE   = '6s'   # usamos 6s y recortamos 0.5–4.5 s dentro (ver extract_trials_from_run)\n",
    "FS = 160.0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Entrenamiento Stage-1\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_STAGE1 = 80\n",
    "LR_STAGE1 = 1e-3\n",
    "WD_STAGE1 = 1e-5\n",
    "SGDR_T0 = 6\n",
    "SGDR_Tmult = 2\n",
    "PATIENCE_STAGE1 = 15\n",
    "LOG_EVERY = 5\n",
    "\n",
    "# Stage-2 (Tabular)\n",
    "USE_TABNET = True  # si no está instalado, cae a MLP automáticamente\n",
    "EPOCHS_STAGE2 = 400\n",
    "PATIENCE_STAGE2 = 50\n",
    "\n",
    "# Blend: se elegirá por validación entre estos pesos\n",
    "BLEND_CANDIDATES = [0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "# Normalización por época\n",
    "NORM_EPOCH_ZSCORE = True\n",
    "\n",
    "# Sujetos excluidos\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "# Runs\n",
    "MI_RUNS_LR = [4, 8, 12]\n",
    "MI_RUNS_OF = [6, 10, 14]\n",
    "BASELINE_RUNS_EO = [1]\n",
    "\n",
    "# Canales (8 con FCz)\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES_4C = ['Left', 'Right', 'Both Fists', 'Both Feet']\n",
    "\n",
    "# ============== UTIL CANALES/EDF (idéntico base) ==============\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"Warning: faltan canales {missing} en archivo {getattr(raw,'filenames', [''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    if run_id in BASELINE_RUNS_EO: return 'EO'\n",
    "    return None\n",
    "\n",
    "_SNR_TABLE = None\n",
    "def _load_snr_table():\n",
    "    global _SNR_TABLE\n",
    "    if _SNR_TABLE is not None:\n",
    "        return _SNR_TABLE\n",
    "    csv_path = PROJ / 'reports' / 'psd_mains' / 'psd_mains_summary.csv'\n",
    "    if csv_path.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            _SNR_TABLE = df\n",
    "        except Exception as e:\n",
    "            print(f\"[SNR] No se pudo leer {csv_path}: {e}\")\n",
    "            _SNR_TABLE = None\n",
    "    return _SNR_TABLE\n",
    "\n",
    "def _decide_notch(subject, run, th_db=10.0):\n",
    "    df = _load_snr_table()\n",
    "    if df is None:  # default\n",
    "        return 60.0\n",
    "    row = df[(df['subject']==subject) & (df['run']==run)]\n",
    "    if row.empty:\n",
    "        return 60.0\n",
    "    snr50 = float(row['snr50_db'].iloc[0]); snr60 = float(row['snr60_db'].iloc[0])\n",
    "    if snr60 >= th_db and snr60 >= snr50: return 60.0\n",
    "    if snr50 >= th_db and snr50 >  snr60: return 50.0\n",
    "    return None  # no notch si no sobresale\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None:\n",
    "        return None\n",
    "    sid, rid = parse_subject_run(path)\n",
    "    notch = _decide_notch(sid, rid)\n",
    "    if notch is not None:\n",
    "        raw.notch_filter(freqs=[float(notch)], picks='eeg', method='spectrum_fit', phase='zero')\n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return []\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ', '')\n",
    "    res = []\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'):\n",
    "            res.append((float(onset), tag))\n",
    "    res.sort()\n",
    "    dedup = []\n",
    "    last_t1 = last_t2 = -1e9\n",
    "    for t, tag in res:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# ============== DATASET BUILD ==============\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR + MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "def extract_trials_from_run(edf_path: Path, scenario: str, window_mode: str):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF','EO'):\n",
    "        return ([], [])\n",
    "\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        return ([], [])\n",
    "\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    assert abs(fs - FS) < 1e-6\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if kind in ('LR','OF'):\n",
    "        events = collect_events_T1T2(raw)\n",
    "        if window_mode == '3s':\n",
    "            rel_start, rel_end = 0.0, 3.0\n",
    "        else:\n",
    "            # usamos 6s pero recortamos la \"ventana útil\" 0.5–4.5 s\n",
    "            rel_start, rel_end = 0.5, 4.5\n",
    "\n",
    "        for onset_sec, tag in events:\n",
    "            if kind == 'LR':\n",
    "                if tag == 'T1': label = 'L'\n",
    "                elif tag == 'T2': label = 'R'\n",
    "                else: continue\n",
    "            else:\n",
    "                if tag == 'T1': label = 'BFISTS'\n",
    "                elif tag == 'T2': label = 'BFEET'\n",
    "                else: continue\n",
    "\n",
    "            if scenario == '2c' and label not in ('L','R'): continue\n",
    "            if scenario == '3c' and label not in ('L','R','BFISTS'): continue\n",
    "            if scenario == '4c' and label not in ('L','R','BFISTS','BFEET'): continue\n",
    "\n",
    "            s = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "            e = int(round((raw.first_time + onset_sec + rel_end) * fs))\n",
    "            if s < 0 or e > data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            seg = data[:, s:e].T.astype(np.float32)  # (T,C)\n",
    "            if NORM_EPOCH_ZSCORE:\n",
    "                seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "\n",
    "            if label == 'L':       y = 0\n",
    "            elif label == 'R':     y = 1\n",
    "            elif label == 'BFISTS':y = 2\n",
    "            elif label == 'BFEET': y = 3\n",
    "            else: continue\n",
    "\n",
    "            out.append((seg, y, subj))\n",
    "\n",
    "    elif kind == 'EO':\n",
    "        return ([], raw.ch_names)\n",
    "\n",
    "    return out, raw.ch_names\n",
    "\n",
    "def build_dataset_all(subjects, scenario='4c', window_mode='6s'):\n",
    "    X, y, groups = [], [], []\n",
    "    ch_template = None\n",
    "\n",
    "    for s in tqdm(subjects, desc=\"Construyendo dataset (RAW)\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "\n",
    "        trials_L, trials_R, trials_FISTS, trials_FEET = [], [], [], []\n",
    "\n",
    "        for r in MI_RUNS_LR:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 0: trials_L.append(seg)\n",
    "                elif lab == 1: trials_R.append(seg)\n",
    "\n",
    "        for r in MI_RUNS_OF:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 2: trials_FISTS.append(seg)\n",
    "                elif lab == 3: trials_FEET.append(seg)\n",
    "\n",
    "        need_per_class = 21\n",
    "        def pick(trials, n, rng):\n",
    "            if len(trials) < n:\n",
    "                idx = rng.choice(len(trials), size=n, replace=True)\n",
    "                return [trials[i] for i in idx]\n",
    "            rng.shuffle(trials)\n",
    "            return trials[:n]\n",
    "\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        if len(trials_L)==0 or len(trials_R)==0 or len(trials_FISTS)==0 or len(trials_FEET)==0:\n",
    "            continue\n",
    "\n",
    "        Lp  = pick(trials_L,     need_per_class, rng)\n",
    "        Rp  = pick(trials_R,     need_per_class, rng)\n",
    "        FIp = pick(trials_FISTS, need_per_class, rng)\n",
    "        FEp = pick(trials_FEET,  need_per_class, rng)\n",
    "\n",
    "        pack = [(Lp, 0), (Rp, 1), (FIp, 2), (FEp, 3)]\n",
    "        for segs, lab in pack:\n",
    "            for seg in segs:\n",
    "                X.append(seg); y.append(lab); groups.append(s)\n",
    "\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    groups = np.asarray(groups, dtype=np.int64)\n",
    "\n",
    "    n, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Dataset construido: N={n} | T={T} | C={C} | clases={n_classes} | sujetos únicos={len(np.unique(groups))}\")\n",
    "    return X, y, groups, ch_template\n",
    "\n",
    "# ============== Dataset y utils torch ==============\n",
    "class EEGTrials(Dataset):\n",
    "    def __init__(self, X, y, groups):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        x = np.expand_dims(x, 0)                 # (1, T, C)\n",
    "        return torch.from_numpy(x), torch.tensor(self.y[idx]), torch.tensor(self.g[idx])\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_max_norm(layers, max_value=2.0, p=2.0):\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            w = layer.weight.data\n",
    "            norms = w.view(w.size(0), -1).norm(p=p, dim=1, keepdim=True)\n",
    "            desired = torch.clamp(norms, max=max_value)\n",
    "            w.view(w.size(0), -1).mul_(desired / (1e-8 + norms))\n",
    "\n",
    "# ============== Augments + TTA ==============\n",
    "def do_time_jitter(x, max_ms=50, fs=160.0):\n",
    "    max_shift = int(round(max_ms/1000.0 * fs))\n",
    "    if max_shift <= 0: return x\n",
    "    B,_,T,C = x.shape\n",
    "    shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=x.device)\n",
    "    out = torch.empty_like(x)\n",
    "    for i,s in enumerate(shifts):\n",
    "        if s==0: out[i] = x[i]; continue\n",
    "        if s>0:\n",
    "            out[i,:,s:,:] = x[i,:,:T-s,:]\n",
    "            out[i,:,:s,:] = 0\n",
    "        else:\n",
    "            s = -s\n",
    "            out[i,:,:T-s,:] = x[i,:,s:,:]\n",
    "            out[i,:,T-s:,:] = 0\n",
    "    return out\n",
    "\n",
    "def do_gaussian_noise(x, sigma=0.01):\n",
    "    if sigma<=0: return x\n",
    "    return x + sigma*torch.randn_like(x)\n",
    "\n",
    "def mixup_batch(x, y, n_classes, alpha=0.2):\n",
    "    if alpha<=0:\n",
    "        y_onehot = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "        return x, y_onehot, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    perm = torch.randperm(x.size(0), device=x.device)\n",
    "    x_mix = lam*x + (1-lam)*x[perm]\n",
    "    y_a = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "    y_b = y_a[perm]\n",
    "    y_mix = lam*y_a + (1-lam)*y_b\n",
    "    return x_mix, y_mix, lam\n",
    "\n",
    "@torch.no_grad()\n",
    "def _tta_logits(model, xb, n=5):\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        xj = do_time_jitter(xb, max_ms=25, fs=FS)\n",
    "        outs.append(model(xj)[0])\n",
    "    return torch.stack(outs, 0).mean(0)\n",
    "\n",
    "# ============== Stage-1: Encoder ==============\n",
    "class MHABlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 4, dim), nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = self.norm(x)\n",
    "        y, _ = self.attn(h, h, h, need_weights=False)\n",
    "        x = x + self.drop(y)\n",
    "        x = x + self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class DSConv1d(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, k: int = 3, dilation: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        pad = (k - 1) // 2 * dilation\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, groups=in_ch, padding=pad, dilation=dilation, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU(); self.drop = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x); x = self.act(x); x = self.drop(x); return x\n",
    "\n",
    "class STCN(nn.Module):\n",
    "    def __init__(self, dim: int, k: int = 3, dilations=(1,2,4,8), dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                DSConv1d(dim, dim, k=k, dilation=d, dropout=dropout),\n",
    "                nn.Conv1d(dim, dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm1d(dim), nn.ELU(), nn.Dropout(dropout)\n",
    "            ) for d in dilations\n",
    "        ])\n",
    "    def forward(self, x):  # (B,D,T)\n",
    "        for b in self.blocks:\n",
    "            res = x; x = b(x); x = x + res\n",
    "        return x\n",
    "\n",
    "class EEGNetParallel(nn.Module):\n",
    "    def __init__(self, n_ch: int, F1: int = 24, D: int = 2, k_t_list=(32,64,96), pool1_t=4, k_sep=16, pool2_t=4, drop=0.2):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.branches = nn.ModuleList()\n",
    "        for k_t in k_t_list:\n",
    "            self.branches.append(nn.Sequential(\n",
    "                nn.Conv2d(1, F1, kernel_size=(k_t, 1), padding=(k_t // 2, 0), bias=False),\n",
    "                nn.BatchNorm2d(F1), nn.ELU(),\n",
    "                nn.Conv2d(F1, F1*D, kernel_size=(1, n_ch), groups=F1, bias=False),\n",
    "                nn.BatchNorm2d(F1*D), nn.ELU(),\n",
    "                nn.AvgPool2d(kernel_size=(pool1_t,1), stride=(pool1_t,1)),\n",
    "                nn.Dropout(drop),\n",
    "                nn.Conv2d(F1*D, F1*D, kernel_size=(k_sep,1), groups=F1*D, padding=(k_sep//2,0), bias=False),\n",
    "                nn.Conv2d(F1*D, F1*D, kernel_size=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(F1*D), nn.ELU(),\n",
    "                nn.AvgPool2d(kernel_size=(pool2_t,1), stride=(pool2_t,1)),\n",
    "                nn.Dropout(drop),\n",
    "            ))\n",
    "        self.out_dim = len(k_t_list) * (F1*D)\n",
    "    def forward(self, x):\n",
    "        feats = [b(x) for b in self.branches]  # each: (B,F2,T',1)\n",
    "        return torch.cat(feats, dim=1)         # (B,Dsum,T',1)\n",
    "\n",
    "class TwoStageEncoder(nn.Module):\n",
    "    def __init__(self, n_ch: int, n_classes: int,\n",
    "                 F1=24, D=2, k_t_list=(32,64,96), attn_heads=4,\n",
    "                 stcn_k=3, stcn_dils=(1,2,4,8), emb_dim=160, drop=0.2,\n",
    "                 slice_len_steps=8, slice_stride_steps=4, avg_on='logits'):\n",
    "        super().__init__()\n",
    "        self.backbone = EEGNetParallel(n_ch=n_ch, F1=F1, D=D, k_t_list=k_t_list, drop=drop)\n",
    "        self.proj = nn.Conv2d(self.backbone.out_dim, emb_dim, kernel_size=(1,1), bias=False)\n",
    "        self.attn = MHABlock(dim=emb_dim, num_heads=attn_heads, dropout=drop)\n",
    "        self.stcn = STCN(dim=emb_dim, k=stcn_k, dilations=stcn_dils, dropout=drop)\n",
    "        self.cls_head = nn.Linear(emb_dim, n_classes)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.avg_on = avg_on\n",
    "        self.slice_len_steps = slice_len_steps\n",
    "        self.slice_stride_steps = slice_stride_steps\n",
    "\n",
    "    def _time_slices(self, T):\n",
    "        L, S = self.slice_len_steps, self.slice_stride_steps\n",
    "        slices, s = [], 0\n",
    "        while s + L <= T:\n",
    "            slices.append((s, s+L)); s += S\n",
    "        if not slices: slices = [(0,T)]\n",
    "        return slices\n",
    "\n",
    "    def forward(self, x):  # x: (B,1,T,C)\n",
    "        z = self.backbone(x)                          # (B,Dsum,T',1)\n",
    "        z = self.proj(z).squeeze(-1).transpose(1,2)  # (B,T',emb)\n",
    "        z = self.attn(z)\n",
    "        z = self.stcn(z.transpose(1,2)).transpose(1,2)  # (B,T',emb)\n",
    "        B,Tp,Demb = z.shape\n",
    "        idxs = self._time_slices(Tp)\n",
    "        slice_embs, slice_logits = [], []\n",
    "        for (a,b) in idxs:\n",
    "            seg = z[:,a:b,:]\n",
    "            e = seg.mean(dim=1)  # GAP temporal\n",
    "            slice_embs.append(e)\n",
    "            slice_logits.append(self.cls_head(e))\n",
    "        if self.avg_on == 'logits':\n",
    "            logits = torch.stack(slice_logits, dim=0).mean(dim=0)\n",
    "            emb = torch.stack(slice_embs, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            emb = torch.stack(slice_embs, dim=0).mean(dim=0)\n",
    "            logits = self.cls_head(emb)\n",
    "        return logits, emb\n",
    "\n",
    "# ============== Stage-1 Trainer ==============\n",
    "def build_weighted_sampler(y, groups):\n",
    "    y = np.asarray(y); groups = np.asarray(groups)\n",
    "    class_counts = np.bincount(y, minlength=len(np.unique(y))).astype(float)\n",
    "    class_w = 1.0 / class_counts[y]\n",
    "    subj_vals, subj_counts = np.unique(groups, return_counts=True)\n",
    "    subj_map = {s:c for s,c in zip(subj_vals, subj_counts)}\n",
    "    subj_w = np.array([1.0/subj_map[g] for g in groups], dtype=float)\n",
    "    w = class_w * subj_w\n",
    "    w = w / w.mean()\n",
    "    w_t = torch.from_numpy(w).float()\n",
    "    sampler = WeightedRandomSampler(weights=w_t, num_samples=len(w_t), replacement=True)\n",
    "    return sampler\n",
    "\n",
    "class Stage1Trainer:\n",
    "    def __init__(self, device=DEVICE, lr=LR_STAGE1, wd=WD_STAGE1, label_smoothing=0.05):\n",
    "        self.device = device; self.lr = lr; self.wd = wd\n",
    "        self.label_smoothing = label_smoothing\n",
    "    def _crit(self, n_classes, class_weights=None):\n",
    "        return nn.CrossEntropyLoss(weight=class_weights, label_smoothing=self.label_smoothing)\n",
    "    def fit(self, model, dl_train, dl_val, epochs=EPOCHS_STAGE1, class_weights=None):\n",
    "        model.to(self.device)\n",
    "        opt = optim.Adam(model.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        sched = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=SGDR_T0, T_mult=SGDR_Tmult)\n",
    "        crit = self._crit(n_classes=model.cls_head.out_features, class_weights=class_weights)\n",
    "        best_state = copy.deepcopy(model.state_dict()); best_val=-1.0; bad=0\n",
    "        history = {'train_acc':[], 'val_acc':[]}\n",
    "        for ep in range(1, epochs+1):\n",
    "            # ---- train ----\n",
    "            model.train(); n_ok=0; n_tot=0\n",
    "            for xb,yb,_ in dl_train:\n",
    "                xb,yb = xb.to(self.device), yb.to(self.device)\n",
    "                # Augments\n",
    "                xb = do_time_jitter(xb, max_ms=50, fs=FS)\n",
    "                xb = do_gaussian_noise(xb, sigma=0.01)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                logits,_ = model(xb)\n",
    "                loss = crit(logits, yb)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                opt.step()\n",
    "                n_ok += (logits.argmax(1)==yb).sum().item(); n_tot += yb.numel()\n",
    "            sched.step(ep-1 + 1e-8)\n",
    "            train_acc = n_ok/max(1,n_tot)\n",
    "            # Max-norm ligero en la cabeza\n",
    "            apply_max_norm([model.cls_head], max_value=2.0, p=2.0)\n",
    "            # ---- val (con TTA) ----\n",
    "            val_acc = self.evaluate(model, dl_val)\n",
    "            history['train_acc'].append(train_acc); history['val_acc'].append(val_acc)\n",
    "            if (ep % LOG_EVERY == 0) or ep in (1, 10, 20, 50, 80):\n",
    "                cur_lr = opt.param_groups[0]['lr']\n",
    "                print(f\"[Stage-1] Ep {ep:3d} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f} | LR={cur_lr:.5f}\")\n",
    "            if val_acc > best_val + 1e-4:\n",
    "                best_val = val_acc; best_state = copy.deepcopy(model.state_dict()); bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= PATIENCE_STAGE1:\n",
    "                    print(f\"[Stage-1] Early stopping @ {ep} (best val_acc={best_val:.4f})\")\n",
    "                    break\n",
    "        return best_state, history\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, model, dl):\n",
    "        model.eval(); n_ok=0; n=0\n",
    "        for xb,yb,_ in dl:\n",
    "            xb,yb = xb.to(self.device), yb.to(self.device)\n",
    "            logits = _tta_logits(model, xb, n=5)\n",
    "            n_ok += (logits.argmax(1)==yb).sum().item(); n += yb.numel()\n",
    "        return n/max(1,n)\n",
    "    @torch.no_grad()\n",
    "    def predict_logits(self, model, dl):\n",
    "        model.eval(); outs=[]\n",
    "        for xb,_,_ in dl:\n",
    "            xb = xb.to(self.device)\n",
    "            outs.append(_tta_logits(model, xb, n=5).detach().cpu().numpy())\n",
    "        return np.vstack(outs)\n",
    "\n",
    "# ============== PSD features (Welch) ==============\n",
    "try:\n",
    "    from scipy.signal import welch\n",
    "except Exception:\n",
    "    welch = None\n",
    "    warnings.warn(\"scipy not found: PSD features disabled. Install scipy to enable.\")\n",
    "\n",
    "class PSDConfig:\n",
    "    def __init__(self, fs=160.0, nperseg_sec=1.0, noverlap=0.5, bands=((1,4),(4,8),(8,14),(14,31),(31,49))):\n",
    "        self.fs = fs; self.nperseg_sec = nperseg_sec; self.noverlap = noverlap; self.bands = bands\n",
    "\n",
    "def _bandpower(f, Pxx, band):\n",
    "    idx = (f >= band[0]) & (f < band[1])\n",
    "    return (Pxx[idx].mean() + 1e-12)\n",
    "\n",
    "def make_psd_features(X_np, cfg=PSDConfig()):\n",
    "    if welch is None:\n",
    "        raise RuntimeError(\"scipy.signal.welch not available.\")\n",
    "    N,T,C = X_np.shape\n",
    "    nperseg = int(round(cfg.nperseg_sec*cfg.fs))\n",
    "    noverlap = int(round(cfg.noverlap*nperseg))\n",
    "    feats = []\n",
    "    for i in range(N):\n",
    "        x = X_np[i]\n",
    "        ch_feats = []\n",
    "        for c in range(C):\n",
    "            f, P = welch(x[:,c], fs=cfg.fs, nperseg=nperseg, noverlap=noverlap)\n",
    "            # log-bandpowers + tres ratios simples\n",
    "            bps = [np.log(_bandpower(f, P, b)) for b in cfg.bands]  # delta, theta, alpha, beta, gamma\n",
    "            ratios = [bps[2]-bps[3], bps[1]-bps[2], bps[0]-bps[2]]  # alpha-beta, theta-alpha, delta-alpha\n",
    "            ch_feats.extend(bps + ratios)\n",
    "        feats.append(ch_feats)\n",
    "    return np.asarray(feats, dtype=np.float32)\n",
    "\n",
    "# ============== Tabular Head (TabNet/MLP) ==============\n",
    "class _MLPHead(nn.Module):\n",
    "    def __init__(self, d_in, n_classes, hidden=512, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, hidden), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(hidden, hidden//2), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(hidden//2, n_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class TabularHead:\n",
    "    def __init__(self, input_dim, n_classes, use_tabnet=USE_TABNET, device=DEVICE, tabnet_params=None):\n",
    "        self.n_classes = n_classes; self.device = device\n",
    "        self.use_tabnet = False; self.tabnet=None\n",
    "        if use_tabnet:\n",
    "            try:\n",
    "                from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "                params = dict(n_d=32, n_a=32, n_steps=4, gamma=1.3,\n",
    "                              lambda_sparse=1e-4, momentum=0.02, clip_value=2.0)\n",
    "                if tabnet_params: params.update(tabnet_params)\n",
    "                self.tabnet = TabNetClassifier(**params)\n",
    "                self.use_tabnet = True\n",
    "            except Exception:\n",
    "                warnings.warn(\"pytorch_tabnet not found; using MLP fallback.\")\n",
    "        if not self.use_tabnet:\n",
    "            self.mlp = _MLPHead(input_dim, n_classes).to(self.device)\n",
    "            self.opt = optim.Adam(self.mlp.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "            self.crit = nn.CrossEntropyLoss()\n",
    "            self.scaler_mean=None; self.scaler_std=None\n",
    "    def fit(self, X, y, X_val=None, y_val=None, epochs=EPOCHS_STAGE2, patience=PATIENCE_STAGE2):\n",
    "        if self.use_tabnet:\n",
    "            eval_set=[(X_val, y_val)] if X_val is not None else None\n",
    "            self.tabnet.fit(X, y, eval_set=eval_set, max_epochs=epochs, patience=patience,\n",
    "                            batch_size=256, virtual_batch_size=128)\n",
    "        else:\n",
    "            self.scaler_mean = X.mean(axis=0, keepdims=True); self.scaler_std = X.std(axis=0, keepdims=True)+1e-6\n",
    "            Xn = (X - self.scaler_mean)/self.scaler_std; Xn = torch.from_numpy(Xn).float().to(self.device)\n",
    "            y_t = torch.from_numpy(y).long().to(self.device)\n",
    "            dset = torch.utils.data.TensorDataset(Xn,y_t)\n",
    "            loader = DataLoader(dset, batch_size=256, shuffle=True)\n",
    "            if X_val is not None and y_val is not None:\n",
    "                Xv = (X_val - self.scaler_mean)/self.scaler_std\n",
    "                self.Xv_t = torch.from_numpy(Xv).float().to(self.device)\n",
    "                self.yv_t = torch.from_numpy(y_val).long().to(self.device)\n",
    "            else:\n",
    "                self.Xv_t=None; self.yv_t=None\n",
    "            best_state = copy.deepcopy(self.mlp.state_dict()); best=-1.0; bad=0\n",
    "            for ep in range(1, epochs+1):\n",
    "                self.mlp.train()\n",
    "                for xb,yb in loader:\n",
    "                    self.opt.zero_grad(set_to_none=True)\n",
    "                    logits = self.mlp(xb)\n",
    "                    loss = self.crit(logits, yb)\n",
    "                    loss.backward(); self.opt.step()\n",
    "                if self.Xv_t is not None:\n",
    "                    self.mlp.eval();\n",
    "                    with torch.no_grad():\n",
    "                        lv = self.mlp(self.Xv_t)\n",
    "                        acc = (lv.argmax(1)==self.yv_t).float().mean().item()\n",
    "                    if ep % 10 == 0:\n",
    "                        print(f\"[Stage-2] Ep {ep:3d} | val_acc={acc:.4f}\")\n",
    "                    if acc > best + 1e-4:\n",
    "                        best = acc; best_state = copy.deepcopy(self.mlp.state_dict()); bad=0\n",
    "                    else:\n",
    "                        bad += 1\n",
    "                        if bad >= patience:\n",
    "                            print(f\"[Stage-2] Early stopping @ {ep} (best val_acc={best:.4f})\"); break\n",
    "            self.mlp.load_state_dict(best_state)\n",
    "    def predict_logits(self, X):\n",
    "        if self.use_tabnet:\n",
    "            proba = self.tabnet.predict_proba(X)\n",
    "            return np.log(proba + 1e-9)\n",
    "        else:\n",
    "            Xn = (X - self.scaler_mean)/self.scaler_std\n",
    "            Xt = torch.from_numpy(Xn).float().to(self.device)\n",
    "            self.mlp.eval();\n",
    "            with torch.no_grad():\n",
    "                logits = self.mlp(Xt).cpu().numpy()\n",
    "            return logits\n",
    "\n",
    "def blend_logits(logits1, logits2, w):\n",
    "    w = float(np.clip(w,0.0,1.0)); return w*logits1 + (1.0-w)*logits2\n",
    "\n",
    "# ============== Folds JSON helpers ==============\n",
    "def save_group_folds_json_with_indices(subject_ids_str, groups_array, n_splits, out_json_path,\n",
    "                                       created_by=\"TwoStage_Exp\", description=None):\n",
    "    out_json_path = Path(out_json_path)\n",
    "    unique_subjects_int = sorted(np.unique(groups_array).tolist())\n",
    "    subject_ids = [f\"S{sid:03d}\" for sid in unique_subjects_int]\n",
    "    if len(subject_ids) < n_splits:\n",
    "        raise ValueError(f\"n_splits={n_splits} mayor que número de sujetos={len(subject_ids)}\")\n",
    "    groups = np.arange(len(subject_ids))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    folds = []\n",
    "    fold_i = 0\n",
    "    for train_idx_grp, test_idx_grp in gkf.split(groups, groups, groups):\n",
    "        fold_i += 1\n",
    "        train_sids = [subject_ids[int(i)] for i in train_idx_grp]\n",
    "        test_sids  = [subject_ids[int(i)] for i in test_idx_grp]\n",
    "        train_sids_int = [int(s[1:]) for s in train_sids]\n",
    "        test_sids_int  = [int(s[1:]) for s in test_sids]\n",
    "        tr_idx = np.where(np.isin(groups_array, train_sids_int))[0].tolist()\n",
    "        te_idx = np.where(np.isin(groups_array, test_sids_int))[0].tolist()\n",
    "        folds.append({\"fold\": int(fold_i), \"train\": train_sids, \"test\": test_sids, \"tr_idx\": tr_idx, \"te_idx\": te_idx})\n",
    "    payload = {\"created_at\": datetime.now().isoformat(), \"created_by\": created_by,\n",
    "               \"description\": description if description is not None else \"\",\n",
    "               \"n_splits\": int(n_splits), \"n_subjects\": len(subject_ids),\n",
    "               \"subject_ids\": subject_ids, \"folds\": folds}\n",
    "    out_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Folds JSON con índices guardado → {out_json_path}\")\n",
    "    return out_json_path\n",
    "\n",
    "def load_group_folds_json(path_json, expected_subject_ids=None, strict_check=True):\n",
    "    path_json = Path(path_json)\n",
    "    if not path_json.exists():\n",
    "        raise FileNotFoundError(f\"No existe {path_json}\")\n",
    "    with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "    subj_json = payload.get(\"subject_ids\", [])\n",
    "    if expected_subject_ids is not None:\n",
    "        expected = sorted(list(expected_subject_ids))\n",
    "        if subj_json != expected:\n",
    "            msg = (\"Los subject_ids del JSON no coinciden con expected_subject_ids.\\n\"\n",
    "                   f\"JSON has {len(subj_json)} subjects, expected {len(expected)}.\\n\"\n",
    "                   f\"First 10 JSON: {subj_json[:10]}\\nFirst 10 expected: {expected[:10]}\")\n",
    "            if strict_check: raise ValueError(msg)\n",
    "            else: print(\"WARNING: \" + msg)\n",
    "    return payload\n",
    "\n",
    "# ============== Confusion + curves ==============\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, ha='right'); plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f'; thresh = cm_norm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i, format(cm_norm[i, j], fmt), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150, bbox_inches='tight'); plt.close()\n",
    "\n",
    "def plot_training_curves(history, fname, title='Stage-1 Training curve'):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history['train_acc'], label='train_acc')\n",
    "    plt.plot(history['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title(title); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "# ============== EXPERIMENTO PRINCIPAL ==============\n",
    "def run_experiment_two_stage():\n",
    "    mne.set_log_level('WARNING')\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos elegibles: {len(subs)} → {subs[:10]}{'...' if len(subs)>10 else ''}\")\n",
    "\n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Listo para entrenar: N={N} | T={T} | C={C} | clases={n_classes} | sujetos={len(np.unique(groups))}\")\n",
    "\n",
    "    ds = EEGTrials(X, y, groups)\n",
    "\n",
    "    # preparar JSON folds\n",
    "    folds_json_path = Path(FOLDS_DIR)\n",
    "    folds_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    unique_subs = sorted(np.unique(groups).tolist())\n",
    "    subject_ids_str = [f\"S{s:03d}\" for s in unique_subs]\n",
    "    if not folds_json_path.exists():\n",
    "        save_group_folds_json_with_indices(subject_ids_str, groups, n_splits=N_FOLDS,\n",
    "                                           out_json_path=folds_json_path,\n",
    "                                           created_by=\"TwoStage_Pipeline_Tuned\",\n",
    "                                           description=\"Two-Stage GroupKFold\")\n",
    "    payload = load_group_folds_json(folds_json_path, expected_subject_ids=subject_ids_str, strict_check=False)\n",
    "    folds = payload[\"folds\"]\n",
    "\n",
    "    stage1_folds = []\n",
    "    blend_folds  = []\n",
    "    all_true = []; all_pred = []\n",
    "\n",
    "    for f in folds:\n",
    "        fold = f[\"fold\"]\n",
    "        tr_idx = np.asarray(f.get(\"tr_idx\", []), dtype=int)\n",
    "        te_idx = np.asarray(f.get(\"te_idx\", []), dtype=int)\n",
    "        if tr_idx.size == 0 or te_idx.size == 0:\n",
    "            print(f\"Advertencia: fold {fold} sin índices tr/te válidos. Saltando.\")\n",
    "            continue\n",
    "\n",
    "        # ======= B) VALIDACIÓN INTERNA POR SUJETOS CON GroupKFold =======\n",
    "        n_groups_tr = len(np.unique(groups[tr_idx]))\n",
    "        if n_groups_tr < 2:\n",
    "            raise RuntimeError(f\"[Fold {fold}] Muy pocos sujetos en train para validación interna (n_groups_tr={n_groups_tr}).\")\n",
    "        n_splits_inner = min(5, n_groups_tr)  # hasta 5 splits; si hay menos sujetos, se ajusta\n",
    "        gkf_in = GroupKFold(n_splits=n_splits_inner)\n",
    "        inner_splits = list(gkf_in.split(tr_idx, y[tr_idx], groups[tr_idx]))\n",
    "        tr_pos, va_pos = inner_splits[0]  # puedes elegir otro índice si prefieres\n",
    "        tr_sub_idx = tr_idx[tr_pos]\n",
    "        va_idx     = tr_idx[va_pos]\n",
    "\n",
    "        # ======= A) PRINTS + ASSERTS DE SANIDAD (no-overlap por sujeto) =======\n",
    "        tr_sub_ids = set(groups[tr_sub_idx].tolist())\n",
    "        va_sub_ids = set(groups[va_idx].tolist())\n",
    "        te_sub_ids = set(groups[te_idx].tolist())\n",
    "\n",
    "        print(f\"[Fold {fold}] sujetos train={len(tr_sub_ids)}, val={len(va_sub_ids)}, test={len(te_sub_ids)}\")\n",
    "        print(f\"  train subs: {sorted(list(tr_sub_ids))[:10]}{'...' if len(tr_sub_ids)>10 else ''}\")\n",
    "        print(f\"  val   subs: {sorted(list(va_sub_ids))[:10]}{'...' if len(va_sub_ids)>10 else ''}\")\n",
    "        print(f\"  test  subs: {sorted(list(te_sub_ids))[:10]}{'...' if len(te_sub_ids)>10 else ''}\")\n",
    "\n",
    "        assert tr_sub_ids.isdisjoint(va_sub_ids), \"♨️ fuga: sujeto aparece en train y val\"\n",
    "        assert tr_sub_ids.isdisjoint(te_sub_ids), \"♨️ fuga: sujeto aparece en train y test\"\n",
    "        assert va_sub_ids.isdisjoint(te_sub_ids), \"♨️ fuga: sujeto aparece en val y test\"\n",
    "\n",
    "        print(f\"[Fold {fold}] n_train={len(tr_sub_idx)} | n_val={len(va_idx)} | n_test={len(te_idx)}\")\n",
    "        vals, cnts = np.unique(y[va_idx], return_counts=True)\n",
    "        print(f\"[Fold {fold}] val class dist: \" + str(dict(zip(vals.tolist(), cnts.tolist()))))\n",
    "\n",
    "        # -------- DataLoaders --------\n",
    "        tr_loader = DataLoader(\n",
    "            Subset(ds, tr_sub_idx),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            sampler=build_weighted_sampler(y[tr_sub_idx], groups[tr_sub_idx]),\n",
    "            drop_last=False\n",
    "        )\n",
    "        va_loader = DataLoader(Subset(ds, va_idx), batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        te_loader = DataLoader(Subset(ds, te_idx), batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "        # -------- Stage-1 --------\n",
    "        model = TwoStageEncoder(n_ch=C, n_classes=n_classes,\n",
    "                                F1=24, D=2, k_t_list=(32,64,96), attn_heads=4,\n",
    "                                stcn_k=3, stcn_dils=(1,2,4,8), emb_dim=160, drop=0.2,\n",
    "                                slice_len_steps=8, slice_stride_steps=4, avg_on='logits').to(DEVICE)\n",
    "\n",
    "        trainer = Stage1Trainer(device=DEVICE, lr=LR_STAGE1, wd=WD_STAGE1, label_smoothing=0.05)\n",
    "        # class weights inversos por clase\n",
    "        class_counts = np.bincount(y[tr_sub_idx], minlength=n_classes).astype(np.float32)\n",
    "        class_counts[class_counts==0]=1.0\n",
    "        class_w = class_counts.sum()/class_counts\n",
    "        class_w = class_w / class_w.mean()\n",
    "        class_w = torch.tensor(class_w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        print(f\"\\n[Fold {fold}/{N_FOLDS}] Entrenando Stage-1 (encoder)...\")\n",
    "        best_state, hist = trainer.fit(model, tr_loader, va_loader, epochs=EPOCHS_STAGE1, class_weights=class_w)\n",
    "        plot_training_curves(hist, f\"stage1_curve_fold{fold}.png\", title='Stage-1 Train/Val Acc')\n",
    "        print(f\"↳ Curva Stage-1 guardada: stage1_curve_fold{fold}.png\")\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # logits Stage-1 en validación y test (con TTA)\n",
    "        logits_stage1_val = trainer.predict_logits(model, va_loader)\n",
    "        logits_stage1_te  = trainer.predict_logits(model, te_loader)\n",
    "\n",
    "        y_va = y[va_idx]\n",
    "        y_te = y[te_idx]\n",
    "        y_pred_stage1 = logits_stage1_te.argmax(1)\n",
    "        acc_stage1 = (y_pred_stage1 == y_te).mean()\n",
    "        print(f\"[Fold {fold}] Stage-1 acc(test) = {acc_stage1:.4f}\")\n",
    "\n",
    "        # -------- Extraer embeddings + PSD --------\n",
    "        @torch.no_grad()\n",
    "        def extract_embeddings(model, dl, device=DEVICE):\n",
    "            model.eval().to(device)\n",
    "            embs, ys = [], []\n",
    "            for xb,yb,_ in dl:\n",
    "                xb = xb.to(device)\n",
    "                _, e = model(xb)\n",
    "                embs.append(e.detach().cpu().numpy()); ys.append(yb.numpy())\n",
    "            return np.vstack(embs), np.concatenate(ys)\n",
    "\n",
    "        emb_tr, y_tr = extract_embeddings(model, tr_loader, DEVICE)\n",
    "        emb_va, _    = extract_embeddings(model, va_loader, DEVICE)\n",
    "        emb_te, _    = extract_embeddings(model, te_loader, DEVICE)\n",
    "\n",
    "        # recolecta X bruto para PSD\n",
    "        def collect_numpy(dl):\n",
    "            Xs, ys = [], []\n",
    "            for xb,yb,_ in dl:\n",
    "                Xs.append(xb.squeeze(1).numpy()); ys.append(yb.numpy())\n",
    "            return np.concatenate(Xs, axis=0), np.concatenate(ys, axis=0)\n",
    "        X_tr_np, _ = collect_numpy(tr_loader)\n",
    "        X_va_np, _ = collect_numpy(va_loader)\n",
    "        X_te_np, _ = collect_numpy(te_loader)\n",
    "\n",
    "        if welch is None:\n",
    "            print(\"WARNING: scipy no disponible → Stage-2 usará SOLO embeddings (sin PSD).\")\n",
    "            psd_tr = np.zeros((emb_tr.shape[0], 0), dtype=np.float32)\n",
    "            psd_va = np.zeros((emb_va.shape[0], 0), dtype=np.float32)\n",
    "            psd_te = np.zeros((emb_te.shape[0], 0), dtype=np.float32)\n",
    "        else:\n",
    "            psd_tr = make_psd_features(X_tr_np, PSDConfig(fs=FS))\n",
    "            psd_va = make_psd_features(X_va_np, PSDConfig(fs=FS))\n",
    "            psd_te = make_psd_features(X_te_np, PSDConfig(fs=FS))\n",
    "\n",
    "        Xtr2 = np.hstack([emb_tr, psd_tr])\n",
    "        Xva2 = np.hstack([emb_va, psd_va])\n",
    "        Xte2 = np.hstack([emb_te, psd_te])\n",
    "\n",
    "        # -------- Stage-2 --------\n",
    "        head = TabularHead(input_dim=Xtr2.shape[1], n_classes=n_classes, use_tabnet=USE_TABNET, device=DEVICE,\n",
    "                           tabnet_params=dict(n_d=32, n_a=32, n_steps=4, gamma=1.3,\n",
    "                                              lambda_sparse=1e-4, momentum=0.02, clip_value=2.0))\n",
    "        print(f\"[Fold {fold}] Entrenando Stage-2 (tabular head)...\")\n",
    "        head.fit(Xtr2, y_tr, X_val=Xva2, y_val=y_va, epochs=EPOCHS_STAGE2, patience=PATIENCE_STAGE2)\n",
    "        logits_stage2_val = head.predict_logits(Xva2)\n",
    "        logits_stage2_te  = head.predict_logits(Xte2)\n",
    "\n",
    "        # -------- Buscar mejor w en validación --------\n",
    "        best_w, best_val_acc = None, -1.0\n",
    "        for w in BLEND_CANDIDATES:\n",
    "            val_logits = blend_logits(logits_stage1_val, logits_stage2_val, w=w)\n",
    "            acc = (val_logits.argmax(1) == y_va).mean()\n",
    "            if acc > best_val_acc:\n",
    "                best_val_acc = acc; best_w = w\n",
    "        print(f\"[Fold {fold}] Mejor w (val) = {best_w} | val_acc_blend = {best_val_acc:.4f}\")\n",
    "\n",
    "        # -------- Evaluar en test con ese w --------\n",
    "        logits_blend_te = blend_logits(logits_stage1_te, logits_stage2_te, w=best_w)\n",
    "        y_pred_blend = logits_blend_te.argmax(1)\n",
    "        acc_blend = (y_pred_blend == y_te).mean()\n",
    "        print(f\"[Fold {fold}] BLEND acc(test) = {acc_blend:.4f} (w={best_w}) | Δ vs Stage-1 = {acc_blend-acc_stage1:+.4f}\")\n",
    "\n",
    "        stage1_folds.append(acc_stage1)\n",
    "        blend_folds.append(acc_blend)\n",
    "        all_true.append(y_te); all_pred.append(y_pred_blend)\n",
    "\n",
    "    if len(all_true)>0:\n",
    "        all_true = np.concatenate(all_true); all_pred = np.concatenate(all_pred)\n",
    "    else:\n",
    "        all_true = np.array([], dtype=int); all_pred = np.array([], dtype=int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADOS FINALES (Two-Stage, tuned)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Stage-1 folds:\", [f\"{a:.4f}\" for a in stage1_folds])\n",
    "    if stage1_folds:\n",
    "        print(f\"Stage-1 mean: {np.mean(stage1_folds):.4f}\")\n",
    "    print(\"BLEND folds:\", [f\"{a:.4f}\" for a in blend_folds])\n",
    "    if blend_folds:\n",
    "        print(f\"BLEND mean: {np.mean(blend_folds):.4f}\")\n",
    "        print(f\"Δ(BLEND - Stage-1) mean: {np.mean(blend_folds) - np.mean(stage1_folds):+.4f}\")\n",
    "\n",
    "    if all_true.size>0:\n",
    "        plot_confusion(all_true, all_pred, CLASS_NAMES_4C,\n",
    "                       title=\"Confusion Matrix - Two-Stage BLEND (All Folds)\",\n",
    "                       fname=\"confusion_twostage_blend_allfolds.png\")\n",
    "        print(\"↳ Matriz de confusión guardada: confusion_twostage_blend_allfolds.png\")\n",
    "\n",
    "    return {\n",
    "        \"stage1_folds\": stage1_folds,\n",
    "        \"blend_folds\": blend_folds,\n",
    "        \"all_true\": all_true,\n",
    "        \"all_pred\": all_pred,\n",
    "        \"folds_json_path\": str(FOLDS_DIR)\n",
    "    }\n",
    "\n",
    "# -------- MAIN --------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🧠 INICIANDO EXPERIMENTO TWO-STAGE (Encoder+Tabular, tuned)\")\n",
    "    print(f\"🔧 Configuración: {CLASS_SCENARIO}, {len(EXPECTED_8)} canales, {WINDOW_MODE}\")\n",
    "    print(f\"⚙️  Stage-1: epochs={EPOCHS_STAGE1}, lr={LR_STAGE1}, SGDR T0={SGDR_T0}, Tmult={SGDR_Tmult}, augments+TTA ✓\")\n",
    "    print(f\"⚙️  Stage-2: {'TabNet' if USE_TABNET else 'MLP'} | epochs={EPOCHS_STAGE2}, patience={PATIENCE_STAGE2}\")\n",
    "    out = run_experiment_two_stage()\n",
    "    print(\"✔️ Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
