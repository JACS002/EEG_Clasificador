{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e28a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:12<00:00,  6.56it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:03<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts: {'left': np.int64(1767), 'right': np.int64(1748), 'both_fists': np.int64(1752), 'both_feet': np.int64(1761)} | total = 7028\n",
      "test  counts: {'left': np.int64(448), 'right': np.int64(446), 'both_fists': np.int64(442), 'both_feet': np.int64(450)} | total = 1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=1.3710 | val_acc=0.3533 | val_f1m=0.3243\n",
      "Epoch 002 | train_loss=1.2879 | val_acc=0.3897 | val_f1m=0.3910\n",
      "Epoch 003 | train_loss=1.2595 | val_acc=0.3763 | val_f1m=0.3440\n",
      "Epoch 004 | train_loss=1.2336 | val_acc=0.3757 | val_f1m=0.3722\n",
      "Epoch 005 | train_loss=1.2297 | val_acc=0.4149 | val_f1m=0.4140\n",
      "Epoch 006 | train_loss=1.2192 | val_acc=0.4009 | val_f1m=0.3996\n",
      "Epoch 007 | train_loss=1.2103 | val_acc=0.3992 | val_f1m=0.3996\n",
      "Epoch 008 | train_loss=1.2072 | val_acc=0.3852 | val_f1m=0.3780\n",
      "Epoch 009 | train_loss=1.1913 | val_acc=0.4065 | val_f1m=0.4018\n",
      "Epoch 010 | train_loss=1.1832 | val_acc=0.3852 | val_f1m=0.3849\n",
      "Epoch 011 | train_loss=1.1808 | val_acc=0.4071 | val_f1m=0.4083\n",
      "Epoch 012 | train_loss=1.1699 | val_acc=0.3852 | val_f1m=0.3858\n",
      "Epoch 013 | train_loss=1.1525 | val_acc=0.3824 | val_f1m=0.3767\n",
      "Epoch 014 | train_loss=1.1547 | val_acc=0.3886 | val_f1m=0.3849\n",
      "Epoch 015 | train_loss=1.1468 | val_acc=0.3757 | val_f1m=0.3682\n",
      "Epoch 016 | train_loss=1.1294 | val_acc=0.3656 | val_f1m=0.3653\n",
      "Epoch 017 | train_loss=1.1209 | val_acc=0.3897 | val_f1m=0.3784\n",
      "Epoch 018 | train_loss=1.1043 | val_acc=0.3925 | val_f1m=0.3907\n",
      "Epoch 019 | train_loss=1.1010 | val_acc=0.3746 | val_f1m=0.3723\n",
      "Epoch 020 | train_loss=1.0854 | val_acc=0.3774 | val_f1m=0.3718\n",
      "Epoch 021 | train_loss=1.0697 | val_acc=0.3875 | val_f1m=0.3852\n",
      "Epoch 022 | train_loss=1.0668 | val_acc=0.3830 | val_f1m=0.3763\n",
      "Epoch 023 | train_loss=1.0444 | val_acc=0.3768 | val_f1m=0.3786\n",
      "Epoch 024 | train_loss=1.0242 | val_acc=0.3858 | val_f1m=0.3828\n",
      "Epoch 025 | train_loss=1.0214 | val_acc=0.3774 | val_f1m=0.3753\n",
      "Epoch 026 | train_loss=1.0026 | val_acc=0.3819 | val_f1m=0.3824\n",
      "Epoch 027 | train_loss=0.9900 | val_acc=0.3785 | val_f1m=0.3726\n",
      "Epoch 028 | train_loss=0.9699 | val_acc=0.3634 | val_f1m=0.3623\n",
      "Epoch 029 | train_loss=0.9518 | val_acc=0.3707 | val_f1m=0.3688\n",
      "Epoch 030 | train_loss=0.9370 | val_acc=0.3701 | val_f1m=0.3621\n",
      "Epoch 031 | train_loss=0.9262 | val_acc=0.3639 | val_f1m=0.3618\n",
      "Epoch 032 | train_loss=0.9049 | val_acc=0.3544 | val_f1m=0.3541\n",
      "Epoch 033 | train_loss=0.8885 | val_acc=0.3645 | val_f1m=0.3638\n",
      "Epoch 034 | train_loss=0.8726 | val_acc=0.3611 | val_f1m=0.3541\n",
      "Epoch 035 | train_loss=0.8716 | val_acc=0.3628 | val_f1m=0.3608\n",
      "Epoch 036 | train_loss=0.8384 | val_acc=0.3595 | val_f1m=0.3593\n",
      "Epoch 037 | train_loss=0.8203 | val_acc=0.3639 | val_f1m=0.3617\n",
      "Epoch 038 | train_loss=0.8112 | val_acc=0.3578 | val_f1m=0.3569\n",
      "Epoch 039 | train_loss=0.8010 | val_acc=0.3477 | val_f1m=0.3477\n",
      "Epoch 040 | train_loss=0.7830 | val_acc=0.3589 | val_f1m=0.3555\n",
      "\n",
      "=== RESULTADOS (fold 1) ===\n",
      "Acc: 0.4149 | Macro-F1: 0.4140\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[187  61  99 101]\n",
      " [ 52 190  60 144]\n",
      " [ 80  89 146 127]\n",
      " [ 79  86  67 218]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN + Transformer (PyTorch) para PhysioNet/BCI2000 MI â€” IMAGINERÃA (4 clases) con 8 canales.\n",
    "# Incluye reproducibilidad (seed=42) y determinismo CUDA para cuBLAS/cuDNN en notebook.\n",
    "\n",
    "# =========================\n",
    "# Reproducibilidad (poner ANTES de importar torch)\n",
    "# =========================\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # determinismo cuBLAS\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD (seed + determinismo)\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # determinismo cuDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Evitar TF32 (puede romper determinismo en algunas GPU)\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    # reforzar determinismo cuando sea posible\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = seed_everything.__defaults__[0] + worker_id if seed_everything.__defaults__ else 42 + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edita a tu gusto)\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'                     # .../S###/S###R##.edf\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "FOLD = 1\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "RESAMPLE_HZ = None              # None para mantener original\n",
    "DO_NOTCH = True                 # 60 Hz\n",
    "DO_BANDPASS = False             # band-pass (4â€“38) desactivado por defecto\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False                   # re-referencia promedio sobre 8 canales\n",
    "\n",
    "# Ventana temporal (seg)\n",
    "TMIN, TMAX = 0.5, 4.5\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "# Runs IMAGINERÃA\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}    # T1=left, T2=right\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}   # T1=both_fists, T2=both_feet\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Device: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    \"\"\"Normaliza: quita no-alfanum, pasa a upper. 'Fc3.' -> 'FC3', 'Cz..' -> 'CZ'.\"\"\"\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    \"\"\"Mapea canales del EDF a EXPECTED_8 aunque tengan puntos/minÃºsculas.\"\"\"\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    \"\"\"Devuelve lista de EDFs IMAGERY para un sujeto S###: R04,R06,R08,R10,R12,R14.\"\"\"\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        pattern = str(subj_dir / f\"{subject_id}R{r:02d}.edf\")\n",
    "        edfs.extend(glob(pattern))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    \"\"\"Carga EDFs de imaginerÃ­a, aplica preproc y devuelve (X[N,8,T], y[N], sfreq).\"\"\"\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        raise FileNotFoundError(f\"No imagery EDF files for {subject_id} under {DATA_RAW}\")\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "        # SelecciÃ³n de 8 canales\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        # --- PREPROC OPCIONAL ---\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        # Resample\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        # Eventos (T0/T1/T2)\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        # Mantener solo T1/T2 (T0 ignorado)\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()  # (n_epochs, 8, T)\n",
    "\n",
    "        # Construir y segÃºn RUN\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}  # id -> 'T1'/'T2'\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)  # left/right\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)  # both_fists/feet\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        keep_mask = y_run >= 0\n",
    "        X = X[keep_mask]\n",
    "        y = y_run[keep_mask]\n",
    "\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, 8, 1)), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    if len(set([round(s) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Inconsistent sampling rates: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            train_sub = list(item.get('train', []))\n",
    "            test_sub  = list(item.get('test', []))\n",
    "            return train_sub, test_sub\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def class_count_summary(y, name):\n",
    "    bc = np.bincount(y, minlength=4)\n",
    "    print(f\"{name} counts:\", dict(zip(CLASS_NAMES, bc)), \"| total =\", bc.sum())\n",
    "\n",
    "# =========================\n",
    "# MODELO: CNN + Transformer (con dropout)\n",
    "# =========================\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            nn.BatchNorm1d(32), nn.ELU(),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "        self.pos_encoding = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)          # regularizaciÃ³n extra\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)  # (B,1,D)\n",
    "        z = torch.cat([cls_tok, z], dim=1)    # (B, 1+L, D)\n",
    "        z = self.encoder(z)                   # (B, 1+L, D)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# ENTRENAMIENTO / EVAL\n",
    "# =========================\n",
    "def standardize_per_channel(train_X, test_X):\n",
    "    \"\"\"Estandariza por canal usando SOLO estadÃ­sticas del train. Entradas (N,C,T).\"\"\"\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X  = test_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        test_X[:, c, :]  = (test_X[:, c, :] - mu) / sd\n",
    "    return train_X, test_X\n",
    "\n",
    "def train_one_fold(fold:int, resample_hz:int, do_notch:bool, do_bandpass:bool,\n",
    "                   bp_lo:float, bp_hi:float, epochs:int, batch_size:int, lr:float,\n",
    "                   device:str=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "\n",
    "    # --- sujetos fold ---\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # --- carga datos ---\n",
    "    X_tr_list, y_tr_list, X_te_list, y_te_list = [], [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_sub, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    if len(X_tr_list) == 0 or len(X_te_list) == 0:\n",
    "        raise RuntimeError(\"Datos insuficientes tras carga de sujetos.\")\n",
    "\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "\n",
    "    # --- diagnÃ³sticos de desbalance ---\n",
    "    print(\"train counts:\", dict(zip(CLASS_NAMES, np.bincount(y_tr, minlength=4))), \"| total =\", len(y_tr))\n",
    "    print(\"test  counts:\", dict(zip(CLASS_NAMES, np.bincount(y_te, minlength=4))), \"| total =\", len(y_te))\n",
    "\n",
    "    # --- estandarizaciÃ³n sin leakage ---\n",
    "    X_tr, X_te = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # --- DataLoaders (reproducibles) ---\n",
    "    g = torch.Generator(device=\"cpu\"); g.manual_seed(RANDOM_STATE)\n",
    "    tr_ld = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_tr), torch.tensor(y_tr).long()),\n",
    "        batch_size=batch_size, shuffle=True, drop_last=False,\n",
    "        generator=g, worker_init_fn=seed_worker\n",
    "    )\n",
    "    te_ld = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_te), torch.tensor(y_te).long()),\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "        generator=g, worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    # --- Modelo, optimizador, pÃ©rdida ---\n",
    "    model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2, p_drop=0.2).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    crit = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc, best_state = 0.0, None\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen = 0.0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * len(yb); n_seen += len(yb)\n",
    "        tr_loss /= max(1, n_seen)\n",
    "\n",
    "        # --- Eval ---\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "        print(f\"Epoch {ep:03d} | train_loss={tr_loss:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f}\")\n",
    "\n",
    "    # cargar el mejor\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # --- reporte final ---\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in te_ld:\n",
    "            xb = xb.to(device)\n",
    "            p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "            preds.append(p); gts.append(yb.numpy())\n",
    "    preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
    "\n",
    "    print(f\"\\n=== RESULTADOS (fold {fold}) ===\")\n",
    "    print(f\"Acc: {acc:.4f} | Macro-F1: {f1m:.4f}\")\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "\n",
    "    return acc, f1m, cm, model\n",
    "\n",
    "# =========================\n",
    "# EJECUCIÃ“N (Notebook)\n",
    "# =========================\n",
    "acc, f1m, cm, model = train_one_fold(\n",
    "    fold=FOLD,\n",
    "    resample_hz=RESAMPLE_HZ,\n",
    "    do_notch=DO_NOTCH,\n",
    "    do_bandpass=DO_BANDPASS,\n",
    "    bp_lo=BP_LO,\n",
    "    bp_hi=BP_HI,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af4a3a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Device: cuda\n",
      "\n",
      "============  FOLD 1  ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.35it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=6888 | n_test=1764)\n",
      "train counts: {'left': np.int64(1722), 'right': np.int64(1722), 'both_fists': np.int64(1722), 'both_feet': np.int64(1722)} | total = 6888\n",
      "test  counts: {'left': np.int64(441), 'right': np.int64(441), 'both_fists': np.int64(441), 'both_feet': np.int64(441)} | total = 1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3483 | val_acc=0.3656 | val_f1m=0.3498 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2134 | val_acc=0.4427 | val_f1m=0.4359 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1752 | val_acc=0.4598 | val_f1m=0.4615 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1564 | val_acc=0.4495 | val_f1m=0.4522 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1524 | val_acc=0.4507 | val_f1m=0.4365 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1156 | val_acc=0.4717 | val_f1m=0.4685 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1040 | val_acc=0.4745 | val_f1m=0.4572 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1060 | val_acc=0.4705 | val_f1m=0.4688 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1008 | val_acc=0.4422 | val_f1m=0.4248 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.0739 | val_acc=0.4586 | val_f1m=0.4385 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0749 | val_acc=0.4830 | val_f1m=0.4818 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0540 | val_acc=0.4615 | val_f1m=0.4579 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0441 | val_acc=0.4683 | val_f1m=0.4621 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0480 | val_acc=0.4768 | val_f1m=0.4794 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0312 | val_acc=0.4461 | val_f1m=0.4343 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0293 | val_acc=0.4575 | val_f1m=0.4567 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0206 | val_acc=0.4728 | val_f1m=0.4731 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0037 | val_acc=0.4620 | val_f1m=0.4459 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=1.0302 | val_acc=0.4773 | val_f1m=0.4707 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0074 | val_acc=0.4711 | val_f1m=0.4634 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=1.0002 | val_acc=0.4858 | val_f1m=0.4847 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=0.9862 | val_acc=0.4836 | val_f1m=0.4859 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9685 | val_acc=0.4722 | val_f1m=0.4782 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9495 | val_acc=0.4751 | val_f1m=0.4790 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9420 | val_acc=0.4841 | val_f1m=0.4773 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9169 | val_acc=0.4546 | val_f1m=0.4612 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9106 | val_acc=0.4756 | val_f1m=0.4740 | LR=0.000655\n",
      "  Ã‰poca  28 | train_loss=0.9101 | val_acc=0.4722 | val_f1m=0.4728 | LR=0.000627\n",
      "  Ã‰poca  29 | train_loss=0.8790 | val_acc=0.4722 | val_f1m=0.4681 | LR=0.000599\n",
      "  Ã‰poca  30 | train_loss=0.8730 | val_acc=0.4722 | val_f1m=0.4718 | LR=0.000571\n",
      "  Ã‰poca  31 | train_loss=0.8520 | val_acc=0.4904 | val_f1m=0.4892 | LR=0.000543\n",
      "  Ã‰poca  32 | train_loss=0.8413 | val_acc=0.4711 | val_f1m=0.4711 | LR=0.000514\n",
      "  Ã‰poca  33 | train_loss=0.8103 | val_acc=0.4677 | val_f1m=0.4659 | LR=0.000486\n",
      "  Ã‰poca  34 | train_loss=0.8311 | val_acc=0.4768 | val_f1m=0.4760 | LR=0.000457\n",
      "  Ã‰poca  35 | train_loss=0.8171 | val_acc=0.4796 | val_f1m=0.4747 | LR=0.000429\n",
      "  Ã‰poca  36 | train_loss=0.7769 | val_acc=0.4700 | val_f1m=0.4735 | LR=0.000401\n",
      "  Ã‰poca  37 | train_loss=0.7640 | val_acc=0.4824 | val_f1m=0.4835 | LR=0.000373\n",
      "  Ã‰poca  38 | train_loss=0.7476 | val_acc=0.4790 | val_f1m=0.4805 | LR=0.000345\n",
      "  Ã‰poca  39 | train_loss=0.7439 | val_acc=0.4802 | val_f1m=0.4776 | LR=0.000319\n",
      "  Ã‰poca  40 | train_loss=0.7100 | val_acc=0.4683 | val_f1m=0.4669 | LR=0.000292\n",
      "  Ã‰poca  41 | train_loss=0.7323 | val_acc=0.4819 | val_f1m=0.4802 | LR=0.000267\n",
      "  Early stopping en Ã©poca 41 (mejor val_f1m=0.4892)\n",
      "[Fold 1/5] Global acc=0.4870\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6192    0.5125    0.5608       441\n",
      "       Right     0.5107    0.5964    0.5502       441\n",
      "  Both Fists     0.3885    0.3515    0.3690       441\n",
      "   Both Feet     0.4433    0.4875    0.4644       441\n",
      "\n",
      "    accuracy                         0.4870      1764\n",
      "   macro avg     0.4904    0.4870    0.4861      1764\n",
      "weighted avg     0.4904    0.4870    0.4861      1764\n",
      "\n",
      "=== RESULTADOS (fold 1) ===\n",
      "Acc: 0.4870 | Macro-F1: 0.4861\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[226  48  97  70]\n",
      " [ 26 263  58  94]\n",
      " [ 73 107 155 106]\n",
      " [ 40  97  89 215]]\n",
      "\n",
      "============  FOLD 2  ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.31it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=6888 | n_test=1764)\n",
      "train counts: {'left': np.int64(1722), 'right': np.int64(1722), 'both_fists': np.int64(1722), 'both_feet': np.int64(1722)} | total = 6888\n",
      "test  counts: {'left': np.int64(441), 'right': np.int64(441), 'both_fists': np.int64(441), 'both_feet': np.int64(441)} | total = 1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3581 | val_acc=0.4286 | val_f1m=0.4178 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2361 | val_acc=0.4864 | val_f1m=0.4735 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.2014 | val_acc=0.5249 | val_f1m=0.5194 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1905 | val_acc=0.5283 | val_f1m=0.5318 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1873 | val_acc=0.5340 | val_f1m=0.5350 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1505 | val_acc=0.5368 | val_f1m=0.5404 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1486 | val_acc=0.5459 | val_f1m=0.5367 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1518 | val_acc=0.5193 | val_f1m=0.4985 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1339 | val_acc=0.5329 | val_f1m=0.5064 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.1026 | val_acc=0.5482 | val_f1m=0.5315 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.1050 | val_acc=0.5465 | val_f1m=0.5389 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0913 | val_acc=0.5527 | val_f1m=0.5528 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0917 | val_acc=0.5527 | val_f1m=0.5463 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0811 | val_acc=0.5255 | val_f1m=0.5248 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0708 | val_acc=0.5493 | val_f1m=0.5397 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0769 | val_acc=0.5493 | val_f1m=0.5420 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0639 | val_acc=0.5544 | val_f1m=0.5530 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0520 | val_acc=0.5283 | val_f1m=0.5117 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=1.0428 | val_acc=0.5488 | val_f1m=0.5465 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0490 | val_acc=0.5459 | val_f1m=0.5383 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=1.0393 | val_acc=0.5465 | val_f1m=0.5392 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=1.0194 | val_acc=0.5454 | val_f1m=0.5431 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=1.0164 | val_acc=0.5368 | val_f1m=0.5393 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9880 | val_acc=0.5624 | val_f1m=0.5643 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9817 | val_acc=0.5408 | val_f1m=0.5342 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9805 | val_acc=0.5618 | val_f1m=0.5633 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9514 | val_acc=0.5510 | val_f1m=0.5481 | LR=0.000655\n",
      "  Ã‰poca  28 | train_loss=0.9288 | val_acc=0.5544 | val_f1m=0.5512 | LR=0.000627\n",
      "  Ã‰poca  29 | train_loss=0.9339 | val_acc=0.5493 | val_f1m=0.5421 | LR=0.000599\n",
      "  Ã‰poca  30 | train_loss=0.9187 | val_acc=0.5368 | val_f1m=0.5329 | LR=0.000571\n",
      "  Ã‰poca  31 | train_loss=0.9150 | val_acc=0.5533 | val_f1m=0.5519 | LR=0.000543\n",
      "  Ã‰poca  32 | train_loss=0.9048 | val_acc=0.5351 | val_f1m=0.5288 | LR=0.000514\n",
      "  Ã‰poca  33 | train_loss=0.8710 | val_acc=0.5312 | val_f1m=0.5225 | LR=0.000486\n",
      "  Ã‰poca  34 | train_loss=0.8673 | val_acc=0.5368 | val_f1m=0.5343 | LR=0.000457\n",
      "  Early stopping en Ã©poca 34 (mejor val_f1m=0.5643)\n",
      "[Fold 2/5] Global acc=0.5703\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6553    0.6077    0.6306       441\n",
      "       Right     0.6372    0.6054    0.6209       441\n",
      "  Both Fists     0.5096    0.4807    0.4947       441\n",
      "   Both Feet     0.4981    0.5873    0.5390       441\n",
      "\n",
      "    accuracy                         0.5703      1764\n",
      "   macro avg     0.5750    0.5703    0.5713      1764\n",
      "weighted avg     0.5750    0.5703    0.5713      1764\n",
      "\n",
      "=== RESULTADOS (fold 2) ===\n",
      "Acc: 0.5703 | Macro-F1: 0.5713\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[268  29  77  67]\n",
      " [ 26 267  56  92]\n",
      " [ 64  63 212 102]\n",
      " [ 51  60  71 259]]\n",
      "\n",
      "============  FOLD 3  ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.30it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=6888 | n_test=1764)\n",
      "train counts: {'left': np.int64(1722), 'right': np.int64(1722), 'both_fists': np.int64(1722), 'both_feet': np.int64(1722)} | total = 6888\n",
      "test  counts: {'left': np.int64(441), 'right': np.int64(441), 'both_fists': np.int64(441), 'both_feet': np.int64(441)} | total = 1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3863 | val_acc=0.3254 | val_f1m=0.2574 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2550 | val_acc=0.4677 | val_f1m=0.4658 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1853 | val_acc=0.4773 | val_f1m=0.4771 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1739 | val_acc=0.4575 | val_f1m=0.4612 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1491 | val_acc=0.4864 | val_f1m=0.4779 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1223 | val_acc=0.4881 | val_f1m=0.4881 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1163 | val_acc=0.4683 | val_f1m=0.4501 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1067 | val_acc=0.4688 | val_f1m=0.4621 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.0928 | val_acc=0.4813 | val_f1m=0.4665 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.0775 | val_acc=0.4813 | val_f1m=0.4804 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0863 | val_acc=0.4717 | val_f1m=0.4595 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0623 | val_acc=0.4586 | val_f1m=0.4511 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0616 | val_acc=0.4745 | val_f1m=0.4736 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0496 | val_acc=0.4739 | val_f1m=0.4797 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0341 | val_acc=0.4943 | val_f1m=0.4810 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0296 | val_acc=0.4938 | val_f1m=0.4927 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0066 | val_acc=0.4813 | val_f1m=0.4837 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0041 | val_acc=0.4734 | val_f1m=0.4731 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=1.0041 | val_acc=0.4813 | val_f1m=0.4777 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0015 | val_acc=0.4802 | val_f1m=0.4805 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=0.9813 | val_acc=0.4626 | val_f1m=0.4636 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=0.9738 | val_acc=0.4813 | val_f1m=0.4814 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9753 | val_acc=0.4649 | val_f1m=0.4669 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9465 | val_acc=0.4836 | val_f1m=0.4857 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9373 | val_acc=0.4773 | val_f1m=0.4714 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9199 | val_acc=0.4626 | val_f1m=0.4670 | LR=0.000681\n",
      "  Early stopping en Ã©poca 26 (mejor val_f1m=0.4927)\n",
      "[Fold 3/5] Global acc=0.4881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5195    0.6054    0.5592       441\n",
      "       Right     0.5933    0.4830    0.5325       441\n",
      "  Both Fists     0.4202    0.4240    0.4221       441\n",
      "   Both Feet     0.4350    0.4399    0.4374       441\n",
      "\n",
      "    accuracy                         0.4881      1764\n",
      "   macro avg     0.4920    0.4881    0.4878      1764\n",
      "weighted avg     0.4920    0.4881    0.4878      1764\n",
      "\n",
      "=== RESULTADOS (fold 3) ===\n",
      "Acc: 0.4881 | Macro-F1: 0.4878\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[267  31  74  69]\n",
      " [ 44 213  92  92]\n",
      " [116  47 187  91]\n",
      " [ 87  68  92 194]]\n",
      "\n",
      "============  FOLD 4  ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:10<00:00,  8.27it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=6972 | n_test=1680)\n",
      "train counts: {'left': np.int64(1743), 'right': np.int64(1743), 'both_fists': np.int64(1743), 'both_feet': np.int64(1743)} | total = 6972\n",
      "test  counts: {'left': np.int64(420), 'right': np.int64(420), 'both_fists': np.int64(420), 'both_feet': np.int64(420)} | total = 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3840 | val_acc=0.4030 | val_f1m=0.4010 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2280 | val_acc=0.4929 | val_f1m=0.4864 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1767 | val_acc=0.4726 | val_f1m=0.4500 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1629 | val_acc=0.4994 | val_f1m=0.4880 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1573 | val_acc=0.5018 | val_f1m=0.4922 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1326 | val_acc=0.5018 | val_f1m=0.4944 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1316 | val_acc=0.5071 | val_f1m=0.5104 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1127 | val_acc=0.5131 | val_f1m=0.5082 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1066 | val_acc=0.5119 | val_f1m=0.5065 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.0880 | val_acc=0.4940 | val_f1m=0.4961 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0813 | val_acc=0.5095 | val_f1m=0.5083 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0809 | val_acc=0.5244 | val_f1m=0.5223 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0706 | val_acc=0.5131 | val_f1m=0.5117 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0620 | val_acc=0.5054 | val_f1m=0.5095 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0454 | val_acc=0.5042 | val_f1m=0.5002 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0538 | val_acc=0.5107 | val_f1m=0.5099 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0214 | val_acc=0.5054 | val_f1m=0.5006 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0180 | val_acc=0.5173 | val_f1m=0.5168 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=0.9941 | val_acc=0.5280 | val_f1m=0.5276 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0123 | val_acc=0.5054 | val_f1m=0.5069 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=0.9835 | val_acc=0.5208 | val_f1m=0.5200 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=0.9862 | val_acc=0.5042 | val_f1m=0.4987 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9668 | val_acc=0.4970 | val_f1m=0.4847 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9582 | val_acc=0.5060 | val_f1m=0.5027 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9449 | val_acc=0.4976 | val_f1m=0.4905 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9241 | val_acc=0.5018 | val_f1m=0.5015 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9219 | val_acc=0.4946 | val_f1m=0.4966 | LR=0.000655\n",
      "  Ã‰poca  28 | train_loss=0.9141 | val_acc=0.4964 | val_f1m=0.4980 | LR=0.000627\n",
      "  Ã‰poca  29 | train_loss=0.9025 | val_acc=0.5077 | val_f1m=0.5042 | LR=0.000599\n",
      "  Early stopping en Ã©poca 29 (mejor val_f1m=0.5276)\n",
      "[Fold 4/5] Global acc=0.5262\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6475    0.5905    0.6177       420\n",
      "       Right     0.5635    0.5810    0.5721       420\n",
      "  Both Fists     0.4540    0.5524    0.4984       420\n",
      "   Both Feet     0.4533    0.3810    0.4140       420\n",
      "\n",
      "    accuracy                         0.5262      1680\n",
      "   macro avg     0.5296    0.5262    0.5255      1680\n",
      "weighted avg     0.5296    0.5262    0.5255      1680\n",
      "\n",
      "=== RESULTADOS (fold 4) ===\n",
      "Acc: 0.5262 | Macro-F1: 0.5255\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[248  22  93  57]\n",
      " [ 20 244  86  70]\n",
      " [ 56  66 232  66]\n",
      " [ 59 101 100 160]]\n",
      "\n",
      "============  FOLD 5  ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:09<00:00,  8.40it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=6972 | n_test=1680)\n",
      "train counts: {'left': np.int64(1743), 'right': np.int64(1743), 'both_fists': np.int64(1743), 'both_feet': np.int64(1743)} | total = 6972\n",
      "test  counts: {'left': np.int64(420), 'right': np.int64(420), 'both_fists': np.int64(420), 'both_feet': np.int64(420)} | total = 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3911 | val_acc=0.3518 | val_f1m=0.3082 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2738 | val_acc=0.5071 | val_f1m=0.5038 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1954 | val_acc=0.5208 | val_f1m=0.5012 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1863 | val_acc=0.5393 | val_f1m=0.5232 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1657 | val_acc=0.5232 | val_f1m=0.5089 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1465 | val_acc=0.5399 | val_f1m=0.5326 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1450 | val_acc=0.5054 | val_f1m=0.4860 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1193 | val_acc=0.5214 | val_f1m=0.5132 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1186 | val_acc=0.5488 | val_f1m=0.5431 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.1034 | val_acc=0.5333 | val_f1m=0.5356 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0964 | val_acc=0.5339 | val_f1m=0.5147 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0925 | val_acc=0.5423 | val_f1m=0.5327 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0821 | val_acc=0.5524 | val_f1m=0.5515 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0721 | val_acc=0.5780 | val_f1m=0.5777 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0550 | val_acc=0.5494 | val_f1m=0.5491 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0607 | val_acc=0.5804 | val_f1m=0.5790 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0381 | val_acc=0.5810 | val_f1m=0.5795 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0459 | val_acc=0.5702 | val_f1m=0.5687 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=1.0318 | val_acc=0.5548 | val_f1m=0.5565 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0249 | val_acc=0.5435 | val_f1m=0.5442 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=1.0145 | val_acc=0.5500 | val_f1m=0.5521 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=1.0046 | val_acc=0.5357 | val_f1m=0.5339 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9861 | val_acc=0.5500 | val_f1m=0.5419 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9796 | val_acc=0.5470 | val_f1m=0.5448 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9614 | val_acc=0.5542 | val_f1m=0.5438 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9527 | val_acc=0.5673 | val_f1m=0.5650 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9408 | val_acc=0.5690 | val_f1m=0.5646 | LR=0.000655\n",
      "  Early stopping en Ã©poca 27 (mejor val_f1m=0.5795)\n",
      "[Fold 5/5] Global acc=0.5780\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6332    0.6000    0.6161       420\n",
      "       Right     0.5937    0.6714    0.6302       420\n",
      "  Both Fists     0.5432    0.4643    0.5006       420\n",
      "   Both Feet     0.5402    0.5762    0.5576       420\n",
      "\n",
      "    accuracy                         0.5780      1680\n",
      "   macro avg     0.5776    0.5780    0.5761      1680\n",
      "weighted avg     0.5776    0.5780    0.5761      1680\n",
      "\n",
      "=== RESULTADOS (fold 5) ===\n",
      "Acc: 0.5780 | Macro-F1: 0.5761\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[252  37  68  63]\n",
      " [ 21 282  41  76]\n",
      " [ 88  70 195  67]\n",
      " [ 37  86  55 242]]\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES (Transformer)\n",
      "============================================================\n",
      "Acc folds: ['0.4870', '0.5703', '0.4881', '0.5262', '0.5780']\n",
      "F1m folds: ['0.4861', '0.5713', '0.4878', '0.5255', '0.5761']\n",
      "Acc mean: 0.5299 | std: 0.0389\n",
      "F1m mean: 0.5294 | std: 0.0389\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN + Transformer (PyTorch) para PhysioNet/BCI2000 MI â€” IMAGINERÃA (4 clases) con 8 canales.\n",
    "# Incluye: class-weights + label smoothing, warmup+cosine+early stopping, sampler balanceado,\n",
    "# augmentations ligeras, TTA estilo EEGNet y reproducibilidad fuerte (seed=42).\n",
    "# Ventana: 6 s (TMIN=-1.0, TMAX=5.0). Z-score por Ã©poca activable con ZSCORE_PER_EPOCH.\n",
    "# Imprime mÃ©tricas por fold (classification_report) y un runner de 5 folds tipo EEGNet.\n",
    "\n",
    "# =========================\n",
    "# Reproducibilidad (poner ANTES de importar torch)\n",
    "# =========================\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # determinismo cuBLAS\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD (seed + determinismo)\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # determinismo cuDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # evitar TF32 (puede romper determinismo)\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    # reforzar determinismo\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edita a tu gusto)\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'                     # .../S###/S###R##.edf\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "FOLD = 5\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "RESAMPLE_HZ = None          # None: mantiene 160 Hz original\n",
    "DO_NOTCH = True             # ganador\n",
    "DO_BANDPASS = False         # ganador\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False              # ganador\n",
    "\n",
    "# NormalizaciÃ³n\n",
    "ZSCORE_PER_EPOCH = False     # <- activa/desactiva z-score por Ã©poca (como EEGNet)\n",
    "\n",
    "# HiperparÃ¡metros del modelo\n",
    "D_MODEL = 128              # (si quieres probar mÃ¡s capacidad: 160/192)\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2               # sube a 0.3 si ves sobreajuste\n",
    "\n",
    "# Ventana temporal (seg) â€” igual a EEGNet (6 s)\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# Sliding windows / TTA en evaluaciÃ³n\n",
    "SW_MODE = 'tta'   # 'none' | 'subwin' | 'tta'\n",
    "SW_ENABLE = True  # si quieres apagar todo, pon False\n",
    "\n",
    "# Para TTA de desplazamientos cortos Â±25 ms (EEGNet)\n",
    "TTA_SHIFTS_S = [-0.025, -0.0125, 0.0, 0.0125, 0.025]\n",
    "\n",
    "# (solo si usas 'subwin'; no se usa en 'tta' EEGNet)\n",
    "SW_LEN   = 2.0\n",
    "SW_STRIDE = 0.5\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "# Runs IMAGINERÃA\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}    # T1=left, T2=right\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}   # T1=both_fists, T2=both_feet\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Device: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        pattern = str(subj_dir / f\"{subject_id}R{r:02d}.edf\")\n",
    "        edfs.extend(glob(pattern))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        raise FileNotFoundError(f\"No imagery EDF files for {subject_id} under {DATA_RAW}\")\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "        # SelecciÃ³n de 8 canales\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        # --- PREPROC OPCIONAL ---\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        # Resample\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        # Eventos (T0/T1/T2)\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        # Mantener solo T1/T2\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()  # (n_epochs, 8, T)\n",
    "\n",
    "        # ---- Z-SCORE POR Ã‰POCA (opcional, como EEGNet) ----\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)              # (N,8,1)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps         # (N,8,1)\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        # Construir y segÃºn RUN\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}  # id -> 'T1'/'T2'\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)  # left/right\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)  # both_fists/feet\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        keep_mask = y_run >= 0\n",
    "        X = X[keep_mask]\n",
    "        y = y_run[keep_mask]\n",
    "\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, 8, 1)), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    if len(set([round(s) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Inconsistent sampling rates: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            train_sub = list(item.get('train', []))\n",
    "            test_sub  = list(item.get('test', []))\n",
    "            return train_sub, test_sub\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def class_count_summary(y, name):\n",
    "    bc = np.bincount(y, minlength=4)\n",
    "    print(f\"{name} counts:\", dict(zip(CLASS_NAMES, bc)), \"| total =\", bc.sum())\n",
    "\n",
    "# =========================\n",
    "# MODELO: CNN + Transformer\n",
    "# =========================\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            nn.BatchNorm1d(32), nn.ELU(),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "        self.pos_encoding = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)  # (B,1,D)\n",
    "        z = torch.cat([cls_tok, z], dim=1)    # (B, 1+L, D)\n",
    "        z = self.encoder(z)                   # (B, 1+L, D)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# ENTRENAMIENTO / EVAL\n",
    "# =========================\n",
    "def standardize_per_channel(train_X, test_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X  = test_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        test_X[:, c, :]  = (test_X[:, c, :] - mu) / sd\n",
    "    return train_X, test_X\n",
    "\n",
    "# --- Augmentations ligeras ---\n",
    "def augment_batch(xb, p_jitter=0.25, p_noise=0.25, p_chdrop=0.15,\n",
    "                  max_jitter_frac=0.02, noise_std=0.02):\n",
    "    \"\"\"\n",
    "    xb: torch.Tensor (B,C,T) (se asume ya normalizado)\n",
    "    - jitter temporal (roll)\n",
    "    - ruido gaussiano\n",
    "    - channel dropout (apagar 1 canal aleatorio)\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop:\n",
    "        k = 1\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    \"\"\"\n",
    "    Promedia logits sobre sub-ventanas de longitud sw_len (seg).\n",
    "    Entrada:  X (N,C,T) estandarizado\n",
    "    Salida:   (N,4)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1]))\n",
    "    st = max(1, st)\n",
    "\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]  # (C,T)\n",
    "            acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]  # (4,)\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)  # (N,4)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    \"\"\"\n",
    "    Test-Time Augmentation (EEGNet-like): 5 desplazamientos cortos Â±25ms manteniendo longitud T.\n",
    "    Entrada:  X (N,C,T) estandarizado\n",
    "    Salida:   (N,4)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    T = X.shape[-1]\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]  # (C,T)\n",
    "            acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]  # (4,)\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)  # (N,4)\n",
    "\n",
    "def load_fold_subject_ids_and_counts(fold:int):\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    return train_sub, test_sub\n",
    "\n",
    "def train_one_fold(fold:int, resample_hz:int, do_notch:bool, do_bandpass:bool,\n",
    "                   bp_lo:float, bp_hi:float, epochs:int, batch_size:int, lr:float,\n",
    "                   device:str=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "\n",
    "    # --- sujetos fold ---\n",
    "    train_sub, test_sub = load_fold_subject_ids_and_counts(fold)\n",
    "\n",
    "    # --- carga datos ---\n",
    "    X_tr_list, y_tr_list, X_te_list, y_te_list = [], [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_sub, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    if len(X_tr_list) == 0 or len(X_te_list) == 0:\n",
    "        raise RuntimeError(\"Datos insuficientes tras carga de sujetos.\")\n",
    "\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "\n",
    "    # --- diagnÃ³sticos de desbalance ---\n",
    "    # (y cabecera al estilo EEGNet con n_train / n_test)\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_test={len(y_te)})\")\n",
    "    print(\"train counts:\", dict(zip(CLASS_NAMES, np.bincount(y_tr, minlength=4))), \"| total =\", len(y_tr))\n",
    "    print(\"test  counts:\", dict(zip(CLASS_NAMES, np.bincount(y_te, minlength=4))), \"| total =\", len(y_te))\n",
    "\n",
    "    # --- NormalizaciÃ³n ---\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        # Ya se normalizÃ³ por Ã©poca dentro de load_subject_epochs â†’ NO hacer z-score global\n",
    "        X_tr_std, X_te_std = X_tr, X_te\n",
    "    else:\n",
    "        # Sin z-score por Ã©poca â†’ aplicar z-score global por canal usando SOLO train\n",
    "        X_tr_std, X_te_std = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # --- DataLoaders (sampler balanceado + reproducible) ---\n",
    "    train_ds = TensorDataset(torch.tensor(X_tr_std), torch.tensor(y_tr).long())\n",
    "    class_counts = np.bincount(y_tr, minlength=4)\n",
    "    class_weights_vec = class_counts.sum() / (4.0 * np.maximum(class_counts, 1))\n",
    "    sample_weights = class_weights_vec[train_ds.tensors[1].numpy()]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.tensor(sample_weights, dtype=torch.float32),\n",
    "        num_samples=len(train_ds), replacement=True,\n",
    "        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "    )\n",
    "    tr_ld = DataLoader(train_ds, batch_size=batch_size, sampler=sampler,\n",
    "                       drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    te_ld = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_te_std), torch.tensor(y_te).long()),\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    # --- Modelo ---\n",
    "    model = EEGCNNTransformer(\n",
    "        n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS, n_layers=N_LAYERS, p_drop=P_DROP\n",
    "    ).to(device)\n",
    "\n",
    "    # --- Optimizador ---\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    # (1) Class-weights + label smoothing\n",
    "    class_weights = torch.tensor(class_weights_vec, dtype=torch.float32, device=device)\n",
    "    crit = torch.nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "\n",
    "    # (2) Warmup + Cosine LR + Early stopping por macro-F1\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = epochs\n",
    "    warmup_epochs = max(1, min(5, epochs//10))\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    best_f1, best_state, patience, wait = 0.0, None, 10, 0\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen = 0.0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            # augs en GPU (se asume input ya normalizado)\n",
    "            xb = xb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * len(yb); n_seen += len(yb)\n",
    "        tr_loss /= max(1, n_seen)\n",
    "\n",
    "        # --- Eval en test set (mismo patrÃ³n que tu script actual) ---\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        # Log estilo EEGNet (usa acc/f1m del split de test como \"val_*\" porque no tenemos val separado)\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # cargar el mejor\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # --- reporte final con TTA/subwin/none ---\n",
    "    model.eval()\n",
    "    sfreq_used = RESAMPLE_HZ if RESAMPLE_HZ is not None else int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "\n",
    "    elif SW_MODE == 'subwin':\n",
    "        logits = subwindow_logits(model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)  # (N,4)\n",
    "        preds = logits.argmax(axis=1)\n",
    "        gts = y_te\n",
    "\n",
    "    elif SW_MODE == 'tta':\n",
    "        logits = time_shift_tta_logits(model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)  # (N,4)\n",
    "        preds = logits.argmax(axis=1)\n",
    "        gts = y_te\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
    "\n",
    "    # ---- Salida estilo EEGNet ----\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\")\n",
    "    print(\"\\n\" + classification_report(gts, preds, target_names=[\n",
    "        'Left','Right','Both Fists','Both Feet'\n",
    "    ], digits=4))\n",
    "\n",
    "    print(f\"=== RESULTADOS (fold {fold}) ===\")\n",
    "    print(f\"Acc: {acc:.4f} | Macro-F1: {f1m:.4f}\")\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "\n",
    "    return acc, f1m, cm, model\n",
    "\n",
    "# =========================\n",
    "# Runner multi-fold con resumen (igual estilo EEGNet)\n",
    "# =========================\n",
    "def run_all_folds(n_folds=5):\n",
    "    accs, f1s = [], []\n",
    "    for f in range(1, n_folds+1):\n",
    "        print(\"\\n\" + \"=\"*12 + f\"  FOLD {f}  \" + \"=\"*12)\n",
    "        acc, f1m, cm, _ = train_one_fold(\n",
    "            fold=f,\n",
    "            resample_hz=RESAMPLE_HZ,\n",
    "            do_notch=DO_NOTCH,\n",
    "            do_bandpass=DO_BANDPASS,\n",
    "            bp_lo=BP_LO,\n",
    "            bp_hi=BP_HI,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            lr=LR,\n",
    "        )\n",
    "        accs.append(acc); f1s.append(f1m)\n",
    "    if accs:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RESULTADOS FINALES (Transformer)\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Acc folds:\", [f\"{a:.4f}\" for a in accs])\n",
    "        print(\"F1m folds:\", [f\"{a:.4f}\" for a in f1s])\n",
    "        print(f\"Acc mean: {np.mean(accs):.4f} | std: {np.std(accs):.4f}\")\n",
    "        print(f\"F1m mean: {np.mean(f1s):.4f} | std: {np.std(f1s):.4f}\")\n",
    "\n",
    "# =========================\n",
    "# EJECUCIÃ“N\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # OpciÃ³n A: correr todos los folds 1..5 con reporte por fold y resumen\n",
    "    run_all_folds(n_folds=5)\n",
    "\n",
    "    # OpciÃ³n B: correr un solo fold\n",
    "    # acc, f1m, cm, model = train_one_fold(\n",
    "    #     fold=FOLD,\n",
    "    #     resample_hz=RESAMPLE_HZ,\n",
    "    #     do_notch=DO_NOTCH,\n",
    "    #     do_bandpass=DO_BANDPASS,\n",
    "    #     bp_lo=BP_LO,\n",
    "    #     bp_hi=BP_HI,\n",
    "    #     epochs=EPOCHS,\n",
    "    #     batch_size=BATCH_SIZE,\n",
    "    #     lr=LR,\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee0a3832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.001 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.46it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3768 | train_acc=0.4282 | val_acc=0.4020 | val_f1m=0.3849 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2056 | train_acc=0.5064 | val_acc=0.4478 | val_f1m=0.4141 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1660 | train_acc=0.5342 | val_acc=0.4744 | val_f1m=0.4706 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1217 | train_acc=0.5012 | val_acc=0.4597 | val_f1m=0.4452 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1386 | train_acc=0.5192 | val_acc=0.4689 | val_f1m=0.4490 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1240 | train_acc=0.5730 | val_acc=0.4890 | val_f1m=0.4799 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1121 | train_acc=0.5818 | val_acc=0.4844 | val_f1m=0.4819 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.0740 | train_acc=0.5945 | val_acc=0.5064 | val_f1m=0.5076 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.0799 | train_acc=0.5849 | val_acc=0.4808 | val_f1m=0.4749 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.0823 | train_acc=0.5952 | val_acc=0.4918 | val_f1m=0.4852 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0341 | train_acc=0.6159 | val_acc=0.5037 | val_f1m=0.5012 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0525 | train_acc=0.5923 | val_acc=0.4597 | val_f1m=0.4559 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0458 | train_acc=0.6002 | val_acc=0.4753 | val_f1m=0.4767 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0398 | train_acc=0.6206 | val_acc=0.4679 | val_f1m=0.4530 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0146 | train_acc=0.6486 | val_acc=0.5073 | val_f1m=0.5031 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0014 | train_acc=0.6446 | val_acc=0.5055 | val_f1m=0.5087 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0000 | train_acc=0.6472 | val_acc=0.4899 | val_f1m=0.4897 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0021 | train_acc=0.6587 | val_acc=0.4945 | val_f1m=0.4936 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=0.9676 | train_acc=0.6582 | val_acc=0.4927 | val_f1m=0.4958 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=0.9902 | train_acc=0.6473 | val_acc=0.4918 | val_f1m=0.4831 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=0.9735 | train_acc=0.6682 | val_acc=0.5055 | val_f1m=0.5077 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=0.9655 | train_acc=0.6900 | val_acc=0.4963 | val_f1m=0.4958 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9633 | train_acc=0.6870 | val_acc=0.4991 | val_f1m=0.5012 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9663 | train_acc=0.6862 | val_acc=0.4780 | val_f1m=0.4801 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9300 | train_acc=0.6993 | val_acc=0.4908 | val_f1m=0.4804 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.8936 | train_acc=0.7295 | val_acc=0.4799 | val_f1m=0.4788 | LR=0.000681\n",
      "  Early stopping en Ã©poca 26 (mejor val_f1m=0.5087)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6180    0.5283    0.5697       441\n",
      "       right     0.5782    0.5283    0.5521       441\n",
      "  both_fists     0.3753    0.3923    0.3836       441\n",
      "   both_feet     0.4226    0.5011    0.4585       441\n",
      "\n",
      "    accuracy                         0.4875      1764\n",
      "   macro avg     0.4985    0.4875    0.4910      1764\n",
      "weighted avg     0.4985    0.4875    0.4910      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[233  29  95  84]\n",
      " [ 26 233  90  92]\n",
      " [ 74  68 173 126]\n",
      " [ 44  73 103 221]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.56it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3762 | train_acc=0.3913 | val_acc=0.3956 | val_f1m=0.3899 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2558 | train_acc=0.4898 | val_acc=0.4579 | val_f1m=0.4376 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.2206 | train_acc=0.4891 | val_acc=0.4652 | val_f1m=0.4489 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1632 | train_acc=0.5219 | val_acc=0.4872 | val_f1m=0.4793 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1626 | train_acc=0.5252 | val_acc=0.4753 | val_f1m=0.4661 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1770 | train_acc=0.5090 | val_acc=0.4615 | val_f1m=0.4608 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1624 | train_acc=0.5235 | val_acc=0.4661 | val_f1m=0.4519 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1202 | train_acc=0.5361 | val_acc=0.5064 | val_f1m=0.5107 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1177 | train_acc=0.5286 | val_acc=0.4679 | val_f1m=0.4461 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.1140 | train_acc=0.5599 | val_acc=0.4771 | val_f1m=0.4579 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0821 | train_acc=0.5754 | val_acc=0.4771 | val_f1m=0.4736 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0928 | train_acc=0.5676 | val_acc=0.4881 | val_f1m=0.4919 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0844 | train_acc=0.5707 | val_acc=0.4817 | val_f1m=0.4810 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0808 | train_acc=0.5863 | val_acc=0.4789 | val_f1m=0.4699 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0505 | train_acc=0.6054 | val_acc=0.4853 | val_f1m=0.4837 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0576 | train_acc=0.6004 | val_acc=0.4835 | val_f1m=0.4888 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0476 | train_acc=0.6201 | val_acc=0.5000 | val_f1m=0.5039 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0342 | train_acc=0.6208 | val_acc=0.4881 | val_f1m=0.4843 | LR=0.000868\n",
      "  Early stopping en Ã©poca 18 (mejor val_f1m=0.5107)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5565    0.6259    0.5891       441\n",
      "       right     0.7323    0.4467    0.5549       441\n",
      "  both_fists     0.4478    0.5442    0.4913       441\n",
      "   both_feet     0.4752    0.4989    0.4867       441\n",
      "\n",
      "    accuracy                         0.5289      1764\n",
      "   macro avg     0.5529    0.5289    0.5305      1764\n",
      "weighted avg     0.5529    0.5289    0.5305      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[276   8 107  50]\n",
      " [ 46 197  88 110]\n",
      " [ 90  28 240  83]\n",
      " [ 84  36 101 220]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.56it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3924 | train_acc=0.3357 | val_acc=0.2921 | val_f1m=0.2554 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2548 | train_acc=0.4947 | val_acc=0.4826 | val_f1m=0.4500 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1909 | train_acc=0.5188 | val_acc=0.5092 | val_f1m=0.4922 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1453 | train_acc=0.5504 | val_acc=0.5302 | val_f1m=0.5215 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1365 | train_acc=0.5488 | val_acc=0.5385 | val_f1m=0.5284 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1531 | train_acc=0.5324 | val_acc=0.5174 | val_f1m=0.5181 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1202 | train_acc=0.5450 | val_acc=0.5128 | val_f1m=0.4961 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.0959 | train_acc=0.5666 | val_acc=0.5421 | val_f1m=0.5465 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.0916 | train_acc=0.5663 | val_acc=0.5266 | val_f1m=0.5108 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.0746 | train_acc=0.5393 | val_acc=0.5238 | val_f1m=0.4958 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0689 | train_acc=0.5683 | val_acc=0.5064 | val_f1m=0.4865 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0683 | train_acc=0.5901 | val_acc=0.5430 | val_f1m=0.5394 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0616 | train_acc=0.5889 | val_acc=0.5037 | val_f1m=0.5009 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0505 | train_acc=0.6051 | val_acc=0.5311 | val_f1m=0.5190 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0425 | train_acc=0.6059 | val_acc=0.5449 | val_f1m=0.5474 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0361 | train_acc=0.6235 | val_acc=0.5339 | val_f1m=0.5319 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0008 | train_acc=0.6379 | val_acc=0.5522 | val_f1m=0.5535 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0062 | train_acc=0.6284 | val_acc=0.5275 | val_f1m=0.5223 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=0.9708 | train_acc=0.6465 | val_acc=0.5275 | val_f1m=0.5310 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0003 | train_acc=0.6639 | val_acc=0.5366 | val_f1m=0.5353 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=0.9543 | train_acc=0.6712 | val_acc=0.5375 | val_f1m=0.5372 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=0.9559 | train_acc=0.6789 | val_acc=0.5357 | val_f1m=0.5405 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9491 | train_acc=0.6931 | val_acc=0.5476 | val_f1m=0.5412 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9246 | train_acc=0.6884 | val_acc=0.5476 | val_f1m=0.5463 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9287 | train_acc=0.7145 | val_acc=0.5403 | val_f1m=0.5413 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9143 | train_acc=0.7143 | val_acc=0.5440 | val_f1m=0.5411 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9023 | train_acc=0.7207 | val_acc=0.5485 | val_f1m=0.5437 | LR=0.000655\n",
      "  Early stopping en Ã©poca 27 (mejor val_f1m=0.5535)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4824\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6183    0.4739    0.5366       441\n",
      "       right     0.6171    0.4422    0.5152       441\n",
      "  both_fists     0.4198    0.4512    0.4350       441\n",
      "   both_feet     0.3899    0.5624    0.4605       441\n",
      "\n",
      "    accuracy                         0.4824      1764\n",
      "   macro avg     0.5113    0.4824    0.4868      1764\n",
      "weighted avg     0.5113    0.4824    0.4868      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[209  30  96 106]\n",
      " [ 16 195  87 143]\n",
      " [ 68  35 199 139]\n",
      " [ 45  56  92 248]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:10<00:00,  8.19it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=5880 | n_val=1092 | n_test=1680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3715 | train_acc=0.4145 | val_acc=0.3810 | val_f1m=0.3803 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2499 | train_acc=0.4844 | val_acc=0.4725 | val_f1m=0.4507 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1861 | train_acc=0.5214 | val_acc=0.4963 | val_f1m=0.4885 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1565 | train_acc=0.5367 | val_acc=0.4927 | val_f1m=0.4787 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1603 | train_acc=0.5335 | val_acc=0.4789 | val_f1m=0.4707 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1359 | train_acc=0.5440 | val_acc=0.4835 | val_f1m=0.4717 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1281 | train_acc=0.5253 | val_acc=0.4753 | val_f1m=0.4447 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1045 | train_acc=0.5529 | val_acc=0.5082 | val_f1m=0.5061 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1021 | train_acc=0.5536 | val_acc=0.4927 | val_f1m=0.4917 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.1016 | train_acc=0.5883 | val_acc=0.5055 | val_f1m=0.4993 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0808 | train_acc=0.5939 | val_acc=0.5137 | val_f1m=0.5084 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.0757 | train_acc=0.5929 | val_acc=0.4853 | val_f1m=0.4858 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0660 | train_acc=0.6034 | val_acc=0.5119 | val_f1m=0.5022 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0675 | train_acc=0.5838 | val_acc=0.5092 | val_f1m=0.4772 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0413 | train_acc=0.6020 | val_acc=0.4872 | val_f1m=0.4909 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0286 | train_acc=0.6126 | val_acc=0.5110 | val_f1m=0.5066 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0293 | train_acc=0.6187 | val_acc=0.5037 | val_f1m=0.5039 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0144 | train_acc=0.6417 | val_acc=0.4954 | val_f1m=0.4852 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=1.0183 | train_acc=0.6454 | val_acc=0.4689 | val_f1m=0.4664 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0047 | train_acc=0.6505 | val_acc=0.5082 | val_f1m=0.5080 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=0.9914 | train_acc=0.6571 | val_acc=0.5165 | val_f1m=0.5149 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=0.9873 | train_acc=0.6726 | val_acc=0.5275 | val_f1m=0.5295 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9731 | train_acc=0.6849 | val_acc=0.5119 | val_f1m=0.5059 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9647 | train_acc=0.6920 | val_acc=0.5137 | val_f1m=0.5143 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9516 | train_acc=0.6934 | val_acc=0.5055 | val_f1m=0.5085 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9365 | train_acc=0.6891 | val_acc=0.4963 | val_f1m=0.4861 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9276 | train_acc=0.6971 | val_acc=0.4973 | val_f1m=0.4876 | LR=0.000655\n",
      "  Ã‰poca  28 | train_loss=0.8963 | train_acc=0.7296 | val_acc=0.5046 | val_f1m=0.5020 | LR=0.000627\n",
      "  Ã‰poca  29 | train_loss=0.8909 | train_acc=0.7473 | val_acc=0.5137 | val_f1m=0.5145 | LR=0.000599\n",
      "  Ã‰poca  30 | train_loss=0.8876 | train_acc=0.7401 | val_acc=0.5147 | val_f1m=0.5145 | LR=0.000571\n",
      "  Ã‰poca  31 | train_loss=0.8580 | train_acc=0.7563 | val_acc=0.5064 | val_f1m=0.4993 | LR=0.000543\n",
      "  Ã‰poca  32 | train_loss=0.8445 | train_acc=0.7498 | val_acc=0.5082 | val_f1m=0.4998 | LR=0.000514\n",
      "  Early stopping en Ã©poca 32 (mejor val_f1m=0.5295)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.5202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6044    0.6548    0.6286       420\n",
      "       right     0.6250    0.4762    0.5405       420\n",
      "  both_fists     0.4342    0.5024    0.4658       420\n",
      "   both_feet     0.4487    0.4476    0.4482       420\n",
      "\n",
      "    accuracy                         0.5202      1680\n",
      "   macro avg     0.5281    0.5202    0.5208      1680\n",
      "weighted avg     0.5281    0.5202    0.5208      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[275  17  71  57]\n",
      " [ 33 200  93  94]\n",
      " [ 83  46 211  80]\n",
      " [ 64  57 111 188]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:09<00:00,  8.34it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=5880 | n_val=1092 | n_test=1680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=1.3815 | train_acc=0.3781 | val_acc=0.3608 | val_f1m=0.3231 | LR=0.000400\n",
      "  Ã‰poca   2 | train_loss=1.2467 | train_acc=0.4827 | val_acc=0.4505 | val_f1m=0.4213 | LR=0.000600\n",
      "  Ã‰poca   3 | train_loss=1.1956 | train_acc=0.5114 | val_acc=0.4789 | val_f1m=0.4674 | LR=0.000800\n",
      "  Ã‰poca   4 | train_loss=1.1715 | train_acc=0.4974 | val_acc=0.4496 | val_f1m=0.4342 | LR=0.001000\n",
      "  Ã‰poca   5 | train_loss=1.1565 | train_acc=0.5310 | val_acc=0.4844 | val_f1m=0.4836 | LR=0.001000\n",
      "  Ã‰poca   6 | train_loss=1.1611 | train_acc=0.5333 | val_acc=0.4606 | val_f1m=0.4499 | LR=0.000999\n",
      "  Ã‰poca   7 | train_loss=1.1409 | train_acc=0.5384 | val_acc=0.4881 | val_f1m=0.4735 | LR=0.000997\n",
      "  Ã‰poca   8 | train_loss=1.1086 | train_acc=0.5600 | val_acc=0.4826 | val_f1m=0.4806 | LR=0.000993\n",
      "  Ã‰poca   9 | train_loss=1.1179 | train_acc=0.5463 | val_acc=0.4835 | val_f1m=0.4690 | LR=0.000987\n",
      "  Ã‰poca  10 | train_loss=1.1123 | train_acc=0.5679 | val_acc=0.4982 | val_f1m=0.4865 | LR=0.000980\n",
      "  Ã‰poca  11 | train_loss=1.0857 | train_acc=0.5774 | val_acc=0.4881 | val_f1m=0.4786 | LR=0.000971\n",
      "  Ã‰poca  12 | train_loss=1.1095 | train_acc=0.5626 | val_acc=0.4826 | val_f1m=0.4747 | LR=0.000961\n",
      "  Ã‰poca  13 | train_loss=1.0854 | train_acc=0.5571 | val_acc=0.4698 | val_f1m=0.4499 | LR=0.000949\n",
      "  Ã‰poca  14 | train_loss=1.0884 | train_acc=0.5913 | val_acc=0.5000 | val_f1m=0.4903 | LR=0.000935\n",
      "  Ã‰poca  15 | train_loss=1.0648 | train_acc=0.5923 | val_acc=0.4945 | val_f1m=0.4966 | LR=0.000921\n",
      "  Ã‰poca  16 | train_loss=1.0429 | train_acc=0.5935 | val_acc=0.5000 | val_f1m=0.4991 | LR=0.000905\n",
      "  Ã‰poca  17 | train_loss=1.0575 | train_acc=0.6049 | val_acc=0.4918 | val_f1m=0.4945 | LR=0.000887\n",
      "  Ã‰poca  18 | train_loss=1.0463 | train_acc=0.6202 | val_acc=0.5055 | val_f1m=0.5041 | LR=0.000868\n",
      "  Ã‰poca  19 | train_loss=1.0345 | train_acc=0.6184 | val_acc=0.5037 | val_f1m=0.5005 | LR=0.000848\n",
      "  Ã‰poca  20 | train_loss=1.0347 | train_acc=0.6396 | val_acc=0.4973 | val_f1m=0.4914 | LR=0.000827\n",
      "  Ã‰poca  21 | train_loss=1.0023 | train_acc=0.6526 | val_acc=0.5055 | val_f1m=0.4997 | LR=0.000805\n",
      "  Ã‰poca  22 | train_loss=1.0075 | train_acc=0.6643 | val_acc=0.5119 | val_f1m=0.5117 | LR=0.000782\n",
      "  Ã‰poca  23 | train_loss=0.9969 | train_acc=0.6539 | val_acc=0.4908 | val_f1m=0.4870 | LR=0.000758\n",
      "  Ã‰poca  24 | train_loss=0.9938 | train_acc=0.6514 | val_acc=0.4835 | val_f1m=0.4889 | LR=0.000733\n",
      "  Ã‰poca  25 | train_loss=0.9619 | train_acc=0.6711 | val_acc=0.4963 | val_f1m=0.5005 | LR=0.000708\n",
      "  Ã‰poca  26 | train_loss=0.9594 | train_acc=0.6745 | val_acc=0.4918 | val_f1m=0.4725 | LR=0.000681\n",
      "  Ã‰poca  27 | train_loss=0.9255 | train_acc=0.7070 | val_acc=0.4826 | val_f1m=0.4736 | LR=0.000655\n",
      "  Ã‰poca  28 | train_loss=0.9182 | train_acc=0.7158 | val_acc=0.5046 | val_f1m=0.4977 | LR=0.000627\n",
      "  Ã‰poca  29 | train_loss=0.8960 | train_acc=0.6811 | val_acc=0.4936 | val_f1m=0.4726 | LR=0.000599\n",
      "  Ã‰poca  30 | train_loss=0.9130 | train_acc=0.7355 | val_acc=0.4789 | val_f1m=0.4801 | LR=0.000571\n",
      "  Ã‰poca  31 | train_loss=0.9085 | train_acc=0.7420 | val_acc=0.4780 | val_f1m=0.4676 | LR=0.000543\n",
      "  Ã‰poca  32 | train_loss=0.8654 | train_acc=0.7541 | val_acc=0.4725 | val_f1m=0.4630 | LR=0.000514\n",
      "  Early stopping en Ã©poca 32 (mejor val_f1m=0.5117)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5577\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6401    0.5929    0.6156       420\n",
      "       right     0.6010    0.5738    0.5871       420\n",
      "  both_fists     0.4747    0.4690    0.4719       420\n",
      "   both_feet     0.5263    0.5952    0.5587       420\n",
      "\n",
      "    accuracy                         0.5577      1680\n",
      "   macro avg     0.5605    0.5577    0.5583      1680\n",
      "weighted avg     0.5605    0.5577    0.5583      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[249  26  75  70]\n",
      " [ 21 241  73  85]\n",
      " [ 82  71 197  70]\n",
      " [ 37  63  70 250]]\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds: ['0.4875', '0.5289', '0.4824', '0.5202', '0.5577']\n",
      "Global mean: 0.5154\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN + Transformer (PyTorch) para PhysioNet/BCI2000 MI â€” IMAGINERÃA (4 clases) con 8 canales.\n",
    "# Eval inter-sujeto con Kfold5.json (igual que EEGNet):\n",
    "# - Split por sujetos (train/test) desde JSON.\n",
    "# - Dentro de train: GroupShuffleSplit 85/15 por sujetos para validaciÃ³n.\n",
    "# - Logs por Ã©poca: train_acc, val_acc, val_f1m, LR + Early stopping (val_f1m).\n",
    "# - Reporte por fold: classification_report + confusion_matrix + curva de entrenamiento.\n",
    "# - Al final: resumen con accuracies por fold y media.\n",
    "# Ventana: 6 s (TMIN=-1.0, TMAX=5.0). Z-score por Ã©poca activable con ZSCORE_PER_EPOCH.\n",
    "\n",
    "# =========================\n",
    "# Reproducibilidad (poner ANTES de importar torch)\n",
    "# =========================\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # determinismo cuBLAS\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD (seed + determinismo)\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # determinismo cuDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # evitar TF32\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'                     # .../S###/S###R##.edf\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "# Entrenamiento\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "\n",
    "# Preproc\n",
    "RESAMPLE_HZ = None          # None: 160 Hz original\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "\n",
    "# NormalizaciÃ³n\n",
    "ZSCORE_PER_EPOCH = False     # <- activa/desactiva z-score por Ã©poca (como EEGNet)\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2\n",
    "\n",
    "# Ventana temporal (seg) â€” como EEGNet (6 s)\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA evaluaciÃ³n (estilo EEGNet: 5 shifts Â±25ms)\n",
    "SW_MODE = 'tta'   # 'none' | 'subwin' | 'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.025, -0.0125, 0.0, 0.0125, 0.025]\n",
    "\n",
    "# (solo si usas 'subwin'; no se usa en 'tta')\n",
    "SW_LEN   = 2.0\n",
    "SW_STRIDE = 0.5\n",
    "\n",
    "# Constantes dataset\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "# Runs IMAGINERÃA\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}    # T1=left, T2=right\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}   # T1=both_fists, T2=both_feet\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        pattern = str(subj_dir / f\"{subject_id}R{r:02d}.edf\")\n",
    "        edfs.extend(glob(pattern))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        raise FileNotFoundError(f\"No imagery EDF files for {subject_id} under {DATA_RAW}\")\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "        # SelecciÃ³n de 8 canales\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        # --- PREPROC OPCIONAL ---\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        # Resample\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        # Eventos (T0/T1/T2)\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        # Mantener solo T1/T2\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()  # (n_epochs, 8, T)\n",
    "\n",
    "        # ---- Z-SCORE POR Ã‰POCA (opcional, como EEGNet) ----\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)              # (N,8,1)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps         # (N,8,1)\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        # Construir y segÃºn RUN\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}  # id -> 'T1'/'T2'\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)  # left/right\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)  # both_fists/feet\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        keep_mask = y_run >= 0\n",
    "        X = X[keep_mask]\n",
    "        y = y_run[keep_mask]\n",
    "\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, 8, 1)), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    if len(set([round(s) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Inconsistent sampling rates: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            train_sub = list(item.get('train', []))\n",
    "            test_sub  = list(item.get('test', []))\n",
    "            return train_sub, test_sub\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def standardize_fit(X_train):\n",
    "    \"\"\"Devuelve Î¼/Ïƒ por canal (C,) calculados sobre (N,C,T) de train.\"\"\"\n",
    "    C = X_train.shape[1]\n",
    "    mu = np.zeros(C, dtype=np.float32)\n",
    "    sd = np.ones(C, dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        mu[c] = X_train[:, c, :].mean()\n",
    "        sd_c = X_train[:, c, :].std()\n",
    "        sd[c] = sd_c if sd_c > 1e-6 else 1.0\n",
    "    return mu, sd\n",
    "\n",
    "def standardize_apply(X, mu, sd):\n",
    "    X = X.astype(np.float32)\n",
    "    for c in range(X.shape[1]):\n",
    "        X[:, c, :] = (X[:, c, :] - mu[c]) / sd[c]\n",
    "    return X\n",
    "\n",
    "def plot_training_curves(history, fname):\n",
    "    try:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(history['train_acc'], label='train_acc')\n",
    "        plt.plot(history['val_acc'], label='val_acc')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Training curve'); plt.legend()\n",
    "        plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "        print(f\"â†³ Curva de entrenamiento guardada: {fname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[plot] No se pudo guardar {fname}: {e}\")\n",
    "\n",
    "# =========================\n",
    "# MODELO: CNN + Transformer\n",
    "# =========================\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            nn.BatchNorm1d(32), nn.ELU(),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "        self.pos_encoding = None\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)  # (B,1,D)\n",
    "        z = torch.cat([cls_tok, z], dim=1)    # (B, 1+L, D)\n",
    "        z = self.encoder(z)                   # (B, 1+L, D)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# AUGS + EVAL HELPERS\n",
    "# =========================\n",
    "def augment_batch(xb, p_jitter=0.25, p_noise=0.25, p_chdrop=0.15,\n",
    "                  max_jitter_frac=0.02, noise_std=0.02):\n",
    "    \"\"\"\n",
    "    xb: torch.Tensor (B,C,T) (se asume ya normalizado)\n",
    "    - jitter temporal (roll)\n",
    "    - ruido gaussiano\n",
    "    - channel dropout (apagar 1 canal aleatorio)\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop:\n",
    "        k = 1\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1]))\n",
    "    st = max(1, st)\n",
    "\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]  # (C,T)\n",
    "            acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    \"\"\"EEGNet-like TTA: 5 desplazamientos cortos Â±25ms manteniendo longitud T.\"\"\"\n",
    "    model.eval()\n",
    "    T = X.shape[-1]\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]  # (C,T)\n",
    "            acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# ENTRENAMIENTO / EVAL (un fold)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, resample_hz:int, do_notch:bool, do_bandpass:bool,\n",
    "                   bp_lo:float, bp_hi:float, epochs:int, batch_size:int, lr:float,\n",
    "                   device:str=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "\n",
    "    # --- sujetos fold (del JSON) ---\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # --- carga datos por sujeto (sin limitar muestras) ---\n",
    "    X_tr_list, y_tr_list, X_te_list, y_te_list = [], [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    # tambiÃ©n guardamos el tamaÃ±o por sujeto para construir groups_tr\n",
    "    train_groups_counts = []  # lista de (sid_int, count)\n",
    "\n",
    "    for sid in tqdm(train_sub, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0:\n",
    "            continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "        train_groups_counts.append((subject_id_to_int(sid), len(ys)))\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0:\n",
    "            continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    if len(X_tr_list) == 0 or len(X_te_list) == 0:\n",
    "        raise RuntimeError(\"Datos insuficientes tras carga de sujetos.\")\n",
    "\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "\n",
    "    # --- construir vector groups_tr (id de sujeto por Ã©poca de train) ---\n",
    "    groups_tr = []\n",
    "    for sid_int, cnt in train_groups_counts:\n",
    "        groups_tr.extend([sid_int]*cnt)\n",
    "    groups_tr = np.array(groups_tr[:len(y_tr)], dtype=int)\n",
    "\n",
    "    # --- split de validaciÃ³n por sujetos (85/15) ---\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=RANDOM_STATE)\n",
    "    (tr_idx, va_idx), = gss.split(X_tr, y_tr, groups=groups_tr)\n",
    "    X_tr_tr, y_tr_tr = X_tr[tr_idx], y_tr[tr_idx]\n",
    "    X_tr_va, y_tr_va = X_tr[va_idx], y_tr[va_idx]\n",
    "\n",
    "    n_train, n_val, n_test = len(y_tr_tr), len(y_tr_va), len(y_te)\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={n_train} | n_val={n_val} | n_test={n_test})\")\n",
    "\n",
    "    # --- NormalizaciÃ³n sin leakage ---\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        Xtr_std, Xva_std, Xte_std = X_tr_tr, X_tr_va, X_te\n",
    "    else:\n",
    "        mu, sd = standardize_fit(X_tr_tr)                 # Î¼/Ïƒ SOLO con train_tr\n",
    "        Xtr_std = standardize_apply(X_tr_tr, mu, sd)\n",
    "        Xva_std = standardize_apply(X_tr_va, mu, sd)\n",
    "        Xte_std = standardize_apply(X_te,    mu, sd)\n",
    "\n",
    "    # --- DataLoaders ---\n",
    "    # sampler balanceado sobre y_tr_tr\n",
    "    class_counts = np.bincount(y_tr_tr, minlength=4)\n",
    "    class_weights_vec = class_counts.sum() / (4.0 * np.maximum(class_counts, 1))\n",
    "    sample_weights = class_weights_vec[y_tr_tr]\n",
    "\n",
    "    tr_ds = TensorDataset(torch.tensor(Xtr_std), torch.tensor(y_tr_tr).long())\n",
    "    va_ds = TensorDataset(torch.tensor(Xva_std), torch.tensor(y_tr_va).long())\n",
    "    te_ds = TensorDataset(torch.tensor(Xte_std), torch.tensor(y_te).long())\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.tensor(sample_weights, dtype=torch.float32),\n",
    "        num_samples=len(tr_ds), replacement=True,\n",
    "        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "    )\n",
    "    tr_ld = DataLoader(tr_ds, batch_size=batch_size, sampler=sampler,\n",
    "                       drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # loaders sin augs para evaluar\n",
    "    tr_eval_ld = DataLoader(tr_ds, batch_size=batch_size, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    va_ld      = DataLoader(va_ds, batch_size=batch_size, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld      = DataLoader(te_ds, batch_size=batch_size, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # --- Modelo ---\n",
    "    model = EEGCNNTransformer(\n",
    "        n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS, n_layers=N_LAYERS, p_drop=P_DROP\n",
    "    ).to(device)\n",
    "\n",
    "    # --- Optimizador ---\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    # (1) Class-weights + label smoothing (basados en y_tr_tr)\n",
    "    class_weights = torch.tensor(class_weights_vec, dtype=torch.float32, device=device)\n",
    "    crit = torch.nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "\n",
    "    # (2) Warmup + Cosine LR + Early stopping por val_f1m\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = epochs\n",
    "    warmup_epochs = max(1, min(5, epochs//10))\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    best_f1, best_state, patience, wait = 0.0, None, 10, 0\n",
    "\n",
    "    # ---- helpers de evaluaciÃ³n rÃ¡pida (sin TTA) ----\n",
    "    def _eval(dl):\n",
    "        model.eval(); preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "        return acc, f1m\n",
    "\n",
    "    # historia para curva\n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "    # =========================\n",
    "    # LOOP DE ENTRENAMIENTO\n",
    "    # =========================\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen = 0.0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            xb = xb.to(device)\n",
    "            xb = augment_batch(xb)  # augs SOLO en train\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * len(yb); n_seen += len(yb)\n",
    "        tr_loss /= max(1, n_seen)\n",
    "\n",
    "        # --- mÃ©tricas en train (sin augs) y val ---\n",
    "        train_acc, train_f1 = _eval(tr_eval_ld)\n",
    "        val_acc,   val_f1   = _eval(va_ld)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        improved = val_f1 > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = val_f1\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={train_acc:.4f} | \"\n",
    "              f\"val_acc={val_acc:.4f} | val_f1m={val_f1:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # cargar el mejor\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # guardar curva\n",
    "    plot_training_curves(history, f\"training_curve_fold{fold}.png\")\n",
    "\n",
    "    # =========================\n",
    "    # EVALUACIÃ“N FINAL EN TEST (con TTA como EEGNet)\n",
    "    # =========================\n",
    "    model.eval()\n",
    "    sfreq_used = RESAMPLE_HZ if RESAMPLE_HZ is not None else int(round(Xte_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "\n",
    "    elif SW_MODE == 'subwin':\n",
    "        logits = subwindow_logits(model, Xte_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        preds = logits.argmax(axis=1)\n",
    "        gts = y_te\n",
    "\n",
    "    elif SW_MODE == 'tta':\n",
    "        logits = time_shift_tta_logits(model, Xte_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        preds = logits.argmax(axis=1)\n",
    "        gts = y_te\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=CLASS_NAMES, digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "\n",
    "    return acc, f1m, cm, model\n",
    "\n",
    "# =========================\n",
    "# RUNNER: TODOS LOS FOLDS del JSON\n",
    "# =========================\n",
    "def run_all_folds():\n",
    "    # leer orden de folds desde el JSON\n",
    "    with open(FOLDS_JSON, 'r') as f:\n",
    "        payload = json.load(f)\n",
    "    folds_info = payload.get('folds', [])\n",
    "    fold_ids = [int(x.get('fold', -1)) for x in folds_info]\n",
    "    fold_ids = [f for f in fold_ids if f > 0]\n",
    "    if not fold_ids:\n",
    "        raise ValueError(\"No se hallaron folds vÃ¡lidos en el JSON.\")\n",
    "\n",
    "    global_accs = []\n",
    "    for i, fold in enumerate(sorted(fold_ids), start=1):\n",
    "        acc, f1m, cm, model = train_one_fold(\n",
    "            fold=fold,\n",
    "            resample_hz=RESAMPLE_HZ,\n",
    "            do_notch=DO_NOTCH,\n",
    "            do_bandpass=DO_BANDPASS,\n",
    "            bp_lo=BP_LO,\n",
    "            bp_hi=BP_HI,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            lr=LR,\n",
    "        )\n",
    "        global_accs.append(acc)\n",
    "\n",
    "    # resumen final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Global folds:\", [f\"{a:.4f}\" for a in global_accs])\n",
    "    if len(global_accs) > 0:\n",
    "        print(f\"Global mean: {np.mean(global_accs):.4f}\")\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\")\n",
    "    print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "    run_all_folds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f4b483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS=80, BATCH=48, LR=0.0005 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.26it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.31it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=6888 | n_test=1764)\n",
      "  Ã‰poca   1 | train_loss=1.3280 | train_acc=0.3368 | val_acc=0.2483 | val_f1m=0.1005 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=1.2326 | train_acc=0.3979 | val_acc=0.4014 | val_f1m=0.3829 | LR=0.000188\n",
      "  Ã‰poca   3 | train_loss=1.1439 | train_acc=0.4859 | val_acc=0.4059 | val_f1m=0.3950 | LR=0.000250\n",
      "  Ã‰poca   4 | train_loss=1.1294 | train_acc=0.4974 | val_acc=0.4365 | val_f1m=0.4316 | LR=0.000313\n",
      "  Ã‰poca   5 | train_loss=1.1158 | train_acc=0.5090 | val_acc=0.4297 | val_f1m=0.4138 | LR=0.000375\n",
      "  Ã‰poca   6 | train_loss=1.1106 | train_acc=0.5148 | val_acc=0.4546 | val_f1m=0.4546 | LR=0.000438\n",
      "  Ã‰poca   7 | train_loss=1.0905 | train_acc=0.5189 | val_acc=0.4620 | val_f1m=0.4632 | LR=0.000500\n",
      "  Ã‰poca   8 | train_loss=1.0943 | train_acc=0.5215 | val_acc=0.4524 | val_f1m=0.4430 | LR=0.000500\n",
      "  Ã‰poca   9 | train_loss=1.0813 | train_acc=0.5315 | val_acc=0.4320 | val_f1m=0.4149 | LR=0.000500\n",
      "  Ã‰poca  10 | train_loss=1.0707 | train_acc=0.5343 | val_acc=0.4620 | val_f1m=0.4615 | LR=0.000499\n",
      "  Ã‰poca  11 | train_loss=1.0374 | train_acc=0.5559 | val_acc=0.4439 | val_f1m=0.4227 | LR=0.000498\n",
      "  Ã‰poca  12 | train_loss=1.0215 | train_acc=0.5751 | val_acc=0.4575 | val_f1m=0.4444 | LR=0.000496\n",
      "  Ã‰poca  13 | train_loss=1.0297 | train_acc=0.5678 | val_acc=0.4688 | val_f1m=0.4691 | LR=0.000494\n",
      "  Ã‰poca  14 | train_loss=1.0051 | train_acc=0.5874 | val_acc=0.4722 | val_f1m=0.4750 | LR=0.000491\n",
      "  Ã‰poca  15 | train_loss=1.0027 | train_acc=0.5828 | val_acc=0.4620 | val_f1m=0.4687 | LR=0.000488\n",
      "  Ã‰poca  16 | train_loss=0.9997 | train_acc=0.5813 | val_acc=0.4563 | val_f1m=0.4601 | LR=0.000485\n",
      "  Ã‰poca  17 | train_loss=0.9894 | train_acc=0.5968 | val_acc=0.4654 | val_f1m=0.4647 | LR=0.000481\n",
      "  Ã‰poca  18 | train_loss=0.9697 | train_acc=0.6002 | val_acc=0.4717 | val_f1m=0.4647 | LR=0.000477\n",
      "  Ã‰poca  19 | train_loss=0.9607 | train_acc=0.6115 | val_acc=0.4620 | val_f1m=0.4573 | LR=0.000472\n",
      "  Ã‰poca  20 | train_loss=0.9460 | train_acc=0.6243 | val_acc=0.4603 | val_f1m=0.4621 | LR=0.000467\n",
      "  Ã‰poca  21 | train_loss=0.9472 | train_acc=0.6166 | val_acc=0.4575 | val_f1m=0.4499 | LR=0.000461\n",
      "  Ã‰poca  22 | train_loss=0.9196 | train_acc=0.6362 | val_acc=0.4546 | val_f1m=0.4572 | LR=0.000455\n",
      "  Ã‰poca  23 | train_loss=0.9024 | train_acc=0.6433 | val_acc=0.4518 | val_f1m=0.4541 | LR=0.000448\n",
      "  Ã‰poca  24 | train_loss=0.9107 | train_acc=0.6333 | val_acc=0.4671 | val_f1m=0.4698 | LR=0.000442\n",
      "  Ã‰poca  25 | train_loss=0.8899 | train_acc=0.6552 | val_acc=0.4303 | val_f1m=0.4287 | LR=0.000434\n",
      "  Ã‰poca  26 | train_loss=0.8640 | train_acc=0.6632 | val_acc=0.4654 | val_f1m=0.4677 | LR=0.000427\n",
      "  Early stopping en Ã©poca 26 (mejor val_f1m=0.4750)\n",
      "\n",
      "[Fold 1/5] Global acc=0.4762\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5994    0.4921    0.5405       441\n",
      "       right     0.6111    0.4490    0.5176       441\n",
      "  both_fists     0.3633    0.6236    0.4591       441\n",
      "   both_feet     0.4673    0.3401    0.3937       441\n",
      "\n",
      "    accuracy                         0.4762      1764\n",
      "   macro avg     0.5103    0.4762    0.4777      1764\n",
      "weighted avg     0.5103    0.4762    0.4777      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[217  23 162  39]\n",
      " [ 31 198 147  65]\n",
      " [ 54  45 275  67]\n",
      " [ 60  58 173 150]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:09<00:00,  8.24it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.27it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=6888 | n_test=1764)\n",
      "  Ã‰poca   1 | train_loss=1.3313 | train_acc=0.3310 | val_acc=0.2500 | val_f1m=0.1000 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=1.2677 | train_acc=0.3743 | val_acc=0.4399 | val_f1m=0.4312 | LR=0.000188\n",
      "  Ã‰poca   3 | train_loss=1.1965 | train_acc=0.4480 | val_acc=0.4144 | val_f1m=0.3824 | LR=0.000250\n",
      "  Ã‰poca   4 | train_loss=1.1410 | train_acc=0.4871 | val_acc=0.4824 | val_f1m=0.4712 | LR=0.000313\n",
      "  Ã‰poca   5 | train_loss=1.1403 | train_acc=0.4801 | val_acc=0.4841 | val_f1m=0.4710 | LR=0.000375\n",
      "  Ã‰poca   6 | train_loss=1.1223 | train_acc=0.5010 | val_acc=0.5079 | val_f1m=0.5000 | LR=0.000438\n",
      "  Ã‰poca   7 | train_loss=1.0854 | train_acc=0.5271 | val_acc=0.5442 | val_f1m=0.5454 | LR=0.000500\n",
      "  Ã‰poca   8 | train_loss=1.1148 | train_acc=0.5128 | val_acc=0.5221 | val_f1m=0.5183 | LR=0.000500\n",
      "  Ã‰poca   9 | train_loss=1.0924 | train_acc=0.5228 | val_acc=0.5227 | val_f1m=0.5070 | LR=0.000500\n",
      "  Ã‰poca  10 | train_loss=1.0793 | train_acc=0.5322 | val_acc=0.5488 | val_f1m=0.5465 | LR=0.000499\n",
      "  Ã‰poca  11 | train_loss=1.0657 | train_acc=0.5330 | val_acc=0.5346 | val_f1m=0.5297 | LR=0.000498\n",
      "  Ã‰poca  12 | train_loss=1.0574 | train_acc=0.5418 | val_acc=0.5068 | val_f1m=0.4895 | LR=0.000496\n",
      "  Ã‰poca  13 | train_loss=1.0471 | train_acc=0.5524 | val_acc=0.5130 | val_f1m=0.5072 | LR=0.000494\n",
      "  Ã‰poca  14 | train_loss=1.0220 | train_acc=0.5716 | val_acc=0.5170 | val_f1m=0.5187 | LR=0.000491\n",
      "  Ã‰poca  15 | train_loss=1.0332 | train_acc=0.5669 | val_acc=0.5300 | val_f1m=0.5330 | LR=0.000488\n",
      "  Ã‰poca  16 | train_loss=1.0173 | train_acc=0.5719 | val_acc=0.5363 | val_f1m=0.5363 | LR=0.000485\n",
      "  Ã‰poca  17 | train_loss=1.0021 | train_acc=0.5783 | val_acc=0.5232 | val_f1m=0.5217 | LR=0.000481\n",
      "  Ã‰poca  18 | train_loss=0.9872 | train_acc=0.5809 | val_acc=0.5346 | val_f1m=0.5325 | LR=0.000477\n",
      "  Ã‰poca  19 | train_loss=0.9910 | train_acc=0.5826 | val_acc=0.5176 | val_f1m=0.5058 | LR=0.000472\n",
      "  Ã‰poca  20 | train_loss=0.9667 | train_acc=0.6045 | val_acc=0.5454 | val_f1m=0.5434 | LR=0.000467\n",
      "  Ã‰poca  21 | train_loss=0.9662 | train_acc=0.6028 | val_acc=0.5255 | val_f1m=0.5250 | LR=0.000461\n",
      "  Ã‰poca  22 | train_loss=0.9445 | train_acc=0.6169 | val_acc=0.5215 | val_f1m=0.5235 | LR=0.000455\n",
      "  Early stopping en Ã©poca 22 (mejor val_f1m=0.5465)\n",
      "\n",
      "[Fold 2/5] Global acc=0.5482\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6959    0.5397    0.6079       441\n",
      "       right     0.6078    0.6395    0.6232       441\n",
      "  both_fists     0.4233    0.6757    0.5205       441\n",
      "   both_feet     0.5866    0.3379    0.4288       441\n",
      "\n",
      "    accuracy                         0.5482      1764\n",
      "   macro avg     0.5784    0.5482    0.5451      1764\n",
      "weighted avg     0.5784    0.5482    0.5451      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[238  24 155  24]\n",
      " [ 25 282  95  39]\n",
      " [ 38  63 298  42]\n",
      " [ 41  95 156 149]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:10<00:00,  8.17it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.08it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=6888 | n_test=1764)\n",
      "  Ã‰poca   1 | train_loss=1.3268 | train_acc=0.3323 | val_acc=0.2755 | val_f1m=0.1552 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=1.2266 | train_acc=0.4265 | val_acc=0.4694 | val_f1m=0.4716 | LR=0.000188\n",
      "  Ã‰poca   3 | train_loss=1.1599 | train_acc=0.4778 | val_acc=0.4280 | val_f1m=0.4189 | LR=0.000250\n",
      "  Ã‰poca   4 | train_loss=1.1196 | train_acc=0.5042 | val_acc=0.4399 | val_f1m=0.4349 | LR=0.000313\n",
      "  Ã‰poca   5 | train_loss=1.1143 | train_acc=0.5038 | val_acc=0.4240 | val_f1m=0.4074 | LR=0.000375\n",
      "  Ã‰poca   6 | train_loss=1.1130 | train_acc=0.5122 | val_acc=0.4325 | val_f1m=0.4224 | LR=0.000438\n",
      "  Ã‰poca   7 | train_loss=1.0708 | train_acc=0.5392 | val_acc=0.4626 | val_f1m=0.4670 | LR=0.000500\n",
      "  Ã‰poca   8 | train_loss=1.0849 | train_acc=0.5273 | val_acc=0.4490 | val_f1m=0.4418 | LR=0.000500\n",
      "  Ã‰poca   9 | train_loss=1.0700 | train_acc=0.5438 | val_acc=0.4609 | val_f1m=0.4566 | LR=0.000500\n",
      "  Ã‰poca  10 | train_loss=1.0446 | train_acc=0.5569 | val_acc=0.4546 | val_f1m=0.4499 | LR=0.000499\n",
      "  Ã‰poca  11 | train_loss=1.0369 | train_acc=0.5579 | val_acc=0.4768 | val_f1m=0.4712 | LR=0.000498\n",
      "  Ã‰poca  12 | train_loss=1.0111 | train_acc=0.5806 | val_acc=0.4484 | val_f1m=0.4433 | LR=0.000496\n",
      "  Ã‰poca  13 | train_loss=1.0151 | train_acc=0.5751 | val_acc=0.4626 | val_f1m=0.4612 | LR=0.000494\n",
      "  Ã‰poca  14 | train_loss=0.9949 | train_acc=0.5939 | val_acc=0.4756 | val_f1m=0.4783 | LR=0.000491\n",
      "  Ã‰poca  15 | train_loss=1.0034 | train_acc=0.5865 | val_acc=0.4501 | val_f1m=0.4456 | LR=0.000488\n",
      "  Ã‰poca  16 | train_loss=0.9893 | train_acc=0.5934 | val_acc=0.4405 | val_f1m=0.4358 | LR=0.000485\n",
      "  Ã‰poca  17 | train_loss=0.9868 | train_acc=0.5874 | val_acc=0.4507 | val_f1m=0.4495 | LR=0.000481\n",
      "  Ã‰poca  18 | train_loss=0.9413 | train_acc=0.6167 | val_acc=0.4711 | val_f1m=0.4718 | LR=0.000477\n",
      "  Ã‰poca  19 | train_loss=0.9523 | train_acc=0.6093 | val_acc=0.4546 | val_f1m=0.4460 | LR=0.000472\n",
      "  Ã‰poca  20 | train_loss=0.9447 | train_acc=0.6211 | val_acc=0.4666 | val_f1m=0.4703 | LR=0.000467\n",
      "  Ã‰poca  21 | train_loss=0.9210 | train_acc=0.6376 | val_acc=0.4705 | val_f1m=0.4726 | LR=0.000461\n",
      "  Ã‰poca  22 | train_loss=0.9133 | train_acc=0.6378 | val_acc=0.4552 | val_f1m=0.4546 | LR=0.000455\n",
      "  Ã‰poca  23 | train_loss=0.9071 | train_acc=0.6400 | val_acc=0.4371 | val_f1m=0.4132 | LR=0.000448\n",
      "  Ã‰poca  24 | train_loss=0.8929 | train_acc=0.6445 | val_acc=0.4666 | val_f1m=0.4725 | LR=0.000442\n",
      "  Ã‰poca  25 | train_loss=0.8761 | train_acc=0.6598 | val_acc=0.4603 | val_f1m=0.4621 | LR=0.000434\n",
      "  Ã‰poca  26 | train_loss=0.8517 | train_acc=0.6722 | val_acc=0.4615 | val_f1m=0.4647 | LR=0.000427\n",
      "  Early stopping en Ã©poca 26 (mejor val_f1m=0.4783)\n",
      "\n",
      "[Fold 3/5] Global acc=0.4790\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6190    0.5011    0.5539       441\n",
      "       right     0.7285    0.3651    0.4864       441\n",
      "  both_fists     0.3622    0.6440    0.4637       441\n",
      "   both_feet     0.4453    0.4059    0.4247       441\n",
      "\n",
      "    accuracy                         0.4790      1764\n",
      "   macro avg     0.5388    0.4790    0.4822      1764\n",
      "weighted avg     0.5388    0.4790    0.4822      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[221  16 148  56]\n",
      " [ 22 161 168  90]\n",
      " [ 63  17 284  77]\n",
      " [ 51  27 184 179]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:09<00:00,  8.33it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.24it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=6972 | n_test=1680)\n",
      "  Ã‰poca   1 | train_loss=1.3366 | train_acc=0.3196 | val_acc=0.2524 | val_f1m=0.1092 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=1.2454 | train_acc=0.3987 | val_acc=0.3304 | val_f1m=0.2582 | LR=0.000188\n",
      "  Ã‰poca   3 | train_loss=1.1598 | train_acc=0.4768 | val_acc=0.4631 | val_f1m=0.4557 | LR=0.000250\n",
      "  Ã‰poca   4 | train_loss=1.1347 | train_acc=0.4974 | val_acc=0.4851 | val_f1m=0.4800 | LR=0.000313\n",
      "  Ã‰poca   5 | train_loss=1.1064 | train_acc=0.5149 | val_acc=0.4429 | val_f1m=0.4177 | LR=0.000375\n",
      "  Ã‰poca   6 | train_loss=1.1061 | train_acc=0.5158 | val_acc=0.4673 | val_f1m=0.4515 | LR=0.000438\n",
      "  Ã‰poca   7 | train_loss=1.0961 | train_acc=0.5275 | val_acc=0.4482 | val_f1m=0.4389 | LR=0.000500\n",
      "  Ã‰poca   8 | train_loss=1.1113 | train_acc=0.5146 | val_acc=0.4827 | val_f1m=0.4712 | LR=0.000500\n",
      "  Ã‰poca   9 | train_loss=1.0856 | train_acc=0.5273 | val_acc=0.4994 | val_f1m=0.4867 | LR=0.000500\n",
      "  Ã‰poca  10 | train_loss=1.0705 | train_acc=0.5453 | val_acc=0.4310 | val_f1m=0.4076 | LR=0.000499\n",
      "  Ã‰poca  11 | train_loss=1.0550 | train_acc=0.5453 | val_acc=0.4399 | val_f1m=0.4065 | LR=0.000498\n",
      "  Ã‰poca  12 | train_loss=1.0353 | train_acc=0.5610 | val_acc=0.4512 | val_f1m=0.4424 | LR=0.000496\n",
      "  Ã‰poca  13 | train_loss=1.0315 | train_acc=0.5585 | val_acc=0.5077 | val_f1m=0.5095 | LR=0.000494\n",
      "  Ã‰poca  14 | train_loss=1.0436 | train_acc=0.5536 | val_acc=0.4732 | val_f1m=0.4739 | LR=0.000491\n",
      "  Ã‰poca  15 | train_loss=1.0003 | train_acc=0.5773 | val_acc=0.5054 | val_f1m=0.5078 | LR=0.000488\n",
      "  Ã‰poca  16 | train_loss=1.0088 | train_acc=0.5803 | val_acc=0.4827 | val_f1m=0.4774 | LR=0.000485\n",
      "  Ã‰poca  17 | train_loss=0.9977 | train_acc=0.5866 | val_acc=0.4899 | val_f1m=0.4834 | LR=0.000481\n",
      "  Ã‰poca  18 | train_loss=0.9920 | train_acc=0.5892 | val_acc=0.4708 | val_f1m=0.4642 | LR=0.000477\n",
      "  Ã‰poca  19 | train_loss=0.9755 | train_acc=0.5968 | val_acc=0.4935 | val_f1m=0.4921 | LR=0.000472\n",
      "  Ã‰poca  20 | train_loss=0.9593 | train_acc=0.6140 | val_acc=0.4792 | val_f1m=0.4783 | LR=0.000467\n",
      "  Ã‰poca  21 | train_loss=0.9562 | train_acc=0.6107 | val_acc=0.4827 | val_f1m=0.4801 | LR=0.000461\n",
      "  Ã‰poca  22 | train_loss=0.9352 | train_acc=0.6242 | val_acc=0.4869 | val_f1m=0.4863 | LR=0.000455\n",
      "  Ã‰poca  23 | train_loss=0.9056 | train_acc=0.6411 | val_acc=0.5048 | val_f1m=0.5034 | LR=0.000448\n",
      "  Ã‰poca  24 | train_loss=0.8943 | train_acc=0.6492 | val_acc=0.4685 | val_f1m=0.4659 | LR=0.000442\n",
      "  Ã‰poca  25 | train_loss=0.8909 | train_acc=0.6459 | val_acc=0.4833 | val_f1m=0.4717 | LR=0.000434\n",
      "  Early stopping en Ã©poca 25 (mejor val_f1m=0.5095)\n",
      "\n",
      "[Fold 4/5] Global acc=0.5155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6875    0.4714    0.5593       420\n",
      "       right     0.5269    0.6071    0.5642       420\n",
      "  both_fists     0.4187    0.5333    0.4691       420\n",
      "   both_feet     0.5067    0.4500    0.4767       420\n",
      "\n",
      "    accuracy                         0.5155      1680\n",
      "   macro avg     0.5349    0.5155    0.5173      1680\n",
      "weighted avg     0.5349    0.5155    0.5173      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[198  43 133  46]\n",
      " [ 12 255  77  76]\n",
      " [ 37  97 224  62]\n",
      " [ 41  89 101 189]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:10<00:00,  7.57it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.46it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=6972 | n_test=1680)\n",
      "  Ã‰poca   1 | train_loss=1.3340 | train_acc=0.3210 | val_acc=0.2518 | val_f1m=0.1040 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=1.2390 | train_acc=0.3985 | val_acc=0.3833 | val_f1m=0.3330 | LR=0.000188\n",
      "  Ã‰poca   3 | train_loss=1.1695 | train_acc=0.4740 | val_acc=0.5405 | val_f1m=0.5431 | LR=0.000250\n",
      "  Ã‰poca   4 | train_loss=1.1480 | train_acc=0.4859 | val_acc=0.5119 | val_f1m=0.4974 | LR=0.000313\n",
      "  Ã‰poca   5 | train_loss=1.1248 | train_acc=0.4944 | val_acc=0.5012 | val_f1m=0.4931 | LR=0.000375\n",
      "  Ã‰poca   6 | train_loss=1.1140 | train_acc=0.5040 | val_acc=0.5268 | val_f1m=0.5248 | LR=0.000438\n",
      "  Ã‰poca   7 | train_loss=1.1024 | train_acc=0.5215 | val_acc=0.5268 | val_f1m=0.5281 | LR=0.000500\n",
      "  Ã‰poca   8 | train_loss=1.1145 | train_acc=0.5050 | val_acc=0.5256 | val_f1m=0.5237 | LR=0.000500\n",
      "  Ã‰poca   9 | train_loss=1.0938 | train_acc=0.5234 | val_acc=0.5185 | val_f1m=0.5191 | LR=0.000500\n",
      "  Ã‰poca  10 | train_loss=1.0753 | train_acc=0.5354 | val_acc=0.4958 | val_f1m=0.4904 | LR=0.000499\n",
      "  Ã‰poca  11 | train_loss=1.0630 | train_acc=0.5445 | val_acc=0.5036 | val_f1m=0.5019 | LR=0.000498\n",
      "  Ã‰poca  12 | train_loss=1.0399 | train_acc=0.5565 | val_acc=0.5185 | val_f1m=0.5176 | LR=0.000496\n",
      "  Ã‰poca  13 | train_loss=1.0508 | train_acc=0.5516 | val_acc=0.5375 | val_f1m=0.5419 | LR=0.000494\n",
      "  Ã‰poca  14 | train_loss=1.0492 | train_acc=0.5534 | val_acc=0.5185 | val_f1m=0.5217 | LR=0.000491\n",
      "  Ã‰poca  15 | train_loss=1.0007 | train_acc=0.5789 | val_acc=0.5143 | val_f1m=0.5179 | LR=0.000488\n",
      "  Early stopping en Ã©poca 15 (mejor val_f1m=0.5431)\n",
      "\n",
      "[Fold 5/5] Global acc=0.5345\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6366    0.5381    0.5832       420\n",
      "       right     0.5960    0.5619    0.5784       420\n",
      "  both_fists     0.4458    0.5190    0.4796       420\n",
      "   both_feet     0.4955    0.5190    0.5070       420\n",
      "\n",
      "    accuracy                         0.5345      1680\n",
      "   macro avg     0.5435    0.5345    0.5371      1680\n",
      "weighted avg     0.5435    0.5345    0.5371      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[226  25 102  67]\n",
      " [ 17 236  85  82]\n",
      " [ 75  54 218  73]\n",
      " [ 37  81  84 218]]\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4762', '0.5482', '0.4790', '0.5155', '0.5345']\n",
      "Global mean ACC: 0.5107\n",
      "F1 folds (MACRO): ['0.4777', '0.5451', '0.4822', '0.5173', '0.5371']\n",
      "F1 mean (MACRO): 0.5119\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN + Transformer (PyTorch) para PhysioNet/BCI2000 MI â€” IMAGINERÃA (4 clases) con 8 canales.\n",
    "# Cambios implementados:\n",
    "# (2) OptimizaciÃ³n: LR=5e-4, EPOCHS=80, BATCH=48, patience=12 (warmup+cosine se mantiene).\n",
    "# (3) Peso extra a 'both_fists' (clase 2): *1.45 en class-weights.\n",
    "# (4) Augment MI especÃ­fico (solo clases 2/3): temporal cutout (70â€“150 ms, p=0.6) + time-warp Â±4%.\n",
    "# (6) Arquitectura: d_model=160, n_heads=5, dropout=0.20, WD=1e-3.\n",
    "# Reporte final incluye F1 mean en CV 5-fold.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'                     # .../S###/S###R##.edf\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "# Entrenamiento / K-Fold\n",
    "FOLDS = [1,2,3,4,5]\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 48\n",
    "LR = 5e-4\n",
    "PATIENCE = 12\n",
    "\n",
    "# Prepro\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False          # (dejamos como estaba si tu baseline lo tenÃ­a asÃ­)\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False     # si lo activas, recuerda que ya normaliza en load_subject_epochs\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 160\n",
    "N_HEADS = 5\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.20\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# Sliding / TTA (igual que antes)\n",
    "SW_MODE = 'tta'   # 'none' | 'subwin' | 'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.025, -0.0125, 0.0, 0.0125, 0.025]\n",
    "\n",
    "# Para subventanas (si se usa)\n",
    "SW_LEN   = 2.0\n",
    "SW_STRIDE = 0.5\n",
    "\n",
    "# Dataset\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}    # T1=left, T2=right\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}   # T1=both_fists, T2=both_feet\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\")\n",
    "print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        pattern = str(subj_dir / f\"{subject_id}R{r:02d}.edf\")\n",
    "        edfs.extend(glob(pattern))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        raise FileNotFoundError(f\"No imagery EDF files for {subject_id} under {DATA_RAW}\")\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}  # id -> 'T1'/'T2'\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        keep_mask = y_run >= 0\n",
    "        X = X[keep_mask]\n",
    "        y = y_run[keep_mask]\n",
    "\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, 8, 1)), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    if len(set([round(s) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Inconsistent sampling rates: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            train_sub = list(item.get('train', []))\n",
    "            test_sub  = list(item.get('test', []))\n",
    "            return train_sub, test_sub\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def standardize_per_channel(train_X, test_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X  = test_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        test_X[:, c, :]  = (test_X[:, c, :] - mu) / sd\n",
    "    return train_X, test_X\n",
    "\n",
    "# =========================\n",
    "# MODELO\n",
    "# =========================\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=160, n_heads=5, n_layers=2, p_drop=0.20):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            nn.BatchNorm1d(32), nn.ELU(),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "        self.pos_encoding = None\n",
    "        enc_ly = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.10, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_ly, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)  # (B,1,D)\n",
    "        z = torch.cat([cls_tok, z], dim=1)    # (B, 1+L, D)\n",
    "        z = self.encoder(z)                   # (B, 1+L, D)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# AUGMENTATIONS\n",
    "# =========================\n",
    "def augment_generic(xb, p_jitter=0.25, p_noise=0.25, p_chdrop=0.15,\n",
    "                    max_jitter_frac=0.02, noise_std=0.02):\n",
    "    \"\"\"\n",
    "    xb: torch.Tensor (B,C,T), ya normalizado. GenÃ©rico (todas las clases)\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop:\n",
    "        k = 1\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "def _temporal_cutout_np(x_np, sfreq, min_ms=70, max_ms=150):\n",
    "    \"\"\"\n",
    "    x_np: (C,T) numpy. Corta a cero un segmento temporal continuo (edge padding no necesario).\n",
    "    \"\"\"\n",
    "    C, T = x_np.shape\n",
    "    min_len = max(1, int(round((min_ms/1000.0)*sfreq)))\n",
    "    max_len = max(1, int(round((max_ms/1000.0)*sfreq)))\n",
    "    w = np.random.randint(min_len, max_len+1)\n",
    "    if w >= T:\n",
    "        start = 0\n",
    "        end = T\n",
    "    else:\n",
    "        start = np.random.randint(0, T - w + 1)\n",
    "        end = start + w\n",
    "    x_np[:, start:end] = 0.0\n",
    "    return x_np\n",
    "\n",
    "def _time_warp_np(x_np, max_warp_frac=0.04):\n",
    "    \"\"\"\n",
    "    Simple time-warp: estira/encoge la seÃ±al en el eje temporal con factor ~ U[1-Î±, 1+Î±]\n",
    "    y re-muestrea a la longitud original.\n",
    "    \"\"\"\n",
    "    C, T = x_np.shape\n",
    "    factor = 1.0 + np.random.uniform(-max_warp_frac, max_warp_frac)\n",
    "    new_T = max(2, int(round(T * factor)))\n",
    "    # InterpolaciÃ³n lineal por canal\n",
    "    orig_t = np.linspace(0.0, 1.0, T, dtype=np.float32)\n",
    "    new_t  = np.linspace(0.0, 1.0, new_T, dtype=np.float32)\n",
    "    warped = np.zeros((C, new_T), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        warped[c] = np.interp(new_t, orig_t, x_np[c])\n",
    "    # Reajuste a T original\n",
    "    resampled = np.zeros((C, T), dtype=np.float32)\n",
    "    if new_T == T:\n",
    "        resampled = warped\n",
    "    elif new_T > T:\n",
    "        # recorte centrado\n",
    "        start = (new_T - T) // 2\n",
    "        resampled = warped[:, start:start+T]\n",
    "    else:\n",
    "        # pad centrado con borde\n",
    "        pad = T - new_T\n",
    "        left = pad // 2\n",
    "        right = pad - left\n",
    "        resampled[:, :left] = warped[:, 0:1]\n",
    "        resampled[:, left:left+new_T] = warped\n",
    "        resampled[:, left+new_T:] = warped[:, -1:]\n",
    "    return resampled\n",
    "\n",
    "def augment_mi_specific(xb, yb, sfreq, p_cutout=0.6, cutout_ms=(70,150), p_warp=0.5, warp_frac=0.04):\n",
    "    \"\"\"\n",
    "    Augment especÃ­fico para MI en clases 2/3 (both_fists / both_feet):\n",
    "    - temporal cutout (70â€“150 ms) con p=0.6\n",
    "    - time-warp Â±4% con p=0.5\n",
    "    xb: torch.Tensor (B,C,T) en GPU\n",
    "    yb: torch.LongTensor (B,)\n",
    "    \"\"\"\n",
    "    xb_np = xb.detach().cpu().numpy()\n",
    "    y_np  = yb.detach().cpu().numpy()\n",
    "    B, C, T = xb_np.shape\n",
    "    for i in range(B):\n",
    "        if y_np[i] in (2, 3):\n",
    "            if np.random.rand() < p_cutout:\n",
    "                xb_np[i] = _temporal_cutout_np(xb_np[i], sfreq, min_ms=cutout_ms[0], max_ms=cutout_ms[1])\n",
    "            if np.random.rand() < p_warp:\n",
    "                xb_np[i] = _time_warp_np(xb_np[i], max_warp_frac=warp_frac)\n",
    "    return torch.tensor(xb_np, dtype=xb.dtype, device=xb.device)\n",
    "\n",
    "# =========================\n",
    "# EVAL helpers\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1]))\n",
    "    st = max(1, st)\n",
    "\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]\n",
    "            acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    model.eval()\n",
    "    T = X.shape[-1]\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]\n",
    "            acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# TRAIN LOOP (por fold)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, resample_hz:int, do_notch:bool, do_bandpass:bool,\n",
    "                   bp_lo:float, bp_hi:float, epochs:int, batch_size:int, lr:float,\n",
    "                   patience:int, device:str=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "\n",
    "    # sujetos fold\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # carga datos\n",
    "    X_tr_list, y_tr_list, X_te_list, y_te_list = [], [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_sub, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, resample_hz, do_notch, do_bandpass, DO_CAR, bp_lo, bp_hi)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    if len(X_tr_list) == 0 or len(X_te_list) == 0:\n",
    "        raise RuntimeError(\"Datos insuficientes tras carga de sujetos.\")\n",
    "\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "\n",
    "    # NormalizaciÃ³n (global por canal, si no usas zscore por Ã©poca)\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_te_std = X_tr, X_te\n",
    "    else:\n",
    "        X_tr_std, X_te_std = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # DataLoaders + sampler balanceado por clase (reproducible)\n",
    "    train_ds = TensorDataset(torch.tensor(X_tr_std), torch.tensor(y_tr).long())\n",
    "    class_counts = np.bincount(y_tr, minlength=4)\n",
    "    class_weights_vec = class_counts.sum() / (4.0 * np.maximum(class_counts, 1))\n",
    "    # (3) empuje a both_fists (clase 2)\n",
    "    class_weights_vec[2] = class_weights_vec[2] * 1.45\n",
    "\n",
    "    sample_weights = class_weights_vec[train_ds.tensors[1].numpy()]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.tensor(sample_weights, dtype=torch.float32),\n",
    "        num_samples=len(train_ds), replacement=True,\n",
    "        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "    )\n",
    "    tr_ld = DataLoader(train_ds, batch_size=batch_size, sampler=sampler,\n",
    "                       drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    te_ld = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_te_std), torch.tensor(y_te).long()),\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    # Modelo\n",
    "    model = EEGCNNTransformer(\n",
    "        n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS, n_layers=N_LAYERS, p_drop=P_DROP\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizador / scheduler\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)  # (6) WD=1e-3\n",
    "\n",
    "    # Loss con class-weights + label smoothing\n",
    "    class_weights = torch.tensor(class_weights_vec, dtype=torch.float32, device=device)\n",
    "    crit = torch.nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "\n",
    "    # Warmup + Cosine LR + Early stopping por macro-F1\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = epochs\n",
    "    warmup_epochs = max(1, min(8, epochs//10))  # un poco mÃ¡s largo que antes\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # Entrenamiento (validaciÃ³n en test set durante training para monitoreo, como venÃ­as usando)\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(X_tr_std)} | n_test={len(X_te_std)})\")\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "\n",
    "            # (4) Augments: primero genÃ©ricos, luego MI-especÃ­fico (clases 2/3)\n",
    "            xb = augment_generic(xb)\n",
    "            xb = augment_mi_specific(xb, yb, sfreq, p_cutout=0.6, cutout_ms=(70,150), p_warp=0.5, warp_frac=0.04)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen  += len(yb)\n",
    "            tr_correct += (logits.argmax(dim=1) == yb).sum().item()\n",
    "\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        # \"ValidaciÃ³n\" (monitoreo) en test (como en tus logs)\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # --- EvaluaciÃ³n final (con TTA si corresponde) ---\n",
    "    model.eval()\n",
    "    sfreq_used = RESAMPLE_HZ if RESAMPLE_HZ is not None else int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "\n",
    "    elif SW_MODE == 'subwin':\n",
    "        logits = subwindow_logits(model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        preds = logits.argmax(axis=1)\n",
    "        gts = y_te\n",
    "\n",
    "    elif SW_MODE == 'tta':\n",
    "        logits = time_shift_tta_logits(model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        preds = logits.argmax(axis=1)\n",
    "        gts = y_te\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
    "\n",
    "    print(f\"\\n[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=['left','right','both_fists','both_feet'], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "\n",
    "    return acc, f1m, cm, model\n",
    "\n",
    "# =========================\n",
    "# EJECUCIÃ“N K-FOLD (1..5) + resumen final con F1 mean\n",
    "# =========================\n",
    "all_acc, all_f1 = [], []\n",
    "for FOLD in FOLDS:\n",
    "    acc, f1m, cm, model = train_one_fold(\n",
    "        fold=FOLD,\n",
    "        resample_hz=RESAMPLE_HZ,\n",
    "        do_notch=DO_NOTCH,\n",
    "        do_bandpass=DO_BANDPASS,\n",
    "        bp_lo=BP_LO,\n",
    "        bp_hi=BP_HI,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr=LR,\n",
    "        patience=PATIENCE,\n",
    "    )\n",
    "    all_acc.append(acc)\n",
    "    all_f1.append(f1m)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\"*60)\n",
    "acc_str = [f\"{a:.4f}\" for a in all_acc]\n",
    "f1_str  = [f\"{f:.4f}\" for f in all_f1]\n",
    "print(f\"Global folds (ACC): {acc_str}\")\n",
    "print(f\"Global mean ACC: {np.mean(all_acc):.4f}\")\n",
    "print(f\"F1 folds (MACRO): {f1_str}\")\n",
    "print(f\"F1 mean (MACRO): {np.mean(all_f1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d3ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.001 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1:   0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.33it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.33it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2274 | train_acc=0.2674 | val_acc=0.3087 | val_f1m=0.2489 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2048 | train_acc=0.3810 | val_acc=0.4913 | val_f1m=0.4946 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1868 | train_acc=0.4636 | val_acc=0.5008 | val_f1m=0.5057 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1786 | train_acc=0.4966 | val_acc=0.4913 | val_f1m=0.4942 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1761 | train_acc=0.5016 | val_acc=0.5317 | val_f1m=0.5321 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1736 | train_acc=0.5071 | val_acc=0.5262 | val_f1m=0.5316 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1715 | train_acc=0.5211 | val_acc=0.5222 | val_f1m=0.5212 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1686 | train_acc=0.5202 | val_acc=0.5397 | val_f1m=0.5403 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1674 | train_acc=0.5337 | val_acc=0.5341 | val_f1m=0.5378 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1622 | train_acc=0.5398 | val_acc=0.5294 | val_f1m=0.5349 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1605 | train_acc=0.5485 | val_acc=0.5492 | val_f1m=0.5484 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1565 | train_acc=0.5559 | val_acc=0.5341 | val_f1m=0.5351 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1559 | train_acc=0.5609 | val_acc=0.5151 | val_f1m=0.5169 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1566 | train_acc=0.5575 | val_acc=0.5278 | val_f1m=0.5297 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1505 | train_acc=0.5779 | val_acc=0.5230 | val_f1m=0.5243 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1470 | train_acc=0.5850 | val_acc=0.5429 | val_f1m=0.5476 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1477 | train_acc=0.5808 | val_acc=0.5381 | val_f1m=0.5380 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1453 | train_acc=0.5882 | val_acc=0.5302 | val_f1m=0.5344 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1405 | train_acc=0.5991 | val_acc=0.5135 | val_f1m=0.5147 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1392 | train_acc=0.6033 | val_acc=0.5190 | val_f1m=0.5213 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1381 | train_acc=0.6062 | val_acc=0.5222 | val_f1m=0.5240 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1348 | train_acc=0.6096 | val_acc=0.5175 | val_f1m=0.5154 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1314 | train_acc=0.6293 | val_acc=0.5206 | val_f1m=0.5210 | LR=0.000848\n",
      "  Early stopping en Ã©poca 23 (mejor val_f1m=0.5484)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4700\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5536    0.5624    0.5579       441\n",
      "       right     0.5556    0.5215    0.5380       441\n",
      "  both fists     0.3437    0.4014    0.3703       441\n",
      "   both feet     0.4496    0.3946    0.4203       441\n",
      "\n",
      "    accuracy                         0.4700      1764\n",
      "   macro avg     0.4756    0.4700    0.4716      1764\n",
      "weighted avg     0.4756    0.4700    0.4716      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[248  35 114  44]\n",
      " [ 30 230 101  80]\n",
      " [106  69 177  89]\n",
      " [ 64  80 123 174]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.36it/s]\n",
      "Cargando val fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.40it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2292 | train_acc=0.2470 | val_acc=0.2952 | val_f1m=0.2315 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2078 | train_acc=0.3665 | val_acc=0.4476 | val_f1m=0.4491 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1913 | train_acc=0.4425 | val_acc=0.4778 | val_f1m=0.4805 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1841 | train_acc=0.4647 | val_acc=0.4881 | val_f1m=0.4892 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1803 | train_acc=0.4860 | val_acc=0.4889 | val_f1m=0.4831 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1791 | train_acc=0.4906 | val_acc=0.5103 | val_f1m=0.5115 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1791 | train_acc=0.4918 | val_acc=0.5071 | val_f1m=0.5075 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1751 | train_acc=0.5044 | val_acc=0.4929 | val_f1m=0.4920 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1714 | train_acc=0.5110 | val_acc=0.4960 | val_f1m=0.5003 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1692 | train_acc=0.5147 | val_acc=0.5032 | val_f1m=0.5016 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1693 | train_acc=0.5146 | val_acc=0.4817 | val_f1m=0.4774 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1645 | train_acc=0.5352 | val_acc=0.5040 | val_f1m=0.5057 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1619 | train_acc=0.5339 | val_acc=0.5135 | val_f1m=0.5107 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1597 | train_acc=0.5387 | val_acc=0.4865 | val_f1m=0.4872 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1558 | train_acc=0.5570 | val_acc=0.5103 | val_f1m=0.5057 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1536 | train_acc=0.5632 | val_acc=0.5095 | val_f1m=0.5099 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1518 | train_acc=0.5710 | val_acc=0.5087 | val_f1m=0.5058 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1514 | train_acc=0.5659 | val_acc=0.4913 | val_f1m=0.4889 | LR=0.000935\n",
      "  Early stopping en Ã©poca 18 (mejor val_f1m=0.5115)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5454\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5631    0.6780    0.6152       441\n",
      "       right     0.6564    0.5805    0.6161       441\n",
      "  both fists     0.4475    0.5125    0.4778       441\n",
      "   both feet     0.5355    0.4104    0.4647       441\n",
      "\n",
      "    accuracy                         0.5454      1764\n",
      "   macro avg     0.5506    0.5454    0.5435      1764\n",
      "weighted avg     0.5506    0.5454    0.5435      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[299  16  85  41]\n",
      " [ 52 256  82  51]\n",
      " [109  41 226  65]\n",
      " [ 71  77 112 181]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.34it/s]\n",
      "Cargando val fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.37it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2278 | train_acc=0.2562 | val_acc=0.2889 | val_f1m=0.2374 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2066 | train_acc=0.3674 | val_acc=0.3810 | val_f1m=0.3703 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1837 | train_acc=0.4721 | val_acc=0.4365 | val_f1m=0.4376 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1764 | train_acc=0.4989 | val_acc=0.4460 | val_f1m=0.4447 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1708 | train_acc=0.5101 | val_acc=0.4611 | val_f1m=0.4610 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1694 | train_acc=0.5165 | val_acc=0.4365 | val_f1m=0.4282 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1677 | train_acc=0.5218 | val_acc=0.4675 | val_f1m=0.4650 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1640 | train_acc=0.5350 | val_acc=0.4500 | val_f1m=0.4475 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1634 | train_acc=0.5309 | val_acc=0.4754 | val_f1m=0.4711 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1566 | train_acc=0.5550 | val_acc=0.4722 | val_f1m=0.4691 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1570 | train_acc=0.5462 | val_acc=0.4603 | val_f1m=0.4551 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1541 | train_acc=0.5524 | val_acc=0.4548 | val_f1m=0.4431 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1517 | train_acc=0.5620 | val_acc=0.4405 | val_f1m=0.4285 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1529 | train_acc=0.5657 | val_acc=0.4706 | val_f1m=0.4644 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1494 | train_acc=0.5703 | val_acc=0.4563 | val_f1m=0.4499 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1427 | train_acc=0.5962 | val_acc=0.4603 | val_f1m=0.4591 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1433 | train_acc=0.5898 | val_acc=0.4706 | val_f1m=0.4690 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1396 | train_acc=0.5985 | val_acc=0.4524 | val_f1m=0.4514 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1383 | train_acc=0.6019 | val_acc=0.4571 | val_f1m=0.4549 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1348 | train_acc=0.6149 | val_acc=0.4452 | val_f1m=0.4436 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1321 | train_acc=0.6183 | val_acc=0.4587 | val_f1m=0.4580 | LR=0.000887\n",
      "  Early stopping en Ã©poca 21 (mejor val_f1m=0.4711)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4688\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.4781    0.6440    0.5488       441\n",
      "       right     0.5652    0.5011    0.5312       441\n",
      "  both fists     0.3958    0.3832    0.3894       441\n",
      "   both feet     0.4347    0.3469    0.3859       441\n",
      "\n",
      "    accuracy                         0.4688      1764\n",
      "   macro avg     0.4684    0.4688    0.4638      1764\n",
      "weighted avg     0.4684    0.4688    0.4638      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[284  39  81  37]\n",
      " [ 45 221  86  89]\n",
      " [135  64 169  73]\n",
      " [130  67  91 153]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  8.35it/s]\n",
      "Cargando val fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.32it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2276 | train_acc=0.2585 | val_acc=0.3087 | val_f1m=0.2695 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2024 | train_acc=0.3858 | val_acc=0.4190 | val_f1m=0.4108 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1844 | train_acc=0.4747 | val_acc=0.4278 | val_f1m=0.4153 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1797 | train_acc=0.4865 | val_acc=0.4532 | val_f1m=0.4504 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1768 | train_acc=0.4977 | val_acc=0.4429 | val_f1m=0.4408 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1736 | train_acc=0.5106 | val_acc=0.4881 | val_f1m=0.4896 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1730 | train_acc=0.5115 | val_acc=0.4683 | val_f1m=0.4640 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1681 | train_acc=0.5243 | val_acc=0.4611 | val_f1m=0.4504 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1666 | train_acc=0.5198 | val_acc=0.4659 | val_f1m=0.4626 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1624 | train_acc=0.5415 | val_acc=0.4571 | val_f1m=0.4561 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1594 | train_acc=0.5408 | val_acc=0.4619 | val_f1m=0.4616 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1576 | train_acc=0.5418 | val_acc=0.4833 | val_f1m=0.4862 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1551 | train_acc=0.5609 | val_acc=0.4556 | val_f1m=0.4568 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1526 | train_acc=0.5639 | val_acc=0.4595 | val_f1m=0.4597 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1483 | train_acc=0.5828 | val_acc=0.4611 | val_f1m=0.4616 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1500 | train_acc=0.5700 | val_acc=0.4548 | val_f1m=0.4485 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1449 | train_acc=0.5774 | val_acc=0.4349 | val_f1m=0.4342 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1433 | train_acc=0.5905 | val_acc=0.4532 | val_f1m=0.4466 | LR=0.000935\n",
      "  Early stopping en Ã©poca 18 (mejor val_f1m=0.4896)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.5185\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6715    0.5500    0.6047       420\n",
      "       right     0.5943    0.4952    0.5403       420\n",
      "  both fists     0.4135    0.6262    0.4981       420\n",
      "   both feet     0.4829    0.4024    0.4390       420\n",
      "\n",
      "    accuracy                         0.5185      1680\n",
      "   macro avg     0.5405    0.5185    0.5205      1680\n",
      "weighted avg     0.5405    0.5185    0.5205      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[231  14 126  49]\n",
      " [ 25 208 110  77]\n",
      " [ 47  55 263  55]\n",
      " [ 41  73 137 169]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  8.30it/s]\n",
      "Cargando val fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.34it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2276 | train_acc=0.2649 | val_acc=0.3000 | val_f1m=0.2215 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2103 | train_acc=0.3601 | val_acc=0.4802 | val_f1m=0.4749 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1945 | train_acc=0.4285 | val_acc=0.4944 | val_f1m=0.4835 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1885 | train_acc=0.4562 | val_acc=0.5206 | val_f1m=0.5210 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1837 | train_acc=0.4667 | val_acc=0.5079 | val_f1m=0.4916 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1812 | train_acc=0.4771 | val_acc=0.5413 | val_f1m=0.5343 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1780 | train_acc=0.4842 | val_acc=0.5365 | val_f1m=0.5381 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1809 | train_acc=0.4712 | val_acc=0.5206 | val_f1m=0.5238 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1747 | train_acc=0.4977 | val_acc=0.5484 | val_f1m=0.5462 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1704 | train_acc=0.5062 | val_acc=0.5468 | val_f1m=0.5491 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1673 | train_acc=0.5146 | val_acc=0.5341 | val_f1m=0.5374 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1689 | train_acc=0.5076 | val_acc=0.5587 | val_f1m=0.5575 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1646 | train_acc=0.5264 | val_acc=0.5492 | val_f1m=0.5518 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1632 | train_acc=0.5366 | val_acc=0.5611 | val_f1m=0.5638 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1608 | train_acc=0.5365 | val_acc=0.5429 | val_f1m=0.5460 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1588 | train_acc=0.5490 | val_acc=0.5365 | val_f1m=0.5318 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1572 | train_acc=0.5599 | val_acc=0.5651 | val_f1m=0.5648 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1539 | train_acc=0.5575 | val_acc=0.5484 | val_f1m=0.5494 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1512 | train_acc=0.5724 | val_acc=0.5508 | val_f1m=0.5508 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1456 | train_acc=0.5783 | val_acc=0.5365 | val_f1m=0.5316 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1471 | train_acc=0.5752 | val_acc=0.5190 | val_f1m=0.5147 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1405 | train_acc=0.5932 | val_acc=0.5437 | val_f1m=0.5437 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1419 | train_acc=0.5924 | val_acc=0.5103 | val_f1m=0.5121 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1386 | train_acc=0.6078 | val_acc=0.5373 | val_f1m=0.5389 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1326 | train_acc=0.6267 | val_acc=0.5111 | val_f1m=0.5094 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.1361 | train_acc=0.6090 | val_acc=0.5317 | val_f1m=0.5295 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.1316 | train_acc=0.6266 | val_acc=0.5040 | val_f1m=0.5023 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.1272 | train_acc=0.6358 | val_acc=0.5222 | val_f1m=0.5213 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.1211 | train_acc=0.6510 | val_acc=0.5214 | val_f1m=0.5221 | LR=0.000710\n",
      "  Early stopping en Ã©poca 29 (mejor val_f1m=0.5648)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6722    0.5810    0.6232       420\n",
      "       right     0.5876    0.6071    0.5972       420\n",
      "  both fists     0.4405    0.4762    0.4577       420\n",
      "   both feet     0.5035    0.5143    0.5088       420\n",
      "\n",
      "    accuracy                         0.5446      1680\n",
      "   macro avg     0.5509    0.5446    0.5467      1680\n",
      "weighted avg     0.5509    0.5446    0.5467      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[244  25  87  64]\n",
      " [ 18 255  80  67]\n",
      " [ 68  70 200  82]\n",
      " [ 33  84  87 216]]\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4700', '0.5454', '0.4688', '0.5185', '0.5446']\n",
      "Global mean ACC: 0.5095\n",
      "F1 folds (MACRO): ['0.4716', '0.5435', '0.4638', '0.5205', '0.5467']\n",
      "F1 mean (MACRO): 0.5092\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN+Transformer para MI (4 clases, 8 canales) con:\n",
    "# (1) Focal Loss, (3) BatchSampler balanceado clase+sujeto (solo train),\n",
    "# (6) LR warmup+cosine, early stopping por F1 macro,\n",
    "# y split train/val sujeto-aware por fold. Guarda curvas por fold y resumen final.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64        # mÃºltiplo de 4\n",
    "BASE_LR = 1e-3\n",
    "WARMUP_EPOCHS = 8\n",
    "PATIENCE = 12\n",
    "\n",
    "# Split de validaciÃ³n por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18  # â‰ˆ 18% de sujetos del train â†’ val\n",
    "VAL_STRAT_SUBJECT = True # split por sujetos (no mezcla muestras de un mismo sujeto)\n",
    "\n",
    "# Prepro\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA (sÃ³lo en TEST)\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.025, -0.0125, 0.0, 0.0125, 0.025]\n",
    "SW_LEN, SW_STRIDE = 2.0, 0.5\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\")\n",
    "print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X[mask])\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :]  = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X\n",
    "\n",
    "# =========================\n",
    "# MODELO\n",
    "# =========================\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            nn.BatchNorm1d(32), nn.ELU(),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "        self.pos_encoding = None\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "        z = self.encoder(z)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# (1) FOCAL LOSS\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# (3) SAMPLER BALANCEADO CLASE+SUJETO\n",
    "# =========================\n",
    "class ClassSubjectBalancedBatchSampler(BatchSampler):\n",
    "    def __init__(self, labels: np.ndarray, subjects: np.ndarray, batch_size: int,\n",
    "                 n_classes: int = 4, min_subjects_per_class: int = 2, generator=None):\n",
    "        assert batch_size % n_classes == 0, \"BATCH_SIZE debe ser mÃºltiplo de n_clases.\"\n",
    "        self.labels = labels.astype(int)\n",
    "        self.subjects = subjects.astype(int)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.per_class = batch_size // n_classes\n",
    "        self.min_subj = min_subjects_per_class\n",
    "        self.generator = generator if generator is not None else random.Random(RANDOM_STATE)\n",
    "        self.by_class = {c: {} for c in range(n_classes)}\n",
    "        for idx, (y, s) in enumerate(zip(self.labels, self.subjects)):\n",
    "            self.by_class[y].setdefault(s, []).append(idx)\n",
    "        for c in range(n_classes):\n",
    "            for s in self.by_class[c]:\n",
    "                self.generator.shuffle(self.by_class[c][s])\n",
    "        self.class_subjects = {c: list(self.by_class[c].keys()) for c in range(n_classes)}\n",
    "        for c in range(n_classes):\n",
    "            self.generator.shuffle(self.class_subjects[c])\n",
    "        self.num_batches = int(np.ceil(len(labels) / batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        cursors = {c: {s: 0 for s in self.class_subjects[c]} for c in range(self.n_classes)}\n",
    "        subj_ptr = {c: 0 for c in range(self.n_classes)}\n",
    "        for _ in range(self.num_batches):\n",
    "            batch = []\n",
    "            for c in range(self.n_classes):\n",
    "                subj_list = self.class_subjects[c]\n",
    "                if len(subj_list) == 0: continue\n",
    "                take_subj = min(max(self.min_subj, 1), len(subj_list), self.per_class)\n",
    "                base = self.per_class // take_subj\n",
    "                rem = self.per_class - base * take_subj\n",
    "                chosen = []\n",
    "                for k in range(take_subj):\n",
    "                    s_idx = (subj_ptr[c] + k) % len(subj_list)\n",
    "                    chosen.append(subj_list[s_idx])\n",
    "                subj_ptr[c] = (subj_ptr[c] + take_subj) % len(subj_list)\n",
    "                per_subj = {s: base for s in chosen}\n",
    "                for k in range(rem): per_subj[chosen[k % take_subj]] += 1\n",
    "                for s in chosen:\n",
    "                    want = per_subj[s]\n",
    "                    pool = self.by_class[c].get(s, [])\n",
    "                    cur = cursors[c].get(s, 0)\n",
    "                    taken = []\n",
    "                    for _t in range(want):\n",
    "                        if cur >= len(pool):\n",
    "                            if len(pool) == 0: break\n",
    "                            self.generator.shuffle(pool); cur = 0\n",
    "                        taken.append(pool[cur]); cur += 1\n",
    "                    cursors[c][s] = cur\n",
    "                    batch.extend(taken)\n",
    "            if len(batch) < self.batch_size:\n",
    "                all_idx = np.arange(len(self.labels))\n",
    "                need = self.batch_size - len(batch)\n",
    "                batch.extend(self.generator.choices(all_idx, k=need))\n",
    "            if len(batch) > self.batch_size:\n",
    "                batch = batch[:self.batch_size]\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS (ligeros)\n",
    "# =========================\n",
    "def augment_batch(xb, p_jitter=0.25, p_noise=0.25, p_chdrop=0.15,\n",
    "                  max_jitter_frac=0.02, noise_std=0.02):\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop:\n",
    "        k = 1\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL por FOLD (con train/val/test)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # Split de validaciÃ³n por sujetos (determinista)\n",
    "    rng = random.Random(RANDOM_STATE + fold)\n",
    "    tr_subjects = train_sub.copy()\n",
    "    rng.shuffle(tr_subjects)\n",
    "    n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "    val_subjects = sorted(tr_subjects[:n_val_subj])\n",
    "    train_subjects = sorted(tr_subjects[n_val_subj:])\n",
    "\n",
    "    # Carga TRAIN\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    # Carga VAL\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    # Carga TEST\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # NormalizaciÃ³n por canal (fit en TRAIN y aplicar a VAL/TEST)\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)  # reutiliza stats de train\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    # (3) Sampler balanceado en TRAIN\n",
    "    labels_np = y_tr\n",
    "    subjects_np = sub_tr\n",
    "    gen = random.Random(RANDOM_STATE + 100*fold)\n",
    "    batch_sampler = ClassSubjectBalancedBatchSampler(labels_np, subjects_np, batch_size=BATCH_SIZE,\n",
    "                                                     n_classes=4, min_subjects_per_class=2, generator=gen)\n",
    "    tr_ld  = DataLoader(tr_ds, batch_sampler=batch_sampler, worker_init_fn=seed_worker)\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # Modelo\n",
    "    model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                              n_layers=N_LAYERS, p_drop=P_DROP).to(device)\n",
    "\n",
    "    # Optimizador + (1) Focal Loss\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "\n",
    "    class_counts = np.bincount(y_tr, minlength=4).astype(np.float32)\n",
    "    inv = class_counts.sum() / (4.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    alpha_mean = alpha.mean().item()\n",
    "    alpha[2] = 1.22 * alpha_mean   # downweight leve para both_fists\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # (6) Warmup+Cosine\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # Entrenamiento con early stopping por F1 macro (en VAL)\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"lr\": []}\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        # ---- Val ----\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in val_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # Guarda mejor estado\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # ---- Guardar curva ----\n",
    "    fig = plt.figure(figsize=(8,4.5))\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_f1m\"], label=\"val_f1m\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_acc\"], label=\"val_acc\")\n",
    "    ax1.set_xlabel(\"Ã‰poca\"); ax1.set_title(f\"Fold {fold} â€” Curva de entrenamiento\")\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "    out_png = f\"training_curve_fold{fold}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.close(fig)\n",
    "    print(f\"â†³ Curva de entrenamiento guardada: {out_png}\")\n",
    "\n",
    "    # ---- EvaluaciÃ³n final en TEST (con TTA/subwindows si aplica) ----\n",
    "    model.eval()\n",
    "    # Estimar sfreq para TTA/subwindow\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        # longitud en puntos / duraciÃ³n ventana\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE == 'subwin':\n",
    "        logits = subwindow_logits(model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    elif SW_MODE == 'tta':\n",
    "        logits = time_shift_tta_logits(model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(gts, preds, labels=[0,1,2,3]))\n",
    "\n",
    "    return acc, f1m\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    acc_folds, f1_folds = [], []\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m = train_one_fold(fold, DEVICE)\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e063b44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.001 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1:   0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.31it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.37it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2252 | train_acc=0.2623 | val_acc=0.3333 | val_f1m=0.2658 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2027 | train_acc=0.3680 | val_acc=0.4857 | val_f1m=0.4747 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1827 | train_acc=0.4572 | val_acc=0.5286 | val_f1m=0.5237 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1775 | train_acc=0.4893 | val_acc=0.4968 | val_f1m=0.5010 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1710 | train_acc=0.5060 | val_acc=0.5476 | val_f1m=0.5431 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1712 | train_acc=0.4998 | val_acc=0.5373 | val_f1m=0.5388 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1694 | train_acc=0.5089 | val_acc=0.5222 | val_f1m=0.5286 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1691 | train_acc=0.5052 | val_acc=0.5016 | val_f1m=0.4929 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1673 | train_acc=0.5171 | val_acc=0.5135 | val_f1m=0.5114 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1623 | train_acc=0.5362 | val_acc=0.5159 | val_f1m=0.5154 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1618 | train_acc=0.5279 | val_acc=0.4913 | val_f1m=0.4903 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1572 | train_acc=0.5362 | val_acc=0.5183 | val_f1m=0.5202 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1589 | train_acc=0.5370 | val_acc=0.5048 | val_f1m=0.5087 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1568 | train_acc=0.5419 | val_acc=0.5310 | val_f1m=0.5302 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1534 | train_acc=0.5544 | val_acc=0.5357 | val_f1m=0.5354 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1536 | train_acc=0.5515 | val_acc=0.5310 | val_f1m=0.5360 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1500 | train_acc=0.5702 | val_acc=0.5294 | val_f1m=0.5327 | LR=0.000948\n",
      "  Early stopping en Ã©poca 17 (mejor val_f1m=0.5431)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4660\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5933    0.4399    0.5052       441\n",
      "       right     0.5197    0.5374    0.5284       441\n",
      "  both fists     0.3739    0.2789    0.3195       441\n",
      "   both feet     0.4110    0.6077    0.4904       441\n",
      "\n",
      "    accuracy                         0.4660      1764\n",
      "   macro avg     0.4745    0.4660    0.4609      1764\n",
      "weighted avg     0.4745    0.4660    0.4609      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[194  43  82 122]\n",
      " [ 28 237  66 110]\n",
      " [ 67  99 123 152]\n",
      " [ 38  77  58 268]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  8.39it/s]\n",
      "Cargando val fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.38it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2269 | train_acc=0.2653 | val_acc=0.3000 | val_f1m=0.1935 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2049 | train_acc=0.3605 | val_acc=0.4667 | val_f1m=0.4441 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1860 | train_acc=0.4449 | val_acc=0.5190 | val_f1m=0.5179 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1823 | train_acc=0.4582 | val_acc=0.4889 | val_f1m=0.4842 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1785 | train_acc=0.4712 | val_acc=0.4992 | val_f1m=0.4978 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1795 | train_acc=0.4670 | val_acc=0.4762 | val_f1m=0.4758 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1777 | train_acc=0.4739 | val_acc=0.5008 | val_f1m=0.5046 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1750 | train_acc=0.4790 | val_acc=0.4952 | val_f1m=0.5000 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1731 | train_acc=0.4956 | val_acc=0.5024 | val_f1m=0.5077 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1683 | train_acc=0.5020 | val_acc=0.4810 | val_f1m=0.4832 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1692 | train_acc=0.4906 | val_acc=0.4937 | val_f1m=0.4952 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1658 | train_acc=0.5103 | val_acc=0.5111 | val_f1m=0.4970 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1659 | train_acc=0.5060 | val_acc=0.4786 | val_f1m=0.4733 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1646 | train_acc=0.5115 | val_acc=0.4857 | val_f1m=0.4689 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1626 | train_acc=0.5226 | val_acc=0.5230 | val_f1m=0.5229 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1604 | train_acc=0.5274 | val_acc=0.4944 | val_f1m=0.4928 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1580 | train_acc=0.5330 | val_acc=0.5103 | val_f1m=0.5102 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1552 | train_acc=0.5343 | val_acc=0.5095 | val_f1m=0.5106 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1543 | train_acc=0.5448 | val_acc=0.4984 | val_f1m=0.4960 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1530 | train_acc=0.5517 | val_acc=0.5016 | val_f1m=0.5057 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1481 | train_acc=0.5595 | val_acc=0.5119 | val_f1m=0.5132 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1494 | train_acc=0.5551 | val_acc=0.4944 | val_f1m=0.4793 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1450 | train_acc=0.5688 | val_acc=0.4857 | val_f1m=0.4822 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1452 | train_acc=0.5640 | val_acc=0.5000 | val_f1m=0.5030 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1471 | train_acc=0.5597 | val_acc=0.5262 | val_f1m=0.5242 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.1408 | train_acc=0.5771 | val_acc=0.4984 | val_f1m=0.5002 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.1387 | train_acc=0.5846 | val_acc=0.5040 | val_f1m=0.5077 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.1369 | train_acc=0.5874 | val_acc=0.5032 | val_f1m=0.5074 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.1352 | train_acc=0.5958 | val_acc=0.5111 | val_f1m=0.5135 | LR=0.000710\n",
      "  Ã‰poca  30 | train_loss=0.1294 | train_acc=0.6134 | val_acc=0.5071 | val_f1m=0.5088 | LR=0.000684\n",
      "  Ã‰poca  31 | train_loss=0.1303 | train_acc=0.6201 | val_acc=0.4984 | val_f1m=0.5040 | LR=0.000658\n",
      "  Ã‰poca  32 | train_loss=0.1281 | train_acc=0.6102 | val_acc=0.4929 | val_f1m=0.4927 | LR=0.000631\n",
      "  Ã‰poca  33 | train_loss=0.1275 | train_acc=0.6103 | val_acc=0.5032 | val_f1m=0.5015 | LR=0.000604\n",
      "  Ã‰poca  34 | train_loss=0.1196 | train_acc=0.6372 | val_acc=0.4889 | val_f1m=0.4935 | LR=0.000577\n",
      "  Ã‰poca  35 | train_loss=0.1176 | train_acc=0.6445 | val_acc=0.4722 | val_f1m=0.4714 | LR=0.000550\n",
      "  Ã‰poca  36 | train_loss=0.1177 | train_acc=0.6507 | val_acc=0.4865 | val_f1m=0.4900 | LR=0.000523\n",
      "  Ã‰poca  37 | train_loss=0.1113 | train_acc=0.6549 | val_acc=0.4794 | val_f1m=0.4839 | LR=0.000496\n",
      "  Early stopping en Ã©poca 37 (mejor val_f1m=0.5242)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5374\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5383    0.6531    0.5902       441\n",
      "       right     0.6561    0.5624    0.6056       441\n",
      "  both fists     0.4350    0.5692    0.4931       441\n",
      "   both feet     0.5876    0.3651    0.4503       441\n",
      "\n",
      "    accuracy                         0.5374      1764\n",
      "   macro avg     0.5543    0.5374    0.5348      1764\n",
      "weighted avg     0.5543    0.5374    0.5348      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[288  19 106  28]\n",
      " [ 54 248  98  41]\n",
      " [106  40 251  44]\n",
      " [ 87  71 122 161]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.37it/s]\n",
      "Cargando val fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.37it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2267 | train_acc=0.2573 | val_acc=0.2508 | val_f1m=0.1168 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2075 | train_acc=0.3527 | val_acc=0.3770 | val_f1m=0.3656 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1819 | train_acc=0.4677 | val_acc=0.4127 | val_f1m=0.4029 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1715 | train_acc=0.5009 | val_acc=0.4413 | val_f1m=0.4353 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1680 | train_acc=0.5092 | val_acc=0.4405 | val_f1m=0.4346 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1712 | train_acc=0.4941 | val_acc=0.4603 | val_f1m=0.4574 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1654 | train_acc=0.5185 | val_acc=0.4286 | val_f1m=0.4211 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1628 | train_acc=0.5270 | val_acc=0.4651 | val_f1m=0.4652 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1575 | train_acc=0.5371 | val_acc=0.4492 | val_f1m=0.4514 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1560 | train_acc=0.5464 | val_acc=0.4738 | val_f1m=0.4755 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1547 | train_acc=0.5476 | val_acc=0.4365 | val_f1m=0.4282 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1531 | train_acc=0.5531 | val_acc=0.4587 | val_f1m=0.4594 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1505 | train_acc=0.5652 | val_acc=0.4603 | val_f1m=0.4563 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1509 | train_acc=0.5698 | val_acc=0.4413 | val_f1m=0.4377 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1497 | train_acc=0.5713 | val_acc=0.4333 | val_f1m=0.4210 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1459 | train_acc=0.5800 | val_acc=0.4603 | val_f1m=0.4484 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1432 | train_acc=0.5789 | val_acc=0.4460 | val_f1m=0.4419 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1420 | train_acc=0.5789 | val_acc=0.4698 | val_f1m=0.4711 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1432 | train_acc=0.5835 | val_acc=0.4516 | val_f1m=0.4466 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1379 | train_acc=0.5986 | val_acc=0.4540 | val_f1m=0.4539 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1389 | train_acc=0.5910 | val_acc=0.4563 | val_f1m=0.4591 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1362 | train_acc=0.5991 | val_acc=0.4563 | val_f1m=0.4584 | LR=0.000868\n",
      "  Early stopping en Ã©poca 22 (mejor val_f1m=0.4755)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4870\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5971    0.4739    0.5284       441\n",
      "       right     0.5778    0.5306    0.5532       441\n",
      "  both fists     0.3942    0.4898    0.4368       441\n",
      "   both feet     0.4338    0.4535    0.4435       441\n",
      "\n",
      "    accuracy                         0.4870      1764\n",
      "   macro avg     0.5007    0.4870    0.4905      1764\n",
      "weighted avg     0.5007    0.4870    0.4905      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[209  38 113  81]\n",
      " [ 19 234 105  83]\n",
      " [ 75  53 216  97]\n",
      " [ 47  80 114 200]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  8.45it/s]\n",
      "Cargando val fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.47it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2283 | train_acc=0.2651 | val_acc=0.2762 | val_f1m=0.1801 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2025 | train_acc=0.3741 | val_acc=0.3690 | val_f1m=0.3387 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1819 | train_acc=0.4641 | val_acc=0.4468 | val_f1m=0.4394 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1769 | train_acc=0.4842 | val_acc=0.4476 | val_f1m=0.4466 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1728 | train_acc=0.4902 | val_acc=0.4492 | val_f1m=0.4452 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1741 | train_acc=0.4951 | val_acc=0.4579 | val_f1m=0.4571 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1696 | train_acc=0.4988 | val_acc=0.4317 | val_f1m=0.4049 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1722 | train_acc=0.5056 | val_acc=0.4103 | val_f1m=0.3774 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1647 | train_acc=0.5242 | val_acc=0.4627 | val_f1m=0.4630 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1637 | train_acc=0.5264 | val_acc=0.4810 | val_f1m=0.4755 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1617 | train_acc=0.5292 | val_acc=0.4603 | val_f1m=0.4560 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1615 | train_acc=0.5303 | val_acc=0.4675 | val_f1m=0.4674 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1597 | train_acc=0.5270 | val_acc=0.4929 | val_f1m=0.4927 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1548 | train_acc=0.5536 | val_acc=0.4778 | val_f1m=0.4766 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1541 | train_acc=0.5492 | val_acc=0.4524 | val_f1m=0.4507 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1509 | train_acc=0.5634 | val_acc=0.4484 | val_f1m=0.4451 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1507 | train_acc=0.5602 | val_acc=0.4706 | val_f1m=0.4688 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1500 | train_acc=0.5546 | val_acc=0.4714 | val_f1m=0.4733 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1487 | train_acc=0.5602 | val_acc=0.4817 | val_f1m=0.4823 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1476 | train_acc=0.5734 | val_acc=0.4913 | val_f1m=0.4890 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1465 | train_acc=0.5641 | val_acc=0.4698 | val_f1m=0.4728 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1401 | train_acc=0.5919 | val_acc=0.4413 | val_f1m=0.4361 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1408 | train_acc=0.5882 | val_acc=0.4810 | val_f1m=0.4822 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1355 | train_acc=0.6059 | val_acc=0.4635 | val_f1m=0.4664 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1359 | train_acc=0.5951 | val_acc=0.4675 | val_f1m=0.4697 | LR=0.000806\n",
      "  Early stopping en Ã©poca 25 (mejor val_f1m=0.4927)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.5208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5944    0.6071    0.6007       420\n",
      "       right     0.6200    0.5167    0.5636       420\n",
      "  both fists     0.4305    0.6190    0.5078       420\n",
      "   both feet     0.4815    0.3405    0.3989       420\n",
      "\n",
      "    accuracy                         0.5208      1680\n",
      "   macro avg     0.5316    0.5208    0.5178      1680\n",
      "weighted avg     0.5316    0.5208    0.5178      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[255  18 109  38]\n",
      " [ 34 217 107  62]\n",
      " [ 67  39 260  54]\n",
      " [ 73  76 128 143]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  8.35it/s]\n",
      "Cargando val fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.42it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ã‰poca   1 | train_loss=0.2259 | train_acc=0.2584 | val_acc=0.2905 | val_f1m=0.1841 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2056 | train_acc=0.3554 | val_acc=0.4302 | val_f1m=0.4172 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1902 | train_acc=0.4361 | val_acc=0.4786 | val_f1m=0.4278 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1858 | train_acc=0.4531 | val_acc=0.5008 | val_f1m=0.4907 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1816 | train_acc=0.4589 | val_acc=0.5302 | val_f1m=0.5374 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1802 | train_acc=0.4697 | val_acc=0.5349 | val_f1m=0.5353 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1802 | train_acc=0.4596 | val_acc=0.5341 | val_f1m=0.5223 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1764 | train_acc=0.4767 | val_acc=0.5524 | val_f1m=0.5572 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1773 | train_acc=0.4690 | val_acc=0.5302 | val_f1m=0.5305 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1756 | train_acc=0.4723 | val_acc=0.5103 | val_f1m=0.5103 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1704 | train_acc=0.4963 | val_acc=0.5540 | val_f1m=0.5575 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1700 | train_acc=0.5079 | val_acc=0.5206 | val_f1m=0.5187 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1695 | train_acc=0.4946 | val_acc=0.5397 | val_f1m=0.5413 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1677 | train_acc=0.5107 | val_acc=0.5437 | val_f1m=0.5469 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1671 | train_acc=0.5077 | val_acc=0.5421 | val_f1m=0.5391 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1642 | train_acc=0.5180 | val_acc=0.5302 | val_f1m=0.5140 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1631 | train_acc=0.5177 | val_acc=0.5659 | val_f1m=0.5681 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1617 | train_acc=0.5278 | val_acc=0.5183 | val_f1m=0.5082 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1590 | train_acc=0.5319 | val_acc=0.5706 | val_f1m=0.5717 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1577 | train_acc=0.5343 | val_acc=0.5238 | val_f1m=0.5202 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1557 | train_acc=0.5378 | val_acc=0.5341 | val_f1m=0.5303 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1542 | train_acc=0.5368 | val_acc=0.5563 | val_f1m=0.5543 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1540 | train_acc=0.5443 | val_acc=0.5595 | val_f1m=0.5624 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1508 | train_acc=0.5569 | val_acc=0.5444 | val_f1m=0.5490 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1502 | train_acc=0.5551 | val_acc=0.5310 | val_f1m=0.5270 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.1466 | train_acc=0.5707 | val_acc=0.5325 | val_f1m=0.5380 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.1427 | train_acc=0.5658 | val_acc=0.5508 | val_f1m=0.5531 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.1407 | train_acc=0.5781 | val_acc=0.5651 | val_f1m=0.5671 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.1388 | train_acc=0.5872 | val_acc=0.5556 | val_f1m=0.5549 | LR=0.000710\n",
      "  Ã‰poca  30 | train_loss=0.1363 | train_acc=0.5891 | val_acc=0.5690 | val_f1m=0.5714 | LR=0.000684\n",
      "  Ã‰poca  31 | train_loss=0.1321 | train_acc=0.6082 | val_acc=0.5429 | val_f1m=0.5458 | LR=0.000658\n",
      "  Early stopping en Ã©poca 31 (mejor val_f1m=0.5717)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6335    0.6214    0.6274       420\n",
      "       right     0.5650    0.6310    0.5962       420\n",
      "  both fists     0.4820    0.4786    0.4803       420\n",
      "   both feet     0.5602    0.5095    0.5337       420\n",
      "\n",
      "    accuracy                         0.5601      1680\n",
      "   macro avg     0.5602    0.5601    0.5594      1680\n",
      "weighted avg     0.5602    0.5601    0.5594      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[261  31  74  54]\n",
      " [ 26 265  65  64]\n",
      " [ 83  86 201  50]\n",
      " [ 42  87  77 214]]\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4660', '0.5374', '0.4870', '0.5208', '0.5601']\n",
      "Global mean ACC: 0.5143\n",
      "F1 folds (MACRO): ['0.4609', '0.5348', '0.4905', '0.5178', '0.5594']\n",
      "F1 mean (MACRO): 0.5127\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN+Transformer para MI (4 clases, 8 canales) con:\n",
    "# (1) Focal Loss\n",
    "# (4) Aumentos mÃ¡s fuertes y estables\n",
    "# (6) LR warmup+cosine, early stopping por F1 macro\n",
    "# Split train/val sujeto-aware por fold. Guarda curvas por fold y resumen final.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64        # mÃºltiplo de 4\n",
    "BASE_LR = 1e-3\n",
    "WARMUP_EPOCHS = 8\n",
    "PATIENCE = 12\n",
    "\n",
    "# Split de validaciÃ³n por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18  # â‰ˆ 18% de sujetos del train â†’ val\n",
    "VAL_STRAT_SUBJECT = True # split por sujetos (no mezcla muestras de un mismo sujeto)\n",
    "\n",
    "# Prepro\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False       # <- dejamos apagado para ceÃ±irnos a 1/4/6\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA (sÃ³lo en TEST)\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.05, -0.025, 0.0, 0.025, 0.05]\n",
    "SW_LEN, SW_STRIDE = 4.5, 2.0\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\")\n",
    "print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X[mask])\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :]  = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X\n",
    "\n",
    "# =========================\n",
    "# MODELO\n",
    "# =========================\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.bn(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            nn.BatchNorm1d(32), nn.ELU(),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "        self.pos_encoding = None\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "        z = self.encoder(z)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# (1) FOCAL LOSS\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# (4) AUGMENTS MÃS FUERTES (pero estables)\n",
    "# =========================\n",
    "def augment_batch(\n",
    "    xb,\n",
    "    p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "    max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1\n",
    "):\n",
    "    \"\"\"\n",
    "    - jitter: shift temporal pequeÃ±o (Â±3% de la longitud)\n",
    "    - noise: ruido gaussiano leve\n",
    "    - chdrop: apagado de 1 canal aleatorio\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL por FOLD (con train/val/test)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    # --- sujetos por fold ---\n",
    "    def load_fold_subjects_local(folds_json: Path, fold: int):\n",
    "        return load_fold_subjects(folds_json, fold)\n",
    "\n",
    "    train_sub, test_sub = load_fold_subjects_local(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # Split de validaciÃ³n por sujetos (determinista)\n",
    "    rng = random.Random(RANDOM_STATE + fold)\n",
    "    tr_subjects = train_sub.copy()\n",
    "    rng.shuffle(tr_subjects)\n",
    "    n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "    val_subjects = sorted(tr_subjects[:n_val_subj])\n",
    "    train_subjects = sorted(tr_subjects[n_val_subj:])\n",
    "\n",
    "    # Carga TRAIN/VAL/TEST\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # NormalizaciÃ³n por canal (fit en TRAIN y aplicar a VAL/TEST)\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)  # reutiliza stats de train\n",
    "\n",
    "    # Datasets + DataLoaders (sin sampler especial, solo shuffle en TRAIN)\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # Modelo\n",
    "    model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                              n_layers=N_LAYERS, p_drop=P_DROP).to(device)\n",
    "\n",
    "    # Optimizador + (1) Focal Loss (ligero upweight a both_fists)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "\n",
    "    class_counts = np.bincount(y_tr, minlength=4).astype(np.float32)\n",
    "    inv = class_counts.sum() / (4.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    # Aumentamos un poco el peso de both_fists para mejorar su recall\n",
    "    alpha_mean = alpha.mean().item()\n",
    "    alpha[2] = 1.5 * alpha_mean\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # (6) Warmup+Cosine\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # Entrenamiento con early stopping por F1 macro (en VAL)\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"lr\": []}\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)  # (4) aumentos mÃ¡s fuertes\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        # ---- Val ----\n",
    "        model.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in val_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # Guarda mejor estado\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # ---- Guardar curva ----\n",
    "    fig = plt.figure(figsize=(8,4.5))\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_f1m\"], label=\"val_f1m\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_acc\"], label=\"val_acc\")\n",
    "    ax1.set_xlabel(\"Ã‰poca\"); ax1.set_title(f\"Fold {fold} â€” Curva de entrenamiento\")\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "    out_png = f\"training_curve_fold{fold}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.close(fig)\n",
    "    print(f\"â†³ Curva de entrenamiento guardada: {out_png}\")\n",
    "\n",
    "    # ---- EvaluaciÃ³n final en TEST (con TTA/subwindows si aplica) ----\n",
    "    model.eval()\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE == 'subwin':\n",
    "        logits = subwindow_logits(model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    elif SW_MODE == 'tta':\n",
    "        logits = time_shift_tta_logits(model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(gts, preds, labels=[0,1,2,3]))\n",
    "\n",
    "    return acc, f1m\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    acc_folds, f1_folds = [], []\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m = train_one_fold(fold, DEVICE)\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d949dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.001 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.06it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  7.47it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e56d872d7a49>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0macc_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0macc_folds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mf1_folds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{f1m:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e56d872d7a49>\u001b[0m in \u001b[0;36mtrain_one_fold\u001b[0;34m(fold, device)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;31m# Modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n\u001b[0;32m--> 585\u001b[0;31m                               n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;31m# Optimizador + (1) Focal Loss (ligero upweight a both_fists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# CNN+Transformer para MI (4 clases, 8 canales) con:\n",
    "# (1) Focal Loss\n",
    "# (4) Aumentos mÃ¡s fuertes y estables\n",
    "# (6) LR warmup+cosine, early stopping por F1 macro\n",
    "# Cambios propuestos:\n",
    "# - GroupNorm en conv (en lugar de BN)\n",
    "# - EMA de pesos para val/test\n",
    "# - Balanced sampler por sujeto/clase (WeightedRandomSampler)\n",
    "# - Dropout antes del encoder = 0.3\n",
    "# - Cosine min_factor=0.2\n",
    "# - Ensemble TTA + Subwindows en test (opcional)\n",
    "# - Val estratificada por sujeto (opcional)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64        # mÃºltiplo de 4\n",
    "BASE_LR = 1e-3\n",
    "WARMUP_EPOCHS = 8\n",
    "PATIENCE = 12\n",
    "\n",
    "# Split de validaciÃ³n por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18  # â‰ˆ 18% de sujetos del train â†’ val\n",
    "VAL_STRAT_SUBJECT = True # <- ACTIVADO: estratifica por etiqueta dominante de cada sujeto\n",
    "\n",
    "# Prepro\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False       # dejamos apagado para respetar tu setup original\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2            # dropout en conv stack\n",
    "P_DROP_ENCODER = 0.3    # dropout antes del encoder (â†‘ respecto a 0.2)\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA / SUBWINDOW en TEST\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.05, -0.025, 0.0, 0.025, 0.05]\n",
    "SW_LEN, SW_STRIDE = 4.5, 2.0\n",
    "COMBINE_TTA_AND_SUBWIN = True  # Promedia logits TTA y Subwindow (50/50) si True\n",
    "\n",
    "# Sampler balanceado\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# EMA\n",
    "USE_EMA = True\n",
    "EMA_DECAY = 0.999  # 0.999 ~ suave y efectivo\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\")\n",
    "print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "        sfreq = raw.info['sfreq']\n",
    "\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X[mask])\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :]  = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X\n",
    "\n",
    "# =========================\n",
    "# MODELO (GroupNorm en conv)\n",
    "# =========================\n",
    "def make_gn(num_channels, num_groups=8):\n",
    "    # Ajusta grupos para que dividan a num_channels\n",
    "    g = min(num_groups, num_channels)\n",
    "    while num_channels % g != 0 and g > 1:\n",
    "        g -= 1\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15, p_drop=p_drop),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7,  p_drop=p_drop),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)  # â†‘ 0.3\n",
    "        self.pos_encoding = None\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "        z = self.encoder(z)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# (1) FOCAL LOSS\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# (4) AUGMENTS MÃS FUERTES (pero estables)\n",
    "# =========================\n",
    "def augment_batch(\n",
    "    xb,\n",
    "    p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "    max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1\n",
    "):\n",
    "    \"\"\"\n",
    "    - jitter: shift temporal pequeÃ±o (Â±3% de la longitud)\n",
    "    - noise: ruido gaussiano leve\n",
    "    - chdrop: apagado de 1 canal aleatorio\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "# =========================\n",
    "# EMA de pesos\n",
    "# =========================\n",
    "class ModelEMA:\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.999, device=None):\n",
    "        self.ema = self._clone(model).to(device if device is not None else next(model.parameters()).device)\n",
    "        self.decay = decay\n",
    "        self._updates = 0\n",
    "        self.update(model, force=True)\n",
    "\n",
    "    def _clone(self, model):\n",
    "        ema = type(model)()\n",
    "        ema.load_state_dict(model.state_dict())\n",
    "        for p in ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        return ema\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module, force: bool = False):\n",
    "        d = self.decay\n",
    "        if self._updates < 200:\n",
    "            # warmup EMA decay para primeras iteraciones\n",
    "            d = 0.0 + (self._updates / 200.0) * self.decay\n",
    "        msd = model.state_dict()\n",
    "        esd = self.ema.state_dict()\n",
    "        for k in esd.keys():\n",
    "            if esd[k].dtype.is_floating_point:\n",
    "                esd[k].mul_(d).add_(msd[k].detach(), alpha=1.0 - d)\n",
    "            else:\n",
    "                esd[k] = msd[k]\n",
    "        self._updates += 1\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# Utilidades splits estratificados por sujeto\n",
    "# =========================\n",
    "def build_subject_label_map(subject_ids):\n",
    "    \"\"\"\n",
    "    Estima una etiqueta dominante por sujeto (argmax de su histograma de clases).\n",
    "    Se usa sÃ³lo para estratificar la selecciÃ³n de sujetos de validaciÃ³n.\n",
    "    \"\"\"\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=4)\n",
    "        y_dom = int(np.argmax(binc))\n",
    "        y_dom_list.append(y_dom)\n",
    "    return np.array(y_dom_list, dtype=int)\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL por FOLD (con train/val/test)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    # --- sujetos por fold ---\n",
    "    def load_fold_subjects_local(folds_json: Path, fold: int):\n",
    "        return load_fold_subjects(folds_json, fold)\n",
    "\n",
    "    train_sub, test_sub = load_fold_subjects_local(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # Split de validaciÃ³n por sujetos (determinista y opcionalmente estratificado)\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        # Reemplaza -1 (sujetos sin trials) por la moda para no romper el split\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        # sss.split(X, y) â€” X no importa, pasamos Ã­ndice\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # Carga TRAIN/VAL/TEST\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # NormalizaciÃ³n por canal (fit en TRAIN y aplicar a VAL/TEST)\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)  # reutiliza stats de train\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    # Weighted sampler por sujeto/clase\n",
    "    def make_weighted_sampler(dataset: TensorDataset):\n",
    "        Xb, yb, sb = dataset.tensors\n",
    "        yb_np = yb.numpy()\n",
    "        sb_np = sb.numpy()\n",
    "        # frec por sujeto\n",
    "        uniq_s, cnt_s = np.unique(sb_np, return_counts=True)\n",
    "        map_s = {s:c for s,c in zip(uniq_s, cnt_s)}\n",
    "        # frec por (sujeto,clase)\n",
    "        key = sb_np.astype(np.int64) * 10 + yb_np.astype(np.int64)  # asumiendo clases <10\n",
    "        uniq_k, cnt_k = np.unique(key, return_counts=True)\n",
    "        map_k = {k:c for k,c in zip(uniq_k, cnt_k)}\n",
    "        # peso = 1 / (frec_sujeto * frec_clase_en_sujeto)\n",
    "        w = []\n",
    "        for s, y in zip(sb_np, yb_np):\n",
    "            k = int(s)*10 + int(y)\n",
    "            ws = map_s[int(s)]\n",
    "            wk = map_k[k]\n",
    "            w.append(1.0 / (float(ws) * float(wk)))\n",
    "        w = np.array(w, dtype=np.float64)\n",
    "        w = w / (w.mean() + 1e-12)\n",
    "        sampler = WeightedRandomSampler(weights=torch.tensor(w, dtype=torch.double),\n",
    "                                        num_samples=len(yb_np), replacement=True)\n",
    "        return sampler\n",
    "\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        tr_sampler = make_weighted_sampler(tr_ds)\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, sampler=tr_sampler, drop_last=False, worker_init_fn=seed_worker)\n",
    "    else:\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # Modelo\n",
    "    model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                              n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "\n",
    "    # Optimizador + (1) Focal Loss (ligero upweight a both_fists)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "\n",
    "    class_counts = np.bincount(y_tr, minlength=4).astype(np.float32)\n",
    "    inv = class_counts.sum() / (4.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    # Aumentamos un poco el peso de both_fists para mejorar su recall\n",
    "    alpha_mean = alpha.mean().item()\n",
    "    alpha[2] = 1.5 * alpha_mean\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # (6) Warmup+Cosine (min_factor 0.2)\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.2\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # EMA\n",
    "    if USE_EMA:\n",
    "        ema = ModelEMA(model, decay=EMA_DECAY, device=device)\n",
    "    else:\n",
    "        ema = None\n",
    "\n",
    "    # Entrenamiento con early stopping por F1 macro (en VAL; usando EMA si estÃ¡ activo)\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"lr\": []}\n",
    "\n",
    "    def evaluate_on(loader, use_ema=True):\n",
    "        mdl = ema.ema if (ema is not None and use_ema) else model\n",
    "        mdl.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in loader:\n",
    "                xb = xb.to(device)\n",
    "                p = mdl(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "        return acc, f1m\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)  # (4) aumentos mÃ¡s fuertes\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            if ema is not None:\n",
    "                ema.update(model)\n",
    "\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        # ---- Val (con EMA si aplica) ----\n",
    "        acc, f1m = evaluate_on(val_ld, use_ema=True)\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            # guardamos el estado EMA si existe; si no, el del modelo\n",
    "            ref_model = ema.ema if ema is not None else model\n",
    "            best_state = {k: v.detach().cpu() for k, v in ref_model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # Cargamos mejor estado guardado (EMA si estaba activo)\n",
    "    if best_state is not None:\n",
    "        (ema.ema if (ema is not None) else model).load_state_dict(best_state)\n",
    "\n",
    "    # ---- Guardar curva ----\n",
    "    fig = plt.figure(figsize=(8,4.5))\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_f1m\"], label=\"val_f1m\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_acc\"], label=\"val_acc\")\n",
    "    ax1.set_xlabel(\"Ã‰poca\"); ax1.set_title(f\"Fold {fold} â€” Curva de entrenamiento\")\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "    out_png = f\"training_curve_fold{fold}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.close(fig)\n",
    "    print(f\"â†³ Curva de entrenamiento guardada: {out_png}\")\n",
    "\n",
    "    # ---- EvaluaciÃ³n final en TEST (con TTA/subwindows y ensemble si aplica) ----\n",
    "    eval_model = ema.ema if (ema is not None) else model\n",
    "    eval_model.eval()\n",
    "\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = eval_model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE in ('subwin', 'tta'):\n",
    "        logits_tta = None\n",
    "        logits_sw  = None\n",
    "        if SW_MODE == 'subwin':\n",
    "            logits_sw = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        elif SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "\n",
    "        if COMBINE_TTA_AND_SUBWIN:\n",
    "            if logits_tta is None:\n",
    "                logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "            if logits_sw is None:\n",
    "                logits_sw  = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "            logits = 0.5 * logits_tta + 0.5 * logits_sw\n",
    "        else:\n",
    "            logits = logits_tta if logits_tta is not None else logits_sw\n",
    "\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(gts, preds, labels=[0,1,2,3]))\n",
    "\n",
    "    return acc, f1m\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    acc_folds, f1_folds = [], []\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m = train_one_fold(fold, DEVICE)\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
