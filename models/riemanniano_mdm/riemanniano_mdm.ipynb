{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e51e8f7",
   "metadata": {},
   "source": [
    "### Bloque — Rutas y logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575c5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Riemann] data procesados → /root/Proyecto/EEG_Clasificador/data/processed\n",
      "[Riemann] figuras  → /root/Proyecto/EEG_Clasificador/models/riemanniano_mdm/figures\n",
      "[Riemann] tablas   → /root/Proyecto/EEG_Clasificador/models/riemanniano_mdm/tables\n",
      "[Riemann] logs     → /root/Proyecto/EEG_Clasificador/models/riemanniano_mdm/logs\n"
     ]
    }
   ],
   "source": [
    "# %% [Rutas & logger — modelo Riemanniano (MDM/FgMDM)]\n",
    "import sys, logging, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import mne\n",
    "\n",
    "# Este notebook está en: models/riemanniano_mdm/\n",
    "# PROJ -> raíz del repo\n",
    "PROJ = Path('..').resolve().parent          # .../models/riemanniano_mdm -> parent() = models -> parent() = <repo root>\n",
    "DATA_PROC = PROJ / 'data' / 'processed'     # datos preprocesados (S???_MI-epo.fif)\n",
    "\n",
    "# Salidas de este modelo (separadas)\n",
    "RIEM_OUT_ROOT = PROJ / 'models' / 'riemanniano_mdm'\n",
    "RIEM_FIG_DIR  = RIEM_OUT_ROOT / 'figures'\n",
    "RIEM_TAB_DIR  = RIEM_OUT_ROOT / 'tables'\n",
    "RIEM_LOG_DIR  = RIEM_OUT_ROOT / 'logs'\n",
    "for d in (RIEM_FIG_DIR, RIEM_TAB_DIR, RIEM_LOG_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[Riemann] data procesados → {DATA_PROC}\")\n",
    "print(f\"[Riemann] figuras  → {RIEM_FIG_DIR}\")\n",
    "print(f\"[Riemann] tablas   → {RIEM_TAB_DIR}\")\n",
    "print(f\"[Riemann] logs     → {RIEM_LOG_DIR}\")\n",
    "\n",
    "def _init_logger_riem(run_name: str):\n",
    "    \"\"\"\n",
    "    Logger propio del modelo riemanniano.\n",
    "    - Escribe a consola y a un TXT con timestamp en models/riemanniano_mdm/logs/.\n",
    "    - Silencia el ruido de MNE.\n",
    "    \"\"\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_path = RIEM_LOG_DIR / f\"{ts}_{run_name}.txt\"\n",
    "\n",
    "    logger = logging.getLogger(run_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.handlers.clear()\n",
    "\n",
    "    fmt = logging.Formatter(\"[%(asctime)s] %(levelname)s: %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "    ch = logging.StreamHandler(stream=sys.stdout); ch.setLevel(logging.INFO); ch.setFormatter(fmt)\n",
    "    fh = logging.FileHandler(log_path, encoding=\"utf-8\"); fh.setLevel(logging.INFO); fh.setFormatter(fmt)\n",
    "    logger.addHandler(ch); logger.addHandler(fh)\n",
    "\n",
    "    mne.set_log_level(\"ERROR\")\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"mne\")\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "    return logger, log_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bdd423",
   "metadata": {},
   "source": [
    "### Bloque - Helpers riemannianos (filtro-banco → covarianzas SPD → combinación “block”)\n",
    "\n",
    "Filtra por sub-bandas (mu/beta),\n",
    "\n",
    "Opcionalmente hace z-score por época,\n",
    "\n",
    "Calcula covarianzas (estables con shrinkage),\n",
    "\n",
    "Combina las sub-bandas en una covarianza bloque (SPD grande) para MDM/FgMDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25fa2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Helpers Riemann — FB covariances en bloque (MDM vs FgMDM)]\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Bandas por defecto (mu/beta denso)\n",
    "FB_BANDS_DENSE = [(f, f+2) for f in range(8, 30, 2)]\n",
    "FB_BANDS_CLASSIC = [(8,12), (12,16), (16,20), (20,24), (24,28), (28,30)]\n",
    "DEFAULT_FB_BANDS = FB_BANDS_DENSE\n",
    "\n",
    "# pyRiemann\n",
    "try:\n",
    "    from pyriemann.estimation import Covariances\n",
    "    from pyriemann.classification import MDM, FgMDM\n",
    "except ImportError:\n",
    "    raise ImportError(\"pyriemann no está instalado. Instala con: pip install pyriemann\")\n",
    "\n",
    "# Tokens motores (si quisieras recortar todavía más, aun cuando ya usas 8 canales)\n",
    "_RIEM_MOTOR_TOKENS = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "\n",
    "def _riem_find_motor_chs(ch_names, tokens=_RIEM_MOTOR_TOKENS):\n",
    "    up = [c.upper() for c in ch_names]\n",
    "    picks = []\n",
    "    for tok in tokens:\n",
    "        TU = tok.upper()\n",
    "        for i, name in enumerate(up):\n",
    "            if TU in name:\n",
    "                picks.append(i); break\n",
    "    return sorted(set(picks))\n",
    "\n",
    "def _riem_epochwise_zscore(X, eps=1e-8):\n",
    "    # No recomendado por defecto para Riemann; dejar False salvo diagnóstico\n",
    "    mean = X.mean(axis=-1, keepdims=True)\n",
    "    std  = X.std(axis=-1, keepdims=True)\n",
    "    return (X - mean) / (std + eps)\n",
    "\n",
    "def _riem_epochs_to_Xy(epochs):\n",
    "    X = epochs.get_data()  # (n_trials, n_ch, n_times)\n",
    "    inv = {v:k for k,v in epochs.event_id.items()}\n",
    "    y = np.array([inv[e[-1]] for e in epochs.events], dtype=object)\n",
    "    return X, y\n",
    "\n",
    "def _normalize_trace(C):\n",
    "    \"\"\"\n",
    "    Normaliza cada SPD por su traza para estabilizar escala.\n",
    "    Soporta shape (..., n_ch, n_ch) arbitraria.\n",
    "    \"\"\"\n",
    "    C = np.asarray(C, dtype=float)\n",
    "    tr = np.trace(C, axis1=-2, axis2=-1)\n",
    "    tr = np.where(tr == 0, 1.0, tr)\n",
    "    return C / tr[..., None, None]\n",
    "\n",
    "def _split_calibration(ep_te, k_per_class=5, shuffle=True, random_state=42, \n",
    "                       require_all_classes=False, return_indices=False):\n",
    "    \"\"\"\n",
    "    Divide un conjunto de épocas de TEST en:\n",
    "      - CALIB (k_per_class por clase)\n",
    "      - EVAL (el resto)\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    ep_te : mne.Epochs\n",
    "        Épocas del sujeto a partir de las cuales se hará calibración+evaluación.\n",
    "    k_per_class : int\n",
    "        Nº de épocas por clase que se irán a CALIB. Si <=0 → (None, ep_te).\n",
    "    shuffle : bool\n",
    "        Si True, baraja índices dentro de cada clase antes de tomar k.\n",
    "        (Recomendado para evitar sesgo por orden temporal).\n",
    "    random_state : int\n",
    "        Semilla para la aleatoriedad (si shuffle=True).\n",
    "    require_all_classes : bool\n",
    "        Si True, exige que TODAS las clases tengan al menos k épocas;\n",
    "        si alguna no alcanza, devuelve (None, ep_te).\n",
    "        Si False, usa min(k, n_clase) y continúa.\n",
    "    return_indices : bool\n",
    "        Si True, además devuelve (idx_calib, idx_eval, class_counts).\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    ep_calib : mne.Epochs or None\n",
    "    ep_eval  : mne.Epochs\n",
    "    (opcionales)\n",
    "    idx_calib : np.ndarray (int)\n",
    "    idx_eval  : np.ndarray (int)\n",
    "    class_counts : dict {code: (n_calib, n_eval, n_total)}\n",
    "    \"\"\"\n",
    "    if k_per_class <= 0:\n",
    "        if return_indices:\n",
    "            n = len(ep_te)\n",
    "            idx_all = np.arange(n)\n",
    "            labels = ep_te.events[:, -1]\n",
    "            counts = {int(c): (0, int((labels == c).sum()), int((labels == c).sum()))\n",
    "                      for c in np.unique(labels)}\n",
    "            return None, ep_te, np.array([], dtype=int), idx_all, counts\n",
    "        return None, ep_te\n",
    "\n",
    "    labels = ep_te.events[:, -1].astype(int)\n",
    "    classes = np.unique(labels)\n",
    "    rng = np.random.RandomState(random_state) if shuffle else None\n",
    "\n",
    "    calib_idx = []\n",
    "    eval_idx  = []\n",
    "    class_counts = {}\n",
    "\n",
    "    # Chequeo opcional: todas las clases deben tener >= k\n",
    "    if require_all_classes:\n",
    "        for c in classes:\n",
    "            n_c = int((labels == c).sum())\n",
    "            if n_c < k_per_class:\n",
    "                # no cumple el mínimo → no calibrar este sujeto\n",
    "                if return_indices:\n",
    "                    counts = {int(code): (0, int((labels == code).sum()), int((labels == code).sum()))\n",
    "                              for code in classes}\n",
    "                    return None, ep_te, np.array([], dtype=int), np.arange(len(ep_te)), counts\n",
    "                return None, ep_te\n",
    "\n",
    "    for c in classes:\n",
    "        idx_c = np.where(labels == c)[0]\n",
    "        if shuffle and len(idx_c) > 1:\n",
    "            rng.shuffle(idx_c)\n",
    "\n",
    "        take = min(k_per_class, len(idx_c))\n",
    "        sel = idx_c[:take]\n",
    "        rem = idx_c[take:]\n",
    "\n",
    "        if take > 0:\n",
    "            calib_idx.append(sel)\n",
    "        if len(rem) > 0:\n",
    "            eval_idx.append(rem)\n",
    "\n",
    "        class_counts[int(c)] = (int(take), int(len(rem)), int(len(idx_c)))\n",
    "\n",
    "    # Si no hay nada para calibrar, devolver (None, ep_te)\n",
    "    if len(calib_idx) == 0:\n",
    "        if return_indices:\n",
    "            idx_all = np.arange(len(ep_te))\n",
    "            return None, ep_te, np.array([], dtype=int), idx_all, class_counts\n",
    "        return None, ep_te\n",
    "\n",
    "    calib_idx = np.concatenate(calib_idx) if len(calib_idx) else np.array([], dtype=int)\n",
    "    eval_idx  = np.concatenate(eval_idx)  if len(eval_idx)  else np.array([], dtype=int)\n",
    "\n",
    "    # Ordenar índices para que cada subconjunto quede en orden cronológico\n",
    "    calib_idx.sort()\n",
    "    eval_idx.sort()\n",
    "\n",
    "    ep_calib = ep_te.copy()[calib_idx]\n",
    "    ep_eval  = ep_te.copy()[eval_idx] if len(eval_idx) > 0 else ep_te.copy()[[]]  # vacío si no hay eval\n",
    "\n",
    "    if return_indices:\n",
    "        return ep_calib, ep_eval, calib_idx, eval_idx, class_counts\n",
    "    return ep_calib, ep_eval\n",
    "\n",
    "\n",
    "\n",
    "def _riem_fb_covariances(epochs,\n",
    "                         fb_bands=DEFAULT_FB_BANDS,\n",
    "                         motor_only=False,\n",
    "                         zscore_epoch=False,\n",
    "                         crop_window=None,\n",
    "                         cov_estimator='oas',\n",
    "                         model='mdm'):\n",
    "    \"\"\"\n",
    "    Calcula covarianzas multi-banda:\n",
    "      - Para 'mdm' → devuelve cov bloque-diagonal: (n_trials, n_fb*n_ch, n_fb*n_ch)\n",
    "      - Para 'fgmdm' → devuelve pila por banda:    (n_trials, n_fb, n_ch, n_ch)\n",
    "    En ambos casos, se normaliza por traza banda a banda.\n",
    "\n",
    "    Retorna: C, y, classes\n",
    "    \"\"\"\n",
    "    ep = epochs.copy()\n",
    "    if crop_window is not None:\n",
    "        ep.crop(*crop_window)\n",
    "\n",
    "    if motor_only:\n",
    "        picks = _riem_find_motor_chs(ep.ch_names)\n",
    "        if picks:\n",
    "            ep.pick(picks)\n",
    "\n",
    "    X, y = _riem_epochs_to_Xy(ep)  # (n_trials, n_ch, n_times)\n",
    "    n_trials, n_ch, _ = X.shape\n",
    "    n_fb = len(fb_bands)\n",
    "\n",
    "    # 1) covarianzas por banda\n",
    "    covs_per_band = []\n",
    "    for (fmin, fmax) in fb_bands:\n",
    "        ep_b = ep.copy().filter(fmin, fmax, picks='eeg', verbose=False)\n",
    "        Xb = ep_b.get_data()  # (n_trials, n_ch, n_times)\n",
    "        if zscore_epoch:\n",
    "            Xb = _riem_epochwise_zscore(Xb)\n",
    "        Cb = Covariances(estimator=cov_estimator).fit_transform(Xb)  # (n_trials, n_ch, n_ch)\n",
    "        Cb = _normalize_trace(Cb)\n",
    "        covs_per_band.append(Cb)\n",
    "\n",
    "    if model.lower() == 'fgmdm':\n",
    "        # pila 4D: (n_trials, n_fb, n_ch, n_ch)\n",
    "        C = np.stack(covs_per_band, axis=1)\n",
    "    else:\n",
    "        # bloque-diagonal (n_trials, n_fb*n_ch, n_fb*n_ch)\n",
    "        C = np.zeros((n_trials, n_fb * n_ch, n_fb * n_ch), dtype=float)\n",
    "        for b, Cb in enumerate(covs_per_band):\n",
    "            i0 = b * n_ch\n",
    "            i1 = (b + 1) * n_ch\n",
    "            C[:, i0:i1, i0:i1] = Cb\n",
    "\n",
    "    classes = np.unique(y).tolist()\n",
    "    return C, y, classes\n",
    "\n",
    "def _riem_fb_cov_train_test(ep_tr, ep_te,\n",
    "                             fb_bands=DEFAULT_FB_BANDS,\n",
    "                             motor_only=False,\n",
    "                             zscore_epoch=False,\n",
    "                             crop_window=None,\n",
    "                             cov_estimator='oas',\n",
    "                             model='mdm'):\n",
    "    \"\"\"\n",
    "    Helper: saca cov multi-banda para TRAIN y TEST y alinea etiquetas con LabelEncoder.\n",
    "    - Para 'mdm'   → Ctr/Cte 3D (bloque-diagonal).\n",
    "    - Para 'fgmdm' → Ctr/Cte 4D (pila por banda).\n",
    "    \"\"\"\n",
    "    Ctr, y_tr, _ = _riem_fb_covariances(ep_tr, fb_bands, motor_only, zscore_epoch, crop_window, cov_estimator, model)\n",
    "    Cte, y_te, _ = _riem_fb_covariances(ep_te, fb_bands, motor_only, zscore_epoch, crop_window, cov_estimator, model)\n",
    "    le = LabelEncoder().fit(np.concatenate([y_tr, y_te]))\n",
    "    return Ctr, le.transform(y_tr), Cte, le.transform(y_te), list(le.classes_)\n",
    "\n",
    "def _to_block_if_4d(X):\n",
    "    \"\"\"\n",
    "    Si X viene 4D (n_trials, n_bands, n_ch, n_ch), lo convertimos\n",
    "    a bloque-diagonal 3D (n_trials, n_bands*n_ch, n_bands*n_ch).\n",
    "    Si ya es 3D, se devuelve tal cual.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 4:\n",
    "        n_trials, n_fb, n_ch, _ = X.shape\n",
    "        Xb = np.zeros((n_trials, n_fb * n_ch, n_fb * n_ch), dtype=X.dtype)\n",
    "        for b in range(n_fb):\n",
    "            i0, i1 = b * n_ch, (b + 1) * n_ch\n",
    "            Xb[:, i0:i1, i0:i1] = X[:, b, :, :]\n",
    "        return Xb\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54eb561",
   "metadata": {},
   "source": [
    "### Bloque — Clasificadores riemannianos (MDM y FgMDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9ead2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [CLF Riemann — MDM/FgMDM]\n",
    "def _riem_make_clf(model='mdm', metric='riemann'):\n",
    "    \"\"\"\n",
    "    Crea el clasificador riemanniano:\n",
    "      - 'mdm'   → Minimum Distance to Mean (metric='riemann' por defecto)\n",
    "      - 'fgmdm' → Filter-Geodesic MDM (agrega por banda en la geometría)\n",
    "    \"\"\"\n",
    "    model = (model or 'mdm').lower()\n",
    "    if model == 'fgmdm':\n",
    "        return FgMDM(metric=metric)\n",
    "    return MDM(metric=metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc69ea",
   "metadata": {},
   "source": [
    "### Bloque 4 — LOSO (todos) con MDM/FgMDM + calibración opcional\n",
    "\n",
    "LOSO clásico (sin calibración) = generalización pura inter-sujeto.\n",
    "\n",
    "Con calibración few-shot (calibrate_k_per_class > 0), se toman k épocas/clase del sujeto test para ajustar las medias riemannianas (MDM), lo que típicamente mejora ACC/F1 sin reentrenar toda la cadena (práctica común en el estado del arte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94050fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [INTER-SUBJECT Riemann desde JSON — validación por sujetos + calibración opcional]\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def run_inter_subject_riem_from_json(\n",
    "    fif_dir=DATA_PROC,\n",
    "    folds_json_path=None,\n",
    "    crop_window=(0.5, 3.5),\n",
    "    motor_only=True,\n",
    "    zscore_epoch=False,\n",
    "    fb_bands=DEFAULT_FB_BANDS,\n",
    "    cov_estimator='oas',\n",
    "    model='mdm',\n",
    "    calibrate_n=None,                 # calibración opcional con sujetos de TEST (modo antiguo)\n",
    "    calibrate_k_per_class=None,       # <<< NUEVO: calibración per-subject k épocas/clase\n",
    "    val_ratio_subjects=0.16,          # % sujetos de TRAIN a VALID\n",
    "    random_state=42,                  # reproducibilidad del split por sujeto\n",
    "    max_subplots_per_fig=12,\n",
    "    n_cols=4,\n",
    "    save_csv_name=None,\n",
    "    save_txt_name=None,\n",
    "    print_fold_classification_table=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Inter-subject CV Riemann con VALIDACIÓN INTERNA POR SUJETOS y calibración opcional.\n",
    "\n",
    "    Modos de calibración:\n",
    "      - Sin calibración: calibrate_n=None y calibrate_k_per_class=None o <=0.\n",
    "      - Calibración por sujetos completos (modo antiguo): calibrate_n>0.\n",
    "      - Calibración per-subject k-shots (RECOMENDADO): calibrate_k_per_class>0.\n",
    "        Para cada sujeto de TEST: toma k épocas por clase para calibrar (junto con TRAIN)\n",
    "        y evalúa en las épocas restantes de ese mismo sujeto.\n",
    "    \"\"\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_tag = f\"riem_inter_subject_{model}_{ts}\"\n",
    "    logger, log_path = _init_logger_riem(run_name=run_tag)\n",
    "\n",
    "    # Normalizar flags de calibración\n",
    "    k_cal = 0 if calibrate_k_per_class is None else int(calibrate_k_per_class)\n",
    "    subj_cal = 0 if calibrate_n is None else int(calibrate_n)\n",
    "    if k_cal > 0:\n",
    "        subj_cal = 0  # prioridad al modo per-subject\n",
    "        logger.info(f\"[RUN {run_tag}] VALID por sujetos + CALIBRACIÓN PER-SUBJECT (k={k_cal} por clase)\")\n",
    "    elif subj_cal > 0:\n",
    "        logger.info(f\"[RUN {run_tag}] VALID por sujetos + CALIBRACIÓN por sujetos completos (n={subj_cal})\")\n",
    "    else:\n",
    "        logger.info(f\"[RUN {run_tag}] VALID por sujetos (SIN calibración)\")\n",
    "\n",
    "    logger.info(\n",
    "        f\"Perillas: crop={crop_window}, motor_only={motor_only}, zscore_epoch={zscore_epoch}, \"\n",
    "        f\"fb_bands={fb_bands}, cov={cov_estimator}, val_ratio_subjects={val_ratio_subjects:.2f}\"\n",
    "    )\n",
    "\n",
    "    # ---------- JSON de folds ----------\n",
    "    if folds_json_path is None:\n",
    "        folds_json_path = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "    folds_json_path = Path(folds_json_path)\n",
    "    if not folds_json_path.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró folds JSON en {folds_json_path}\")\n",
    "\n",
    "    with open(folds_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "    folds = payload.get(\"folds\", [])\n",
    "    subject_ids_json = payload.get(\"subject_ids\", [])\n",
    "    logger.info(f\"Folds cargadas: {len(folds)} | sujetos en JSON: {len(subject_ids_json)}\")\n",
    "\n",
    "    # ---------- Cargar epochs por sujeto ----------\n",
    "    ep_map = {}\n",
    "    for sid in subject_ids_json:\n",
    "        fif_path = Path(fif_dir) / f\"{sid}_MI-epo.fif\"\n",
    "        if fif_path.exists():\n",
    "            try:\n",
    "                ep_map[sid] = mne.read_epochs(str(fif_path), preload=True, verbose=False)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error leyendo {fif_path} para {sid}: {e}\")\n",
    "        else:\n",
    "            logger.warning(f\"Falta archivo FIF para {sid}: {fif_path}\")\n",
    "\n",
    "    # ---------- Acumuladores ----------\n",
    "    rows = []\n",
    "    cm_items = []\n",
    "    cm_global = None\n",
    "    classes_global = None\n",
    "    per_fold_reports = []\n",
    "\n",
    "    # ---------- Iterar folds ----------\n",
    "    for f in folds:\n",
    "        fold_i = int(f.get(\"fold\"))\n",
    "        train_sids = [sid for sid in f.get(\"train\", []) if sid in ep_map]\n",
    "        test_sids  = [sid for sid in f.get(\"test\", [])  if sid in ep_map]\n",
    "\n",
    "        logger.info(f\"[Fold {fold_i}] train({len(train_sids)}): {train_sids}\")\n",
    "        logger.info(f\"[Fold {fold_i}] test ({len(test_sids)}): {test_sids}\")\n",
    "\n",
    "        if len(train_sids) == 0 or len(test_sids) == 0:\n",
    "            logger.warning(f\"[Fold {fold_i}] faltan sujetos train/test — saltando fold.\")\n",
    "            continue\n",
    "\n",
    "        # ---------- VALIDACIÓN INTERNA POR SUJETOS ----------\n",
    "        rng = np.random.RandomState(random_state + fold_i)\n",
    "        n_val_subj = max(1, int(round(len(train_sids) * float(val_ratio_subjects))))\n",
    "        val_indices = rng.choice(len(train_sids), size=n_val_subj, replace=False)\n",
    "        val_sids = sorted([train_sids[i] for i in val_indices])\n",
    "        tr_sids  = sorted([sid for sid in train_sids if sid not in set(val_sids)])\n",
    "\n",
    "        logger.info(f\"[Fold {fold_i}] split interno → train_sids={len(tr_sids)}, val_sids={len(val_sids)}\")\n",
    "\n",
    "        # Concatenar epochs por split\n",
    "        ep_tr  = mne.concatenate_epochs([ep_map[sid] for sid in tr_sids],  on_mismatch='ignore')\n",
    "        ep_val = mne.concatenate_epochs([ep_map[sid] for sid in val_sids], on_mismatch='ignore')\n",
    "        ep_te  = mne.concatenate_epochs([ep_map[sid] for sid in test_sids], on_mismatch='ignore')\n",
    "\n",
    "        # Alinear canales con respecto a train\n",
    "        try:\n",
    "            ep_val = ep_val.copy().reorder_channels(ep_tr.ch_names)\n",
    "            ep_te  = ep_te.copy().reorder_channels(ep_tr.ch_names)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"[Fold {fold_i}] reorder_channels: {e}\")\n",
    "\n",
    "        # Etiquetas\n",
    "        _, y_tr_str  = _riem_epochs_to_Xy(ep_tr)\n",
    "        _, y_val_str = _riem_epochs_to_Xy(ep_val)\n",
    "        _, y_te_str  = _riem_epochs_to_Xy(ep_te)\n",
    "\n",
    "        le = LabelEncoder().fit(np.concatenate([y_tr_str, y_val_str, y_te_str]))\n",
    "        y_tr  = le.transform(y_tr_str)\n",
    "        y_val = le.transform(y_val_str)\n",
    "        y_te  = le.transform(y_te_str)\n",
    "        classes = list(le.classes_)\n",
    "\n",
    "        if classes_global is None:\n",
    "            classes_global = classes\n",
    "            cm_global = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "\n",
    "        # ---------- FEATURES/ESPACIO (ajuste SOLO con TRAIN) ----------\n",
    "        with mne.utils.use_log_level(\"ERROR\"):\n",
    "            # Fit contra ep_tr; transformar ep_val (y ep_te si no hay calibración) con el MISMO ajuste\n",
    "            Ctr, y_tr_fit, Cval, y_val_fit, _ = _riem_fb_cov_train_test(\n",
    "                ep_tr, ep_val,\n",
    "                fb_bands=fb_bands,\n",
    "                motor_only=motor_only,\n",
    "                zscore_epoch=zscore_epoch,\n",
    "                crop_window=crop_window,\n",
    "                cov_estimator=cov_estimator,\n",
    "                model=model\n",
    "            )\n",
    "            _Ctr_dummy, _ytr_dummy, Cte, y_te_fit, _ = _riem_fb_cov_train_test(\n",
    "                ep_tr, ep_te,\n",
    "                fb_bands=fb_bands,\n",
    "                motor_only=motor_only,\n",
    "                zscore_epoch=zscore_epoch,\n",
    "                crop_window=crop_window,\n",
    "                cov_estimator=cov_estimator,\n",
    "                model=model\n",
    "            )\n",
    "\n",
    "        # Aplanar si viene 4D (banco) a 3D (apilado)\n",
    "        Ctr  = _to_block_if_4d(Ctr)\n",
    "        Cval = _to_block_if_4d(Cval)\n",
    "        Cte  = _to_block_if_4d(Cte)\n",
    "\n",
    "        # ---------- ENTRENAR CLASIFICADOR SOLO CON TRAIN ----------\n",
    "        clf = _riem_make_clf(model=model)\n",
    "        clf.fit(Ctr, y_tr_fit)\n",
    "\n",
    "        # ---------- VALID ----------\n",
    "        yhat_val = clf.predict(Cval)\n",
    "        acc_val = accuracy_score(y_val_fit, yhat_val)\n",
    "        f1m_val = f1_score(y_val_fit, yhat_val, average='macro')\n",
    "        logger.info(f\"[Fold {fold_i}] VAL   acc={acc_val:.4f} | f1m={f1m_val:.4f} | n_val={len(y_val_fit)}\")\n",
    "\n",
    "        # ---------- TEST: tres caminos ----------\n",
    "        if k_cal > 0:\n",
    "            # ===== Calibración per-subject k-shots =====\n",
    "            y_te_all, yhat_all = [], []\n",
    "            cm_fold = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "\n",
    "            for sid in test_sids:\n",
    "                ep_te_subj = ep_map[sid].copy()\n",
    "                try:\n",
    "                    ep_te_subj = ep_te_subj.reorder_channels(ep_tr.ch_names)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"[Fold {fold_i}] reorder (test subject {sid}): {e}\")\n",
    "\n",
    "                # Partir en CALIB vs EVAL (k por clase)\n",
    "                ep_calib, ep_eval = _split_calibration(ep_te_subj, k_per_class=k_cal)\n",
    "                if (ep_calib is None) or (len(ep_calib) == 0) or (len(ep_eval) == 0):\n",
    "                    logger.warning(f\"[Fold {fold_i}] {sid}: calibración insuficiente (k={k_cal}) o sin eval; se omite este sujeto.\")\n",
    "                    continue\n",
    "\n",
    "                # Etiquetas\n",
    "                _, y_calib_str = _riem_epochs_to_Xy(ep_calib)\n",
    "                _, y_eval_str  = _riem_epochs_to_Xy(ep_eval)\n",
    "                y_calib = le.transform(y_calib_str)\n",
    "                y_eval  = le.transform(y_eval_str)\n",
    "\n",
    "                # Refit espacio con TRAIN + CALIB_del_sujeto; transformar EVAL\n",
    "                with mne.utils.use_log_level(\"ERROR\"):\n",
    "                    ep_train_plus_calib = mne.concatenate_epochs([ep_tr, ep_calib], on_mismatch='ignore')\n",
    "                    Ctr_comb, y_tr_comb_fit, Ceval, y_eval_fit, _ = _riem_fb_cov_train_test(\n",
    "                        ep_train_plus_calib, ep_eval,\n",
    "                        fb_bands=fb_bands,\n",
    "                        motor_only=motor_only,\n",
    "                        zscore_epoch=zscore_epoch,\n",
    "                        crop_window=crop_window,\n",
    "                        cov_estimator=cov_estimator,\n",
    "                        model=model\n",
    "                    )\n",
    "                Ctr_comb = _to_block_if_4d(Ctr_comb)\n",
    "                Ceval    = _to_block_if_4d(Ceval)\n",
    "\n",
    "                clf_s = _riem_make_clf(model=model)\n",
    "                clf_s.fit(Ctr_comb, y_tr_comb_fit)\n",
    "                yhat_eval = clf_s.predict(Ceval)\n",
    "\n",
    "                # Acumular por sujeto\n",
    "                y_te_all.append(y_eval_fit)     # usar y_eval_fit alineado a Ceval\n",
    "                yhat_all.append(yhat_eval)\n",
    "                cm_s = confusion_matrix(y_eval_fit, yhat_eval, labels=np.arange(len(classes)))\n",
    "                cm_fold += cm_s\n",
    "                logger.info(f\"[Fold {fold_i}] TEST (per-subject k-shots) {sid} → acc={accuracy_score(y_eval_fit, yhat_eval):.4f}, n={len(y_eval_fit)}\")\n",
    "\n",
    "            if len(y_te_all) == 0:\n",
    "                logger.warning(f\"[Fold {fold_i}] Sin sujetos válidos para k-shots (k={k_cal}). Se usa modelo sin calibrar.\")\n",
    "                y_te_cat = y_te_fit\n",
    "                yhat_te  = clf.predict(Cte)\n",
    "                cm = confusion_matrix(y_te_cat, yhat_te, labels=np.arange(len(classes)))\n",
    "            else:\n",
    "                y_te_cat = np.concatenate(y_te_all)\n",
    "                yhat_te  = np.concatenate(yhat_all)\n",
    "                cm = cm_fold\n",
    "\n",
    "        elif subj_cal > 0:\n",
    "            # ===== Calibración por sujetos completos (modo antiguo) =====\n",
    "            n_subjs = min(int(subj_cal), len(test_sids))\n",
    "            if n_subjs >= len(test_sids):\n",
    "                logger.warning(f\"[Fold {fold_i}] calibrate_n ({subj_cal}) >= nº test_sids ({len(test_sids)}). Se reducirá a {len(test_sids)-1}.\")\n",
    "                n_subjs = max(0, len(test_sids) - 1)\n",
    "\n",
    "            calib_sids = test_sids[:n_subjs]\n",
    "            rest_sids  = test_sids[n_subjs:]\n",
    "\n",
    "            ep_calib   = mne.concatenate_epochs([ep_map[sid] for sid in calib_sids], on_mismatch='ignore') if calib_sids else None\n",
    "            ep_te_rest = mne.concatenate_epochs([ep_map[sid] for sid in rest_sids],  on_mismatch='ignore') if rest_sids else None\n",
    "\n",
    "            if (ep_calib is None) or (ep_te_rest is None):\n",
    "                y_te_cat = y_te_fit\n",
    "                yhat_te  = clf.predict(Cte)\n",
    "                cm = confusion_matrix(y_te_cat, yhat_te, labels=np.arange(len(classes)))\n",
    "            else:\n",
    "                try:\n",
    "                    ep_calib   = ep_calib.copy().reorder_channels(ep_tr.ch_names)\n",
    "                    ep_te_rest = ep_te_rest.copy().reorder_channels(ep_tr.ch_names)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"[Fold {fold_i}] reorder (calib/test_rest): {e}\")\n",
    "\n",
    "                with mne.utils.use_log_level(\"ERROR\"):\n",
    "                    ep_train_plus_calib = mne.concatenate_epochs([ep_tr, ep_calib], on_mismatch='ignore')\n",
    "                    Ctr_comb, y_tr_comb_fit, Cte_rest, y_te_rest_fit, _ = _riem_fb_cov_train_test(\n",
    "                        ep_train_plus_calib, ep_te_rest,\n",
    "                        fb_bands=fb_bands,\n",
    "                        motor_only=motor_only,\n",
    "                        zscore_epoch=zscore_epoch,\n",
    "                        crop_window=crop_window,\n",
    "                        cov_estimator=cov_estimator,\n",
    "                        model=model\n",
    "                    )\n",
    "                Ctr_comb = _to_block_if_4d(Ctr_comb)\n",
    "                Cte_rest = _to_block_if_4d(Cte_rest)\n",
    "\n",
    "                clf_c = _riem_make_clf(model=model)\n",
    "                clf_c.fit(Ctr_comb, y_tr_comb_fit)\n",
    "                yhat_te  = clf_c.predict(Cte_rest)\n",
    "                y_te_cat = y_te_rest_fit\n",
    "                cm = confusion_matrix(y_te_cat, yhat_te, labels=np.arange(len(classes)))\n",
    "        else:\n",
    "            # ===== Sin calibración =====\n",
    "            y_te_cat = y_te_fit\n",
    "            yhat_te  = clf.predict(Cte)\n",
    "            cm = confusion_matrix(y_te_cat, yhat_te, labels=np.arange(len(classes)))\n",
    "\n",
    "        # ---------- MÉTRICAS TEST ----------\n",
    "        acc = accuracy_score(y_te_cat, yhat_te)\n",
    "        f1m = f1_score(y_te_cat, yhat_te, average='macro')\n",
    "        cm_global += cm\n",
    "\n",
    "        # Reporte por fold\n",
    "        if print_fold_classification_table:\n",
    "            try:\n",
    "                rep = classification_report(y_te_cat, yhat_te, target_names=classes, digits=4)\n",
    "                print(f\"\\n[Fold {fold_i}/{len(folds)}] Classification report (TEST)\\n{rep}\")\n",
    "                logger.info(f\"[Fold {fold_i}] Classification report (TEST):\\n{rep}\")\n",
    "                per_fold_reports.append((fold_i, rep))\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"[Fold {fold_i}] classification_report error: {e}\")\n",
    "\n",
    "        rows.append(dict(\n",
    "            fold=int(fold_i),\n",
    "            train_subjects=\",\".join(tr_sids),\n",
    "            val_subjects=\",\".join(val_sids),\n",
    "            test_subjects=\",\".join(test_sids),\n",
    "            val_acc=float(acc_val),\n",
    "            val_f1_macro=float(f1m_val),\n",
    "            acc=float(acc),\n",
    "            f1_macro=float(f1m),\n",
    "            n_val=int(len(y_val_fit)),\n",
    "            n_test=int(len(y_te_cat)),\n",
    "            calibrate_mode=(\"k-per-class\" if k_cal > 0 else (\"subjects\" if subj_cal > 0 else \"none\")),\n",
    "            calibrate_param=(k_cal if k_cal > 0 else (subj_cal if subj_cal > 0 else 0))\n",
    "        ))\n",
    "        cm_items.append((f\"fold_{fold_i}\", cm, classes))\n",
    "\n",
    "    # ---------- Consolidados ----------\n",
    "    df_rows = pd.DataFrame(rows).sort_values(\"fold\") if rows else pd.DataFrame()\n",
    "    acc_mu   = float(df_rows['acc'].mean()) if not df_rows.empty else 0.0\n",
    "    f1_mu    = float(df_rows['f1_macro'].mean()) if not df_rows.empty else 0.0\n",
    "    val_mu   = float(df_rows['val_acc'].mean()) if not df_rows.empty else 0.0\n",
    "    valf1_mu = float(df_rows['val_f1_macro'].mean()) if not df_rows.empty else 0.0\n",
    "\n",
    "    if not df_rows.empty:\n",
    "        df_rows = pd.concat([df_rows, pd.DataFrame([{\n",
    "            'fold': 0,\n",
    "            'train_subjects': 'GLOBAL',\n",
    "            'val_subjects': 'GLOBAL',\n",
    "            'test_subjects': 'GLOBAL',\n",
    "            'val_acc': val_mu,\n",
    "            'val_f1_macro': valf1_mu,\n",
    "            'acc': acc_mu,\n",
    "            'f1_macro': f1_mu,\n",
    "            'n_val': int(df_rows['n_val'].sum()),\n",
    "            'n_test': int(df_rows['n_test'].sum()),\n",
    "            'calibrate_mode': df_rows['calibrate_mode'].mode()[0] if 'calibrate_mode' in df_rows else 'none',\n",
    "            'calibrate_param': int(df_rows['calibrate_param'].mean()) if 'calibrate_param' in df_rows else 0\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    # ---------- Guardar CSV/TXT ----------\n",
    "    out_csv = (RIEM_TAB_DIR / f\"{ts}_{save_csv_name}\") if save_csv_name \\\n",
    "              else (RIEM_TAB_DIR / f\"riem_inter_subject_{model}_{ts}.csv\")\n",
    "    df_rows.to_csv(out_csv, index=False)\n",
    "    logger.info(f\"CSV consolidado → {out_csv}\")\n",
    "    print(\"CSV consolidado →\", out_csv)\n",
    "\n",
    "    out_txt = (RIEM_LOG_DIR / f\"{ts}_{save_txt_name}\") if save_txt_name \\\n",
    "              else (RIEM_LOG_DIR / f\"riem_inter_subject_{model}_{ts}.txt\")\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"INTER-SUBJECT Riemann ({model}) — Con VALID interno por sujetos\\n\")\n",
    "        f.write(f\"Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Total filas: {len(df_rows)}\\n\\n\")\n",
    "        header = df_rows.columns.tolist()\n",
    "        f.write(\" | \".join(header) + \"\\n\")\n",
    "        f.write(\"-\" * 160 + \"\\n\")\n",
    "        for _, r in df_rows.iterrows():\n",
    "            vals = []\n",
    "            for kcol in header:\n",
    "                v = r[kcol]\n",
    "                if isinstance(v, float):\n",
    "                    vals.append(f\"{v:.4f}\")\n",
    "                elif isinstance(v, (np.integer,)):\n",
    "                    vals.append(str(int(v)))\n",
    "                else:\n",
    "                    vals.append(str(v))\n",
    "            f.write(\" | \".join(vals) + \"\\n\")\n",
    "    logger.info(f\"TXT consolidado → {out_txt}\")\n",
    "    print(\"TXT consolidado →\", out_txt)\n",
    "\n",
    "    # ---------- Mosaicos de confusión por fold ----------\n",
    "    if cm_items:\n",
    "        n = len(cm_items)\n",
    "        per_fig = max(1, int(max_subplots_per_fig))\n",
    "        n_figs = ceil(n / per_fig)\n",
    "\n",
    "        def _n_rows_for_count(count):\n",
    "            return ceil(count / n_cols)\n",
    "\n",
    "        for fig_idx in range(n_figs):\n",
    "            start = fig_idx * per_fig\n",
    "            end   = min((fig_idx + 1) * per_fig, n)\n",
    "            chunk = cm_items[start:end]\n",
    "            count = len(chunk)\n",
    "            n_rows = _n_rows_for_count(count)\n",
    "\n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(4.5*n_cols, 3.8*n_rows), dpi=140)\n",
    "            axes = np.atleast_2d(axes).flatten()\n",
    "            for ax_i, (label, cm_sum, classes) in enumerate(chunk):\n",
    "                ax = axes[ax_i]\n",
    "                disp = ConfusionMatrixDisplay(cm_sum, display_labels=classes)\n",
    "                disp.plot(ax=ax, cmap=\"Blues\", colorbar=False, values_format='d')\n",
    "                ax.set_title(f\"{label}\")\n",
    "                ax.set_xlabel(\"\"); ax.set_ylabel(\"\")\n",
    "            for j in range(ax_i + 1, len(axes)):\n",
    "                axes[j].axis(\"off\")\n",
    "\n",
    "            out_png = RIEM_FIG_DIR / f\"riem_inter_subject_confusions_{model}_{ts}_p{fig_idx+1}.png\"\n",
    "            fig.suptitle(f\"Inter-Subject Riemann ({model}) — Matrices de confusión (página {fig_idx+1}/{n_figs})\",\n",
    "                         y=0.995, fontsize=14)\n",
    "            fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "            fig.savefig(out_png)\n",
    "            plt.close(fig)\n",
    "            logger.info(f\"Figura consolidada → {out_png}\")\n",
    "            print(\"Figura consolidada →\", out_png)\n",
    "\n",
    "    # ---------- Matriz GLOBAL ----------\n",
    "    if cm_global is not None and classes_global is not None:\n",
    "        fig, ax = plt.subplots(figsize=(6.5, 5.2), dpi=140)\n",
    "        disp = ConfusionMatrixDisplay(cm_global, display_labels=classes_global)\n",
    "        disp.plot(ax=ax, cmap=\"Blues\", colorbar=True, values_format='d')\n",
    "        ax.set_title(f\"Inter-Subject Riemann ({model}) — Matriz de confusión GLOBAL\")\n",
    "        fig.tight_layout()\n",
    "        out_png_glob = RIEM_FIG_DIR / f\"riem_inter_subject_global_confusion_{model}_{ts}.png\"\n",
    "        fig.savefig(out_png_glob)\n",
    "        plt.close(fig)\n",
    "        logger.info(f\"Matriz GLOBAL → {out_png_glob}\")\n",
    "        print(\"Matriz GLOBAL →\", out_png_glob)\n",
    "\n",
    "    logger.info(f\"[GLOBAL] VAL_acc={val_mu:.3f} | VAL_f1m={valf1_mu:.3f} | TEST_acc={acc_mu:.3f} | TEST_f1m={f1_mu:.3f}\")\n",
    "    print(f\"[GLOBAL] VAL_acc={val_mu:.3f} | VAL_f1m={valf1_mu:.3f} | TEST_acc={acc_mu:.3f} | TEST_f1m={f1_mu:.3f}\")\n",
    "    logger.info(f\"Log global → {log_path}\")\n",
    "    print(f\"Log global → {log_path}\")\n",
    "\n",
    "    return df_rows.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74cbbf",
   "metadata": {},
   "source": [
    "### Bloque — Ejemplos\n",
    "\n",
    "Corre INTRA y LOSO con MDM (o FgMDM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] INFO: [RUN riem_inter_subject_fgmdm_20251030-001104] VALID por sujetos + CALIBRACIÓN PER-SUBJECT (k=5 por clase)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:[RUN riem_inter_subject_fgmdm_20251030-001104] VALID por sujetos + CALIBRACIÓN PER-SUBJECT (k=5 por clase)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] INFO: Perillas: crop=(0.5, 3.5), motor_only=True, zscore_epoch=False, fb_bands=[(8, 10), (10, 12), (12, 14), (14, 16), (16, 18), (18, 20), (20, 22), (22, 24), (24, 26), (26, 28), (28, 30)], cov=oas, val_ratio_subjects=0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:Perillas: crop=(0.5, 3.5), motor_only=True, zscore_epoch=False, fb_bands=[(8, 10), (10, 12), (12, 14), (14, 16), (16, 18), (18, 20), (20, 22), (22, 24), (24, 26), (26, 28), (28, 30)], cov=oas, val_ratio_subjects=0.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] INFO: Folds cargadas: 5 | sujetos en JSON: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:Folds cargadas: 5 | sujetos en JSON: 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] INFO: [Fold 1] train(82): ['S001', 'S002', 'S004', 'S005', 'S006', 'S007', 'S009', 'S010', 'S011', 'S012', 'S014', 'S015', 'S016', 'S017', 'S019', 'S020', 'S021', 'S022', 'S024', 'S025', 'S026', 'S027', 'S029', 'S030', 'S031', 'S032', 'S034', 'S035', 'S036', 'S037', 'S040', 'S041', 'S042', 'S043', 'S045', 'S046', 'S047', 'S048', 'S050', 'S051', 'S052', 'S053', 'S055', 'S056', 'S057', 'S058', 'S060', 'S061', 'S062', 'S063', 'S065', 'S066', 'S067', 'S068', 'S070', 'S071', 'S072', 'S073', 'S075', 'S076', 'S077', 'S078', 'S080', 'S081', 'S082', 'S083', 'S085', 'S086', 'S087', 'S090', 'S093', 'S094', 'S095', 'S096', 'S098', 'S099', 'S101', 'S102', 'S105', 'S106', 'S107', 'S108']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:[Fold 1] train(82): ['S001', 'S002', 'S004', 'S005', 'S006', 'S007', 'S009', 'S010', 'S011', 'S012', 'S014', 'S015', 'S016', 'S017', 'S019', 'S020', 'S021', 'S022', 'S024', 'S025', 'S026', 'S027', 'S029', 'S030', 'S031', 'S032', 'S034', 'S035', 'S036', 'S037', 'S040', 'S041', 'S042', 'S043', 'S045', 'S046', 'S047', 'S048', 'S050', 'S051', 'S052', 'S053', 'S055', 'S056', 'S057', 'S058', 'S060', 'S061', 'S062', 'S063', 'S065', 'S066', 'S067', 'S068', 'S070', 'S071', 'S072', 'S073', 'S075', 'S076', 'S077', 'S078', 'S080', 'S081', 'S082', 'S083', 'S085', 'S086', 'S087', 'S090', 'S093', 'S094', 'S095', 'S096', 'S098', 'S099', 'S101', 'S102', 'S105', 'S106', 'S107', 'S108']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] INFO: [Fold 1] test (21): ['S003', 'S008', 'S013', 'S018', 'S023', 'S028', 'S033', 'S039', 'S044', 'S049', 'S054', 'S059', 'S064', 'S069', 'S074', 'S079', 'S084', 'S091', 'S097', 'S103', 'S109']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:[Fold 1] test (21): ['S003', 'S008', 'S013', 'S018', 'S023', 'S028', 'S033', 'S039', 'S044', 'S049', 'S054', 'S059', 'S064', 'S069', 'S074', 'S079', 'S084', 'S091', 'S097', 'S103', 'S109']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] INFO: [Fold 1] split interno → train_sids=69, val_sids=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:[Fold 1] split interno → train_sids=69, val_sids=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:14:34] INFO: [Fold 1] VAL   acc=0.3839 | f1m=0.3799 | n_val=1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:[Fold 1] VAL   acc=0.3839 | f1m=0.3799 | n_val=1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:16:39] INFO: [Fold 1] TEST (per-subject k-shots) S003 → acc=0.2857, n=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:riem_inter_subject_fgmdm_20251030-001104:[Fold 1] TEST (per-subject k-shots) S003 → acc=0.2857, n=70\n"
     ]
    }
   ],
   "source": [
    "# %% [Ejemplos — Riemann]\n",
    "# INTRA — FgMDM (aprovecha mejor la estructura multi-banda), mismas bandas y setup\n",
    "# df_intra_fgmdm = run_intra_all_riem(\n",
    "#     fif_dir=DATA_PROC,\n",
    "#     k=5,\n",
    "#     random_state=42,\n",
    "#     crop_window=(0.5, 4.5),\n",
    "#     motor_only=True,\n",
    "#     zscore_epoch=False,\n",
    "#     fb_bands=DEFAULT_FB_BANDS,\n",
    "#     cov_estimator='oas',\n",
    "#     model='fgmdm',             # << FgMDM\n",
    "#     save_csv_name=\"riem_intra_fgmdm_optim.csv\",\n",
    "#     save_txt_name=\"riem_intra_fgmdm_optim.txt\"\n",
    "# )\n",
    "\n",
    "\n",
    "# LOSO — MDM, sin calibración\n",
    "df_inter_fgmdm = run_inter_subject_riem_from_json(\n",
    "    fif_dir=DATA_PROC,\n",
    "    folds_json_path=PROJ / 'models' / 'folds' / 'Kfold5.json',  # path a tu JSON de folds\n",
    "    crop_window=(0.5, 3.5),\n",
    "    motor_only=True,\n",
    "    zscore_epoch=False,\n",
    "    fb_bands=DEFAULT_FB_BANDS,\n",
    "    cov_estimator='oas',\n",
    "    model='fgmdm',                # << FgMDM\n",
    "    calibrate_k_per_class=5,                # calibración: 5 epochs por sujeto de test\n",
    "    max_subplots_per_fig=12,\n",
    "    n_cols=4,\n",
    "    save_csv_name=\"riem_inter_fgmdm_calib.csv\",\n",
    "    save_txt_name=\"riem_inter_fgmdm_calib.txt\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
