{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fe1413",
   "metadata": {},
   "source": [
    "# EEG Motor Imagery (Left/Right) — CNN + Transformer\n",
    "Este notebook entrena y evalúa un modelo CNN+Transformer para clasificación binaria (left/right)\n",
    "en EEG usando K-Fold por sujeto, con opciones de:\n",
    "- Preprocesamiento\n",
    "- Balanceo (WeightedRandomSampler)\n",
    "- EMA de pesos\n",
    "- Inferencia con TTA y/o subventanas\n",
    "- Interpretabilidad\n",
    "- Barrido de arquitectura y evaluación final 5-fold del mejor set de hiperparámetros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f54465",
   "metadata": {},
   "source": [
    "### Configuración Inicial y Reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959034aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random, copy, time, csv\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, classification_report,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from scipy import stats\n",
    "from sklearn.manifold import TSNE  # Añadido para t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccfe22",
   "metadata": {},
   "source": [
    "### Configuración de Reproducibilidad\n",
    "\n",
    "Esta sección establece las semillas y configuraciones necesarias para garantizar resultados reproducibles en el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7acf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Establece semillas para todas las bibliotecas de aleatoriedad\n",
    "    para garantizar reproducibilidad completa.\n",
    "    \"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"\n",
    "    Función para inicializar workers de DataLoader con semilla.\n",
    "    \"\"\"\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba0543",
   "metadata": {},
   "source": [
    "### Configuración de Hiperparámetros\n",
    "\n",
    "Definición de todos los hiperparámetros del modelo y preprocesamiento de datos EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca907ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Usando dispositivo: cuda\n",
      " INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto)\n",
      " Config: 2c (L/R), 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.0005 | ZSCORE_PER_EPOCH=False\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / '00_folds' / 'Kfold5.json'\n",
    "\n",
    "# Hiperparámetros de entrenamiento\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "BASE_LR = 5e-4\n",
    "WARMUP_EPOCHS = 4\n",
    "PATIENCE = 8\n",
    "\n",
    "# Split de validación por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18\n",
    "VAL_STRAT_SUBJECT = True\n",
    "\n",
    "# Prepro global\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Parámetros del modelo\n",
    "D_MODEL = 144\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 1\n",
    "P_DROP = 0.1\n",
    "P_DROP_ENCODER = 0.1\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA / SUBWINDOW en TEST\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.075, -0.05, -0.025, 0.0, 0.025, 0.05, 0.075]\n",
    "SW_LEN, SW_STRIDE = 4.5, 1.5\n",
    "COMBINE_TTA_AND_SUBWIN = False\n",
    "\n",
    "# Sampler balanceado\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# EMA (solo GLOBAL). En FT se desactiva.\n",
    "USE_EMA = True\n",
    "EMA_DECAY = 0.9995\n",
    "\n",
    "# Fine-tuning (por sujeto) — sigue activo, pero ahora con n_cls=2\n",
    "FT_N_FOLDS = 4\n",
    "FT_FREEZE_EPOCHS = 8\n",
    "FT_UNFREEZE_EPOCHS = 8\n",
    "FT_PATIENCE = 6\n",
    "FT_BATCH = 64\n",
    "FT_LR_HEAD = 1e-3\n",
    "FT_LR_BACKBONE = 2e-4\n",
    "FT_WD = 1e-3\n",
    "FT_AUG = dict(p_jitter=0.25, p_noise=0.25, p_chdrop=0.10, max_jitter_frac=0.02, noise_std=0.02, max_chdrop=1)\n",
    "\n",
    "# Configuración de sujetos y canales\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right']  # <-- 2 clases\n",
    "\n",
    "# Solo runs de imaginación L/R\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Usando dispositivo: {DEVICE}\")\n",
    "print(\" INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto)\")\n",
    "print(f\" Config: 2c (L/R), 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a5652",
   "metadata": {},
   "source": [
    "### Funciones de Utilidad para I/O\n",
    "\n",
    "Funciones para manejar la carga y normalización de datos EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06db0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza nombres de canales eliminando caracteres especiales.\n",
    "    \"\"\"\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    \"\"\"\n",
    "    Selecciona los 8 canales motores específicos del dataset.\n",
    "    \"\"\"\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    \"\"\"\n",
    "    Lista archivos EDF de imaginación motora para un sujeto.\n",
    "    \"\"\"\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    \"\"\"\n",
    "    Convierte ID de sujeto de string a entero.\n",
    "    \"\"\"\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    \"\"\"\n",
    "    Carga y preprocesa épocas EEG para un sujeto específico.\n",
    "    \"\"\"\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        # Usar SOLO runs L/R\n",
    "        if run not in IMAGERY_RUNS_LR:\n",
    "            continue\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "\n",
    "        sfreq = raw.info['sfreq']\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = np.array([0 if inv[c] == 'T1' else 1 for c in ev_codes], dtype=int)\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y_run)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    \"\"\"\n",
    "    Carga sujetos de train y test para un fold específico.\n",
    "    \"\"\"\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    \"\"\"\n",
    "    Estandariza datos por canal usando estadísticas del conjunto de entrenamiento.\n",
    "    \"\"\"\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :] = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77134da",
   "metadata": {},
   "source": [
    "### Arquitectura del Modelo: CNN + Transformer\n",
    "\n",
    "Implementación del modelo híbrido CNN-Transformer para clasificación de EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddb7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MODELO (GroupNorm en conv) con capturas y variaciones\n",
    "# =========================\n",
    "def make_gn(num_channels, num_groups=8):\n",
    "    \"\"\"\n",
    "    Crea capa GroupNorm adaptativa que garantiza divisibilidad.\n",
    "    \"\"\"\n",
    "    g = min(num_groups, num_channels)\n",
    "    while num_channels % g != 0 and g > 1:\n",
    "        g -= 1\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolución depthwise separable para reducción de parámetros.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class _CustomEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Capa personalizada del encoder Transformer con atención multi-cabeza.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout, batch_first, norm_first, return_attn=True):\n",
    "        super().__init__()\n",
    "        self.return_attn = return_attn\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "        self.norm_first = norm_first\n",
    "\n",
    "    def forward(self, src):\n",
    "        sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
    "        src = self.norm1(src + self.dropout1(sa_out))\n",
    "        ff = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = self.norm2(src + self.dropout2(ff))\n",
    "        return src, attn_weights  # [B, heads, T, T]\n",
    "\n",
    "class _CustomEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder Transformer compuesto por múltiples capas.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, src):\n",
    "        attn_list = []\n",
    "        out = src\n",
    "        for lyr in self.layers:\n",
    "            out, attn = lyr(out)\n",
    "            attn_list.append(attn)\n",
    "        return out, attn_list\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo híbrido CNN-Transformer para clasificación de señales EEG.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem convolucional inicial\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise separable\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head de clasificación\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        \"\"\"\n",
    "        Codificación posicional sinusoidal para secuencias.\n",
    "        \"\"\"\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Capas convolucionales\n",
    "        z = self.conv_t(x)           # (B, C', T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        \n",
    "        # Codificación posicional\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # Añadir token CLS\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)  # (B, 1+L, D)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        # Clasificación usando token CLS\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        \"\"\"\n",
    "        Retorna mapas de atención de la última pasada forward.\n",
    "        \"\"\"\n",
    "        return self._last_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac343e4",
   "metadata": {},
   "source": [
    "### Funciones de Pérdida y Aumentación de Datos\n",
    "\n",
    "Implementación de Focal Loss y técnicas de aumentación de datos para EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe5aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FOCAL LOSS (2 clases)\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss para manejar desbalance de clases.\n",
    "    Reduce la contribución de ejemplos fáciles y enfoca en los difíciles.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS\n",
    "# =========================\n",
    "def augment_batch(xb, p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "                  max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1):\n",
    "    \"\"\"\n",
    "    Aplica aumentación de datos a un batch de señales EEG.\n",
    "    Técnicas: jitter temporal, ruido gaussiano, drop de canales.\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "def augment_batch_ft(xb):\n",
    "    \"\"\"\n",
    "    Aplica aumentación específica para fine-tuning.\n",
    "    \"\"\"\n",
    "    return augment_batch(xb, **FT_AUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619874d",
   "metadata": {},
   "source": [
    "### EMA y Técnicas de Inferencia\n",
    "\n",
    "Implementación de Exponential Moving Average y técnicas de inferencia robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980460a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EMA de pesos (solo global)\n",
    "# =========================\n",
    "class ModelEMA:\n",
    "    \"\"\"\n",
    "    Exponential Moving Average para estabilizar el entrenamiento.\n",
    "    Mantiene una versión suavizada de los pesos del modelo.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.9995, device=None):\n",
    "        self.ema = self._clone(model).to(device if device is not None else next(model.parameters()).device)\n",
    "        self.decay = decay\n",
    "        self._updates = 0\n",
    "        self.update(model, force=True)\n",
    "\n",
    "    def _clone(self, model):\n",
    "        import copy\n",
    "        ema = copy.deepcopy(model)\n",
    "        for p in ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        return ema\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module, force: bool = False):\n",
    "        d = self.decay\n",
    "        if self._updates < 1000:\n",
    "            d = (self._updates / 1000.0) * self.decay\n",
    "        msd = model.state_dict()\n",
    "        esd = self.ema.state_dict()\n",
    "        for k in esd.keys():\n",
    "            if esd[k].dtype.is_floating_point:\n",
    "                esd[k].mul_(d).add_(msd[k].detach(), alpha=1.0 - d)\n",
    "            else:\n",
    "                esd[k] = msd[k]\n",
    "        self._updates += 1\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    \"\"\"\n",
    "    Inferencia usando subventanas para capturar información temporal.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(2, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    \"\"\"\n",
    "    Test Time Augmentation usando desplazamientos temporales.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72ab9f",
   "metadata": {},
   "source": [
    "### Métricas y Herramientas de Visualización\n",
    "\n",
    "Funciones para calcular métricas y visualizar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68aec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Métricas extendidas\n",
    "# =========================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula métricas extendidas de clasificación.\n",
    "    \"\"\"\n",
    "    prec_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec_macro  = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro   = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    TN0 = cm[1,1]; FP0 = cm[1,0]\n",
    "    spec0 = TN0 / (TN0 + FP0 + 1e-12)\n",
    "    TN1 = cm[0,0]; FP1 = cm[0,1]\n",
    "    spec1 = TN1 / (TN1 + FP1 + 1e-12)\n",
    "    spec_macro = (spec0 + spec1) / 2.0\n",
    "\n",
    "    recs = recall_score(y_true, y_pred, labels=[0,1], average=None, zero_division=0)\n",
    "    sens_macro = float(recs.mean())\n",
    "\n",
    "    return {\n",
    "        \"precision_macro\": float(prec_macro),\n",
    "        \"recall_macro\": float(rec_macro),\n",
    "        \"f1_macro\": float(f1_macro),\n",
    "        \"specificity_macro\": float(spec_macro),\n",
    "        \"sensitivity_macro\": float(sens_macro),\n",
    "        \"cm\": cm.tolist()\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Helper: matriz de confusión con anotaciones\n",
    "# =========================\n",
    "def plot_confusion_with_text(cm, class_names, title, out_path, cmap='Blues'):\n",
    "    \"\"\"\n",
    "    Plota matriz de confusión con valores anotados.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(4.8, 4.2))\n",
    "    im = ax.imshow(cm, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_xticks(range(len(class_names))); ax.set_xticklabels(class_names)\n",
    "    ax.set_yticks(range(len(class_names))); ax.set_yticklabels(class_names)\n",
    "\n",
    "    vmax = cm.max() if cm.size else 1\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]),\n",
    "                    ha='center', va='center',\n",
    "                    color='white' if cm[i, j] > vmax/2 else 'black',\n",
    "                    fontsize=11, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=140)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc2f68",
   "metadata": {},
   "source": [
    "### Herramientas de Interpretabilidad\n",
    "\n",
    "Funciones para analizar y visualizar el comportamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "213a71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FUNCIONES DE INTERPRETABILIDAD (SOLO LAS QUE PIDES)\n",
    "# =========================\n",
    "\n",
    "# ===== Saliency por canal =====\n",
    "def channel_saliency(model, xb, target_class=None):\n",
    "    \"\"\"\n",
    "    Importancia por canal basada en |∂score/∂x| promedio en el tiempo.\n",
    "    xb: tensor (1, C, T) en GPU.\n",
    "    Devuelve: vector (C,) normalizado [0,1].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    xb = xb.clone().detach().requires_grad_(True)\n",
    "\n",
    "    logits = model(xb)\n",
    "    if target_class is None:\n",
    "        cls = logits.argmax(1)\n",
    "    else:\n",
    "        cls = torch.tensor([int(target_class)], device=xb.device)\n",
    "    score = logits[0, cls]\n",
    "\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    if xb.grad is not None:\n",
    "        xb.grad.zero_()\n",
    "    score.backward()\n",
    "\n",
    "    grad = xb.grad.detach()[0]     # (C, T)\n",
    "    sal = grad.abs().mean(dim=1)   # (C,)\n",
    "    sal = (sal - sal.min()) / (sal.max() - sal.min() + 1e-8)\n",
    "    return sal.cpu().numpy()\n",
    "\n",
    "# ===== Topomaps =====\n",
    "def make_mne_info_8ch(sfreq: float):\n",
    "    \"\"\"\n",
    "    Crea un Info de MNE con tus 8 canales motores.\n",
    "    \"\"\"\n",
    "    info = mne.create_info(\n",
    "        ch_names=EXPECTED_8,\n",
    "        sfreq=float(sfreq),\n",
    "        ch_types=\"eeg\"\n",
    "    )\n",
    "    try:\n",
    "        montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "        info.set_montage(montage)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def plot_topomap_from_values(values, info, title: str, out_path: Path,\n",
    "                             cmap=\"Reds\", cbar_label=\"Value\",\n",
    "                             vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Dibuja y guarda un topomap dado un vector de valores por canal.\n",
    "    values: array (n_channels,)\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 4.0))\n",
    "    im, _ = mne.viz.plot_topomap(\n",
    "        values, info, axes=ax, show=False, cmap=cmap\n",
    "    )\n",
    "    if (vmin is not None) or (vmax is not None):\n",
    "        im.set_clim(vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    cbar = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "    cbar.set_label(cbar_label, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"↳ Topomap guardado: {out_path}\")\n",
    "\n",
    "# ===== -log10(p) análisis estadístico =====\n",
    "def compute_channel_pvalues_lr(X, y):\n",
    "    \"\"\"\n",
    "    P-values por canal para la diferencia left vs right.\n",
    "    Usa potencia media (X^2) promediada en el tiempo como feature.\n",
    "    X: (N, C, T)  | y: (N,) con labels 0=left, 1=right\n",
    "    Devuelve: vector (C,) con p-values (ttest_ind Welch).\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    left = X[y == 0]\n",
    "    right = X[y == 1]\n",
    "\n",
    "    if (left.size == 0) or (right.size == 0):\n",
    "        return np.ones(X.shape[1], dtype=float)\n",
    "\n",
    "    feat_left = (left ** 2).mean(axis=2)   # (N_left, C)\n",
    "    feat_right = (right ** 2).mean(axis=2)\n",
    "\n",
    "    pvals = []\n",
    "    for ch in range(feat_left.shape[1]):\n",
    "        _, p = stats.ttest_ind(\n",
    "            feat_left[:, ch],\n",
    "            feat_right[:, ch],\n",
    "            equal_var=False\n",
    "        )\n",
    "        pvals.append(p)\n",
    "    return np.array(pvals, dtype=float)\n",
    "\n",
    "# ===== t-SNE de CLS embeddings =====\n",
    "def compute_cls_embeddings(model, X_data, device):\n",
    "    \"\"\"\n",
    "    Calcula embeddings CLS del modelo.\n",
    "    X_data: (N, C, T)\n",
    "    Devuelve: (N, d_model) embeddings CLS\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_data), 64):\n",
    "            xb = torch.tensor(X_data[i:i+64], dtype=torch.float32, device=device)\n",
    "            # Pasar por el modelo completo para obtener CLS token\n",
    "            z = model.conv_t(xb)           # (B, C', T')\n",
    "            z = model.proj(z)              # (B, d_model, T')\n",
    "            z = z.transpose(1, 2)          # (B, T', d_model)\n",
    "            \n",
    "            # Añadir positional encoding (simulando forward)\n",
    "            B, L, D = z.shape\n",
    "            if model.pos_encoding is None or model.pos_encoding.shape[0] != L or model.pos_encoding.shape[1] != D:\n",
    "                pos_enc = model._positional_encoding(L, D).to(z.device)\n",
    "            else:\n",
    "                pos_enc = model.pos_encoding\n",
    "            z = z + pos_enc[None, :, :]\n",
    "            \n",
    "            # Añadir CLS token y pasar por encoder\n",
    "            cls_tok = model.cls.expand(B, -1, -1)\n",
    "            z_with_cls = torch.cat([cls_tok, z], dim=1)  # (B, 1+L, D)\n",
    "            \n",
    "            # Pasar por encoder (solo necesitamos CLS)\n",
    "            z_encoder, _ = model.encoder(z_with_cls)\n",
    "            cls_embedding = z_encoder[:, 0, :]  # CLS token (B, D)\n",
    "            embeddings.append(cls_embedding.cpu().numpy())\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings\n",
    "\n",
    "def compute_tsne_embeddings(model, X_data, device, n_components=2, perplexity=30):\n",
    "    \"\"\"\n",
    "    Calcula embeddings CLS y luego aplica t-SNE.\n",
    "    X_data: (N, C, T)\n",
    "    \"\"\"\n",
    "    # Obtener embeddings CLS\n",
    "    embeddings = compute_cls_embeddings(model, X_data, device)\n",
    "    \n",
    "    # Aplicar t-SNE\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, \n",
    "                random_state=RANDOM_STATE, init='pca', n_iter=1000)\n",
    "    tsne_result = tsne.fit_transform(embeddings)\n",
    "    return tsne_result, embeddings\n",
    "\n",
    "def plot_tsne(tsne_result, y_true, title, out_path: Path):\n",
    "    \"\"\"\n",
    "    Grafica t-SNE con colores según clase.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    \n",
    "    # Colores para cada clase\n",
    "    colors = ['green', 'blue']  # 0:left (verde), 1:right (azul)\n",
    "    \n",
    "    for cls_idx in range(2):\n",
    "        mask = y_true == cls_idx\n",
    "        if mask.any():\n",
    "            ax.scatter(tsne_result[mask, 0], tsne_result[mask, 1], \n",
    "                      c=colors[cls_idx], label=CLASS_NAMES[cls_idx], \n",
    "                      alpha=0.7, s=25, edgecolors='w', linewidth=0.5)\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(\"t-SNE 1\")\n",
    "    ax.set_ylabel(\"t-SNE 2\")\n",
    "    ax.legend(title=\"Clase\", fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Añadir información adicional\n",
    "    n_samples = len(y_true)\n",
    "    n_left = np.sum(y_true == 0)\n",
    "    n_right = np.sum(y_true == 1)\n",
    "    info_text = f\"Total: {n_samples} | Left: {n_left} | Right: {n_right}\"\n",
    "    ax.text(0.02, 0.98, info_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"↳ t-SNE (CLS embeddings) guardado: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7e8e",
   "metadata": {},
   "source": [
    "### Métricas de Consumo y Hiperparámetros\n",
    "\n",
    "Funciones para calcular consumo computacional y gestionar hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3dc0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Consumo / hiperparámetros\n",
    "# =========================\n",
    "def count_params(model, trainable_only=False):\n",
    "    \"\"\"\n",
    "    Cuenta parámetros del modelo.\n",
    "    \"\"\"\n",
    "    if trainable_only:\n",
    "        return int(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    return int(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "def estimate_transformer_flops(L, d, n_heads, n_layers):\n",
    "    \"\"\"\n",
    "    Estima FLOPs del encoder Transformer.\n",
    "    \"\"\"\n",
    "    d_ff = 2*d\n",
    "    proj = 4 * L * (d*d)         # Q,K,V,Out\n",
    "    attn = 2 * (L*L*d)           # scores + aplicar a V\n",
    "    ff   = 2 * L * (d * d_ff)    # FFN (2 lineales)\n",
    "    return n_layers * (proj + attn + ff)\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_latency(model, X_sample, device, n_warm=10, n_runs=50):\n",
    "    \"\"\"\n",
    "    Mide latencia de inferencia del modelo.\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(X_sample):\n",
    "        xb = X_sample.clone().detach().to(device)\n",
    "    else:\n",
    "        xb = torch.tensor(X_sample, dtype=torch.float32, device=device).clone().detach()\n",
    "\n",
    "    for _ in range(n_warm):\n",
    "        _ = model(xb)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(n_runs):\n",
    "        _ = model(xb)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    return (time.time() - t0) / n_runs\n",
    "\n",
    "def current_hparams():\n",
    "    \"\"\"\n",
    "    Retorna diccionario con todos los hiperparámetros actuales.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"EPOCHS\": EPOCHS, \"BATCH_SIZE\": BATCH_SIZE, \"BASE_LR\": BASE_LR,\n",
    "        \"WARMUP_EPOCHS\": WARMUP_EPOCHS, \"PATIENCE\": PATIENCE,\n",
    "        \"RESAMPLE_HZ\": RESAMPLE_HZ, \"DO_NOTCH\": DO_NOTCH, \"DO_BANDPASS\": DO_BANDPASS,\n",
    "        \"BP_LO\": BP_LO, \"BP_HI\": BP_HI, \"DO_CAR\": DO_CAR, \"ZSCORE_PER_EPOCH\": ZSCORE_PER_EPOCH,\n",
    "        \"D_MODEL\": D_MODEL, \"N_HEADS\": N_HEADS, \"N_LAYERS\": N_LAYERS,\n",
    "        \"P_DROP\": P_DROP, \"P_DROP_ENCODER\": P_DROP_ENCODER,\n",
    "        \"TMIN\": TMIN, \"TMAX\": TMAX, \"SW_MODE\": SW_MODE, \"SW_ENABLE\": SW_ENABLE,\n",
    "        \"TTA_SHIFTS_S\": TTA_SHIFTS_S, \"SW_LEN\": SW_LEN, \"SW_STRIDE\": SW_STRIDE,\n",
    "        \"COMBINE_TTA_AND_SUBWIN\": COMBINE_TTA_AND_SUBWIN,\n",
    "        \"USE_WEIGHTED_SAMPLER\": USE_WEIGHTED_SAMPLER,\n",
    "        \"USE_EMA\": USE_EMA, \"EMA_DECAY\": EMA_DECAY,\n",
    "        \"FT_N_FOLDS\": FT_N_FOLDS, \"FT_FREEZE_EPOCHS\": FT_FREEZE_EPOCHS, \"FT_UNFREEZE_EPOCHS\": FT_UNFREEZE_EPOCHS,\n",
    "        \"FT_PATIENCE\": FT_PATIENCE, \"FT_BATCH\": FT_BATCH, \"FT_LR_HEAD\": FT_LR_HEAD,\n",
    "        \"FT_LR_BACKBONE\": FT_LR_BACKBONE, \"FT_WD\": FT_WD, \"FT_AUG\": FT_AUG,\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Helpers de salida/archivos\n",
    "# =========================\n",
    "def ensure_dir(p: Path):\n",
    "    \"\"\"\n",
    "    Crea directorio si no existe.\n",
    "    \"\"\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def make_run_dirs(base_dir: Path, tag: str, fold: int):\n",
    "    \"\"\"\n",
    "    Devuelve (run_dir, fold_dir).\n",
    "    \"\"\"\n",
    "    run_dir = ensure_dir(base_dir / tag)\n",
    "    fold_dir = ensure_dir(run_dir / f\"fold{fold}\")\n",
    "    return run_dir, fold_dir\n",
    "\n",
    "def save_csv_rows(csv_path: Path, fieldnames: list, rows: list):\n",
    "    \"\"\"\n",
    "    Guarda filas en archivo CSV.\n",
    "    \"\"\"\n",
    "    write_header = not csv_path.exists()\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if write_header:\n",
    "            w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbf6b0",
   "metadata": {},
   "source": [
    "### Función Principal de Entrenamiento\n",
    "\n",
    "Función que entrena un fold completo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9773a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TRAIN/EVAL GLOBAL POR FOLD\n",
    "# =========================\n",
    "def train_one_fold(\n",
    "    fold:int,\n",
    "    device,\n",
    "    model_factory=None,\n",
    "    run_tag=\"base\",\n",
    "    out_dir: Path = None,\n",
    "    seed=None,\n",
    "    save_artifacts: bool = True,  \n",
    "    do_ft: bool = True            \n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa el modelo para un fold específico.\n",
    "    \n",
    "    Args:\n",
    "        fold: Número del fold (1-5)\n",
    "        device: Dispositivo para entrenamiento (CPU/GPU)\n",
    "        model_factory: Función que crea instancia del modelo\n",
    "        run_tag: Identificador de la ejecución\n",
    "        out_dir: Directorio de salida\n",
    "        seed: Semilla para reproducibilidad\n",
    "        save_artifacts: Si guarda artefactos de entrenamiento\n",
    "        do_ft: Si realiza fine-tuning por sujeto\n",
    "    \"\"\"\n",
    "    # Semilla fija por corrida (justa entre combos/folds)\n",
    "    base = RANDOM_STATE if seed is None else int(seed)\n",
    "    seed_everything(base)\n",
    "\n",
    "    def load_fold_subjects_local(folds_json: Path, fold: int):\n",
    "        return load_fold_subjects(folds_json, fold)\n",
    "\n",
    "    # --- directorios de salida ---\n",
    "    if save_artifacts:\n",
    "        base_out = Path(\".\") if out_dir is None else Path(out_dir)\n",
    "        run_dir, fold_dir = make_run_dirs(base_out, run_tag, fold)\n",
    "        print(f\"[IO] Guardando artefactos en: {fold_dir.resolve()}\")\n",
    "    else:\n",
    "        run_dir = None\n",
    "        fold_dir = None\n",
    "        print(\"[LITE] GridSearch: no se guardarán artefactos por combinación.\")\n",
    "\n",
    "    # --- split de sujetos ---\n",
    "    train_sub, test_sub = load_fold_subjects_local(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # --- carga de datos ---\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # Normalización por canal\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    # Weighted sampler\n",
    "    def make_weighted_sampler(dataset: TensorDataset):\n",
    "        _Xb, yb, sb = dataset.tensors\n",
    "        yb_np = yb.numpy()\n",
    "        sb_np = sb.numpy()\n",
    "        uniq_s, cnt_s = np.unique(sb_np, return_counts=True)\n",
    "        map_s = {s:c for s,c in zip(uniq_s, cnt_s)}\n",
    "        key = sb_np.astype(np.int64) * 10 + yb_np.astype(np.int64)\n",
    "        uniq_k, cnt_k = np.unique(key, return_counts=True)\n",
    "        map_k = {k:c for k,c in zip(uniq_k, cnt_k)}\n",
    "        a, b = 0.8, 1.0\n",
    "        w = []\n",
    "        for s, y in zip(sb_np, yb_np):\n",
    "            k = int(s)*10 + int(y)\n",
    "            ws = float(map_s[int(s)])\n",
    "            wk = float(map_k[k])\n",
    "            w.append((ws ** (-a)) * (wk ** (-b)))\n",
    "        w = np.array(w, dtype=np.float64)\n",
    "        w = w / (w.mean() + 1e-12)\n",
    "        sampler = WeightedRandomSampler(weights=torch.tensor(w, dtype=torch.double),\n",
    "                                        num_samples=len(yb_np), replacement=True)\n",
    "        return sampler\n",
    "\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        tr_sampler = make_weighted_sampler(tr_ds)\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, sampler=tr_sampler, drop_last=False, worker_init_fn=seed_worker)\n",
    "    else:\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # --- Medidores de tiempo/memoria por fase ---\n",
    "    train_time_s = None\n",
    "    train_mem_mb = None\n",
    "    test_time_s  = None\n",
    "    test_mem_mb  = None\n",
    "\n",
    "    # Modelo\n",
    "    if model_factory is None:\n",
    "        model = EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                                  n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                                  n_dw_blocks=2, capture_attn=True).to(device)\n",
    "    else:\n",
    "        model = model_factory()\n",
    "\n",
    "    # Opt + Loss\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "    class_counts = np.bincount(y_tr, minlength=2).astype(np.float32)\n",
    "    inv = class_counts.sum() / (2.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # LR scheduler Warmup+Cosine\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # EMA\n",
    "    ema = ModelEMA(model, decay=EMA_DECAY, device=device) if USE_EMA else None\n",
    "\n",
    "    # Entrenamiento global (con tracking de GAP)\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"val_loss\": [], \"lr\": []}\n",
    "\n",
    "    # NUEVO: métricas en la época de mejor valid F1\n",
    "    best_val_acc = float('nan')\n",
    "    best_val_f1  = float('nan')\n",
    "    best_tr_acc  = float('nan')\n",
    "    best_tr_f1   = float('nan')\n",
    "\n",
    "    def evaluate_on(loader, use_ema=True, loss_fn=None):\n",
    "        mdl = ema.ema if (ema is not None and use_ema) else model\n",
    "        mdl.eval()\n",
    "        preds, gts = [], []\n",
    "        tot_loss, n_seen = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in loader:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                logits = mdl(xb)\n",
    "                if loss_fn is not None:\n",
    "                    L = loss_fn(logits, yb).item()\n",
    "                    tot_loss += L * len(yb); n_seen += len(yb)\n",
    "                p = logits.argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.cpu().numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "        vloss = (tot_loss / max(1,n_seen)) if n_seen>0 else float('nan')\n",
    "        return acc, f1m, vloss, preds, gts\n",
    "\n",
    "    # === NUEVO: iniciar cronómetro + memoria de ENTRENAMIENTO ===\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "    t_train_start = time.time()\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "            if ema is not None:\n",
    "                ema.update(model)\n",
    "\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        acc, f1m, vloss, _, _ = evaluate_on(val_ld, use_ema=True, loss_fn=crit)\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"val_loss\"].append(vloss)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Época {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_loss={vloss:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            ref_model = ema.ema if ema is not None else model\n",
    "            best_state = {k: v.detach().cpu() for k, v in ref_model.state_dict().items()}\n",
    "            wait = 0\n",
    "\n",
    "            # NUEVO: computar train en el mismo modelo/época p/ medir gap\n",
    "            tr_acc_eval, tr_f1_eval, _, _, _ = evaluate_on(tr_ld, use_ema=True, loss_fn=None)\n",
    "            best_tr_acc = tr_acc_eval\n",
    "            best_tr_f1  = tr_f1_eval\n",
    "            best_val_acc = acc\n",
    "            best_val_f1  = f1m\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en época {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # === cerrar cronómetro de ENTRENAMIENTO ===\n",
    "    t_train_end = time.time()\n",
    "    train_time_s = t_train_end - t_train_start\n",
    "    if torch.cuda.is_available():\n",
    "        train_mem_mb = torch.cuda.max_memory_allocated(device) / (1024.0 ** 2)\n",
    "\n",
    "    # Restaurar mejor estado\n",
    "    if best_state is not None:\n",
    "        (ema.ema if (ema is not None) else model).load_state_dict(best_state)\n",
    "        model.load_state_dict(best_state)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(True)\n",
    "\n",
    "    if save_artifacts and fold_dir is not None:\n",
    "        torch.save(best_state, fold_dir / f\"model_global_fold{fold}_{run_tag}.pth\")\n",
    "        print(f\"↳ Modelo global guardado en: {fold_dir / f'model_global_fold{fold}_{run_tag}.pth'}\")\n",
    "\n",
    "    # ---- Curvas (sólo si se guardan artefactos) ----\n",
    "    if save_artifacts:\n",
    "        # ONLY train_loss and val_loss, correct scale\n",
    "        fig = plt.figure(figsize=(8, 4.5))\n",
    "        ax1 = plt.gca()\n",
    "        ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "        ax1.plot(hist[\"ep\"], hist[\"val_loss\"], label=\"val_loss\")\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.set_title(f\"Fold {fold} — Training Curve (2 classes) [{run_tag}]\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        out_png = fold_dir / f\"training_curve_fold{fold}_{run_tag}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=140)\n",
    "        plt.close(fig)\n",
    "        print(f\"↳ Training curve saved: {out_png}\")\n",
    "        # Guardar historial de curvas (epoch, train_loss, val_loss) para curva global\n",
    "        hist_path = fold_dir / f\"history_fold{fold}_{run_tag}.npz\"\n",
    "        np.savez(\n",
    "            hist_path,\n",
    "            ep=np.array(hist[\"ep\"], dtype=np.int32),\n",
    "            tr_loss=np.array(hist[\"tr_loss\"], dtype=np.float32),\n",
    "            val_loss=np.array(hist[\"val_loss\"], dtype=np.float32),\n",
    "        )\n",
    "        print(f\"↳ History saved: {hist_path}\")\n",
    "\n",
    "    # ---- Evaluación final en TEST (global) ----\n",
    "    eval_model = ema.ema if (ema is not None) else model\n",
    "    eval_model.eval()\n",
    "\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    # === NUEVO: cronómetro + memoria de TEST ===\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "    t_test_start = time.time()\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = eval_model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE in ('subwin', 'tta'):\n",
    "        logits_tta = None\n",
    "        logits_sw  = None\n",
    "        if SW_MODE == 'subwin':\n",
    "            logits_sw = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        elif SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        logits = logits_tta if logits_tta is not None else logits_sw\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    # === NUEVO: cerrar cronómetro de TEST ===\n",
    "    t_test_end = time.time()\n",
    "    test_time_s = t_test_end - t_test_start\n",
    "    if torch.cuda.is_available():\n",
    "        test_mem_mb = torch.cuda.max_memory_allocated(device) / (1024.0 ** 2)\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f} | f1_macro={f1m:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1])\n",
    "    print(cm)\n",
    "\n",
    "    # Métricas extendidas SIEMPRE (aunque no guardes artefactos)\n",
    "    met = compute_metrics(gts, preds)\n",
    "    print(\n",
    "        f\"precision_macro={met['precision_macro']:.4f} | \"\n",
    "        f\"recall_macro={met['recall_macro']:.4f} | \"\n",
    "        f\"specificity_macro={met['specificity_macro']:.4f} | \"\n",
    "        f\"sensitivity_macro={met['sensitivity_macro']:.4f}\"\n",
    "    )\n",
    "\n",
    "    if save_artifacts:\n",
    "        cm_png = fold_dir / f\"confusion_global_fold{fold}_{run_tag}.png\"\n",
    "        plot_confusion_with_text(\n",
    "            cm=cm,\n",
    "            class_names=CLASS_NAMES,\n",
    "            title=f\"Confusion — Fold {fold} Global (2 classes) [{run_tag}]\",\n",
    "            out_path=cm_png,\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        print(f\"↳ Confusion matrix saved: {cm_png}\")\n",
    "\n",
    "    # =========================\n",
    "    # INTERPRETABILIDAD\n",
    "    # =========================\n",
    "    if save_artifacts:\n",
    "        try:\n",
    "            model_to_probe = model\n",
    "            model_to_probe.eval()\n",
    "\n",
    "            # Minibatch de validación para ejemplos ilustrativos\n",
    "            with torch.no_grad():\n",
    "                xb_val, yb_val, _ = next(iter(val_ld))\n",
    "            xb_val = xb_val[:8].to(device)\n",
    "\n",
    "            # --- 1. Mapas de atención (Transformer) ---\n",
    "            _ = model_to_probe(xb_val)\n",
    "            attn_list = model_to_probe.get_last_attention_maps()\n",
    "            if attn_list and len(attn_list) > 0:\n",
    "                # attn_list[0]: [B, heads, T, T]\n",
    "                A = attn_list[0][0].mean(dim=0).detach().cpu().numpy()\n",
    "                plt.figure(figsize=(5, 4))\n",
    "                plt.imshow(A, aspect=\"auto\")\n",
    "                plt.title(f\"Attention (layer1, mean heads) [{run_tag}]\")\n",
    "                plt.colorbar()\n",
    "                plt.tight_layout()\n",
    "                attn_png = fold_dir / f\"attention_map_fold{fold}_{run_tag}.png\"\n",
    "                plt.savefig(attn_png, dpi=140)\n",
    "                plt.close()\n",
    "                print(f\"↳ Mapa de atención: {attn_png}\")\n",
    "\n",
    "            # Tomamos UN ejemplo para todos los mapas\n",
    "            xb_ex = xb_val[:1]\n",
    "            pred_cls = int(model_to_probe(xb_ex).argmax(1).item())\n",
    "\n",
    "            # --- 2. Topomap de saliency por canal ---\n",
    "            saliency_ch = channel_saliency(model_to_probe, xb_ex, target_class=pred_cls)\n",
    "\n",
    "            sfreq_topo = sfreq_used if sfreq_used is not None else int(\n",
    "                round(X_te_std.shape[-1] / (TMAX - TMIN))\n",
    "            )\n",
    "            info_topo = make_mne_info_8ch(sfreq_topo)\n",
    "\n",
    "            topo_sal_png = fold_dir / f\"topomap_saliency_fold{fold}_{run_tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                saliency_ch,\n",
    "                info_topo,\n",
    "                title=f\"Channel saliency — Fold {fold} [{run_tag}]\",\n",
    "                out_path=topo_sal_png,\n",
    "                cmap=\"Reds\",\n",
    "                cbar_label=\"Normalized saliency\"\n",
    "            )\n",
    "            # Guardar saliency numérica por canal para promedio GLOBAL\n",
    "            saliency_path = fold_dir / f\"saliency_channels_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(saliency_path, saliency_ch)\n",
    "\n",
    "            # --- 3. Topomap de -log10(p) left vs right (TEST) ---\n",
    "            pvals = compute_channel_pvalues_lr(X_te_std, y_te)\n",
    "            pvals_log = -np.log10(pvals + 1e-12)\n",
    "\n",
    "            topo_p_png = fold_dir / f\"topomap_log10p_fold{fold}_{run_tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                pvals_log,\n",
    "                info_topo,\n",
    "                title=f\"-log10(p) Left vs Right — Fold {fold} [{run_tag}]\",\n",
    "                out_path=topo_p_png,\n",
    "                cmap=\"viridis\",\n",
    "                cbar_label=\"-log10(p)\"\n",
    "            )\n",
    "\n",
    "            # Guardar valores numéricos por canal para promedio GLOBAL\n",
    "            pvals_log_path = fold_dir / f\"pvals_log_channels_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(pvals_log_path, pvals_log)\n",
    "\n",
    "            # --- 4. t-SNE de embeddings del modelo ---\n",
    "            # Usar un subconjunto de TEST para t-SNE (máximo 1000 muestras)\n",
    "            n_tsne_samples = min(1000, len(X_te_std))\n",
    "            indices = rng.choice(len(X_te_std), n_tsne_samples, replace=False)\n",
    "            X_tsne = X_te_std[indices]\n",
    "            y_tsne = y_te[indices]\n",
    "\n",
    "            tsne_result, cls_embeddings = compute_tsne_embeddings(\n",
    "                model_to_probe, X_tsne, DEVICE, n_components=2, perplexity=30\n",
    "            )\n",
    "            \n",
    "            tsne_png = fold_dir / f\"tsne_cls_fold{fold}_{run_tag}.png\"\n",
    "            plot_tsne(\n",
    "                tsne_result, \n",
    "                y_tsne,\n",
    "                title=f\"t-SNE CLS embeddings — Fold {fold} [{run_tag}]\",\n",
    "                out_path=tsne_png\n",
    "            )\n",
    "            \n",
    "            # Guardar t-SNE resultados y embeddings CLS\n",
    "            tsne_path = fold_dir / f\"tsne_results_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(tsne_path, tsne_result)\n",
    "            \n",
    "            cls_emb_path = fold_dir / f\"cls_embeddings_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(cls_emb_path, cls_embeddings)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Interpretabilidad no generada: {e}\")\n",
    "\n",
    "    # =========================\n",
    "    # Fine-tuning progresivo por sujeto (opcional)\n",
    "    # =========================\n",
    "    if do_ft:\n",
    "        subjects = np.unique(sub_te)\n",
    "        subj_to_idx = {s: np.where(sub_te == s)[0] for s in subjects}\n",
    "\n",
    "        def make_ft_optimizer(model_ft):\n",
    "            head_params = list(model_ft.head.parameters())\n",
    "            backbone_params = [p for n,p in model_ft.named_parameters() if not n.startswith('head.')]\n",
    "            return torch.optim.AdamW([\n",
    "                {'params': backbone_params, 'lr': FT_LR_BACKBONE},\n",
    "                {'params': head_params,     'lr': FT_LR_HEAD}\n",
    "            ], weight_decay=FT_WD)\n",
    "\n",
    "        def freeze_backbone(model_ft, freeze=True):\n",
    "            for n,p in model_ft.named_parameters():\n",
    "                if not n.startswith('head.'):\n",
    "                    p.requires_grad_(not freeze)\n",
    "\n",
    "        def ft_make_criterion_from_counts(counts):\n",
    "            inv = counts.sum() / (2.0 * np.maximum(counts.astype(np.float32), 1.0))\n",
    "            a = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "            return FocalLoss(alpha=a, gamma=1.5, reduction='mean')\n",
    "\n",
    "        def evaluate_tensor(model_t, X, y):\n",
    "            model_t.eval()\n",
    "            with torch.no_grad():\n",
    "                xb = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "                p = model_t(xb).argmax(1).cpu().numpy()\n",
    "            return accuracy_score(y, p), f1_score(y, p, average='macro'), p\n",
    "\n",
    "        all_true, all_pred = [], []\n",
    "        base_state = (ema.ema if (ema is not None) else model).state_dict()\n",
    "\n",
    "        for s in subjects:\n",
    "            idx = subj_to_idx[s]\n",
    "            Xs, ys = X_te_std[idx], y_te[idx]\n",
    "            if len(np.unique(ys)) < 2 or len(ys) < 20:\n",
    "                eval_model2 = model_factory() if model_factory is not None else EEGCNNTransformer(\n",
    "                    n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                    n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                    n_dw_blocks=2, capture_attn=False).to(device)\n",
    "                eval_model2.load_state_dict(base_state)\n",
    "                _, _, pred_s = evaluate_tensor(eval_model2, Xs, ys)\n",
    "                all_true.append(ys); all_pred.append(pred_s)\n",
    "                continue\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=FT_N_FOLDS, shuffle=True, random_state=RANDOM_STATE + fold + int(s))\n",
    "            for tr_idx, te_idx in skf.split(Xs, ys):\n",
    "                Xtr, ytr = Xs[tr_idx].copy(), ys[tr_idx].copy()\n",
    "                Xte_s, yte_s = Xs[te_idx].copy(), ys[te_idx].copy()\n",
    "                Xtr_std, Xte_std = standardize_per_channel(Xtr, Xte_s)\n",
    "\n",
    "                ft_model = model_factory() if model_factory is not None else EEGCNNTransformer(\n",
    "                    n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                    n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                    n_dw_blocks=2, capture_attn=False).to(device)\n",
    "                ft_model.load_state_dict(base_state)\n",
    "\n",
    "                opt_ft = make_ft_optimizer(ft_model)\n",
    "                alpha_counts = np.bincount(ytr, minlength=2)\n",
    "                ft_crit = ft_make_criterion_from_counts(alpha_counts)\n",
    "\n",
    "                ds_tr = TensorDataset(torch.tensor(Xtr_std), torch.tensor(ytr).long())\n",
    "                ds_te = TensorDataset(torch.tensor(Xte_std), torch.tensor(yte_s).long())\n",
    "                ld_tr = DataLoader(ds_tr, batch_size=FT_BATCH, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "                ld_te = DataLoader(ds_te, batch_size=FT_BATCH, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "                # freeze\n",
    "                freeze_backbone(ft_model, True)\n",
    "                best_f1_s, best_state_s, wait_s = -1, None, 0\n",
    "                for _ep in range(1, FT_FREEZE_EPOCHS+1):\n",
    "                    ft_model.train()\n",
    "                    for xb, yb in ld_tr:\n",
    "                        xb = xb.to(device); yb = yb.to(device)\n",
    "                        xb = augment_batch_ft(xb)\n",
    "                        opt_ft.zero_grad()\n",
    "                        logits = ft_model(xb)\n",
    "                        loss = ft_crit(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                        opt_ft.step()\n",
    "                    acc_s, f1_s, _ = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "                    if f1_s > best_f1_s + 1e-4:\n",
    "                        best_f1_s = f1_s\n",
    "                        best_state_s = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                        wait_s = 0\n",
    "                    else:\n",
    "                        wait_s += 1\n",
    "                    if wait_s >= FT_PATIENCE: break\n",
    "                if best_state_s is not None:\n",
    "                    ft_model.load_state_dict(best_state_s)\n",
    "\n",
    "                # unfreeze\n",
    "                freeze_backbone(ft_model, False)\n",
    "                best_f1_s2, best_state_s2, wait_s2 = -1, None, 0\n",
    "                for _ep in range(1, FT_UNFREEZE_EPOCHS+1):\n",
    "                    ft_model.train()\n",
    "                    for xb, yb in ld_tr:\n",
    "                        xb = xb.to(device); yb = yb.to(device)\n",
    "                        xb = augment_batch_ft(xb)\n",
    "                        opt_ft.zero_grad()\n",
    "                        logits = ft_model(xb)\n",
    "                        loss = ft_crit(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                        opt_ft.step()\n",
    "                    acc_s, f1_s, _ = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "                    if f1_s > best_f1_s2 + 1e-4:\n",
    "                        best_f1_s2 = f1_s\n",
    "                        best_state_s2 = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                        wait_s2 = 0\n",
    "                    else:\n",
    "                        wait_s2 += 1\n",
    "                    if wait_s2 >= FT_PATIENCE: break\n",
    "                if best_state_s2 is not None:\n",
    "                    ft_model.load_state_dict(best_state_s2)\n",
    "\n",
    "                _, _, pred_s = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "                all_true.append(yte_s); all_pred.append(pred_s)\n",
    "\n",
    "        all_true = np.concatenate(all_true) if len(all_true) else np.array([], dtype=int)\n",
    "        all_pred = np.concatenate(all_pred) if len(all_pred) else np.array([], dtype=int)\n",
    "        if len(all_true) > 0:\n",
    "            ft_acc = accuracy_score(all_true, all_pred)\n",
    "            ft_f1m = f1_score(all_true, all_pred, average='macro')\n",
    "            print(f\"  Fine-tuning PROGRESIVO (por sujeto, {FT_N_FOLDS}-fold CV) acc={ft_acc:.4f} | f1_macro={ft_f1m:.4f}\")\n",
    "            if save_artifacts:\n",
    "                cm_ft = confusion_matrix(all_true, all_pred, labels=[0,1])\n",
    "                ft_png = fold_dir / f\"confusion_ft_fold{fold}_{run_tag}.png\"\n",
    "                plot_confusion_with_text(\n",
    "                    cm=cm_ft,\n",
    "                    class_names=CLASS_NAMES,\n",
    "                    title=f\"Confusion — Fold {fold} FT (2 clases) [{run_tag}]\",\n",
    "                    out_path=ft_png,\n",
    "                    cmap='Greens'\n",
    "                )\n",
    "                print(f\"↳ Matriz de confusión FT guardada: {ft_png}\")\n",
    "        else:\n",
    "            ft_acc = float('nan')\n",
    "            print(\"  Fine-tuning PROGRESIVO: no se generaron splits válidos.\")\n",
    "    else:\n",
    "        ft_acc = float('nan')\n",
    "        print(\"  [LITE] FT desactivado (do_ft=False).\")\n",
    "\n",
    "    # =========================\n",
    "    # Consumo (siempre calculado); guardar JSON sólo si save_artifacts\n",
    "    # =========================\n",
    "    cons = {}\n",
    "    try:\n",
    "        eval_model.eval()\n",
    "        with torch.no_grad():\n",
    "            xb_small, _, _ = next(iter(val_ld))\n",
    "        xb_small = xb_small[:8].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = eval_model.conv_t(xb_small)\n",
    "            z = eval_model.proj(z).transpose(1, 2)  # (B, L, D)\n",
    "            L, d = z.shape[1], z.shape[2]\n",
    "\n",
    "        params_total = count_params(eval_model, trainable_only=False)\n",
    "        params_train = count_params(model, trainable_only=True)\n",
    "        flops = estimate_transformer_flops(L=L, d=d, n_heads=N_HEADS, n_layers=N_LAYERS)\n",
    "        lat   = benchmark_latency(eval_model, xb_small, DEVICE)\n",
    "\n",
    "        cons = dict(\n",
    "            params_total=params_total,\n",
    "            params_trainable=params_train,\n",
    "            flops_est=int(flops),\n",
    "            latency_s=float(lat),\n",
    "            L=L, d=d,\n",
    "            n_heads=N_HEADS, n_layers=N_LAYERS,\n",
    "            run_tag=run_tag, fold=fold,\n",
    "            # GAP val-train en la mejor época de valid F1\n",
    "            val_best_acc=float(best_val_acc),\n",
    "            val_best_f1=float(best_val_f1),\n",
    "            tr_at_best_acc=float(best_tr_acc),\n",
    "            tr_at_best_f1=float(best_tr_f1),\n",
    "            # === NUEVO: métricas de tiempo/memoria por fase ===\n",
    "            train_time_s=float(train_time_s) if train_time_s is not None else None,\n",
    "            train_mem_mb=float(train_mem_mb) if train_mem_mb is not None else None,\n",
    "            test_time_s=float(test_time_s) if test_time_s is not None else None,\n",
    "            test_mem_mb=float(test_mem_mb) if test_mem_mb is not None else None,\n",
    "        )\n",
    "\n",
    "        if save_artifacts and (fold_dir is not None):\n",
    "            cons_json = fold_dir / f\"consumption_fold{fold}_{run_tag}.json\"\n",
    "            with open(cons_json, \"w\") as f:\n",
    "                json.dump(cons, f, indent=2)\n",
    "\n",
    "        print(f\"[Consumo] params_total={params_total:,} | params_trainable={params_train:,} | \"\n",
    "              f\"FLOPs~{flops/1e6:.1f}M | latency/batch={lat*1000:.2f} ms (B={xb_small.size(0)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Métricas de consumo no generadas: {e}\")\n",
    "\n",
    "    return acc, f1m, ft_acc, cons, met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9081e9",
   "metadata": {},
   "source": [
    "### Utilidades de Splits y Configuraciones Adicionales\n",
    "\n",
    "Funciones auxiliares para manejar splits de datos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba22a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utilidades splits estratificados por sujeto\n",
    "# =========================\n",
    "def build_subject_label_map(subject_ids):\n",
    "    \"\"\"\n",
    "    Construye mapa de etiquetas dominantes por sujeto para estratificación.\n",
    "    \"\"\"\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=2)\n",
    "        y_dom = int(np.argmax(binc))\n",
    "        y_dom_list.append(y_dom)\n",
    "    return np.array(y_dom_list, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02534dca",
   "metadata": {},
   "source": [
    "### Funciones de Barrido de Hiperparámetros\n",
    "\n",
    "Funciones para realizar búsqueda de hiperparámetros y entrenamiento completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93bd57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Barrido (con carpetas y resumen)\n",
    "# =========================\n",
    "def run_arch_sweep(device, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=1):\n",
    "    \"\"\"\n",
    "    Realiza barrido de hiperparámetros (número de bloques y cabezas de atención).\n",
    "    \"\"\"\n",
    "    base_dir = ensure_dir(Path(\"Barrido\"))\n",
    "    results = []\n",
    "    run_id = 0\n",
    "    for dlt in deltas:\n",
    "        n_blocks = int(np.clip(base_blocks + dlt, 0, 4))\n",
    "        for nh in head_set:\n",
    "            if D_MODEL % nh != 0:\n",
    "                print(f\"[SKIP] n_heads={nh} incompatible con D_MODEL={D_MODEL} (no divisible).\")\n",
    "                continue\n",
    "            run_id += 1\n",
    "            run_tag = f\"nb{n_blocks}_h{nh}\"\n",
    "            print(f\"\\n=== RUN {run_id} | n_dw_blocks={n_blocks} | n_heads={nh} ===\")\n",
    "\n",
    "            def make_model_for_fold():\n",
    "                return EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=nh,\n",
    "                                         n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                                         n_dw_blocks=n_blocks, capture_attn=True).to(device)\n",
    "            acc, f1m, ft_acc, cons, met = train_one_fold(\n",
    "                fold=sweep_fold, device=device,\n",
    "                model_factory=make_model_for_fold, run_tag=run_tag, out_dir=base_dir,\n",
    "                save_artifacts=False, do_ft=False\n",
    "            )\n",
    "            results.append(dict(\n",
    "                run=run_id,\n",
    "                n_dw_blocks=n_blocks,\n",
    "                n_heads=nh,\n",
    "                fold=sweep_fold,\n",
    "                acc=acc,\n",
    "                f1_macro=f1m,\n",
    "                ft_acc=ft_acc,\n",
    "                # === MÉTRICAS EXTENDIDAS EN TEST ===\n",
    "                precision_macro=met[\"precision_macro\"],\n",
    "                recall_macro=met[\"recall_macro\"],\n",
    "                specificity_macro=met[\"specificity_macro\"],\n",
    "                sensitivity_macro=met[\"sensitivity_macro\"],\n",
    "                # === CONSUMO ===\n",
    "                tag=run_tag,\n",
    "                params_total=cons.get(\"params_total\"),\n",
    "                params_trainable=cons.get(\"params_trainable\"),\n",
    "                flops_est=cons.get(\"flops_est\"),\n",
    "                latency_s=cons.get(\"latency_s\"),\n",
    "                L=cons.get(\"L\"),\n",
    "                d=cons.get(\"d\"),\n",
    "                enc_heads=cons.get(\"n_heads\"),\n",
    "                enc_layers=cons.get(\"n_layers\"),\n",
    "            ))\n",
    "\n",
    "    if len(results):\n",
    "        summary_path = Path(\"Barrido\") / \"summary_sweep.csv\"\n",
    "        fields = list(results[0].keys())\n",
    "        save_csv_rows(summary_path, fields, results)\n",
    "        print(f\"↳ Resumen de barrido (con consumo) actualizado: {summary_path.resolve()}\")\n",
    "    return results\n",
    "\n",
    "# =========================\n",
    "# 5 Folds del ganador (con carpetas y resumen)\n",
    "# =========================\n",
    "def run_full_5fold_for_config(device, n_blocks, n_heads):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa el modelo en los 5 folds para una configuración específica.\n",
    "    \"\"\"\n",
    "    tag = f\"nb{n_blocks}_h{n_heads}\"\n",
    "    base_dir = ensure_dir(Path(\"ModeloW\") / tag)\n",
    "\n",
    "    acc_folds, f1_folds, ft_acc_folds = [], [], []\n",
    "    rows = []\n",
    "\n",
    "    # === NUEVO: listas para costo computacional por fold ===\n",
    "    train_times, train_mems = [], []\n",
    "    test_times,  test_mems  = [], []\n",
    "    params_list, flops_list = [], []\n",
    "\n",
    "    # Acumuladores para mapas GLOBALES\n",
    "    saliency_list = []   # Para saliency por fold\n",
    "    pvals_log_list = []  # Para -log10(p) por fold\n",
    "    tsne_results_list = []  # Para t-SNE por fold (solo guardamos, no promediamos)\n",
    "\n",
    "    # Acumulador para matriz de confusión global (suma de las de cada fold)\n",
    "    global_cm = np.zeros((2, 2), dtype=int)\n",
    "    \n",
    "    def factory():\n",
    "        return EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=n_heads,\n",
    "                                 n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                                 n_dw_blocks=n_blocks, capture_attn=True).to(device)\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m, ft_acc, cons, met = train_one_fold(\n",
    "            fold, device, model_factory=factory, run_tag=tag, out_dir=base_dir\n",
    "        )\n",
    "        # Acumular matriz de confusión de este fold en la matriz GLOBAL\n",
    "        if met is not None and \"cm\" in met:\n",
    "            global_cm += np.array(met[\"cm\"], dtype=int)\n",
    "        acc_folds.append(acc); f1_folds.append(f1m)\n",
    "        ft_acc_folds.append(ft_acc if ft_acc == ft_acc else np.nan)\n",
    "\n",
    "        # === NUEVO: guardar consumo de este fold ===\n",
    "        train_times.append(cons.get(\"train_time_s\"))\n",
    "        train_mems.append(cons.get(\"train_mem_mb\"))\n",
    "        test_times.append(cons.get(\"test_time_s\"))\n",
    "        test_mems.append(cons.get(\"test_mem_mb\"))\n",
    "        params_list.append(cons.get(\"params_total\"))\n",
    "        flops_list.append(cons.get(\"flops_est\"))\n",
    "\n",
    "        rows.append(dict(\n",
    "            tag=tag, fold=fold, acc=acc, f1_macro=f1m, ft_acc=ft_acc,\n",
    "            params_total=cons.get(\"params_total\"),\n",
    "            params_trainable=cons.get(\"params_trainable\"),\n",
    "            flops_est=cons.get(\"flops_est\"),\n",
    "            latency_s=cons.get(\"latency_s\"),\n",
    "            L=cons.get(\"L\"), d=cons.get(\"d\"),\n",
    "            enc_heads=cons.get(\"n_heads\"), enc_layers=cons.get(\"n_layers\")\n",
    "        ))\n",
    "\n",
    "        # Cargar mapas de interpretabilidad de este fold para promedio GLOBAL\n",
    "        try:\n",
    "            fold_dir = base_dir / tag / f\"fold{fold}\"\n",
    "            # Cargar saliency\n",
    "            sal_path = fold_dir / f\"saliency_channels_fold{fold}_{tag}.npy\"\n",
    "            if sal_path.exists():\n",
    "                saliency_list.append(np.load(sal_path))\n",
    "            \n",
    "            # Cargar -log10(p)\n",
    "            pvals_path = fold_dir / f\"pvals_log_channels_fold{fold}_{tag}.npy\"\n",
    "            if pvals_path.exists():\n",
    "                pvals_log_list.append(np.load(pvals_path))\n",
    "                \n",
    "            # Cargar t-SNE (solo para referencia, no promediamos)\n",
    "            tsne_path = fold_dir / f\"tsne_results_fold{fold}_{tag}.npy\"\n",
    "            if tsne_path.exists():\n",
    "                tsne_results_list.append(np.load(tsne_path))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] No se pudieron cargar mapas para fold {fold}: {e}\")\n",
    "\n",
    "    acc_mean = float(np.nanmean(acc_folds))\n",
    "    f1_mean  = float(np.nanmean(f1_folds))\n",
    "    ft_mean  = float(np.nanmean(ft_acc_folds))\n",
    "    delta_mean = float(ft_mean - acc_mean) if not np.isnan(ft_mean) else np.nan\n",
    "\n",
    "    summary_path = base_dir / f\"summary_{tag}.csv\"\n",
    "    save_csv_rows(summary_path, list(rows[0].keys()), rows)\n",
    "    print(f\"↳ Resumen 5-fold guardado: {summary_path.resolve()}\")\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(f\"RESULTADOS FINALES [{tag}] (2 clases: left/right)\")\n",
    "    print(\"============================================================\")\n",
    "    print(\"Global folds (ACC):\", [f\"{a:.4f}\" for a in acc_folds])\n",
    "    print(\"Global mean ACC:   \", f\"{acc_mean:.4f}\")\n",
    "    print(\"F1 folds (MACRO):  \", [f\"{f:.4f}\" for f in f1_folds])\n",
    "    print(\"F1 mean (MACRO):   \", f\"{f1_mean:.4f}\")\n",
    "    if not np.isnan(ft_mean):\n",
    "        print(\"FT folds (ACC):    \", [(\"nan\" if np.isnan(a) else f\"{a:.4f}\") for a in ft_acc_folds])\n",
    "        print(\"FT mean (ACC):     \", f\"{ft_mean:.4f}\")\n",
    "        print(\"Δ(FT-Global) mean: \", f\"{delta_mean:+.4f}\")\n",
    "    else:\n",
    "        print(\"FT mean (ACC): N/A\")\n",
    "\n",
    "    # ========================================================\n",
    "    # Tabla de métricas computacionales tipo paper\n",
    "    # ========================================================\n",
    "\n",
    "    tt = np.array([t for t in train_times if t is not None], dtype=float)\n",
    "    tm = np.array([m for m in train_mems if m is not None], dtype=float)\n",
    "\n",
    "    train_time_mean = float(tt.mean()) if len(tt) else float('nan')\n",
    "    train_time_std  = float(tt.std(ddof=0)) if len(tt) else float('nan')\n",
    "    train_mem_mean  = float(tm.mean()) if len(tm) else float('nan')\n",
    "    train_mem_std   = float(tm.std(ddof=0)) if len(tm) else float('nan')\n",
    "\n",
    "    # Para test tomamos el primer fold válido (single run)\n",
    "    test_time = next((float(t) for t in test_times if t is not None), float('nan'))\n",
    "    test_mem  = next((float(m) for m in test_mems if m is not None), float('nan'))\n",
    "\n",
    "    # Modelo (mismo en todos los folds)\n",
    "    params_total = next((p for p in params_list if p is not None), 0)\n",
    "    flops_est    = next((f for f in flops_list if f is not None), 0)\n",
    "\n",
    "    params_m = params_total / 1e6\n",
    "    flops_g  = flops_est / 1e9\n",
    "\n",
    "    print(\"\\n================ Computational metrics ================\")\n",
    "    print(f\"Model tag: {tag}\")\n",
    "    print(\"Phase        time (s)           memory (MB)        FLOPs (g)   params (m)\")\n",
    "    print(\"-----------  -----------------  -----------------  ----------  ----------\")\n",
    "    print(f\"model specs  N/A                N/A                 {flops_g:8.3f}   {params_m:8.3f}\")\n",
    "    print(f\"train        {train_time_mean:6.2f} ({train_time_std:5.2f})   {train_mem_mean:7.1f} ({train_mem_std:5.1f})     N/A        N/A\")\n",
    "    print(f\"test         {test_time:6.2f}              {test_mem:7.1f}              N/A        N/A\")\n",
    "\n",
    "    comp_rows = [\n",
    "        dict(phase=\"model_specs\",\n",
    "             time_mean_s=None, time_std_s=None,\n",
    "             mem_mean_mb=None, mem_std_mb=None,\n",
    "             flops_g=flops_g, params_m=params_m),\n",
    "        dict(phase=\"train\",\n",
    "             time_mean_s=train_time_mean, time_std_s=train_time_std,\n",
    "             mem_mean_mb=train_mem_mean, mem_std_mb=train_mem_std,\n",
    "             flops_g=None, params_m=None),\n",
    "        dict(phase=\"test\",\n",
    "             time_mean_s=test_time, time_std_s=None,\n",
    "             mem_mean_mb=test_mem, mem_std_mb=None,\n",
    "             flops_g=None, params_m=None),\n",
    "    ]\n",
    "\n",
    "    comp_path = base_dir / f\"computational_{tag}.csv\"\n",
    "    save_csv_rows(comp_path,\n",
    "                  fieldnames=list(comp_rows[0].keys()),\n",
    "                  rows=comp_rows)\n",
    "    print(f\"↳ Tabla de métricas computacionales guardada en: {comp_path.resolve()}\")\n",
    "    \n",
    "    # ========================================================\n",
    "    # Matriz de confusión GLOBAL (5 folds concatenados)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        cm_global_png = base_dir / f\"confusion_global_allfolds_{tag}.png\"\n",
    "        plot_confusion_with_text(\n",
    "            cm=global_cm,\n",
    "            class_names=CLASS_NAMES,\n",
    "            title=f\"Confusion — Global (5-fold) [{tag}]\",\n",
    "            out_path=cm_global_png,\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        print(f\"↳ Matriz de confusión GLOBAL guardada: {cm_global_png}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudo generar la matriz de confusión global: {e}\")\n",
    "\n",
    "    # ========================================================\n",
    "    # Curva de LOSS GLOBAL (promedio sobre los 5 folds)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        histories = []\n",
    "        for fold in range(1, 6):\n",
    "            hist_path = base_dir / tag / f\"fold{fold}\" / f\"history_fold{fold}_{tag}.npz\"\n",
    "            if not hist_path.exists():\n",
    "                print(f\"[WARN] History no encontrado para fold {fold}: {hist_path}\")\n",
    "                continue\n",
    "            data = np.load(hist_path)\n",
    "            hist = {\n",
    "                \"ep\":      data[\"ep\"],\n",
    "                \"tr_loss\": data[\"tr_loss\"],\n",
    "                \"val_loss\": data[\"val_loss\"],\n",
    "            }\n",
    "            histories.append(hist)\n",
    "\n",
    "        if len(histories) > 0:\n",
    "            # Longitud máxima de epochs entre los folds\n",
    "            max_len = max(h[\"ep\"].shape[0] for h in histories)\n",
    "            epochs = np.arange(1, max_len + 1)\n",
    "\n",
    "            mean_tr = []\n",
    "            mean_val = []\n",
    "\n",
    "            for i in range(max_len):\n",
    "                tr_vals = [h[\"tr_loss\"][i] for h in histories if h[\"tr_loss\"].shape[0] > i]\n",
    "                val_vals = [h[\"val_loss\"][i] for h in histories if h[\"val_loss\"].shape[0] > i]\n",
    "                if len(tr_vals) == 0 or len(val_vals) == 0:\n",
    "                    break  # ya no hay más epochs comunes\n",
    "                mean_tr.append(np.mean(tr_vals))\n",
    "                mean_val.append(np.mean(val_vals))\n",
    "\n",
    "            epochs = epochs[:len(mean_tr)]\n",
    "            mean_tr = np.array(mean_tr)\n",
    "            mean_val = np.array(mean_val)\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 4.5))\n",
    "            ax = plt.gca()\n",
    "            ax.plot(epochs, mean_tr, label=\"Train loss (mean across folds)\")\n",
    "            ax.plot(epochs, mean_val, label=\"Val loss (mean across folds)\")\n",
    "            ax.set_xlabel(\"Epoch\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.set_title(f\"Global Training Curve — 5-fold mean [{tag}]\")\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            out_png = base_dir / f\"training_curve_global_{tag}.png\"\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(out_png, dpi=140)\n",
    "            plt.close(fig)\n",
    "            print(f\"↳ Curva de loss GLOBAL guardada: {out_png}\")\n",
    "        else:\n",
    "            print(\"[WARN] No se encontraron historiales para construir curva global.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudo generar la curva de loss global: {e}\")\n",
    "\n",
    "    # ========================================================\n",
    "    # MAPAS GLOBALES (promedio de los 5 folds)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        # Crear info para topomaps\n",
    "        info_topo_global = make_mne_info_8ch(sfreq=160.0)\n",
    "        \n",
    "        # 1. Topomap GLOBAL de saliency (promedio 5 folds)\n",
    "        if len(saliency_list) > 0:\n",
    "            sal_mean = np.mean(np.stack(saliency_list, axis=0), axis=0)   # (C,)\n",
    "            topo_sal_global_png = base_dir / f\"topomap_saliency_GLOBAL_{tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                sal_mean,\n",
    "                info_topo_global,\n",
    "                title=f\"Channel saliency — GLOBAL (5 folds) [{tag}]\",\n",
    "                out_path=topo_sal_global_png,\n",
    "                cmap=\"Reds\",\n",
    "                cbar_label=\"Normalized saliency\"\n",
    "            )\n",
    "            print(f\"↳ Topomap GLOBAL de saliency guardado: {topo_sal_global_png}\")\n",
    "        \n",
    "        # 2. Topomap GLOBAL de -log10(p) (promedio 5 folds)\n",
    "        if len(pvals_log_list) > 0:\n",
    "            pvals_log_mean = np.mean(np.stack(pvals_log_list, axis=0), axis=0)   # (C,)\n",
    "            topo_p_global_png = base_dir / f\"topomap_log10p_GLOBAL_{tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                pvals_log_mean,\n",
    "                info_topo_global,\n",
    "                title=f\"-log10(p) Left vs Right — GLOBAL (5 folds) [{tag}]\",\n",
    "                out_path=topo_p_global_png,\n",
    "                cmap=\"viridis\",\n",
    "                cbar_label=\"-log10(p)\"\n",
    "            )\n",
    "            print(f\"↳ Topomap GLOBAL de -log10(p) guardado: {topo_p_global_png}\")\n",
    "        \n",
    "        # 3. t-SNE GLOBAL usando CLS embeddings del último fold\n",
    "        if len(tsne_results_list) > 0:\n",
    "            # Usar el t-SNE del último fold como representativo\n",
    "            tsne_representative = tsne_results_list[-1]\n",
    "            \n",
    "            # Cargar etiquetas correspondientes (del último fold)\n",
    "            fold_dir = base_dir / tag / f\"fold5\"\n",
    "            \n",
    "            # Cargar y_te del fold 5 (si existe guardado)\n",
    "            y_te_fold5_path = fold_dir / \"y_te.npy\"\n",
    "            if y_te_fold5_path.exists():\n",
    "                y_te_fold5 = np.load(y_te_fold5_path)\n",
    "                # Tomar las mismas muestras que usamos para t-SNE\n",
    "                rng = np.random.RandomState(RANDOM_STATE)\n",
    "                n_tsne_samples = min(1000, len(y_te_fold5))\n",
    "                indices = rng.choice(len(y_te_fold5), n_tsne_samples, replace=False)\n",
    "                y_tsne_global = y_te_fold5[indices]\n",
    "                \n",
    "                tsne_global_png = base_dir / f\"tsne_cls_GLOBAL_{tag}.png\"\n",
    "                plot_tsne(\n",
    "                    tsne_representative,\n",
    "                    y_tsne_global,\n",
    "                    title=f\"t-SNE CLS embeddings — GLOBAL (Fold 5 representative) [{tag}]\",\n",
    "                    out_path=tsne_global_png\n",
    "                )\n",
    "                print(f\"↳ t-SNE GLOBAL (CLS embeddings) guardado: {tsne_global_png}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudieron generar mapas GLOBALES: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179864e5",
   "metadata": {},
   "source": [
    "### Main y Ejecución Principal\n",
    "\n",
    "Función principal para ejecutar el pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c24d9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:04<00:00, 15.64it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:01<00:00, 14.81it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1318 | train_acc=0.5213 | val_loss=0.1249 | val_acc=0.5000 | val_f1m=0.3443 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1224 | train_acc=0.5729 | val_loss=0.1187 | val_acc=0.6190 | val_f1m=0.6166 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1102 | train_acc=0.6546 | val_loss=0.1111 | val_acc=0.6508 | val_f1m=0.6402 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0962 | train_acc=0.7416 | val_loss=0.1044 | val_acc=0.7206 | val_f1m=0.7198 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0841 | train_acc=0.7839 | val_loss=0.0987 | val_acc=0.7444 | val_f1m=0.7439 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0764 | train_acc=0.8003 | val_loss=0.0960 | val_acc=0.7556 | val_f1m=0.7539 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0721 | train_acc=0.8124 | val_loss=0.0919 | val_acc=0.7635 | val_f1m=0.7627 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0662 | train_acc=0.8348 | val_loss=0.1250 | val_acc=0.7190 | val_f1m=0.7119 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0641 | train_acc=0.8394 | val_loss=0.0944 | val_acc=0.7571 | val_f1m=0.7569 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0651 | train_acc=0.8340 | val_loss=0.0993 | val_acc=0.7683 | val_f1m=0.7678 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0614 | train_acc=0.8539 | val_loss=0.1028 | val_acc=0.7556 | val_f1m=0.7548 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0620 | train_acc=0.8490 | val_loss=0.0927 | val_acc=0.7683 | val_f1m=0.7673 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0606 | train_acc=0.8547 | val_loss=0.0891 | val_acc=0.7683 | val_f1m=0.7678 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0606 | train_acc=0.8497 | val_loss=0.0948 | val_acc=0.7540 | val_f1m=0.7510 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0583 | train_acc=0.8632 | val_loss=0.1093 | val_acc=0.7603 | val_f1m=0.7594 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0578 | train_acc=0.8561 | val_loss=0.1027 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0605 | train_acc=0.8515 | val_loss=0.1016 | val_acc=0.7746 | val_f1m=0.7745 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0591 | train_acc=0.8582 | val_loss=0.1005 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0565 | train_acc=0.8653 | val_loss=0.1005 | val_acc=0.7810 | val_f1m=0.7800 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0520 | train_acc=0.8699 | val_loss=0.1050 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0525 | train_acc=0.8738 | val_loss=0.1018 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0495 | train_acc=0.8778 | val_loss=0.1040 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0495 | train_acc=0.8767 | val_loss=0.1033 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0512 | train_acc=0.8714 | val_loss=0.1032 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0541 | train_acc=0.8582 | val_loss=0.1031 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0425 | train_acc=0.8969 | val_loss=0.1032 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0486 | train_acc=0.8824 | val_loss=0.1032 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0496 | train_acc=0.8738 | val_loss=0.1032 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0454 | train_acc=0.8877 | val_loss=0.1033 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000325\n",
      "  Época  30 | train_loss=0.0481 | train_acc=0.8799 | val_loss=0.1034 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000313\n",
      "  Época  31 | train_loss=0.0439 | train_acc=0.9019 | val_loss=0.1036 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000300\n",
      "  Época  32 | train_loss=0.0454 | train_acc=0.8927 | val_loss=0.1037 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000288\n",
      "  Época  33 | train_loss=0.0381 | train_acc=0.9129 | val_loss=0.1040 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000275\n",
      "  Época  34 | train_loss=0.0427 | train_acc=0.8994 | val_loss=0.1042 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000262\n",
      "  Época  35 | train_loss=0.0376 | train_acc=0.9115 | val_loss=0.1046 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000250\n",
      "  Época  36 | train_loss=0.0409 | train_acc=0.9055 | val_loss=0.1049 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000237\n",
      "  Época  37 | train_loss=0.0394 | train_acc=0.9087 | val_loss=0.1053 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000225\n",
      "  Época  38 | train_loss=0.0394 | train_acc=0.9101 | val_loss=0.1057 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000213\n",
      "  Época  39 | train_loss=0.0387 | train_acc=0.9033 | val_loss=0.1061 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000201\n",
      "  Época  40 | train_loss=0.0380 | train_acc=0.9115 | val_loss=0.1066 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000189\n",
      "  Época  41 | train_loss=0.0352 | train_acc=0.9186 | val_loss=0.1071 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000177\n",
      "  Early stopping en época 41 (mejor val_f1m=0.7968)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold1/model_global_fold1_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold1/training_curve_fold1_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold1/history_fold1_nb2_h6.npz\n",
      "[Fold 1/5] Global acc=0.8107 | f1_macro=0.8107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8114    0.8095    0.8104       441\n",
      "       right     0.8100    0.8118    0.8109       441\n",
      "\n",
      "    accuracy                         0.8107       882\n",
      "   macro avg     0.8107    0.8107    0.8107       882\n",
      "weighted avg     0.8107    0.8107    0.8107       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[357  84]\n",
      " [ 83 358]]\n",
      "precision_macro=0.8107 | recall_macro=0.8107 | specificity_macro=0.8107 | sensitivity_macro=0.8107\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold1/confusion_global_fold1_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold1/attention_map_fold1_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold1/topomap_saliency_fold1_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold1/topomap_log10p_fold1_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold1/tsne_cls_fold1_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8526 | f1_macro=0.8526\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold1/confusion_ft_fold1_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.12 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.24it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.30it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1290 | train_acc=0.5267 | val_loss=0.1202 | val_acc=0.6032 | val_f1m=0.6029 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1214 | train_acc=0.5839 | val_loss=0.1159 | val_acc=0.6222 | val_f1m=0.6183 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1168 | train_acc=0.6276 | val_loss=0.1052 | val_acc=0.7095 | val_f1m=0.7095 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0987 | train_acc=0.7278 | val_loss=0.0958 | val_acc=0.7206 | val_f1m=0.7202 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0910 | train_acc=0.7594 | val_loss=0.0973 | val_acc=0.7175 | val_f1m=0.7028 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0808 | train_acc=0.7921 | val_loss=0.0942 | val_acc=0.7492 | val_f1m=0.7492 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0776 | train_acc=0.8042 | val_loss=0.0910 | val_acc=0.7476 | val_f1m=0.7417 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0771 | train_acc=0.8056 | val_loss=0.0823 | val_acc=0.7873 | val_f1m=0.7870 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0677 | train_acc=0.8316 | val_loss=0.0846 | val_acc=0.7857 | val_f1m=0.7854 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0691 | train_acc=0.8301 | val_loss=0.0821 | val_acc=0.8000 | val_f1m=0.8000 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0672 | train_acc=0.8333 | val_loss=0.0826 | val_acc=0.7952 | val_f1m=0.7951 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0662 | train_acc=0.8358 | val_loss=0.0840 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0671 | train_acc=0.8394 | val_loss=0.0854 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0637 | train_acc=0.8454 | val_loss=0.0850 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0649 | train_acc=0.8380 | val_loss=0.0878 | val_acc=0.7825 | val_f1m=0.7818 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0614 | train_acc=0.8500 | val_loss=0.0856 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0597 | train_acc=0.8568 | val_loss=0.0897 | val_acc=0.7825 | val_f1m=0.7821 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0624 | train_acc=0.8497 | val_loss=0.0885 | val_acc=0.7952 | val_f1m=0.7950 | LR=0.000443\n",
      "  Early stopping en época 18 (mejor val_f1m=0.8000)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold2/model_global_fold2_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold2/training_curve_fold2_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold2/history_fold2_nb2_h6.npz\n",
      "[Fold 2/5] Global acc=0.8356 | f1_macro=0.8353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8083    0.8798    0.8426       441\n",
      "       right     0.8682    0.7914    0.8280       441\n",
      "\n",
      "    accuracy                         0.8356       882\n",
      "   macro avg     0.8382    0.8356    0.8353       882\n",
      "weighted avg     0.8382    0.8356    0.8353       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[388  53]\n",
      " [ 92 349]]\n",
      "precision_macro=0.8382 | recall_macro=0.8356 | specificity_macro=0.8356 | sensitivity_macro=0.8356\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold2/confusion_global_fold2_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold2/attention_map_fold2_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold2/topomap_saliency_fold2_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold2/topomap_log10p_fold2_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold2/tsne_cls_fold2_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8878 | f1_macro=0.8877\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold2/confusion_ft_fold2_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.12 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 17.21it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.32it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1315 | train_acc=0.5174 | val_loss=0.1267 | val_acc=0.5079 | val_f1m=0.3685 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1251 | train_acc=0.5402 | val_loss=0.1324 | val_acc=0.5190 | val_f1m=0.3840 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1242 | train_acc=0.5547 | val_loss=0.1109 | val_acc=0.6810 | val_f1m=0.6809 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1067 | train_acc=0.6844 | val_loss=0.0947 | val_acc=0.7222 | val_f1m=0.7221 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0889 | train_acc=0.7633 | val_loss=0.0884 | val_acc=0.7651 | val_f1m=0.7621 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0765 | train_acc=0.7974 | val_loss=0.0827 | val_acc=0.8016 | val_f1m=0.8015 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0721 | train_acc=0.8259 | val_loss=0.0834 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0738 | train_acc=0.8223 | val_loss=0.0810 | val_acc=0.8063 | val_f1m=0.8063 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0656 | train_acc=0.8447 | val_loss=0.0795 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0677 | train_acc=0.8269 | val_loss=0.0765 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0634 | train_acc=0.8340 | val_loss=0.0907 | val_acc=0.7921 | val_f1m=0.7917 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0644 | train_acc=0.8387 | val_loss=0.0783 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0603 | train_acc=0.8557 | val_loss=0.0842 | val_acc=0.7794 | val_f1m=0.7777 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0598 | train_acc=0.8586 | val_loss=0.0823 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0597 | train_acc=0.8621 | val_loss=0.0857 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0584 | train_acc=0.8539 | val_loss=0.0815 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0598 | train_acc=0.8547 | val_loss=0.0823 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0627 | train_acc=0.8454 | val_loss=0.0810 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0563 | train_acc=0.8696 | val_loss=0.0901 | val_acc=0.8048 | val_f1m=0.8045 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0605 | train_acc=0.8525 | val_loss=0.0829 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0539 | train_acc=0.8735 | val_loss=0.0882 | val_acc=0.8111 | val_f1m=0.8110 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0514 | train_acc=0.8788 | val_loss=0.0900 | val_acc=0.7794 | val_f1m=0.7791 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0486 | train_acc=0.8852 | val_loss=0.0920 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0528 | train_acc=0.8738 | val_loss=0.0920 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0511 | train_acc=0.8738 | val_loss=0.0921 | val_acc=0.7889 | val_f1m=0.7885 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0510 | train_acc=0.8763 | val_loss=0.0922 | val_acc=0.7889 | val_f1m=0.7885 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0521 | train_acc=0.8795 | val_loss=0.0922 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0485 | train_acc=0.8852 | val_loss=0.0923 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0492 | train_acc=0.8852 | val_loss=0.0924 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.8110)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold3/model_global_fold3_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold3/training_curve_fold3_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold3/history_fold3_nb2_h6.npz\n",
      "[Fold 3/5] Global acc=0.8084 | f1_macro=0.8084\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8134    0.8005    0.8069       441\n",
      "       right     0.8036    0.8163    0.8099       441\n",
      "\n",
      "    accuracy                         0.8084       882\n",
      "   macro avg     0.8085    0.8084    0.8084       882\n",
      "weighted avg     0.8085    0.8084    0.8084       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[353  88]\n",
      " [ 81 360]]\n",
      "precision_macro=0.8085 | recall_macro=0.8084 | specificity_macro=0.8084 | sensitivity_macro=0.8084\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold3/confusion_global_fold3_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold3/attention_map_fold3_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold3/topomap_saliency_fold3_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold3/topomap_log10p_fold3_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold3/tsne_cls_fold3_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8469 | f1_macro=0.8469\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold3/confusion_ft_fold3_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.13 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.07it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.04it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1308 | train_acc=0.4972 | val_loss=0.1204 | val_acc=0.5651 | val_f1m=0.5476 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1254 | train_acc=0.5501 | val_loss=0.1177 | val_acc=0.6079 | val_f1m=0.6056 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1174 | train_acc=0.6008 | val_loss=0.1263 | val_acc=0.6508 | val_f1m=0.6418 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1039 | train_acc=0.6992 | val_loss=0.1061 | val_acc=0.6889 | val_f1m=0.6888 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0898 | train_acc=0.7626 | val_loss=0.1008 | val_acc=0.7349 | val_f1m=0.7327 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0802 | train_acc=0.7805 | val_loss=0.0876 | val_acc=0.7635 | val_f1m=0.7622 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0810 | train_acc=0.7920 | val_loss=0.0990 | val_acc=0.7286 | val_f1m=0.7182 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0737 | train_acc=0.8099 | val_loss=0.0873 | val_acc=0.7762 | val_f1m=0.7749 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0725 | train_acc=0.8253 | val_loss=0.0881 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0707 | train_acc=0.8165 | val_loss=0.1018 | val_acc=0.7492 | val_f1m=0.7479 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0702 | train_acc=0.8228 | val_loss=0.0897 | val_acc=0.7667 | val_f1m=0.7647 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0689 | train_acc=0.8347 | val_loss=0.0898 | val_acc=0.7492 | val_f1m=0.7482 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0657 | train_acc=0.8326 | val_loss=0.0864 | val_acc=0.7746 | val_f1m=0.7742 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0636 | train_acc=0.8424 | val_loss=0.0880 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0684 | train_acc=0.8347 | val_loss=0.0887 | val_acc=0.7667 | val_f1m=0.7650 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0602 | train_acc=0.8526 | val_loss=0.0867 | val_acc=0.7730 | val_f1m=0.7725 | LR=0.000459\n",
      "  Early stopping en época 16 (mejor val_f1m=0.7749)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold4/model_global_fold4_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold4/training_curve_fold4_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold4/history_fold4_nb2_h6.npz\n",
      "[Fold 4/5] Global acc=0.8119 | f1_macro=0.8098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7579    0.9167    0.8297       420\n",
      "       right     0.8946    0.7071    0.7899       420\n",
      "\n",
      "    accuracy                         0.8119       840\n",
      "   macro avg     0.8262    0.8119    0.8098       840\n",
      "weighted avg     0.8262    0.8119    0.8098       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[385  35]\n",
      " [123 297]]\n",
      "precision_macro=0.8262 | recall_macro=0.8119 | specificity_macro=0.8119 | sensitivity_macro=0.8119\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold4/confusion_global_fold4_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold4/attention_map_fold4_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold4/topomap_saliency_fold4_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold4/topomap_log10p_fold4_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold4/tsne_cls_fold4_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8738 | f1_macro=0.8738\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold4/confusion_ft_fold4_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.12 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.30it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.43it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1320 | train_acc=0.5035 | val_loss=0.1220 | val_acc=0.5095 | val_f1m=0.4079 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1241 | train_acc=0.5445 | val_loss=0.1177 | val_acc=0.5889 | val_f1m=0.5691 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1225 | train_acc=0.5795 | val_loss=0.1122 | val_acc=0.6619 | val_f1m=0.6540 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0968 | train_acc=0.7416 | val_loss=0.1055 | val_acc=0.7000 | val_f1m=0.6988 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0907 | train_acc=0.7560 | val_loss=0.1002 | val_acc=0.7127 | val_f1m=0.7107 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0747 | train_acc=0.8123 | val_loss=0.0961 | val_acc=0.7190 | val_f1m=0.7162 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0737 | train_acc=0.8200 | val_loss=0.1029 | val_acc=0.7286 | val_f1m=0.7273 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0708 | train_acc=0.8232 | val_loss=0.1032 | val_acc=0.7333 | val_f1m=0.7278 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0685 | train_acc=0.8239 | val_loss=0.0916 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0660 | train_acc=0.8351 | val_loss=0.0938 | val_acc=0.7333 | val_f1m=0.7315 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0686 | train_acc=0.8291 | val_loss=0.0903 | val_acc=0.7556 | val_f1m=0.7554 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0652 | train_acc=0.8319 | val_loss=0.0981 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0622 | train_acc=0.8435 | val_loss=0.0971 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0620 | train_acc=0.8456 | val_loss=0.0978 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0609 | train_acc=0.8410 | val_loss=0.0988 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0615 | train_acc=0.8494 | val_loss=0.0961 | val_acc=0.7460 | val_f1m=0.7460 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0585 | train_acc=0.8557 | val_loss=0.1158 | val_acc=0.7683 | val_f1m=0.7673 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0600 | train_acc=0.8512 | val_loss=0.1142 | val_acc=0.7476 | val_f1m=0.7463 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0597 | train_acc=0.8519 | val_loss=0.0966 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0584 | train_acc=0.8578 | val_loss=0.0998 | val_acc=0.7667 | val_f1m=0.7655 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0582 | train_acc=0.8508 | val_loss=0.1060 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0553 | train_acc=0.8666 | val_loss=0.1058 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0536 | train_acc=0.8704 | val_loss=0.1055 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0549 | train_acc=0.8662 | val_loss=0.1055 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0537 | train_acc=0.8676 | val_loss=0.1054 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0528 | train_acc=0.8761 | val_loss=0.1054 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0529 | train_acc=0.8739 | val_loss=0.1054 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000349\n",
      "  Early stopping en época 27 (mejor val_f1m=0.7777)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold5/model_global_fold5_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold5/training_curve_fold5_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold5/history_fold5_nb2_h6.npz\n",
      "[Fold 5/5] Global acc=0.8464 | f1_macro=0.8464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8540    0.8357    0.8448       420\n",
      "       right     0.8392    0.8571    0.8481       420\n",
      "\n",
      "    accuracy                         0.8464       840\n",
      "   macro avg     0.8466    0.8464    0.8464       840\n",
      "weighted avg     0.8466    0.8464    0.8464       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[351  69]\n",
      " [ 60 360]]\n",
      "precision_macro=0.8466 | recall_macro=0.8464 | specificity_macro=0.8464 | sensitivity_macro=0.8464\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold5/confusion_global_fold5_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold5/attention_map_fold5_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold5/topomap_saliency_fold5_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold5/topomap_log10p_fold5_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold5/tsne_cls_fold5_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8786 | f1_macro=0.8786\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold5/confusion_ft_fold5_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.12 ms (B=8)\n",
      "↳ Resumen 5-fold guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/summary_nb2_h6.csv\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES [nb2_h6] (2 clases: left/right)\n",
      "============================================================\n",
      "Global folds (ACC): ['0.8107', '0.8356', '0.8084', '0.8119', '0.8464']\n",
      "Global mean ACC:    0.8226\n",
      "F1 folds (MACRO):   ['0.8107', '0.8353', '0.8084', '0.8098', '0.8464']\n",
      "F1 mean (MACRO):    0.8221\n",
      "FT folds (ACC):     ['0.8526', '0.8878', '0.8469', '0.8738', '0.8786']\n",
      "FT mean (ACC):      0.8679\n",
      "Δ(FT-Global) mean:  +0.0453\n",
      "\n",
      "================ Computational metrics ================\n",
      "Model tag: nb2_h6\n",
      "Phase        time (s)           memory (MB)        FLOPs (g)   params (m)\n",
      "-----------  -----------------  -----------------  ----------  ----------\n",
      "model specs  N/A                N/A                    0.024      0.232\n",
      "train         19.51 ( 7.64)    3233.9 (  1.3)     N/A        N/A\n",
      "test           8.75                112.6              N/A        N/A\n",
      "↳ Tabla de métricas computacionales guardada en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/computational_nb2_h6.csv\n",
      "↳ Matriz de confusión GLOBAL guardada: ModeloW/nb2_h6/confusion_global_allfolds_nb2_h6.png\n",
      "↳ Curva de loss GLOBAL guardada: ModeloW/nb2_h6/training_curve_global_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/topomap_saliency_GLOBAL_nb2_h6.png\n",
      "↳ Topomap GLOBAL de saliency guardado: ModeloW/nb2_h6/topomap_saliency_GLOBAL_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/topomap_log10p_GLOBAL_nb2_h6.png\n",
      "↳ Topomap GLOBAL de -log10(p) guardado: ModeloW/nb2_h6/topomap_log10p_GLOBAL_nb2_h6.png\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"MODELO\")\n",
    "    # 1) Barrido con UN SOLO FOLD (fold=1). Ajusta deltas y head_set si quieres.\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=1)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=2)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=3)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=4)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=5)\n",
    "\n",
    "    # 2) (Luego) con los GANADORES corre los 5 folds:\n",
    "    run_full_5fold_for_config(DEVICE, n_blocks=2, n_heads=6)\n",
    "\n",
    "    # 3) (Opcional) imprimir hiperparámetros contados:\n",
    "    # hp = current_hparams()\n",
    "    # print(f\"\\nHiperparámetros (n={len(hp)}):\")\n",
    "    # for k,v in hp.items():\n",
    "    #     print(f\" - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3391ab",
   "metadata": {},
   "source": [
    "---\n",
    "## ESTUDIO DE ABLACIÓN\n",
    "\n",
    "Esta sección implementa un estudio de ablación sistemático para evaluar la contribución de cada componente del modelo híbrido CNN-Transformer.\n",
    "\n",
    "### Variantes evaluadas:\n",
    "1. **Baseline**: Modelo completo con todos los componentes\n",
    "2. **Sin Depthwise Blocks**: Solo stem convolucional (n_dw_blocks=0)\n",
    "3. **Sin Codificación Posicional**: Elimina positional encoding\n",
    "4. **Sin Token CLS**: Usa average pooling en vez del token de clasificación\n",
    "5. **Con BatchNorm**: Reemplaza GroupNorm por BatchNorm\n",
    "6. **Con ReLU**: Reemplaza activaciones ELU/GELU por ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db544524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Variantes del modelo definidas para estudio de ablación\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# VARIANTES DEL MODELO PARA ABLACIÓN\n",
    "# =========================\n",
    "\n",
    "# VARIANTE 1: Sin bloques depthwise (solo stem)\n",
    "class EEGCNNTransformer_NoDepthwise(nn.Module):\n",
    "    \"\"\"Variante sin bloques depthwise separable\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Solo stem, sin bloques depthwise\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        )\n",
    "        \n",
    "        self.proj = nn.Conv1d(32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # CLS token\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 2: Sin codificación posicional\n",
    "class EEGCNNTransformer_NoPosEncoding(nn.Module):\n",
    "    \"\"\"Variante sin positional encoding\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "\n",
    "        # Stem convolucional\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # SIN positional encoding\n",
    "        \n",
    "        # CLS token\n",
    "        B = z.shape[0]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 3: Sin token CLS (average pooling)\n",
    "class EEGCNNTransformer_NoCLS(nn.Module):\n",
    "    \"\"\"Variante sin token CLS, usa average pooling\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem convolucional\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Head (sin CLS token)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # SIN CLS token\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        # Average pooling en lugar de CLS\n",
    "        pooled = z.mean(dim=1)  # (B, D)\n",
    "        return self.head(pooled)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 4: Con BatchNorm en vez de GroupNorm\n",
    "def make_bn(num_channels):\n",
    "    \"\"\"Crea capa BatchNorm1d\"\"\"\n",
    "    return nn.BatchNorm1d(num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv_BN(nn.Module):\n",
    "    \"\"\"Convolución depthwise separable con BatchNorm\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_bn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class EEGCNNTransformer_BatchNorm(nn.Module):\n",
    "    \"\"\"Variante con BatchNorm en vez de GroupNorm\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem con BatchNorm\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_bn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise con BatchNorm\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv_BN(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # CLS token\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 5: Con ReLU en vez de ELU/GELU\n",
    "class DepthwiseSeparableConv_ReLU(nn.Module):\n",
    "    \"\"\"Convolución depthwise separable con ReLU\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ReLU()  # ReLU en vez de ELU\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class _CustomEncoderLayer_ReLU(nn.Module):\n",
    "    \"\"\"Encoder Transformer con ReLU en FFN\"\"\"\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout, batch_first, norm_first, return_attn=True):\n",
    "        super().__init__()\n",
    "        self.return_attn = return_attn\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()  # ReLU en vez de GELU\n",
    "        self.norm_first = norm_first\n",
    "\n",
    "    def forward(self, src):\n",
    "        sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
    "        src = self.norm1(src + self.dropout1(sa_out))\n",
    "        ff = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = self.norm2(src + self.dropout2(ff))\n",
    "        return src, attn_weights\n",
    "\n",
    "class EEGCNNTransformer_ReLU(nn.Module):\n",
    "    \"\"\"Variante con ReLU en vez de ELU/GELU\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem con ReLU\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ReLU(),  # ReLU en vez de ELU\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise con ReLU\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv_ReLU(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer con ReLU\n",
    "        enc = _CustomEncoderLayer_ReLU(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                       dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # CLS token\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "print(\"✓ Variantes del modelo definidas para estudio de ablación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe6e20",
   "metadata": {},
   "source": [
    "### Función de Entrenamiento del Estudio de Ablación\n",
    "\n",
    "Esta función entrena cada variante del modelo y recopila métricas para comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ffb08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de estudio de ablación definidas\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ESTUDIO DE ABLACIÓN - FUNCIÓN PRINCIPAL\n",
    "# =========================\n",
    "\n",
    "def run_ablation_study(device, fold_list=[1], base_dir=None):\n",
    "    \"\"\"\n",
    "    Ejecuta estudio de ablación entrenando todas las variantes del modelo.\n",
    "    \n",
    "    Args:\n",
    "        device: Dispositivo para entrenamiento (cuda/cpu)\n",
    "        fold_list: Lista de folds a evaluar (default: [1])\n",
    "        base_dir: Directorio base para guardar resultados\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con resultados comparativos\n",
    "    \"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    else:\n",
    "        base_dir = Path(base_dir)\n",
    "    \n",
    "    ensure_dir(base_dir)\n",
    "    \n",
    "    # Definir variantes del modelo\n",
    "    variants = {\n",
    "        'baseline': {\n",
    "            'name': 'Baseline (Completo)',\n",
    "            'factory': lambda: EEGCNNTransformer(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS, \n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'Modelo completo con todos los componentes'\n",
    "        },\n",
    "        'no_depthwise': {\n",
    "            'name': 'Sin Depthwise Blocks',\n",
    "            'factory': lambda: EEGCNNTransformer_NoDepthwise(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                capture_attn=False\n",
    "            ),\n",
    "            'description': 'Solo stem convolucional, sin bloques depthwise'\n",
    "        },\n",
    "        'no_posenc': {\n",
    "            'name': 'Sin Codificación Posicional',\n",
    "            'factory': lambda: EEGCNNTransformer_NoPosEncoding(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'Sin positional encoding en Transformer'\n",
    "        },\n",
    "        'no_cls': {\n",
    "            'name': 'Sin Token CLS',\n",
    "            'factory': lambda: EEGCNNTransformer_NoCLS(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'Usa average pooling en vez de token CLS'\n",
    "        },\n",
    "        'batchnorm': {\n",
    "            'name': 'Con BatchNorm',\n",
    "            'factory': lambda: EEGCNNTransformer_BatchNorm(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'BatchNorm en vez de GroupNorm'\n",
    "        },\n",
    "        'relu': {\n",
    "            'name': 'Con ReLU',\n",
    "            'factory': lambda: EEGCNNTransformer_ReLU(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'ReLU en vez de ELU/GELU'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    results = []\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"INICIANDO ESTUDIO DE ABLACIÓN\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Variantes a evaluar: {len(variants)}\")\n",
    "    print(f\"Folds: {fold_list}\")\n",
    "    print(f\"Directorio de salida: {base_dir}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Entrenar cada variante\n",
    "    for variant_key, variant_info in variants.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"VARIANTE: {variant_info['name']}\")\n",
    "        print(f\"Descripción: {variant_info['description']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        variant_dir = base_dir / variant_key\n",
    "        ensure_dir(variant_dir)\n",
    "        \n",
    "        # Resultados de esta variante\n",
    "        variant_results = {\n",
    "            'variant': variant_key,\n",
    "            'name': variant_info['name'],\n",
    "            'description': variant_info['description']\n",
    "        }\n",
    "        \n",
    "        # Métricas acumuladas por fold\n",
    "        fold_accs = []\n",
    "        fold_f1s = []\n",
    "        fold_params = []\n",
    "        \n",
    "        for fold in fold_list:\n",
    "            print(f\"\\n--- Fold {fold} ---\")\n",
    "            seed_everything(RANDOM_STATE + fold)\n",
    "            \n",
    "            try:\n",
    "                # Cargar datos\n",
    "                train_subs, test_subs = load_fold_subjects(FOLDS_JSON, fold)\n",
    "                print(f\"Train: {len(train_subs)} sujetos, Test: {len(test_subs)} sujetos\")\n",
    "                \n",
    "                # Cargar épocas\n",
    "                X_train_list, y_train_list = [], []\n",
    "                for sid in tqdm(train_subs, desc=\"Cargando train\"):\n",
    "                    X, y, _ = load_subject_epochs(\n",
    "                        sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, \n",
    "                        DO_CAR, BP_LO, BP_HI\n",
    "                    )\n",
    "                    if X.shape[0] > 0:\n",
    "                        X_train_list.append(X)\n",
    "                        y_train_list.append(y)\n",
    "                \n",
    "                X_test_list, y_test_list = [], []\n",
    "                for sid in tqdm(test_subs, desc=\"Cargando test\"):\n",
    "                    X, y, _ = load_subject_epochs(\n",
    "                        sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS,\n",
    "                        DO_CAR, BP_LO, BP_HI\n",
    "                    )\n",
    "                    if X.shape[0] > 0:\n",
    "                        X_test_list.append(X)\n",
    "                        y_test_list.append(y)\n",
    "                \n",
    "                X_train = np.concatenate(X_train_list, axis=0)\n",
    "                y_train = np.concatenate(y_train_list, axis=0)\n",
    "                X_test = np.concatenate(X_test_list, axis=0)\n",
    "                y_test = np.concatenate(y_test_list, axis=0)\n",
    "                \n",
    "                # Estandarizar\n",
    "                X_train, X_test = standardize_per_channel(X_train, X_test)\n",
    "                \n",
    "                print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "                \n",
    "                # Crear modelo\n",
    "                model = variant_info['factory']().to(device)\n",
    "                n_params = count_params(model)\n",
    "                fold_params.append(n_params)\n",
    "                print(f\"Parámetros: {n_params:,}\")\n",
    "                \n",
    "                # Preparar DataLoader\n",
    "                train_dataset = TensorDataset(\n",
    "                    torch.tensor(X_train, dtype=torch.float32),\n",
    "                    torch.tensor(y_train, dtype=torch.long)\n",
    "                )\n",
    "                \n",
    "                if USE_WEIGHTED_SAMPLER:\n",
    "                    class_counts = np.bincount(y_train)\n",
    "                    class_weights = 1.0 / (class_counts + 1e-6)\n",
    "                    sample_weights = class_weights[y_train]\n",
    "                    sampler = WeightedRandomSampler(\n",
    "                        weights=sample_weights,\n",
    "                        num_samples=len(sample_weights),\n",
    "                        replacement=True\n",
    "                    )\n",
    "                    train_loader = DataLoader(\n",
    "                        train_dataset, batch_size=BATCH_SIZE,\n",
    "                        sampler=sampler, worker_init_fn=seed_worker,\n",
    "                        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                    )\n",
    "                else:\n",
    "                    train_loader = DataLoader(\n",
    "                        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                    )\n",
    "                \n",
    "                # Pérdida y optimizador\n",
    "                alpha = torch.tensor([1.0, 1.0], device=device)\n",
    "                criterion = FocalLoss(alpha=alpha, gamma=1.5)\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-4)\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer, T_max=EPOCHS, eta_min=1e-6\n",
    "                )\n",
    "                \n",
    "                # EMA\n",
    "                ema = ModelEMA(model, decay=EMA_DECAY, device=device) if USE_EMA else None\n",
    "                \n",
    "                # Entrenamiento\n",
    "                best_val_acc = 0.0\n",
    "                patience_counter = 0\n",
    "                \n",
    "                for epoch in range(EPOCHS):\n",
    "                    model.train()\n",
    "                    train_loss = 0.0\n",
    "                    \n",
    "                    for xb, yb in train_loader:\n",
    "                        xb, yb = xb.to(device), yb.to(device)\n",
    "                        \n",
    "                        # Augmentación\n",
    "                        if epoch > WARMUP_EPOCHS:\n",
    "                            xb = augment_batch(xb)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model(xb)\n",
    "                        loss = criterion(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if ema is not None:\n",
    "                            ema.update(model)\n",
    "                        \n",
    "                        train_loss += loss.item()\n",
    "                    \n",
    "                    scheduler.step()\n",
    "                    \n",
    "                    # Validación en test set (simplificado)\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                        logits = model(X_test_t)\n",
    "                        y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                        val_acc = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {train_loss/len(train_loader):.4f}, Val Acc: {val_acc:.4f}\")\n",
    "                    \n",
    "                    # Early stopping\n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = val_acc\n",
    "                        patience_counter = 0\n",
    "                        # Guardar mejor modelo\n",
    "                        torch.save(model.state_dict(), variant_dir / f\"best_fold{fold}.pt\")\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        if patience_counter >= PATIENCE:\n",
    "                            print(f\"Early stopping en epoch {epoch+1}\")\n",
    "                            break\n",
    "                \n",
    "                # Evaluación final\n",
    "                model.load_state_dict(torch.load(variant_dir / f\"best_fold{fold}.pt\"))\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                    logits = model(X_test_t)\n",
    "                    y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                \n",
    "                # Métricas\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                metrics = compute_metrics(y_test, y_pred)\n",
    "                \n",
    "                fold_accs.append(acc)\n",
    "                fold_f1s.append(f1)\n",
    "                \n",
    "                print(f\"Fold {fold} - Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "                \n",
    "                # Limpiar memoria\n",
    "                del model, optimizer, scheduler, train_loader, X_train, y_train\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR en fold {fold}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                fold_accs.append(0.0)\n",
    "                fold_f1s.append(0.0)\n",
    "                fold_params.append(0)\n",
    "        \n",
    "        # Compilar resultados de la variante\n",
    "        variant_results['mean_accuracy'] = np.mean(fold_accs) if fold_accs else 0.0\n",
    "        variant_results['std_accuracy'] = np.std(fold_accs) if fold_accs else 0.0\n",
    "        variant_results['mean_f1'] = np.mean(fold_f1s) if fold_f1s else 0.0\n",
    "        variant_results['std_f1'] = np.std(fold_f1s) if fold_f1s else 0.0\n",
    "        variant_results['n_params'] = fold_params[0] if fold_params else 0\n",
    "        variant_results['folds'] = fold_list\n",
    "        variant_results['fold_accs'] = fold_accs\n",
    "        variant_results['fold_f1s'] = fold_f1s\n",
    "        \n",
    "        results.append(variant_results)\n",
    "        \n",
    "        print(f\"\\n{variant_info['name']} - Resumen:\")\n",
    "        print(f\"  Accuracy: {variant_results['mean_accuracy']:.4f} ± {variant_results['std_accuracy']:.4f}\")\n",
    "        print(f\"  F1-Score: {variant_results['mean_f1']:.4f} ± {variant_results['std_f1']:.4f}\")\n",
    "        print(f\"  Parámetros: {variant_results['n_params']:,}\")\n",
    "    \n",
    "    # Crear DataFrame con resultados\n",
    "    import pandas as pd\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_csv = base_dir / 'ablation_results.csv'\n",
    "    df_results.to_csv(results_csv, index=False)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Resultados guardados en: {results_csv}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "def plot_ablation_results(df_results, output_dir=None):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones de los resultados del estudio de ablación.\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame con resultados\n",
    "        output_dir: Directorio para guardar gráficos\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    # Ordenar por accuracy\n",
    "    df_sorted = df_results.sort_values('mean_accuracy', ascending=False)\n",
    "    \n",
    "    # Gráfico de barras con accuracy y F1\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.barh(df_sorted['name'], df_sorted['mean_accuracy'], \n",
    "             xerr=df_sorted['std_accuracy'], capsize=5, color='steelblue')\n",
    "    ax1.set_xlabel('Accuracy')\n",
    "    ax1.set_title('Comparación de Accuracy por Variante')\n",
    "    ax1.set_xlim([0, 1.0])\n",
    "    ax1.axvline(x=df_sorted.iloc[0]['mean_accuracy'], color='red', \n",
    "                linestyle='--', alpha=0.5, label='Mejor')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # F1-Score\n",
    "    ax2.barh(df_sorted['name'], df_sorted['mean_f1'], \n",
    "             xerr=df_sorted['std_f1'], capsize=5, color='coral')\n",
    "    ax2.set_xlabel('F1-Score (Macro)')\n",
    "    ax2.set_title('Comparación de F1-Score por Variante')\n",
    "    ax2.set_xlim([0, 1.0])\n",
    "    ax2.axvline(x=df_sorted.iloc[0]['mean_f1'], color='red', \n",
    "                linestyle='--', alpha=0.5, label='Mejor')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = output_dir / 'ablation_comparison.png'\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Gráfico guardado en: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Tabla de comparación\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = []\n",
    "    for _, row in df_sorted.iterrows():\n",
    "        table_data.append([\n",
    "            row['name'],\n",
    "            f\"{row['mean_accuracy']:.4f} ± {row['std_accuracy']:.4f}\",\n",
    "            f\"{row['mean_f1']:.4f} ± {row['std_f1']:.4f}\",\n",
    "            f\"{row['n_params']:,}\"\n",
    "        ])\n",
    "    \n",
    "    table = ax.table(cellText=table_data,\n",
    "                     colLabels=['Variante', 'Accuracy', 'F1-Score', 'Parámetros'],\n",
    "                     cellLoc='left',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Colorear la mejor fila\n",
    "    for i in range(4):\n",
    "        table[(1, i)].set_facecolor('#90EE90')\n",
    "    \n",
    "    plt.title('Resumen de Resultados - Estudio de Ablación', \n",
    "              fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    table_path = output_dir / 'ablation_table.png'\n",
    "    plt.savefig(table_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Tabla guardada en: {table_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "print(\"✓ Funciones de estudio de ablación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2996ec",
   "metadata": {},
   "source": [
    "### Ejecución del Estudio de Ablación\n",
    "\n",
    "Ejecuta el estudio de ablación y genera visualizaciones comparativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5eab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ESTUDIO DE ABLACIÓN - CNN+Transformer para EEG Motor Imagery\n",
      "================================================================================\n",
      "\n",
      "Ejecutando estudio con 5 fold(s): [1, 2, 3, 4, 5]\n",
      "Esto puede tardar varios minutos dependiendo del número de folds...\n",
      "\n",
      "================================================================================\n",
      "INICIANDO ESTUDIO DE ABLACIÓN\n",
      "================================================================================\n",
      "Variantes a evaluar: 6\n",
      "Folds: [1, 2, 3, 4, 5]\n",
      "Directorio de salida: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ablation_study\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "VARIANTE: Baseline (Completo)\n",
      "Descripción: Modelo completo con todos los componentes\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.36it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0648, Val Acc: 0.7778\n",
      "Early stopping en epoch 13\n",
      "Fold 1 - Acc: 0.7971, F1: 0.7967\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.43it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0672, Val Acc: 0.8141\n",
      "Epoch 20/60 - Loss: 0.0544, Val Acc: 0.8231\n",
      "Early stopping en epoch 21\n",
      "Fold 2 - Acc: 0.8469, F1: 0.8466\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.30it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0702, Val Acc: 0.7868\n",
      "Epoch 20/60 - Loss: 0.0607, Val Acc: 0.7846\n",
      "Early stopping en epoch 25\n",
      "Fold 3 - Acc: 0.8107, F1: 0.8106\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.32it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0681, Val Acc: 0.8298\n",
      "Early stopping en epoch 15\n",
      "Fold 4 - Acc: 0.8476, F1: 0.8476\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.30it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0691, Val Acc: 0.8202\n",
      "Epoch 20/60 - Loss: 0.0598, Val Acc: 0.8333\n",
      "Early stopping en epoch 23\n",
      "Fold 5 - Acc: 0.8583, F1: 0.8582\n",
      "\n",
      "Baseline (Completo) - Resumen:\n",
      "  Accuracy: 0.8321 ± 0.0238\n",
      "  F1-Score: 0.8319 ± 0.0239\n",
      "  Parámetros: 232,290\n",
      "\n",
      "================================================================================\n",
      "VARIANTE: Sin Depthwise Blocks\n",
      "Descripción: Solo stem convolucional, sin bloques depthwise\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 16.48it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 205,890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-16-8a02d1bef429>\", line 232, in run_ablation_study\n",
      "    logits = model(X_test_t)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-15-6102edd9c698>\", line 61, in forward\n",
      "    z, attn_list = self.encoder(z)\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 67, in forward\n",
      "    out, attn = lyr(out)\n",
      "                ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 49, in forward\n",
      "    sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1313, in forward\n",
      "    return torch._native_multi_head_attention(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 139.81 GiB of which 463.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR en fold 1: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 139.81 GiB of which 463.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.31it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 205,890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-16-8a02d1bef429>\", line 232, in run_ablation_study\n",
      "    logits = model(X_test_t)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-15-6102edd9c698>\", line 61, in forward\n",
      "    z, attn_list = self.encoder(z)\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 67, in forward\n",
      "    out, attn = lyr(out)\n",
      "                ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 49, in forward\n",
      "    sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1313, in forward\n",
      "    return torch._native_multi_head_attention(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 139.81 GiB of which 465.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR en fold 2: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 139.81 GiB of which 465.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.24it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 205,890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-16-8a02d1bef429>\", line 232, in run_ablation_study\n",
      "    logits = model(X_test_t)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-15-6102edd9c698>\", line 61, in forward\n",
      "    z, attn_list = self.encoder(z)\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 67, in forward\n",
      "    out, attn = lyr(out)\n",
      "                ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 49, in forward\n",
      "    sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1313, in forward\n",
      "    return torch._native_multi_head_attention(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 139.81 GiB of which 467.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR en fold 3: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 139.81 GiB of which 467.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.36it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 205,890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-16-8a02d1bef429>\", line 232, in run_ablation_study\n",
      "    logits = model(X_test_t)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-15-6102edd9c698>\", line 61, in forward\n",
      "    z, attn_list = self.encoder(z)\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 67, in forward\n",
      "    out, attn = lyr(out)\n",
      "                ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 49, in forward\n",
      "    sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1313, in forward\n",
      "    return torch._native_multi_head_attention(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 139.81 GiB of which 467.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 983.37 MiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR en fold 4: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 139.81 GiB of which 467.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 983.37 MiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.28it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 205,890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-16-8a02d1bef429>\", line 232, in run_ablation_study\n",
      "    logits = model(X_test_t)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-15-6102edd9c698>\", line 61, in forward\n",
      "    z, attn_list = self.encoder(z)\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 67, in forward\n",
      "    out, attn = lyr(out)\n",
      "                ^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-5-359cf97cc42d>\", line 49, in forward\n",
      "    sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1313, in forward\n",
      "    return torch._native_multi_head_attention(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 139.81 GiB of which 465.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 983.37 MiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR en fold 5: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacity of 139.81 GiB of which 465.25 MiB is free. Process 2382944 has 522.00 MiB memory in use. Process 735135 has 97.92 GiB memory in use. Process 894919 has 37.12 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 983.37 MiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Sin Depthwise Blocks - Resumen:\n",
      "  Accuracy: 0.0000 ± 0.0000\n",
      "  F1-Score: 0.0000 ± 0.0000\n",
      "  Parámetros: 205,890\n",
      "\n",
      "================================================================================\n",
      "VARIANTE: Sin Codificación Posicional\n",
      "Descripción: Sin positional encoding en Transformer\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.30it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0913, Val Acc: 0.6825\n",
      "Early stopping en epoch 19\n",
      "Fold 1 - Acc: 0.7177, F1: 0.7176\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.10it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0972, Val Acc: 0.6893\n",
      "Epoch 20/60 - Loss: 0.0839, Val Acc: 0.7392\n",
      "Epoch 30/60 - Loss: 0.0833, Val Acc: 0.7630\n",
      "Early stopping en epoch 35\n",
      "Fold 2 - Acc: 0.7642, F1: 0.7618\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.21it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0961, Val Acc: 0.7404\n",
      "Epoch 20/60 - Loss: 0.0845, Val Acc: 0.7540\n",
      "Early stopping en epoch 27\n",
      "Fold 3 - Acc: 0.7630, F1: 0.7629\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.22it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0951, Val Acc: 0.7738\n",
      "Epoch 20/60 - Loss: 0.0857, Val Acc: 0.7869\n",
      "Epoch 30/60 - Loss: 0.0783, Val Acc: 0.7524\n",
      "Early stopping en epoch 31\n",
      "Fold 4 - Acc: 0.7905, F1: 0.7901\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.11it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0994, Val Acc: 0.7345\n",
      "Epoch 20/60 - Loss: 0.0872, Val Acc: 0.7512\n",
      "Early stopping en epoch 27\n",
      "Fold 5 - Acc: 0.7738, F1: 0.7735\n",
      "\n",
      "Sin Codificación Posicional - Resumen:\n",
      "  Accuracy: 0.7618 ± 0.0242\n",
      "  F1-Score: 0.7612 ± 0.0240\n",
      "  Parámetros: 232,290\n",
      "\n",
      "================================================================================\n",
      "VARIANTE: Sin Token CLS\n",
      "Descripción: Usa average pooling en vez de token CLS\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 16.91it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,146\n",
      "Epoch 10/60 - Loss: 0.0622, Val Acc: 0.7914\n",
      "Epoch 20/60 - Loss: 0.0532, Val Acc: 0.7959\n",
      "Early stopping en epoch 27\n",
      "Fold 1 - Acc: 0.8016, F1: 0.8013\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.07it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,146\n",
      "Epoch 10/60 - Loss: 0.0629, Val Acc: 0.8265\n",
      "Early stopping en epoch 19\n",
      "Fold 2 - Acc: 0.8311, F1: 0.8309\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.16it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,146\n",
      "Epoch 10/60 - Loss: 0.0656, Val Acc: 0.7993\n",
      "Epoch 20/60 - Loss: 0.0517, Val Acc: 0.8016\n",
      "Early stopping en epoch 24\n",
      "Fold 3 - Acc: 0.8095, F1: 0.8095\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.11it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,146\n",
      "Epoch 10/60 - Loss: 0.0667, Val Acc: 0.8048\n",
      "Early stopping en epoch 13\n",
      "Fold 4 - Acc: 0.8298, F1: 0.8296\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.48it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,146\n",
      "Epoch 10/60 - Loss: 0.0634, Val Acc: 0.8024\n",
      "Early stopping en epoch 19\n",
      "Fold 5 - Acc: 0.8571, F1: 0.8571\n",
      "\n",
      "Sin Token CLS - Resumen:\n",
      "  Accuracy: 0.8258 ± 0.0194\n",
      "  F1-Score: 0.8257 ± 0.0194\n",
      "  Parámetros: 232,146\n",
      "\n",
      "================================================================================\n",
      "VARIANTE: Con BatchNorm\n",
      "Descripción: BatchNorm en vez de GroupNorm\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.50it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0676, Val Acc: 0.7834\n",
      "Early stopping en epoch 17\n",
      "Fold 1 - Acc: 0.7857, F1: 0.7857\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.38it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0733, Val Acc: 0.8209\n",
      "Epoch 20/60 - Loss: 0.0642, Val Acc: 0.8288\n",
      "Early stopping en epoch 27\n",
      "Fold 2 - Acc: 0.8537, F1: 0.8537\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.18it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0741, Val Acc: 0.7902\n",
      "Early stopping en epoch 19\n",
      "Fold 3 - Acc: 0.7993, F1: 0.7993\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.27it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0743, Val Acc: 0.8155\n",
      "Epoch 20/60 - Loss: 0.0642, Val Acc: 0.8214\n",
      "Early stopping en epoch 20\n",
      "Fold 4 - Acc: 0.8298, F1: 0.8296\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.07it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0744, Val Acc: 0.8083\n",
      "Early stopping en epoch 15\n",
      "Fold 5 - Acc: 0.8417, F1: 0.8416\n",
      "\n",
      "Con BatchNorm - Resumen:\n",
      "  Accuracy: 0.8220 ± 0.0256\n",
      "  F1-Score: 0.8220 ± 0.0256\n",
      "  Parámetros: 232,290\n",
      "\n",
      "================================================================================\n",
      "VARIANTE: Con ReLU\n",
      "Descripción: ReLU en vez de ELU/GELU\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.09it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0651, Val Acc: 0.8039\n",
      "Epoch 20/60 - Loss: 0.0539, Val Acc: 0.7959\n",
      "Early stopping en epoch 23\n",
      "Fold 1 - Acc: 0.8095, F1: 0.8095\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.22it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0681, Val Acc: 0.8209\n",
      "Early stopping en epoch 19\n",
      "Fold 2 - Acc: 0.8390, F1: 0.8389\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train: 82 sujetos, Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 82/82 [00:04<00:00, 17.49it/s]\n",
      "Cargando test: 100%|██████████| 21/21 [00:01<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961), Test: (882, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0672, Val Acc: 0.7880\n",
      "Epoch 20/60 - Loss: 0.0608, Val Acc: 0.7948\n",
      "Early stopping en epoch 24\n",
      "Fold 3 - Acc: 0.7971, F1: 0.7970\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 17.43it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0703, Val Acc: 0.8238\n",
      "Early stopping en epoch 15\n",
      "Fold 4 - Acc: 0.8417, F1: 0.8416\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train: 83 sujetos, Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train: 100%|██████████| 83/83 [00:04<00:00, 16.68it/s]\n",
      "Cargando test: 100%|██████████| 20/20 [00:01<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961), Test: (840, 8, 961)\n",
      "Parámetros: 232,290\n",
      "Epoch 10/60 - Loss: 0.0710, Val Acc: 0.8262\n",
      "Early stopping en epoch 13\n",
      "Fold 5 - Acc: 0.8381, F1: 0.8377\n",
      "\n",
      "Con ReLU - Resumen:\n",
      "  Accuracy: 0.8251 ± 0.0183\n",
      "  F1-Score: 0.8250 ± 0.0182\n",
      "  Parámetros: 232,290\n",
      "\n",
      "================================================================================\n",
      "Resultados guardados en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ablation_study/ablation_results.csv\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS DEL ESTUDIO DE ABLACIÓN\n",
      "================================================================================\n",
      "                       name  mean_accuracy  std_accuracy  mean_f1   std_f1  n_params\n",
      "        Baseline (Completo)       0.832120      0.023822 0.831932 0.023861    232290\n",
      "       Sin Depthwise Blocks       0.000000      0.000000 0.000000 0.000000    205890\n",
      "Sin Codificación Posicional       0.761837      0.024165 0.761189 0.024025    232290\n",
      "              Sin Token CLS       0.825816      0.019375 0.825687 0.019420    232146\n",
      "              Con BatchNorm       0.822041      0.025634 0.821963 0.025619    232290\n",
      "                   Con ReLU       0.825068      0.018253 0.824956 0.018186    232290\n",
      "\n",
      "Generando visualizaciones...\n",
      "Gráfico guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ablation_study/ablation_comparison.png\n",
      "Tabla guardada en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ablation_study/ablation_table.png\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE CONTRIBUCIÓN RELATIVA\n",
      "================================================================================\n",
      "\n",
      "Baseline Accuracy: 0.8321\n",
      "\n",
      "Variante                      | Acc ± Std          | Δ vs Baseline | % Change\n",
      "--------------------------------------------------------------------------------\n",
      "Baseline (Completo)            | 0.8321 ± 0.0238 | ++0.0000    | ++0.00%\n",
      "Sin Token CLS                  | 0.8258 ± 0.0194 | -0.0063    | -0.76%\n",
      "Con ReLU                       | 0.8251 ± 0.0183 | -0.0071    | -0.85%\n",
      "Con BatchNorm                  | 0.8220 ± 0.0256 | -0.0101    | -1.21%\n",
      "Sin Codificación Posicional    | 0.7618 ± 0.0242 | -0.0703    | -8.45%\n",
      "Sin Depthwise Blocks           | 0.0000 ± 0.0000 | -0.8321    | -100.00%\n",
      "\n",
      "================================================================================\n",
      "INTERPRETACIÓN:\n",
      "================================================================================\n",
      "• Δ positivo: El componente REDUCE el rendimiento (su eliminación mejora)\n",
      "• Δ negativo: El componente MEJORA el rendimiento (su eliminación empeora)\n",
      "• Δ cercano a 0: El componente tiene impacto mínimo\n",
      "\n",
      "\n",
      "Ranking de componentes por impacto (mayor a menor):\n",
      "--------------------------------------------------------------------------------\n",
      "1. Sin Depthwise Blocks           | Contribución: +0.8321 | BENEFICIOSO\n",
      "2. Sin Codificación Posicional    | Contribución: +0.0703 | BENEFICIOSO\n",
      "3. Con BatchNorm                  | Contribución: +0.0101 | BENEFICIOSO\n",
      "4. Con ReLU                       | Contribución: +0.0071 | BENEFICIOSO\n",
      "5. Sin Token CLS                  | Contribución: +0.0063 | BENEFICIOSO\n",
      "\n",
      "================================================================================\n",
      "ESTUDIO COMPLETADO\n",
      "================================================================================\n",
      "Resultados guardados en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ablation_study\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# EJECUTAR ESTUDIO DE ABLACIÓN\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuración del estudio\n",
    "    # Puedes cambiar fold_list para evaluar en múltiples folds\n",
    "    # Por defecto usa solo fold 1 para rapidez (para pruebas)\n",
    "    # Para resultados finales, usar fold_list=[1, 2, 3, 4, 5]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTUDIO DE ABLACIÓN - CNN+Transformer para EEG Motor Imagery\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # OPCIÓN 1: Prueba rápida con 1 fold\n",
    "    # fold_list = [1]\n",
    "    \n",
    "    # OPCIÓN 2: Evaluación completa con 5 folds (descomenta para usar)\n",
    "    fold_list = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    # Ejecutar estudio de ablación\n",
    "    print(f\"Ejecutando estudio con {len(fold_list)} fold(s): {fold_list}\")\n",
    "    print(\"Esto puede tardar varios minutos dependiendo del número de folds...\\n\")\n",
    "    \n",
    "    df_results = run_ablation_study(\n",
    "        device=DEVICE,\n",
    "        fold_list=fold_list,\n",
    "        base_dir=PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    )\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTADOS DEL ESTUDIO DE ABLACIÓN\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_results[['name', 'mean_accuracy', 'std_accuracy', 'mean_f1', 'std_f1', 'n_params']].to_string(index=False))\n",
    "    \n",
    "    # Generar gráficos\n",
    "    print(\"\\nGenerando visualizaciones...\")\n",
    "    df_sorted = plot_ablation_results(\n",
    "        df_results,\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    )\n",
    "    \n",
    "    # Análisis de contribución relativa (vs baseline)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS DE CONTRIBUCIÓN RELATIVA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    baseline_acc = df_results[df_results['variant'] == 'baseline']['mean_accuracy'].values[0]\n",
    "    \n",
    "    print(f\"\\nBaseline Accuracy: {baseline_acc:.4f}\\n\")\n",
    "    print(\"Variante                      | Acc ± Std          | Δ vs Baseline | % Change\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for _, row in df_sorted.iterrows():\n",
    "        delta = row['mean_accuracy'] - baseline_acc\n",
    "        pct_change = (delta / baseline_acc) * 100 if baseline_acc > 0 else 0\n",
    "        sign = \"+\" if delta >= 0 else \"\"\n",
    "        \n",
    "        print(f\"{row['name']:30s} | {row['mean_accuracy']:.4f} ± {row['std_accuracy']:.4f} | \"\n",
    "              f\"{sign}{delta:+.4f}    | {sign}{pct_change:+.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERPRETACIÓN:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"• Δ positivo: El componente REDUCE el rendimiento (su eliminación mejora)\")\n",
    "    print(\"• Δ negativo: El componente MEJORA el rendimiento (su eliminación empeora)\")\n",
    "    print(\"• Δ cercano a 0: El componente tiene impacto mínimo\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Identificar componentes más importantes\n",
    "    contributions = []\n",
    "    for _, row in df_results.iterrows():\n",
    "        if row['variant'] != 'baseline':\n",
    "            delta = baseline_acc - row['mean_accuracy']  # Invertido: pérdida de rendimiento\n",
    "            contributions.append({\n",
    "                'component': row['name'],\n",
    "                'contribution': delta,\n",
    "                'abs_contribution': abs(delta)\n",
    "            })\n",
    "    \n",
    "    contributions_sorted = sorted(contributions, key=lambda x: x['abs_contribution'], reverse=True)\n",
    "    \n",
    "    print(\"Ranking de componentes por impacto (mayor a menor):\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, comp in enumerate(contributions_sorted, 1):\n",
    "        impact = \"BENEFICIOSO\" if comp['contribution'] > 0 else \"PERJUDICIAL\" if comp['contribution'] < 0 else \"NEUTRAL\"\n",
    "        print(f\"{i}. {comp['component']:30s} | Contribución: {comp['contribution']:+.4f} | {impact}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTUDIO COMPLETADO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Resultados guardados en: {PROJ / 'models' / '04_hybrid' / 'ablation_study'}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9a4df",
   "metadata": {},
   "source": [
    "---\n",
    "## Instrucciones de Uso\n",
    "\n",
    "### Configuración rápida:\n",
    "1. **Prueba rápida** (1 fold): Deja `fold_list = [1]` en la celda anterior\n",
    "2. **Evaluación completa** (5 folds): Cambia a `fold_list = [1, 2, 3, 4, 5]`\n",
    "\n",
    "### Tiempo estimado:\n",
    "- **1 fold**: ~10-15 minutos por variante (total ~60-90 minutos para 6 variantes)\n",
    "- **5 folds**: ~50-75 minutos por variante (total ~5-7.5 horas para 6 variantes)\n",
    "\n",
    "### Resultados generados:\n",
    "- **CSV**: `ablation_results.csv` - Tabla con todas las métricas\n",
    "- **Gráficos**: \n",
    "  - `ablation_comparison.png` - Comparación visual de accuracy y F1\n",
    "  - `ablation_table.png` - Tabla formateada con resultados\n",
    "- **Modelos**: Guardados en `ablation_study/<variante>/best_fold{X}.pt`\n",
    "\n",
    "### Interpretación de resultados:\n",
    "- **Baseline** es tu modelo completo (referencia)\n",
    "- Si al **eliminar un componente** el accuracy **baja** → ese componente es **beneficioso**\n",
    "- Si al **eliminar un componente** el accuracy **sube** → ese componente puede estar **perjudicando**\n",
    "- Diferencias < 1-2% pueden ser ruido estadístico\n",
    "\n",
    "### Para tu tesis:\n",
    "Puedes usar los gráficos y tablas generadas directamente en tu documento. La tabla de \"Contribución Relativa\" te ayudará a argumentar qué componentes son esenciales para tu modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd68a9b",
   "metadata": {},
   "source": [
    "---\n",
    "## ANÁLISIS ESTADÍSTICO DE VARIACIONES ARQUITECTÓNICAS\n",
    "\n",
    "Esta sección implementa un análisis estadístico riguroso de diferentes configuraciones arquitectónicas del modelo híbrido CNN-Transformer, evaluando variaciones en el número de bloques depthwise y cabezas de atención.\n",
    "\n",
    "### Objetivo:\n",
    "Evaluar sistemáticamente diferentes arquitecturas usando 5-fold CV y determinar mediante tests estadísticos (Wilcoxon/Friedman) si las diferencias son significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be2a9caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de análisis arquitectónico estadístico definidas\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SWEEP ARQUITECTÓNICO CON 5 FOLDS\n",
    "# =========================\n",
    "\n",
    "def run_arch_sweep_5folds(device, base_blocks=2, deltas=(-2, 0, +2), head_set=(2, 4, 6), output_dir=None):\n",
    "    \"\"\"\n",
    "    Ejecuta barrido arquitectónico completo con 5-fold Cross-Validation.\n",
    "    \n",
    "    Evalúa todas las combinaciones de:\n",
    "    - Número de bloques depthwise: base_blocks + deltas\n",
    "    - Número de attention heads: head_set\n",
    "    \n",
    "    Args:\n",
    "        device: torch.device - Dispositivo para entrenamiento\n",
    "        base_blocks: int - Número base de bloques depthwise (default: 2)\n",
    "        deltas: tuple - Variaciones del número de bloques (default: (-2, 0, +2))\n",
    "        head_set: tuple - Conjunto de attention heads a probar (default: (2, 4, 6))\n",
    "        output_dir: Path - Directorio para guardar resultados\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame - Resultados con columnas:\n",
    "            - arch_id: ID de la arquitectura\n",
    "            - n_dw_blocks: Número de bloques depthwise\n",
    "            - n_heads: Número de attention heads\n",
    "            - fold_1 a fold_5: Resultados de F1-macro por fold\n",
    "            - mean_f1: Media de F1\n",
    "            - std_f1: Desviación estándar de F1\n",
    "            - mean_acc: Media de Accuracy\n",
    "            - std_acc: Desviación estándar de Accuracy\n",
    "            - n_params: Número de parámetros\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from itertools import product\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    # Generar todas las combinaciones arquitectónicas\n",
    "    arch_configs = []\n",
    "    for dlt in deltas:\n",
    "        n_blocks = int(np.clip(base_blocks + dlt, 0, 5))\n",
    "        for n_heads in head_set:\n",
    "            # Validar que d_model sea divisible por n_heads\n",
    "            if D_MODEL % n_heads != 0:\n",
    "                print(f\"[SKIP] n_heads={n_heads} no es divisible con D_MODEL={D_MODEL}\")\n",
    "                continue\n",
    "            arch_configs.append({\n",
    "                'n_dw_blocks': n_blocks,\n",
    "                'n_heads': n_heads,\n",
    "                'arch_id': f'nb{n_blocks}_h{n_heads}'\n",
    "            })\n",
    "    \n",
    "    total_archs = len(arch_configs)\n",
    "    total_runs = total_archs * 5\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"SWEEP ARQUITECTÓNICO CON 5-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nParámetros del sweep:\")\n",
    "    print(f\"  • Base blocks: {base_blocks}\")\n",
    "    print(f\"  • Deltas: {deltas}\")\n",
    "    print(f\"  • Head set: {head_set}\")\n",
    "    print(f\"  • D_MODEL: {D_MODEL}\")\n",
    "    \n",
    "    print(f\"\\nArquitecturas a evaluar: {total_archs}\")\n",
    "    print(f\"Total de entrenamientos: {total_runs} ({total_archs} archs × 5 folds)\")\n",
    "    print(f\"Directorio de salida: {output_dir}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    results = []\n",
    "    \n",
    "    # ========================================\n",
    "    # LOOP PRINCIPAL: ARQUITECTURAS × FOLDS\n",
    "    # ========================================\n",
    "    for arch_idx, config in enumerate(arch_configs, 1):\n",
    "        arch_id = config['arch_id']\n",
    "        n_blocks = config['n_dw_blocks']\n",
    "        n_heads = config['n_heads']\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ARQUITECTURA {arch_idx}/{total_archs}: {arch_id}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"  • Depthwise Blocks: {n_blocks}\")\n",
    "        print(f\"  • Attention Heads: {n_heads}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        arch_dir = output_dir / arch_id\n",
    "        ensure_dir(arch_dir)\n",
    "        \n",
    "        # Resultados de los 5 folds para esta arquitectura\n",
    "        fold_f1s = []\n",
    "        fold_accs = []\n",
    "        n_params = None\n",
    "        \n",
    "        # ========================================\n",
    "        # 5-FOLD LOOP\n",
    "        # ========================================\n",
    "        for fold_idx in range(1, 6):\n",
    "            print(f\"\\n--- Fold {fold_idx}/5 ---\")\n",
    "            seed_everything(RANDOM_STATE + fold_idx)\n",
    "            \n",
    "            try:\n",
    "                # Factory del modelo con esta arquitectura\n",
    "                def make_model():\n",
    "                    return EEGCNNTransformer(\n",
    "                        n_ch=8,\n",
    "                        n_cls=2,\n",
    "                        d_model=D_MODEL,\n",
    "                        n_heads=n_heads,\n",
    "                        n_layers=N_LAYERS,\n",
    "                        p_drop=P_DROP,\n",
    "                        p_drop_encoder=P_DROP_ENCODER,\n",
    "                        n_dw_blocks=n_blocks,\n",
    "                        capture_attn=False\n",
    "                    ).to(device)\n",
    "                \n",
    "                # Entrenar este fold con train_one_fold\n",
    "                acc, f1_macro, ft_acc, consumption, metrics = train_one_fold(\n",
    "                    fold=fold_idx,\n",
    "                    device=device,\n",
    "                    model_factory=make_model,\n",
    "                    run_tag=arch_id,\n",
    "                    out_dir=arch_dir,\n",
    "                    save_artifacts=True,\n",
    "                    do_ft=False\n",
    "                )\n",
    "                \n",
    "                fold_accs.append(acc)\n",
    "                fold_f1s.append(f1_macro)\n",
    "                \n",
    "                if n_params is None:\n",
    "                    n_params = consumption.get('params_total', 0)\n",
    "                \n",
    "                print(f\"✓ Fold {fold_idx} completado: ACC={acc:.4f}, F1={f1_macro:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ ERROR en Fold {fold_idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                fold_accs.append(0.0)\n",
    "                fold_f1s.append(0.0)\n",
    "        \n",
    "        # ========================================\n",
    "        # COMPILAR RESULTADOS DE ESTA ARQUITECTURA\n",
    "        # ========================================\n",
    "        result_row = {\n",
    "            'arch_id': arch_id,\n",
    "            'n_dw_blocks': n_blocks,\n",
    "            'n_heads': n_heads,\n",
    "            'fold_1_f1': fold_f1s[0] if len(fold_f1s) > 0 else 0.0,\n",
    "            'fold_2_f1': fold_f1s[1] if len(fold_f1s) > 1 else 0.0,\n",
    "            'fold_3_f1': fold_f1s[2] if len(fold_f1s) > 2 else 0.0,\n",
    "            'fold_4_f1': fold_f1s[3] if len(fold_f1s) > 3 else 0.0,\n",
    "            'fold_5_f1': fold_f1s[4] if len(fold_f1s) > 4 else 0.0,\n",
    "            'fold_1_acc': fold_accs[0] if len(fold_accs) > 0 else 0.0,\n",
    "            'fold_2_acc': fold_accs[1] if len(fold_accs) > 1 else 0.0,\n",
    "            'fold_3_acc': fold_accs[2] if len(fold_accs) > 2 else 0.0,\n",
    "            'fold_4_acc': fold_accs[3] if len(fold_accs) > 3 else 0.0,\n",
    "            'fold_5_acc': fold_accs[4] if len(fold_accs) > 4 else 0.0,\n",
    "            'mean_f1': np.mean(fold_f1s) if fold_f1s else 0.0,\n",
    "            'std_f1': np.std(fold_f1s) if fold_f1s else 0.0,\n",
    "            'mean_acc': np.mean(fold_accs) if fold_accs else 0.0,\n",
    "            'std_acc': np.std(fold_accs) if fold_accs else 0.0,\n",
    "            'n_params': n_params if n_params else 0\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(f\"RESUMEN {arch_id}:\")\n",
    "        print(f\"  F1 por fold: {[f'{f:.4f}' for f in fold_f1s]}\")\n",
    "        print(f\"  F1 Media ± Std: {result_row['mean_f1']:.4f} ± {result_row['std_f1']:.4f}\")\n",
    "        print(f\"  ACC Media ± Std: {result_row['mean_acc']:.4f} ± {result_row['std_acc']:.4f}\")\n",
    "        print(f\"  Parámetros: {result_row['n_params']:,}\")\n",
    "        print(f\"{'─'*80}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # COMPILAR RESULTADOS FINALES\n",
    "    # ========================================\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Ordenar por mean_f1 descendente\n",
    "    df_results = df_results.sort_values('mean_f1', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    csv_path = output_dir / 'arch_sweep_5fold_results.csv'\n",
    "    df_results.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SWEEP ARQUITECTÓNICO COMPLETADO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nResultados guardados en: {csv_path}\")\n",
    "    print(f\"\\nMejor arquitectura:\")\n",
    "    best = df_results.iloc[0]\n",
    "    print(f\"  • Arch ID: {best['arch_id']}\")\n",
    "    print(f\"  • Blocks: {int(best['n_dw_blocks'])}, Heads: {int(best['n_heads'])}\")\n",
    "    print(f\"  • F1 Score: {best['mean_f1']:.4f} ± {best['std_f1']:.4f}\")\n",
    "    print(f\"  • Accuracy: {best['mean_acc']:.4f} ± {best['std_acc']:.4f}\")\n",
    "    print(f\"  • Parámetros: {int(best['n_params']):,}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "def analyze_arch_sweep_statistical(df_results, baseline_arch='nb2_h6', output_dir=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Realiza análisis estadístico de los resultados del sweep arquitectónico.\n",
    "    \n",
    "    Incluye:\n",
    "    - Test de Wilcoxon pareado (cada arquitectura vs baseline)\n",
    "    - Test de Friedman (comparación múltiple)\n",
    "    - Post-hoc tests si Friedman es significativo\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame con resultados del sweep\n",
    "        baseline_arch: str - ID de la arquitectura baseline para comparación\n",
    "        output_dir: Path - Directorio para guardar resultados\n",
    "        alpha: float - Nivel de significancia (default: 0.05)\n",
    "    \n",
    "    Returns:\n",
    "        dict - Resultados del análisis estadístico\n",
    "    \"\"\"\n",
    "    from scipy.stats import wilcoxon, friedmanchisquare\n",
    "    import pandas as pd\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS ESTADÍSTICO DEL SWEEP ARQUITECTÓNICO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Verificar que existe el baseline\n",
    "    if baseline_arch not in df_results['arch_id'].values:\n",
    "        print(f\"[WARN] Baseline '{baseline_arch}' no encontrado. Usando primera arquitectura.\")\n",
    "        baseline_arch = df_results.iloc[0]['arch_id']\n",
    "    \n",
    "    baseline_row = df_results[df_results['arch_id'] == baseline_arch].iloc[0]\n",
    "    baseline_f1s = [baseline_row[f'fold_{i}_f1'] for i in range(1, 6)]\n",
    "    \n",
    "    print(f\"Arquitectura Baseline: {baseline_arch}\")\n",
    "    print(f\"  F1 Scores: {[f'{f:.4f}' for f in baseline_f1s]}\")\n",
    "    print(f\"  Media: {np.mean(baseline_f1s):.4f} ± {np.std(baseline_f1s):.4f}\\n\")\n",
    "    \n",
    "    # ========================================\n",
    "    # TEST DE WILCOXON (vs Baseline)\n",
    "    # ========================================\n",
    "    print(\"-\"*80)\n",
    "    print(\"TEST DE WILCOXON PAREADO (cada arquitectura vs baseline)\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    wilcoxon_results = []\n",
    "    \n",
    "    for _, row in df_results.iterrows():\n",
    "        arch_id = row['arch_id']\n",
    "        \n",
    "        if arch_id == baseline_arch:\n",
    "            continue  # No comparar baseline consigo mismo\n",
    "        \n",
    "        arch_f1s = [row[f'fold_{i}_f1'] for i in range(1, 6)]\n",
    "        \n",
    "        try:\n",
    "            # Test de Wilcoxon pareado\n",
    "            stat, p_value = wilcoxon(arch_f1s, baseline_f1s, alternative='two-sided')\n",
    "            \n",
    "            # Calcular diferencia media\n",
    "            mean_diff = np.mean(arch_f1s) - np.mean(baseline_f1s)\n",
    "            \n",
    "            # Determinar significancia\n",
    "            is_significant = p_value < alpha\n",
    "            \n",
    "            wilcoxon_results.append({\n",
    "                'arch_id': arch_id,\n",
    "                'n_dw_blocks': int(row['n_dw_blocks']),\n",
    "                'n_heads': int(row['n_heads']),\n",
    "                'mean_f1': row['mean_f1'],\n",
    "                'mean_diff_vs_baseline': mean_diff,\n",
    "                'wilcoxon_stat': stat,\n",
    "                'p_value': p_value,\n",
    "                'significant': is_significant,\n",
    "                'interpretation': 'SIGNIFICATIVO' if is_significant else 'No significativo'\n",
    "            })\n",
    "            \n",
    "            print(f\"{arch_id}:\")\n",
    "            print(f\"  F1: {row['mean_f1']:.4f} ± {row['std_f1']:.4f}\")\n",
    "            print(f\"  Δ vs baseline: {mean_diff:+.4f}\")\n",
    "            print(f\"  Wilcoxon stat: {stat:.4f}, p-value: {p_value:.4f} {'***' if is_significant else ''}\")\n",
    "            print(f\"  {wilcoxon_results[-1]['interpretation']}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{arch_id}: ERROR - {e}\\n\")\n",
    "            wilcoxon_results.append({\n",
    "                'arch_id': arch_id,\n",
    "                'n_dw_blocks': int(row['n_dw_blocks']),\n",
    "                'n_heads': int(row['n_heads']),\n",
    "                'mean_f1': row['mean_f1'],\n",
    "                'mean_diff_vs_baseline': 0.0,\n",
    "                'wilcoxon_stat': np.nan,\n",
    "                'p_value': np.nan,\n",
    "                'significant': False,\n",
    "                'interpretation': 'ERROR'\n",
    "            })\n",
    "    \n",
    "    df_wilcoxon = pd.DataFrame(wilcoxon_results)\n",
    "    \n",
    "    # Guardar resultados de Wilcoxon\n",
    "    wilcoxon_path = output_dir / 'wilcoxon_results.csv'\n",
    "    df_wilcoxon.to_csv(wilcoxon_path, index=False)\n",
    "    print(f\"Resultados de Wilcoxon guardados en: {wilcoxon_path}\\n\")\n",
    "    \n",
    "    # ========================================\n",
    "    # TEST DE FRIEDMAN (Comparación múltiple)\n",
    "    # ========================================\n",
    "    print(\"-\"*80)\n",
    "    print(\"TEST DE FRIEDMAN (comparación múltiple)\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    # Preparar datos para Friedman: matriz (n_folds × n_arquitecturas)\n",
    "    all_f1s = []\n",
    "    arch_labels = []\n",
    "    \n",
    "    for _, row in df_results.iterrows():\n",
    "        arch_f1s = [row[f'fold_{i}_f1'] for i in range(1, 6)]\n",
    "        all_f1s.append(arch_f1s)\n",
    "        arch_labels.append(row['arch_id'])\n",
    "    \n",
    "    try:\n",
    "        # Test de Friedman\n",
    "        friedman_stat, friedman_p = friedmanchisquare(*all_f1s)\n",
    "        \n",
    "        print(f\"Friedman χ² statistic: {friedman_stat:.4f}\")\n",
    "        print(f\"p-value: {friedman_p:.6f}\")\n",
    "        \n",
    "        if friedman_p < alpha:\n",
    "            print(f\"\\n✓ SIGNIFICATIVO (p < {alpha})\")\n",
    "            print(\"Conclusión: Existen diferencias significativas entre las arquitecturas.\")\n",
    "        else:\n",
    "            print(f\"\\n✗ NO SIGNIFICATIVO (p ≥ {alpha})\")\n",
    "            print(\"Conclusión: No hay evidencia de diferencias significativas entre arquitecturas.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en test de Friedman: {e}\")\n",
    "        friedman_stat = np.nan\n",
    "        friedman_p = np.nan\n",
    "    \n",
    "    # ========================================\n",
    "    # COMPILAR RESULTADOS\n",
    "    # ========================================\n",
    "    statistical_summary = {\n",
    "        'baseline_arch': baseline_arch,\n",
    "        'baseline_mean_f1': np.mean(baseline_f1s),\n",
    "        'baseline_std_f1': np.std(baseline_f1s),\n",
    "        'n_architectures': len(df_results),\n",
    "        'alpha': alpha,\n",
    "        'wilcoxon_results': df_wilcoxon,\n",
    "        'friedman_stat': friedman_stat,\n",
    "        'friedman_p_value': friedman_p,\n",
    "        'friedman_significant': friedman_p < alpha if not np.isnan(friedman_p) else False\n",
    "    }\n",
    "    \n",
    "    # Guardar resumen\n",
    "    summary = {\n",
    "        'baseline_arch': baseline_arch,\n",
    "        'baseline_mean_f1': np.mean(baseline_f1s),\n",
    "        'n_architectures_tested': len(df_results),\n",
    "        'n_significant_vs_baseline': int(df_wilcoxon['significant'].sum()),\n",
    "        'friedman_statistic': friedman_stat,\n",
    "        'friedman_p_value': friedman_p,\n",
    "        'friedman_significant': friedman_p < alpha if not np.isnan(friedman_p) else False\n",
    "    }\n",
    "    \n",
    "    summary_path = output_dir / 'statistical_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RESUMEN ESTADÍSTICO:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  • Total arquitecturas: {len(df_results)}\")\n",
    "    print(f\"  • Significativas vs baseline (Wilcoxon): {int(df_wilcoxon['significant'].sum())}\")\n",
    "    print(f\"  • Test de Friedman: {'SIGNIFICATIVO' if summary['friedman_significant'] else 'No significativo'}\")\n",
    "    print(f\"\\nResumen guardado en: {summary_path}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return statistical_summary\n",
    "\n",
    "\n",
    "def run_winner_architecture(device, arch_id, output_dir=None):\n",
    "    \"\"\"\n",
    "    Ejecuta la arquitectura ganadora en los 5 folds completos con todos los artefactos.\n",
    "    \n",
    "    Args:\n",
    "        device: torch.device - Dispositivo para entrenamiento\n",
    "        arch_id: str - ID de la arquitectura ganadora (ej: 'nb2_h6')\n",
    "        output_dir: Path - Directorio para guardar resultados\n",
    "    \n",
    "    Returns:\n",
    "        dict - Resultados finales con métricas\n",
    "    \"\"\"\n",
    "    # Extraer n_blocks y n_heads del arch_id\n",
    "    import re\n",
    "    match = re.match(r'nb(\\d+)_h(\\d+)', arch_id)\n",
    "    if not match:\n",
    "        raise ValueError(f\"arch_id '{arch_id}' no tiene formato válido (debe ser 'nbX_hY')\")\n",
    "    \n",
    "    n_blocks = int(match.group(1))\n",
    "    n_heads = int(match.group(2))\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'winner_architecture'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"EJECUTANDO ARQUITECTURA GANADORA: {arch_id}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  • Depthwise Blocks: {n_blocks}\")\n",
    "    print(f\"  • Attention Heads: {n_heads}\")\n",
    "    print(f\"  • D_MODEL: {D_MODEL}\")\n",
    "    print(f\"  • Directorio: {output_dir}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Usar la función existente run_full_5fold_for_config\n",
    "    # Pero con un output_dir personalizado\n",
    "    \n",
    "    # Llamar directamente a la función con el output_dir correcto\n",
    "    tag = arch_id\n",
    "    base_dir = output_dir\n",
    "    \n",
    "    acc_folds, f1_folds = [], []\n",
    "    results = []\n",
    "    \n",
    "    def factory():\n",
    "        return EEGCNNTransformer(\n",
    "            n_ch=8,\n",
    "            n_cls=2,\n",
    "            d_model=D_MODEL,\n",
    "            n_heads=n_heads,\n",
    "            n_layers=N_LAYERS,\n",
    "            p_drop=P_DROP,\n",
    "            p_drop_encoder=P_DROP_ENCODER,\n",
    "            n_dw_blocks=n_blocks,\n",
    "            capture_attn=True\n",
    "        ).to(device)\n",
    "    \n",
    "    for fold in range(1, 6):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"FOLD {fold}/5\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        acc, f1m, ft_acc, cons, met = train_one_fold(\n",
    "            fold=fold,\n",
    "            device=device,\n",
    "            model_factory=factory,\n",
    "            run_tag=tag,\n",
    "            out_dir=base_dir,\n",
    "            save_artifacts=True,\n",
    "            do_ft=True\n",
    "        )\n",
    "        \n",
    "        acc_folds.append(acc)\n",
    "        f1_folds.append(f1m)\n",
    "        \n",
    "        results.append({\n",
    "            'fold': fold,\n",
    "            'accuracy': acc,\n",
    "            'f1_macro': f1m,\n",
    "            'ft_accuracy': ft_acc,\n",
    "            'n_params': cons.get('params_total'),\n",
    "            'precision_macro': met.get('precision_macro'),\n",
    "            'recall_macro': met.get('recall_macro'),\n",
    "            'specificity_macro': met.get('specificity_macro')\n",
    "        })\n",
    "        \n",
    "        print(f\"✓ Fold {fold} - ACC: {acc:.4f}, F1: {f1m:.4f}\")\n",
    "    \n",
    "    # Resumen final\n",
    "    acc_mean = np.mean(acc_folds)\n",
    "    f1_mean = np.mean(f1_folds)\n",
    "    acc_std = np.std(acc_folds)\n",
    "    f1_std = np.std(f1_folds)\n",
    "    \n",
    "    final_results = {\n",
    "        'arch_id': arch_id,\n",
    "        'n_dw_blocks': n_blocks,\n",
    "        'n_heads': n_heads,\n",
    "        'fold_results': results,\n",
    "        'mean_accuracy': acc_mean,\n",
    "        'std_accuracy': acc_std,\n",
    "        'mean_f1': f1_mean,\n",
    "        'std_f1': f1_std,\n",
    "        'fold_accuracies': acc_folds,\n",
    "        'fold_f1s': f1_folds\n",
    "    }\n",
    "    \n",
    "    # Guardar resultados\n",
    "    import pandas as pd\n",
    "    df_results = pd.DataFrame(results)\n",
    "    results_path = output_dir / f'winner_{arch_id}_results.csv'\n",
    "    df_results.to_csv(results_path, index=False)\n",
    "    \n",
    "    # Guardar JSON con resumen\n",
    "    summary_path = output_dir / f'winner_{arch_id}_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'arch_id': arch_id,\n",
    "            'n_dw_blocks': n_blocks,\n",
    "            'n_heads': n_heads,\n",
    "            'mean_accuracy': acc_mean,\n",
    "            'std_accuracy': acc_std,\n",
    "            'mean_f1': f1_mean,\n",
    "            'std_f1': f1_std\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTADOS FINALES - ARQUITECTURA GANADORA\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nArquitectura: {arch_id}\")\n",
    "    print(f\"  • Blocks: {n_blocks}, Heads: {n_heads}\")\n",
    "    print(f\"\\nAccuracy por fold: {[f'{a:.4f}' for a in acc_folds]}\")\n",
    "    print(f\"  Media ± Std: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"\\nF1-Macro por fold: {[f'{f:.4f}' for f in f1_folds]}\")\n",
    "    print(f\"  Media ± Std: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    print(f\"\\nResultados guardados en:\")\n",
    "    print(f\"  • CSV: {results_path}\")\n",
    "    print(f\"  • JSON: {summary_path}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "print(\"✓ Funciones de análisis arquitectónico estadístico definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71bfe7",
   "metadata": {},
   "source": [
    "### Visualización de Resultados del Sweep Arquitectónico\n",
    "\n",
    "Funciones para generar gráficos comparativos de las diferentes arquitecturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a53ff9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de visualización definidas\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# VISUALIZACIÓN DEL SWEEP ARQUITECTÓNICO\n",
    "# =========================\n",
    "\n",
    "def plot_arch_sweep_results(df_results, df_wilcoxon=None, output_dir=None):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones comprehensivas de los resultados del sweep arquitectónico.\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame con resultados del sweep\n",
    "        df_wilcoxon: DataFrame con resultados de tests de Wilcoxon (opcional)\n",
    "        output_dir: Path - Directorio para guardar gráficos\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    # ========================================\n",
    "    # GRÁFICO 1: Barras con errorbar + p-values\n",
    "    # ========================================\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    x = np.arange(len(df_results))\n",
    "    bars = ax.bar(x, df_results['mean_f1'], yerr=df_results['std_f1'],\n",
    "                  capsize=5, alpha=0.8, edgecolor='navy')\n",
    "    \n",
    "    # Colorear barras según significancia (si hay datos de Wilcoxon)\n",
    "    if df_wilcoxon is not None:\n",
    "        for i, (idx, row) in enumerate(df_results.iterrows()):\n",
    "            wilcox_row = df_wilcoxon[df_wilcoxon['arch_id'] == row['arch_id']]\n",
    "            if len(wilcox_row) > 0 and wilcox_row.iloc[0]['significant']:\n",
    "                bars[i].set_color('salmon')\n",
    "                bars[i].set_edgecolor('darkred')\n",
    "            else:\n",
    "                bars[i].set_color('steelblue')\n",
    "    \n",
    "    ax.set_xlabel('Arquitectura', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('F1-Score (Macro)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Comparación de Arquitecturas - Sweep con 5-Fold CV', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_results['arch_id'], rotation=45, ha='right', fontsize=10)\n",
    "    ax.axhline(y=df_results['mean_f1'].iloc[0], color='red', linestyle='--', \n",
    "               alpha=0.5, linewidth=2, label='Mejor')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    \n",
    "    # Leyenda\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='steelblue', edgecolor='navy', label='No significativo'),\n",
    "        Patch(facecolor='salmon', edgecolor='darkred', label='Significativo (p<0.05)'),\n",
    "        ax.lines[0]\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = output_dir / 'arch_sweep_comparison.png'\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Gráfico de comparación guardado: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # ========================================\n",
    "    # GRÁFICO 2: Heatmap de Blocks vs Heads\n",
    "    # ========================================\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Heatmap de F1-Score\n",
    "    pivot_f1 = df_results.pivot_table(\n",
    "        values='mean_f1',\n",
    "        index='n_dw_blocks',\n",
    "        columns='n_heads',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    im1 = ax1.imshow(pivot_f1, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n",
    "    ax1.set_title('F1-Score por Configuración', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Número de Attention Heads', fontsize=11)\n",
    "    ax1.set_ylabel('Número de Bloques Depthwise', fontsize=11)\n",
    "    ax1.set_xticks(range(len(pivot_f1.columns)))\n",
    "    ax1.set_xticklabels([int(v) for v in pivot_f1.columns])\n",
    "    ax1.set_yticks(range(len(pivot_f1.index)))\n",
    "    ax1.set_yticklabels([int(v) for v in pivot_f1.index])\n",
    "    \n",
    "    # Anotar valores\n",
    "    for i in range(len(pivot_f1.index)):\n",
    "        for j in range(len(pivot_f1.columns)):\n",
    "            if not np.isnan(pivot_f1.iloc[i, j]):\n",
    "                ax1.text(j, i, f'{pivot_f1.iloc[i, j]:.3f}',\n",
    "                        ha='center', va='center', color='black', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im1, ax=ax1, label='F1-Score')\n",
    "    \n",
    "    # Heatmap de número de parámetros\n",
    "    pivot_params = df_results.pivot_table(\n",
    "        values='n_params',\n",
    "        index='n_dw_blocks',\n",
    "        columns='n_heads',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    im2 = ax2.imshow(pivot_params / 1e6, cmap='Blues', aspect='auto')\n",
    "    ax2.set_title('Número de Parámetros (M)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('Número de Attention Heads', fontsize=11)\n",
    "    ax2.set_ylabel('Número de Bloques Depthwise', fontsize=11)\n",
    "    ax2.set_xticks(range(len(pivot_params.columns)))\n",
    "    ax2.set_xticklabels([int(v) for v in pivot_params.columns])\n",
    "    ax2.set_yticks(range(len(pivot_params.index)))\n",
    "    ax2.set_yticklabels([int(v) for v in pivot_params.index])\n",
    "    \n",
    "    # Anotar valores\n",
    "    for i in range(len(pivot_params.index)):\n",
    "        for j in range(len(pivot_params.columns)):\n",
    "            if not np.isnan(pivot_params.iloc[i, j]):\n",
    "                ax2.text(j, i, f'{pivot_params.iloc[i, j]/1e6:.2f}M',\n",
    "                        ha='center', va='center', color='white' if pivot_params.iloc[i, j]/1e6 > 0.5 else 'black',\n",
    "                        fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im2, ax=ax2, label='Parámetros (Millones)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    heatmap_path = output_dir / 'arch_sweep_heatmaps.png'\n",
    "    plt.savefig(heatmap_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Heatmaps guardados: {heatmap_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # ========================================\n",
    "    # GRÁFICO 3: P-values del test de Wilcoxon\n",
    "    # ========================================\n",
    "    if df_wilcoxon is not None and len(df_wilcoxon) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        # Ordenar por p-value\n",
    "        df_wilcoxon_sorted = df_wilcoxon.sort_values('p_value')\n",
    "        \n",
    "        x = np.arange(len(df_wilcoxon_sorted))\n",
    "        colors = ['red' if sig else 'gray' for sig in df_wilcoxon_sorted['significant']]\n",
    "        \n",
    "        ax.bar(x, -np.log10(df_wilcoxon_sorted['p_value']), color=colors, alpha=0.7, edgecolor='black')\n",
    "        ax.axhline(y=-np.log10(0.05), color='blue', linestyle='--', linewidth=2, label='α=0.05')\n",
    "        ax.axhline(y=-np.log10(0.01), color='green', linestyle='--', linewidth=2, label='α=0.01')\n",
    "        \n",
    "        ax.set_xlabel('Arquitectura', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('-log₁₀(p-value)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Significancia Estadística vs Baseline (Test de Wilcoxon)', fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_wilcoxon_sorted['arch_id'], rotation=45, ha='right', fontsize=10)\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pvalue_path = output_dir / 'arch_sweep_pvalues.png'\n",
    "        plt.savefig(pvalue_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"✓ Gráfico de p-values guardado: {pvalue_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    # ========================================\n",
    "    # TABLA RESUMEN\n",
    "    # ========================================\n",
    "    fig, ax = plt.subplots(figsize=(16, max(6, len(df_results) * 0.4)))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = []\n",
    "    for idx, row in df_results.iterrows():\n",
    "        sig_marker = ''\n",
    "        if df_wilcoxon is not None:\n",
    "            wilcox_row = df_wilcoxon[df_wilcoxon['arch_id'] == row['arch_id']]\n",
    "            if len(wilcox_row) > 0:\n",
    "                if wilcox_row.iloc[0]['significant']:\n",
    "                    sig_marker = ' ***'\n",
    "                p_val = wilcox_row.iloc[0]['p_value']\n",
    "                sig_marker += f\" (p={p_val:.4f})\"\n",
    "        \n",
    "        table_data.append([\n",
    "            row['arch_id'] + sig_marker,\n",
    "            f\"{int(row['n_dw_blocks'])}\",\n",
    "            f\"{int(row['n_heads'])}\",\n",
    "            f\"{row['mean_f1']:.4f} ± {row['std_f1']:.4f}\",\n",
    "            f\"{row['mean_acc']:.4f} ± {row['std_acc']:.4f}\",\n",
    "            f\"{int(row['n_params']):,}\"\n",
    "        ])\n",
    "    \n",
    "    table = ax.table(cellText=table_data,\n",
    "                     colLabels=['Arquitectura', 'Blocks', 'Heads', 'F1-Score', 'Accuracy', 'Parámetros'],\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     colWidths=[0.25, 0.1, 0.1, 0.2, 0.2, 0.15])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Colorear la mejor fila\n",
    "    for i in range(6):\n",
    "        table[(1, i)].set_facecolor('#90EE90')\n",
    "    \n",
    "    plt.title('Tabla Resumen - Sweep Arquitectónico (*** = significativo vs baseline)', \n",
    "              fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    table_path = output_dir / 'arch_sweep_table.png'\n",
    "    plt.savefig(table_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Tabla guardada: {table_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "print(\"✓ Funciones de visualización definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183306fe",
   "metadata": {},
   "source": [
    "### Ejecución del Sweep Arquitectónico\n",
    "\n",
    "Ejecuta el sweep completo con análisis estadístico y visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8de9f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SWEEP ARQUITECTÓNICO CON ANÁLISIS ESTADÍSTICO\n",
      "================================================================================\n",
      "\n",
      "PASO 1: Ejecutando sweep arquitectónico con 5-fold CV\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Configuración:\n",
      "  • Base blocks: 2\n",
      "  • Deltas: (-2, 0, 2)\n",
      "  • Head set: (2, 4, 6)\n",
      "  • Total de arquitecturas: 9 (máximo)\n",
      "\n",
      "ADVERTENCIA: Este proceso tomará varias horas.\n",
      "  Tiempo estimado: ~6-10 horas (depende del hardware)\n",
      "\n",
      "================================================================================\n",
      "SWEEP ARQUITECTÓNICO CON 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Parámetros del sweep:\n",
      "  • Base blocks: 2\n",
      "  • Deltas: (-2, 0, 2)\n",
      "  • Head set: (2, 4, 6)\n",
      "  • D_MODEL: 144\n",
      "\n",
      "Arquitecturas a evaluar: 9\n",
      "Total de entrenamientos: 45 (9 archs × 5 folds)\n",
      "Directorio de salida: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 1/9: nb0_h2\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 0\n",
      "  • Attention Heads: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.25it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.33it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1330 | train_acc=0.5256 | val_loss=0.1214 | val_acc=0.5778 | val_f1m=0.5565 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1240 | train_acc=0.5569 | val_loss=0.1197 | val_acc=0.5889 | val_f1m=0.5703 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1222 | train_acc=0.5885 | val_loss=0.1155 | val_acc=0.6206 | val_f1m=0.6051 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0954 | train_acc=0.7434 | val_loss=0.0993 | val_acc=0.7143 | val_f1m=0.7137 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0779 | train_acc=0.8038 | val_loss=0.1010 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0784 | train_acc=0.8049 | val_loss=0.0936 | val_acc=0.7381 | val_f1m=0.7380 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0695 | train_acc=0.8234 | val_loss=0.0989 | val_acc=0.7460 | val_f1m=0.7460 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0713 | train_acc=0.8205 | val_loss=0.0982 | val_acc=0.7857 | val_f1m=0.7841 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0644 | train_acc=0.8408 | val_loss=0.0958 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0717 | train_acc=0.8216 | val_loss=0.0928 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0638 | train_acc=0.8426 | val_loss=0.0987 | val_acc=0.7825 | val_f1m=0.7824 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0621 | train_acc=0.8443 | val_loss=0.1166 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0627 | train_acc=0.8468 | val_loss=0.1005 | val_acc=0.7746 | val_f1m=0.7743 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0638 | train_acc=0.8380 | val_loss=0.0971 | val_acc=0.7730 | val_f1m=0.7725 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0620 | train_acc=0.8429 | val_loss=0.0951 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0607 | train_acc=0.8422 | val_loss=0.0965 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0569 | train_acc=0.8646 | val_loss=0.1019 | val_acc=0.7778 | val_f1m=0.7775 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0615 | train_acc=0.8515 | val_loss=0.0971 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0572 | train_acc=0.8582 | val_loss=0.1009 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0612 | train_acc=0.8461 | val_loss=0.0960 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0550 | train_acc=0.8554 | val_loss=0.0971 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0567 | train_acc=0.8603 | val_loss=0.0981 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0540 | train_acc=0.8650 | val_loss=0.0985 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0550 | train_acc=0.8611 | val_loss=0.0985 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0542 | train_acc=0.8646 | val_loss=0.0986 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0544 | train_acc=0.8689 | val_loss=0.0986 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0517 | train_acc=0.8714 | val_loss=0.0988 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0521 | train_acc=0.8746 | val_loss=0.0989 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000337\n",
      "  Early stopping en época 28 (mejor val_f1m=0.7984)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/model_global_fold1_nb0_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/training_curve_fold1_nb0_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/history_fold1_nb0_h2.npz\n",
      "[Fold 1/5] Global acc=0.8050 | f1_macro=0.8049\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7956    0.8209    0.8080       441\n",
      "       right     0.8150    0.7891    0.8018       441\n",
      "\n",
      "    accuracy                         0.8050       882\n",
      "   macro avg     0.8053    0.8050    0.8049       882\n",
      "weighted avg     0.8053    0.8050    0.8049       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[362  79]\n",
      " [ 93 348]]\n",
      "precision_macro=0.8053 | recall_macro=0.8050 | specificity_macro=0.8050 | sensitivity_macro=0.8050\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/confusion_global_fold1_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/topomap_saliency_fold1_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/topomap_log10p_fold1_nb0_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold1/tsne_cls_fold1_nb0_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.8050, F1=0.8049\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.21it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 16.89it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1318 | train_acc=0.5156 | val_loss=0.1210 | val_acc=0.5587 | val_f1m=0.5275 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1243 | train_acc=0.5547 | val_loss=0.1185 | val_acc=0.5857 | val_f1m=0.5807 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1128 | train_acc=0.6365 | val_loss=0.1146 | val_acc=0.6698 | val_f1m=0.6527 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0966 | train_acc=0.7367 | val_loss=0.1004 | val_acc=0.7349 | val_f1m=0.7305 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0901 | train_acc=0.7640 | val_loss=0.0908 | val_acc=0.7508 | val_f1m=0.7508 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0823 | train_acc=0.7900 | val_loss=0.0868 | val_acc=0.7683 | val_f1m=0.7668 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0831 | train_acc=0.7864 | val_loss=0.0913 | val_acc=0.7540 | val_f1m=0.7540 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0830 | train_acc=0.7793 | val_loss=0.0932 | val_acc=0.7413 | val_f1m=0.7408 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0734 | train_acc=0.8117 | val_loss=0.0952 | val_acc=0.7587 | val_f1m=0.7564 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0772 | train_acc=0.8021 | val_loss=0.0843 | val_acc=0.7698 | val_f1m=0.7696 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0733 | train_acc=0.8070 | val_loss=0.0846 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0694 | train_acc=0.8355 | val_loss=0.0899 | val_acc=0.7587 | val_f1m=0.7585 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0699 | train_acc=0.8237 | val_loss=0.0951 | val_acc=0.7540 | val_f1m=0.7480 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0740 | train_acc=0.8106 | val_loss=0.0858 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0720 | train_acc=0.8177 | val_loss=0.0856 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0717 | train_acc=0.8191 | val_loss=0.0881 | val_acc=0.7556 | val_f1m=0.7554 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0735 | train_acc=0.8152 | val_loss=0.0816 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0710 | train_acc=0.8209 | val_loss=0.0839 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0720 | train_acc=0.8166 | val_loss=0.0850 | val_acc=0.7683 | val_f1m=0.7681 | LR=0.000434\n",
      "  Early stopping en época 19 (mejor val_f1m=0.7762)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/model_global_fold2_nb0_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/training_curve_fold2_nb0_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/history_fold2_nb0_h2.npz\n",
      "[Fold 2/5] Global acc=0.8005 | f1_macro=0.8004\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7887    0.8209    0.8044       441\n",
      "       right     0.8132    0.7800    0.7963       441\n",
      "\n",
      "    accuracy                         0.8005       882\n",
      "   macro avg     0.8010    0.8005    0.8004       882\n",
      "weighted avg     0.8010    0.8005    0.8004       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[362  79]\n",
      " [ 97 344]]\n",
      "precision_macro=0.8010 | recall_macro=0.8005 | specificity_macro=0.8005 | sensitivity_macro=0.8005\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/confusion_global_fold2_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/topomap_saliency_fold2_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/topomap_log10p_fold2_nb0_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold2/tsne_cls_fold2_nb0_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.91 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8005, F1=0.8004\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 17.13it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.45it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1330 | train_acc=0.5163 | val_loss=0.1206 | val_acc=0.5825 | val_f1m=0.5804 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1262 | train_acc=0.5235 | val_loss=0.1183 | val_acc=0.5952 | val_f1m=0.5924 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1216 | train_acc=0.5682 | val_loss=0.1109 | val_acc=0.6810 | val_f1m=0.6679 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0986 | train_acc=0.7217 | val_loss=0.0884 | val_acc=0.7794 | val_f1m=0.7788 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0865 | train_acc=0.7662 | val_loss=0.0860 | val_acc=0.7905 | val_f1m=0.7903 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0820 | train_acc=0.7825 | val_loss=0.0825 | val_acc=0.7810 | val_f1m=0.7802 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0781 | train_acc=0.8006 | val_loss=0.0809 | val_acc=0.7714 | val_f1m=0.7682 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0781 | train_acc=0.8028 | val_loss=0.0791 | val_acc=0.7921 | val_f1m=0.7920 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0705 | train_acc=0.8269 | val_loss=0.0850 | val_acc=0.7905 | val_f1m=0.7879 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0725 | train_acc=0.8166 | val_loss=0.0811 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0704 | train_acc=0.8284 | val_loss=0.0846 | val_acc=0.7810 | val_f1m=0.7800 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0716 | train_acc=0.8280 | val_loss=0.0787 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0679 | train_acc=0.8291 | val_loss=0.0803 | val_acc=0.8032 | val_f1m=0.8023 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0660 | train_acc=0.8387 | val_loss=0.0766 | val_acc=0.8063 | val_f1m=0.8063 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0668 | train_acc=0.8348 | val_loss=0.0778 | val_acc=0.8000 | val_f1m=0.8000 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0599 | train_acc=0.8596 | val_loss=0.0827 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0654 | train_acc=0.8383 | val_loss=0.0778 | val_acc=0.7984 | val_f1m=0.7983 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0600 | train_acc=0.8522 | val_loss=0.0829 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0623 | train_acc=0.8483 | val_loss=0.0778 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0650 | train_acc=0.8401 | val_loss=0.0787 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0617 | train_acc=0.8564 | val_loss=0.0805 | val_acc=0.8079 | val_f1m=0.8077 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0592 | train_acc=0.8607 | val_loss=0.0821 | val_acc=0.8032 | val_f1m=0.8027 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0542 | train_acc=0.8689 | val_loss=0.0842 | val_acc=0.8032 | val_f1m=0.8029 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0596 | train_acc=0.8525 | val_loss=0.0841 | val_acc=0.8016 | val_f1m=0.8013 | LR=0.000384\n",
      "  Early stopping en época 24 (mejor val_f1m=0.8079)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/model_global_fold3_nb0_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/training_curve_fold3_nb0_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/history_fold3_nb0_h2.npz\n",
      "[Fold 3/5] Global acc=0.7914 | f1_macro=0.7913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7800    0.8118    0.7956       441\n",
      "       right     0.8038    0.7710    0.7870       441\n",
      "\n",
      "    accuracy                         0.7914       882\n",
      "   macro avg     0.7919    0.7914    0.7913       882\n",
      "weighted avg     0.7919    0.7914    0.7913       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[358  83]\n",
      " [101 340]]\n",
      "precision_macro=0.7919 | recall_macro=0.7914 | specificity_macro=0.7914 | sensitivity_macro=0.7914\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/confusion_global_fold3_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/topomap_saliency_fold3_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/topomap_log10p_fold3_nb0_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold3/tsne_cls_fold3_nb0_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.7914, F1=0.7913\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.25it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.59it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1328 | train_acc=0.5207 | val_loss=0.1272 | val_acc=0.4984 | val_f1m=0.3382 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1245 | train_acc=0.5483 | val_loss=0.1209 | val_acc=0.5905 | val_f1m=0.5905 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1183 | train_acc=0.6019 | val_loss=0.1096 | val_acc=0.6905 | val_f1m=0.6896 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0997 | train_acc=0.7192 | val_loss=0.1018 | val_acc=0.6937 | val_f1m=0.6856 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0895 | train_acc=0.7511 | val_loss=0.0984 | val_acc=0.7175 | val_f1m=0.7131 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0850 | train_acc=0.7752 | val_loss=0.1267 | val_acc=0.6762 | val_f1m=0.6495 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0800 | train_acc=0.7889 | val_loss=0.0932 | val_acc=0.7333 | val_f1m=0.7319 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0755 | train_acc=0.8102 | val_loss=0.0872 | val_acc=0.7730 | val_f1m=0.7723 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0766 | train_acc=0.8008 | val_loss=0.0904 | val_acc=0.7492 | val_f1m=0.7488 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0727 | train_acc=0.8263 | val_loss=0.0907 | val_acc=0.7651 | val_f1m=0.7641 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0753 | train_acc=0.8106 | val_loss=0.0899 | val_acc=0.7492 | val_f1m=0.7463 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0725 | train_acc=0.8158 | val_loss=0.0895 | val_acc=0.7905 | val_f1m=0.7901 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0690 | train_acc=0.8284 | val_loss=0.0884 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0691 | train_acc=0.8260 | val_loss=0.0898 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0673 | train_acc=0.8274 | val_loss=0.0866 | val_acc=0.7873 | val_f1m=0.7870 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0674 | train_acc=0.8298 | val_loss=0.0860 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0651 | train_acc=0.8417 | val_loss=0.0847 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0666 | train_acc=0.8389 | val_loss=0.0853 | val_acc=0.7841 | val_f1m=0.7838 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0642 | train_acc=0.8442 | val_loss=0.0821 | val_acc=0.7841 | val_f1m=0.7837 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0645 | train_acc=0.8368 | val_loss=0.0838 | val_acc=0.7762 | val_f1m=0.7761 | LR=0.000425\n",
      "  Early stopping en época 20 (mejor val_f1m=0.7901)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/model_global_fold4_nb0_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/training_curve_fold4_nb0_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/history_fold4_nb0_h2.npz\n",
      "[Fold 4/5] Global acc=0.8060 | f1_macro=0.8039\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7545    0.9071    0.8238       420\n",
      "       right     0.8836    0.7048    0.7841       420\n",
      "\n",
      "    accuracy                         0.8060       840\n",
      "   macro avg     0.8190    0.8060    0.8039       840\n",
      "weighted avg     0.8190    0.8060    0.8039       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[381  39]\n",
      " [124 296]]\n",
      "precision_macro=0.8190 | recall_macro=0.8060 | specificity_macro=0.8060 | sensitivity_macro=0.8060\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/confusion_global_fold4_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/topomap_saliency_fold4_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/topomap_log10p_fold4_nb0_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold4/tsne_cls_fold4_nb0_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.89 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8060, F1=0.8039\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.30it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 16.66it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1286 | train_acc=0.5445 | val_loss=0.1238 | val_acc=0.5460 | val_f1m=0.5283 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1262 | train_acc=0.5417 | val_loss=0.1176 | val_acc=0.6159 | val_f1m=0.6159 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1219 | train_acc=0.5970 | val_loss=0.1111 | val_acc=0.6635 | val_f1m=0.6633 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1014 | train_acc=0.7199 | val_loss=0.1010 | val_acc=0.6984 | val_f1m=0.6982 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0928 | train_acc=0.7479 | val_loss=0.1120 | val_acc=0.6714 | val_f1m=0.6446 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0899 | train_acc=0.7574 | val_loss=0.0962 | val_acc=0.7365 | val_f1m=0.7328 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0823 | train_acc=0.7910 | val_loss=0.0944 | val_acc=0.7397 | val_f1m=0.7345 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0817 | train_acc=0.7917 | val_loss=0.0954 | val_acc=0.7444 | val_f1m=0.7442 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0806 | train_acc=0.7973 | val_loss=0.0926 | val_acc=0.7365 | val_f1m=0.7364 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0780 | train_acc=0.8053 | val_loss=0.0974 | val_acc=0.7317 | val_f1m=0.7287 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0728 | train_acc=0.8109 | val_loss=0.0969 | val_acc=0.7429 | val_f1m=0.7420 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0770 | train_acc=0.7997 | val_loss=0.0976 | val_acc=0.7270 | val_f1m=0.7218 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0758 | train_acc=0.8102 | val_loss=0.0904 | val_acc=0.7508 | val_f1m=0.7505 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0692 | train_acc=0.8260 | val_loss=0.0886 | val_acc=0.7667 | val_f1m=0.7664 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0720 | train_acc=0.8263 | val_loss=0.0939 | val_acc=0.7492 | val_f1m=0.7474 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0695 | train_acc=0.8253 | val_loss=0.0918 | val_acc=0.7683 | val_f1m=0.7681 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0682 | train_acc=0.8256 | val_loss=0.0875 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0698 | train_acc=0.8270 | val_loss=0.0920 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0703 | train_acc=0.8176 | val_loss=0.0890 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0632 | train_acc=0.8410 | val_loss=0.0902 | val_acc=0.7667 | val_f1m=0.7665 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0614 | train_acc=0.8389 | val_loss=0.0923 | val_acc=0.7651 | val_f1m=0.7651 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0658 | train_acc=0.8389 | val_loss=0.0894 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0657 | train_acc=0.8403 | val_loss=0.0893 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0607 | train_acc=0.8487 | val_loss=0.0892 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000384\n",
      "  Early stopping en época 24 (mejor val_f1m=0.7681)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/model_global_fold5_nb0_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/training_curve_fold5_nb0_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/history_fold5_nb0_h2.npz\n",
      "[Fold 5/5] Global acc=0.8417 | f1_macro=0.8417\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8409    0.8429    0.8419       420\n",
      "       right     0.8425    0.8405    0.8415       420\n",
      "\n",
      "    accuracy                         0.8417       840\n",
      "   macro avg     0.8417    0.8417    0.8417       840\n",
      "weighted avg     0.8417    0.8417    0.8417       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[354  66]\n",
      " [ 67 353]]\n",
      "precision_macro=0.8417 | recall_macro=0.8417 | specificity_macro=0.8417 | sensitivity_macro=0.8417\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/confusion_global_fold5_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/topomap_saliency_fold5_nb0_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/topomap_log10p_fold5_nb0_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h2/nb0_h2/fold5/tsne_cls_fold5_nb0_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.88 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8417, F1=0.8417\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb0_h2:\n",
      "  F1 por fold: ['0.8049', '0.8004', '0.7913', '0.8039', '0.8417']\n",
      "  F1 Media ± Std: 0.8084 ± 0.0173\n",
      "  ACC Media ± Std: 0.8089 ± 0.0172\n",
      "  Parámetros: 205,890\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 2/9: nb0_h4\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 0\n",
      "  • Attention Heads: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.27it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.31it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1315 | train_acc=0.5345 | val_loss=0.1205 | val_acc=0.5857 | val_f1m=0.5840 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1246 | train_acc=0.5608 | val_loss=0.1193 | val_acc=0.6016 | val_f1m=0.5931 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1186 | train_acc=0.6095 | val_loss=0.1063 | val_acc=0.6984 | val_f1m=0.6984 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0898 | train_acc=0.7544 | val_loss=0.1006 | val_acc=0.7317 | val_f1m=0.7302 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0735 | train_acc=0.8188 | val_loss=0.0968 | val_acc=0.7651 | val_f1m=0.7651 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0741 | train_acc=0.8127 | val_loss=0.0915 | val_acc=0.7413 | val_f1m=0.7406 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0671 | train_acc=0.8319 | val_loss=0.0980 | val_acc=0.7349 | val_f1m=0.7342 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0657 | train_acc=0.8404 | val_loss=0.0971 | val_acc=0.7825 | val_f1m=0.7822 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0633 | train_acc=0.8440 | val_loss=0.0940 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0690 | train_acc=0.8198 | val_loss=0.0916 | val_acc=0.7651 | val_f1m=0.7642 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0581 | train_acc=0.8611 | val_loss=0.0957 | val_acc=0.7873 | val_f1m=0.7866 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0590 | train_acc=0.8586 | val_loss=0.1015 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0608 | train_acc=0.8493 | val_loss=0.0960 | val_acc=0.7635 | val_f1m=0.7631 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0605 | train_acc=0.8465 | val_loss=0.0924 | val_acc=0.7921 | val_f1m=0.7919 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0567 | train_acc=0.8561 | val_loss=0.0997 | val_acc=0.7667 | val_f1m=0.7665 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0536 | train_acc=0.8696 | val_loss=0.0959 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0561 | train_acc=0.8682 | val_loss=0.1074 | val_acc=0.7762 | val_f1m=0.7761 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0588 | train_acc=0.8571 | val_loss=0.1036 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0519 | train_acc=0.8706 | val_loss=0.1071 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0505 | train_acc=0.8763 | val_loss=0.1072 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0522 | train_acc=0.8731 | val_loss=0.0991 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0525 | train_acc=0.8728 | val_loss=0.1042 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000405\n",
      "  Early stopping en época 22 (mejor val_f1m=0.7919)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/model_global_fold1_nb0_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/training_curve_fold1_nb0_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/history_fold1_nb0_h4.npz\n",
      "[Fold 1/5] Global acc=0.7982 | f1_macro=0.7980\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7828    0.8254    0.8035       441\n",
      "       right     0.8153    0.7710    0.7925       441\n",
      "\n",
      "    accuracy                         0.7982       882\n",
      "   macro avg     0.7991    0.7982    0.7980       882\n",
      "weighted avg     0.7991    0.7982    0.7980       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[364  77]\n",
      " [101 340]]\n",
      "precision_macro=0.7991 | recall_macro=0.7982 | specificity_macro=0.7982 | sensitivity_macro=0.7982\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/confusion_global_fold1_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/topomap_saliency_fold1_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/topomap_log10p_fold1_nb0_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold1/tsne_cls_fold1_nb0_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7982, F1=0.7980\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 16.78it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 16.78it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1299 | train_acc=0.5284 | val_loss=0.1241 | val_acc=0.5492 | val_f1m=0.4904 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1257 | train_acc=0.5583 | val_loss=0.1183 | val_acc=0.5952 | val_f1m=0.5803 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1086 | train_acc=0.6677 | val_loss=0.1082 | val_acc=0.6937 | val_f1m=0.6904 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0907 | train_acc=0.7552 | val_loss=0.0896 | val_acc=0.7667 | val_f1m=0.7663 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0823 | train_acc=0.7839 | val_loss=0.0868 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0767 | train_acc=0.8042 | val_loss=0.0846 | val_acc=0.7667 | val_f1m=0.7658 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0797 | train_acc=0.7893 | val_loss=0.0853 | val_acc=0.7825 | val_f1m=0.7812 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0760 | train_acc=0.8063 | val_loss=0.0829 | val_acc=0.7778 | val_f1m=0.7770 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0676 | train_acc=0.8294 | val_loss=0.0834 | val_acc=0.7937 | val_f1m=0.7928 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0687 | train_acc=0.8195 | val_loss=0.0808 | val_acc=0.7984 | val_f1m=0.7983 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0676 | train_acc=0.8330 | val_loss=0.0855 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0649 | train_acc=0.8465 | val_loss=0.0848 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0645 | train_acc=0.8447 | val_loss=0.0823 | val_acc=0.7984 | val_f1m=0.7978 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0657 | train_acc=0.8369 | val_loss=0.0783 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0623 | train_acc=0.8333 | val_loss=0.0850 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0637 | train_acc=0.8454 | val_loss=0.0817 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0638 | train_acc=0.8497 | val_loss=0.0790 | val_acc=0.7952 | val_f1m=0.7951 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0593 | train_acc=0.8539 | val_loss=0.0805 | val_acc=0.8063 | val_f1m=0.8062 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0605 | train_acc=0.8426 | val_loss=0.0864 | val_acc=0.7937 | val_f1m=0.7935 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0589 | train_acc=0.8536 | val_loss=0.0862 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0620 | train_acc=0.8365 | val_loss=0.0836 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0537 | train_acc=0.8674 | val_loss=0.0890 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0568 | train_acc=0.8632 | val_loss=0.0872 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0545 | train_acc=0.8643 | val_loss=0.0872 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0547 | train_acc=0.8607 | val_loss=0.0872 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0536 | train_acc=0.8706 | val_loss=0.0871 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000361\n",
      "  Early stopping en época 26 (mejor val_f1m=0.8062)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/model_global_fold2_nb0_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/training_curve_fold2_nb0_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/history_fold2_nb0_h4.npz\n",
      "[Fold 2/5] Global acc=0.8311 | f1_macro=0.8310\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8216    0.8458    0.8335       441\n",
      "       right     0.8411    0.8163    0.8285       441\n",
      "\n",
      "    accuracy                         0.8311       882\n",
      "   macro avg     0.8314    0.8311    0.8310       882\n",
      "weighted avg     0.8314    0.8311    0.8310       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[373  68]\n",
      " [ 81 360]]\n",
      "precision_macro=0.8314 | recall_macro=0.8311 | specificity_macro=0.8311 | sensitivity_macro=0.8311\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/confusion_global_fold2_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/topomap_saliency_fold2_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/topomap_log10p_fold2_nb0_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold2/tsne_cls_fold2_nb0_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8311, F1=0.8310\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 17.27it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.53it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1321 | train_acc=0.5174 | val_loss=0.1204 | val_acc=0.5905 | val_f1m=0.5897 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1258 | train_acc=0.5320 | val_loss=0.1183 | val_acc=0.5952 | val_f1m=0.5941 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1179 | train_acc=0.5906 | val_loss=0.1052 | val_acc=0.6730 | val_f1m=0.6522 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0945 | train_acc=0.7484 | val_loss=0.0893 | val_acc=0.7714 | val_f1m=0.7677 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0796 | train_acc=0.7942 | val_loss=0.0839 | val_acc=0.7603 | val_f1m=0.7576 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0697 | train_acc=0.8323 | val_loss=0.0768 | val_acc=0.7889 | val_f1m=0.7889 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0748 | train_acc=0.8141 | val_loss=0.0789 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0740 | train_acc=0.8149 | val_loss=0.0794 | val_acc=0.7857 | val_f1m=0.7855 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0691 | train_acc=0.8301 | val_loss=0.0794 | val_acc=0.7984 | val_f1m=0.7983 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0685 | train_acc=0.8330 | val_loss=0.0777 | val_acc=0.8063 | val_f1m=0.8057 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0660 | train_acc=0.8394 | val_loss=0.0841 | val_acc=0.7889 | val_f1m=0.7887 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0690 | train_acc=0.8337 | val_loss=0.0794 | val_acc=0.7952 | val_f1m=0.7951 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0595 | train_acc=0.8628 | val_loss=0.0884 | val_acc=0.7762 | val_f1m=0.7751 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0629 | train_acc=0.8497 | val_loss=0.0780 | val_acc=0.7937 | val_f1m=0.7931 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0593 | train_acc=0.8564 | val_loss=0.0797 | val_acc=0.8063 | val_f1m=0.8063 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0586 | train_acc=0.8596 | val_loss=0.0801 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0568 | train_acc=0.8575 | val_loss=0.0802 | val_acc=0.8111 | val_f1m=0.8108 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0620 | train_acc=0.8507 | val_loss=0.0775 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0531 | train_acc=0.8731 | val_loss=0.0840 | val_acc=0.8302 | val_f1m=0.8300 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0603 | train_acc=0.8447 | val_loss=0.0740 | val_acc=0.8206 | val_f1m=0.8206 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0571 | train_acc=0.8586 | val_loss=0.0788 | val_acc=0.8175 | val_f1m=0.8173 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0538 | train_acc=0.8696 | val_loss=0.0819 | val_acc=0.8063 | val_f1m=0.8062 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0493 | train_acc=0.8767 | val_loss=0.0830 | val_acc=0.8048 | val_f1m=0.8045 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0549 | train_acc=0.8674 | val_loss=0.0830 | val_acc=0.8048 | val_f1m=0.8045 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0485 | train_acc=0.8859 | val_loss=0.0831 | val_acc=0.8063 | val_f1m=0.8061 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0471 | train_acc=0.8866 | val_loss=0.0832 | val_acc=0.8063 | val_f1m=0.8061 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0506 | train_acc=0.8824 | val_loss=0.0834 | val_acc=0.8063 | val_f1m=0.8061 | LR=0.000349\n",
      "  Early stopping en época 27 (mejor val_f1m=0.8300)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/model_global_fold3_nb0_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/training_curve_fold3_nb0_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/history_fold3_nb0_h4.npz\n",
      "[Fold 3/5] Global acc=0.8027 | f1_macro=0.8027\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7973    0.8118    0.8045       441\n",
      "       right     0.8083    0.7937    0.8009       441\n",
      "\n",
      "    accuracy                         0.8027       882\n",
      "   macro avg     0.8028    0.8027    0.8027       882\n",
      "weighted avg     0.8028    0.8027    0.8027       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[358  83]\n",
      " [ 91 350]]\n",
      "precision_macro=0.8028 | recall_macro=0.8027 | specificity_macro=0.8027 | sensitivity_macro=0.8027\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/confusion_global_fold3_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/topomap_saliency_fold3_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/topomap_log10p_fold3_nb0_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold3/tsne_cls_fold3_nb0_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.89 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.8027, F1=0.8027\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.29it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 16.89it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1312 | train_acc=0.5494 | val_loss=0.1272 | val_acc=0.5000 | val_f1m=0.3546 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1239 | train_acc=0.5529 | val_loss=0.1200 | val_acc=0.6111 | val_f1m=0.6111 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1147 | train_acc=0.6194 | val_loss=0.1029 | val_acc=0.6921 | val_f1m=0.6900 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0959 | train_acc=0.7402 | val_loss=0.0992 | val_acc=0.7317 | val_f1m=0.7260 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0814 | train_acc=0.7962 | val_loss=0.0916 | val_acc=0.7365 | val_f1m=0.7328 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0776 | train_acc=0.8022 | val_loss=0.0886 | val_acc=0.7444 | val_f1m=0.7444 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0725 | train_acc=0.8200 | val_loss=0.0902 | val_acc=0.7492 | val_f1m=0.7471 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0735 | train_acc=0.8004 | val_loss=0.0881 | val_acc=0.7651 | val_f1m=0.7642 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0715 | train_acc=0.8232 | val_loss=0.0933 | val_acc=0.7349 | val_f1m=0.7295 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0704 | train_acc=0.8193 | val_loss=0.0864 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0688 | train_acc=0.8340 | val_loss=0.0835 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0685 | train_acc=0.8256 | val_loss=0.0936 | val_acc=0.7714 | val_f1m=0.7711 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0639 | train_acc=0.8386 | val_loss=0.0853 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0640 | train_acc=0.8452 | val_loss=0.0907 | val_acc=0.7730 | val_f1m=0.7722 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0660 | train_acc=0.8368 | val_loss=0.0856 | val_acc=0.7603 | val_f1m=0.7595 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0644 | train_acc=0.8386 | val_loss=0.0875 | val_acc=0.7778 | val_f1m=0.7761 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0629 | train_acc=0.8421 | val_loss=0.0828 | val_acc=0.7841 | val_f1m=0.7839 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0635 | train_acc=0.8386 | val_loss=0.0832 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0584 | train_acc=0.8498 | val_loss=0.0817 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0573 | train_acc=0.8578 | val_loss=0.0864 | val_acc=0.7651 | val_f1m=0.7646 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0608 | train_acc=0.8526 | val_loss=0.0840 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0575 | train_acc=0.8606 | val_loss=0.0824 | val_acc=0.7683 | val_f1m=0.7683 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0588 | train_acc=0.8585 | val_loss=0.0828 | val_acc=0.7683 | val_f1m=0.7683 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0595 | train_acc=0.8498 | val_loss=0.0829 | val_acc=0.7683 | val_f1m=0.7683 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0549 | train_acc=0.8669 | val_loss=0.0830 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0555 | train_acc=0.8652 | val_loss=0.0831 | val_acc=0.7683 | val_f1m=0.7683 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0508 | train_acc=0.8789 | val_loss=0.0833 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0562 | train_acc=0.8641 | val_loss=0.0834 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0589 | train_acc=0.8589 | val_loss=0.0835 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.7841)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/model_global_fold4_nb0_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/training_curve_fold4_nb0_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/history_fold4_nb0_h4.npz\n",
      "[Fold 4/5] Global acc=0.8345 | f1_macro=0.8345\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8215    0.8548    0.8378       420\n",
      "       right     0.8486    0.8143    0.8311       420\n",
      "\n",
      "    accuracy                         0.8345       840\n",
      "   macro avg     0.8351    0.8345    0.8345       840\n",
      "weighted avg     0.8351    0.8345    0.8345       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[359  61]\n",
      " [ 78 342]]\n",
      "precision_macro=0.8351 | recall_macro=0.8345 | specificity_macro=0.8345 | sensitivity_macro=0.8345\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/confusion_global_fold4_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/topomap_saliency_fold4_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/topomap_log10p_fold4_nb0_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold4/tsne_cls_fold4_nb0_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.91 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8345, F1=0.8345\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.04it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 16.64it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1299 | train_acc=0.5357 | val_loss=0.1200 | val_acc=0.5730 | val_f1m=0.5675 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1254 | train_acc=0.5459 | val_loss=0.1175 | val_acc=0.6175 | val_f1m=0.6174 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1214 | train_acc=0.6078 | val_loss=0.1107 | val_acc=0.6714 | val_f1m=0.6712 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0990 | train_acc=0.7328 | val_loss=0.1066 | val_acc=0.6619 | val_f1m=0.6609 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0849 | train_acc=0.7798 | val_loss=0.0980 | val_acc=0.7349 | val_f1m=0.7322 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0804 | train_acc=0.7945 | val_loss=0.0978 | val_acc=0.7413 | val_f1m=0.7381 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0707 | train_acc=0.8218 | val_loss=0.0921 | val_acc=0.7429 | val_f1m=0.7418 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0715 | train_acc=0.8186 | val_loss=0.0881 | val_acc=0.7794 | val_f1m=0.7790 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0693 | train_acc=0.8267 | val_loss=0.0912 | val_acc=0.7540 | val_f1m=0.7538 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0688 | train_acc=0.8319 | val_loss=0.0950 | val_acc=0.7587 | val_f1m=0.7584 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0671 | train_acc=0.8263 | val_loss=0.0936 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0634 | train_acc=0.8337 | val_loss=0.0925 | val_acc=0.7825 | val_f1m=0.7823 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0615 | train_acc=0.8505 | val_loss=0.0939 | val_acc=0.7619 | val_f1m=0.7605 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0616 | train_acc=0.8424 | val_loss=0.0953 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0564 | train_acc=0.8662 | val_loss=0.0978 | val_acc=0.7714 | val_f1m=0.7712 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0634 | train_acc=0.8379 | val_loss=0.0916 | val_acc=0.7746 | val_f1m=0.7744 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0612 | train_acc=0.8480 | val_loss=0.0954 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0648 | train_acc=0.8340 | val_loss=0.0870 | val_acc=0.7810 | val_f1m=0.7808 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0567 | train_acc=0.8631 | val_loss=0.0863 | val_acc=0.7889 | val_f1m=0.7889 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0576 | train_acc=0.8561 | val_loss=0.0938 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0576 | train_acc=0.8582 | val_loss=0.0971 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0596 | train_acc=0.8487 | val_loss=0.0935 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0514 | train_acc=0.8708 | val_loss=0.0937 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0523 | train_acc=0.8768 | val_loss=0.0938 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0557 | train_acc=0.8561 | val_loss=0.0939 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0484 | train_acc=0.8827 | val_loss=0.0940 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0542 | train_acc=0.8687 | val_loss=0.0941 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0515 | train_acc=0.8715 | val_loss=0.0942 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0485 | train_acc=0.8785 | val_loss=0.0944 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.7905)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/model_global_fold5_nb0_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/training_curve_fold5_nb0_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/history_fold5_nb0_h4.npz\n",
      "[Fold 5/5] Global acc=0.8452 | f1_macro=0.8452\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8502    0.8381    0.8441       420\n",
      "       right     0.8404    0.8524    0.8463       420\n",
      "\n",
      "    accuracy                         0.8452       840\n",
      "   macro avg     0.8453    0.8452    0.8452       840\n",
      "weighted avg     0.8453    0.8452    0.8452       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[352  68]\n",
      " [ 62 358]]\n",
      "precision_macro=0.8453 | recall_macro=0.8452 | specificity_macro=0.8452 | sensitivity_macro=0.8452\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/confusion_global_fold5_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/topomap_saliency_fold5_nb0_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/topomap_log10p_fold5_nb0_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h4/nb0_h4/fold5/tsne_cls_fold5_nb0_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8452, F1=0.8452\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb0_h4:\n",
      "  F1 por fold: ['0.7980', '0.8310', '0.8027', '0.8345', '0.8452']\n",
      "  F1 Media ± Std: 0.8223 ± 0.0186\n",
      "  ACC Media ± Std: 0.8223 ± 0.0185\n",
      "  Parámetros: 205,890\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 3/9: nb0_h6\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 0\n",
      "  • Attention Heads: 6\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.16it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.25it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1332 | train_acc=0.5348 | val_loss=0.1234 | val_acc=0.5254 | val_f1m=0.4472 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1251 | train_acc=0.5473 | val_loss=0.1196 | val_acc=0.6063 | val_f1m=0.5920 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1253 | train_acc=0.5629 | val_loss=0.1212 | val_acc=0.5429 | val_f1m=0.4905 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1010 | train_acc=0.7029 | val_loss=0.1000 | val_acc=0.7270 | val_f1m=0.7265 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0817 | train_acc=0.7882 | val_loss=0.1104 | val_acc=0.7095 | val_f1m=0.6984 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0717 | train_acc=0.8237 | val_loss=0.0983 | val_acc=0.7540 | val_f1m=0.7532 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0707 | train_acc=0.8234 | val_loss=0.0903 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0661 | train_acc=0.8383 | val_loss=0.1004 | val_acc=0.7714 | val_f1m=0.7705 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0626 | train_acc=0.8419 | val_loss=0.0956 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0686 | train_acc=0.8308 | val_loss=0.0903 | val_acc=0.7667 | val_f1m=0.7662 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0625 | train_acc=0.8447 | val_loss=0.0924 | val_acc=0.7810 | val_f1m=0.7805 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0590 | train_acc=0.8593 | val_loss=0.0937 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0608 | train_acc=0.8458 | val_loss=0.0929 | val_acc=0.7730 | val_f1m=0.7726 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0638 | train_acc=0.8408 | val_loss=0.0879 | val_acc=0.7905 | val_f1m=0.7903 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0576 | train_acc=0.8511 | val_loss=0.0904 | val_acc=0.7746 | val_f1m=0.7744 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0568 | train_acc=0.8678 | val_loss=0.0976 | val_acc=0.7746 | val_f1m=0.7745 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0578 | train_acc=0.8586 | val_loss=0.0955 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0574 | train_acc=0.8497 | val_loss=0.1001 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0571 | train_acc=0.8586 | val_loss=0.0951 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0516 | train_acc=0.8689 | val_loss=0.1000 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0557 | train_acc=0.8671 | val_loss=0.0977 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0532 | train_acc=0.8714 | val_loss=0.1033 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000405\n",
      "  Early stopping en época 22 (mejor val_f1m=0.7903)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/model_global_fold1_nb0_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/training_curve_fold1_nb0_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/history_fold1_nb0_h6.npz\n",
      "[Fold 1/5] Global acc=0.7914 | f1_macro=0.7910\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7683    0.8345    0.8000       441\n",
      "       right     0.8189    0.7483    0.7820       441\n",
      "\n",
      "    accuracy                         0.7914       882\n",
      "   macro avg     0.7936    0.7914    0.7910       882\n",
      "weighted avg     0.7936    0.7914    0.7910       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[368  73]\n",
      " [111 330]]\n",
      "precision_macro=0.7936 | recall_macro=0.7914 | specificity_macro=0.7914 | sensitivity_macro=0.7914\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/confusion_global_fold1_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/topomap_saliency_fold1_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/topomap_log10p_fold1_nb0_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold1/tsne_cls_fold1_nb0_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.89 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7914, F1=0.7910\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.00it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.15it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1307 | train_acc=0.5409 | val_loss=0.1207 | val_acc=0.5683 | val_f1m=0.5509 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1234 | train_acc=0.5615 | val_loss=0.1186 | val_acc=0.5905 | val_f1m=0.5698 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1137 | train_acc=0.6365 | val_loss=0.1129 | val_acc=0.6730 | val_f1m=0.6580 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0958 | train_acc=0.7477 | val_loss=0.0986 | val_acc=0.7476 | val_f1m=0.7438 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0820 | train_acc=0.7939 | val_loss=0.0853 | val_acc=0.7746 | val_f1m=0.7742 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0742 | train_acc=0.8010 | val_loss=0.0817 | val_acc=0.7905 | val_f1m=0.7904 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0736 | train_acc=0.8056 | val_loss=0.0846 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0737 | train_acc=0.8113 | val_loss=0.0814 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0656 | train_acc=0.8380 | val_loss=0.0830 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0690 | train_acc=0.8152 | val_loss=0.0811 | val_acc=0.7857 | val_f1m=0.7854 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0645 | train_acc=0.8365 | val_loss=0.0801 | val_acc=0.7778 | val_f1m=0.7775 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0700 | train_acc=0.8198 | val_loss=0.0833 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0612 | train_acc=0.8486 | val_loss=0.0828 | val_acc=0.7873 | val_f1m=0.7870 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0614 | train_acc=0.8525 | val_loss=0.0857 | val_acc=0.7683 | val_f1m=0.7660 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0619 | train_acc=0.8433 | val_loss=0.0819 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0596 | train_acc=0.8493 | val_loss=0.0898 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000459\n",
      "  Early stopping en época 16 (mejor val_f1m=0.7984)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/model_global_fold2_nb0_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/training_curve_fold2_nb0_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/history_fold2_nb0_h6.npz\n",
      "[Fold 2/5] Global acc=0.8231 | f1_macro=0.8231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8105    0.8435    0.8267       441\n",
      "       right     0.8369    0.8027    0.8194       441\n",
      "\n",
      "    accuracy                         0.8231       882\n",
      "   macro avg     0.8237    0.8231    0.8231       882\n",
      "weighted avg     0.8237    0.8231    0.8231       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[372  69]\n",
      " [ 87 354]]\n",
      "precision_macro=0.8237 | recall_macro=0.8231 | specificity_macro=0.8231 | sensitivity_macro=0.8231\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/confusion_global_fold2_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/topomap_saliency_fold2_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/topomap_log10p_fold2_nb0_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold2/tsne_cls_fold2_nb0_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8231, F1=0.8231\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 16.90it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.29it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1329 | train_acc=0.5195 | val_loss=0.1203 | val_acc=0.5857 | val_f1m=0.5855 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1264 | train_acc=0.5206 | val_loss=0.1187 | val_acc=0.5873 | val_f1m=0.5872 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1218 | train_acc=0.5604 | val_loss=0.1083 | val_acc=0.7032 | val_f1m=0.7024 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0965 | train_acc=0.7299 | val_loss=0.0846 | val_acc=0.7873 | val_f1m=0.7870 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0803 | train_acc=0.7957 | val_loss=0.0828 | val_acc=0.7778 | val_f1m=0.7761 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0727 | train_acc=0.8227 | val_loss=0.0779 | val_acc=0.7968 | val_f1m=0.7965 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0762 | train_acc=0.8117 | val_loss=0.0776 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0713 | train_acc=0.8145 | val_loss=0.0836 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0701 | train_acc=0.8170 | val_loss=0.0849 | val_acc=0.7984 | val_f1m=0.7961 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0668 | train_acc=0.8333 | val_loss=0.0831 | val_acc=0.7921 | val_f1m=0.7901 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0628 | train_acc=0.8490 | val_loss=0.0819 | val_acc=0.7968 | val_f1m=0.7964 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0629 | train_acc=0.8443 | val_loss=0.0783 | val_acc=0.8127 | val_f1m=0.8126 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0642 | train_acc=0.8465 | val_loss=0.0790 | val_acc=0.7825 | val_f1m=0.7824 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0593 | train_acc=0.8575 | val_loss=0.0860 | val_acc=0.7762 | val_f1m=0.7758 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0618 | train_acc=0.8536 | val_loss=0.0791 | val_acc=0.7810 | val_f1m=0.7802 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0587 | train_acc=0.8618 | val_loss=0.0803 | val_acc=0.8063 | val_f1m=0.8063 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0585 | train_acc=0.8589 | val_loss=0.0826 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0595 | train_acc=0.8461 | val_loss=0.0860 | val_acc=0.7714 | val_f1m=0.7711 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0541 | train_acc=0.8618 | val_loss=0.0903 | val_acc=0.7984 | val_f1m=0.7983 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0558 | train_acc=0.8678 | val_loss=0.0829 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000425\n",
      "  Early stopping en época 20 (mejor val_f1m=0.8126)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/model_global_fold3_nb0_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/training_curve_fold3_nb0_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/history_fold3_nb0_h6.npz\n",
      "[Fold 3/5] Global acc=0.7857 | f1_macro=0.7856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7727    0.8095    0.7907       441\n",
      "       right     0.8000    0.7619    0.7805       441\n",
      "\n",
      "    accuracy                         0.7857       882\n",
      "   macro avg     0.7864    0.7857    0.7856       882\n",
      "weighted avg     0.7864    0.7857    0.7856       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[357  84]\n",
      " [105 336]]\n",
      "precision_macro=0.7864 | recall_macro=0.7857 | specificity_macro=0.7857 | sensitivity_macro=0.7857\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/confusion_global_fold3_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/topomap_saliency_fold3_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/topomap_log10p_fold3_nb0_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold3/tsne_cls_fold3_nb0_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.90 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.7857, F1=0.7856\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.14it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.43it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1322 | train_acc=0.5410 | val_loss=0.1270 | val_acc=0.5000 | val_f1m=0.3469 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1233 | train_acc=0.5557 | val_loss=0.1226 | val_acc=0.5968 | val_f1m=0.5964 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1168 | train_acc=0.6082 | val_loss=0.1098 | val_acc=0.6635 | val_f1m=0.6600 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0981 | train_acc=0.7265 | val_loss=0.0952 | val_acc=0.7063 | val_f1m=0.7039 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0843 | train_acc=0.7885 | val_loss=0.0935 | val_acc=0.7381 | val_f1m=0.7300 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0794 | train_acc=0.7920 | val_loss=0.0872 | val_acc=0.7571 | val_f1m=0.7561 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0730 | train_acc=0.8162 | val_loss=0.0920 | val_acc=0.7571 | val_f1m=0.7538 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0713 | train_acc=0.8235 | val_loss=0.0983 | val_acc=0.7460 | val_f1m=0.7392 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0736 | train_acc=0.8106 | val_loss=0.0908 | val_acc=0.7413 | val_f1m=0.7402 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0672 | train_acc=0.8295 | val_loss=0.0898 | val_acc=0.7619 | val_f1m=0.7584 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0685 | train_acc=0.8186 | val_loss=0.0882 | val_acc=0.7889 | val_f1m=0.7889 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0683 | train_acc=0.8316 | val_loss=0.0825 | val_acc=0.7825 | val_f1m=0.7823 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0697 | train_acc=0.8291 | val_loss=0.0857 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0644 | train_acc=0.8351 | val_loss=0.0820 | val_acc=0.7889 | val_f1m=0.7887 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0663 | train_acc=0.8347 | val_loss=0.0824 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0610 | train_acc=0.8550 | val_loss=0.0854 | val_acc=0.7857 | val_f1m=0.7855 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0628 | train_acc=0.8452 | val_loss=0.0845 | val_acc=0.7825 | val_f1m=0.7817 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0648 | train_acc=0.8470 | val_loss=0.0854 | val_acc=0.7683 | val_f1m=0.7663 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0622 | train_acc=0.8505 | val_loss=0.0815 | val_acc=0.7762 | val_f1m=0.7760 | LR=0.000434\n",
      "  Early stopping en época 19 (mejor val_f1m=0.7889)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/model_global_fold4_nb0_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/training_curve_fold4_nb0_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/history_fold4_nb0_h6.npz\n",
      "[Fold 4/5] Global acc=0.8298 | f1_macro=0.8295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8044    0.8714    0.8366       420\n",
      "       right     0.8597    0.7881    0.8224       420\n",
      "\n",
      "    accuracy                         0.8298       840\n",
      "   macro avg     0.8321    0.8298    0.8295       840\n",
      "weighted avg     0.8321    0.8298    0.8295       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[366  54]\n",
      " [ 89 331]]\n",
      "precision_macro=0.8321 | recall_macro=0.8298 | specificity_macro=0.8298 | sensitivity_macro=0.8298\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/confusion_global_fold4_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/topomap_saliency_fold4_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/topomap_log10p_fold4_nb0_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold4/tsne_cls_fold4_nb0_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.89 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8298, F1=0.8295\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.58it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.69it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1279 | train_acc=0.5231 | val_loss=0.1210 | val_acc=0.5667 | val_f1m=0.5594 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1267 | train_acc=0.5385 | val_loss=0.1177 | val_acc=0.6286 | val_f1m=0.6284 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1236 | train_acc=0.5816 | val_loss=0.1129 | val_acc=0.6397 | val_f1m=0.6396 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1004 | train_acc=0.7181 | val_loss=0.1023 | val_acc=0.7143 | val_f1m=0.7130 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0839 | train_acc=0.7854 | val_loss=0.0987 | val_acc=0.7270 | val_f1m=0.7199 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0779 | train_acc=0.7945 | val_loss=0.0899 | val_acc=0.7508 | val_f1m=0.7506 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0715 | train_acc=0.8148 | val_loss=0.0902 | val_acc=0.7540 | val_f1m=0.7538 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0708 | train_acc=0.8109 | val_loss=0.0916 | val_acc=0.7587 | val_f1m=0.7587 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0653 | train_acc=0.8323 | val_loss=0.0936 | val_acc=0.7317 | val_f1m=0.7275 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0685 | train_acc=0.8298 | val_loss=0.0971 | val_acc=0.7730 | val_f1m=0.7715 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0664 | train_acc=0.8288 | val_loss=0.0946 | val_acc=0.7508 | val_f1m=0.7490 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0642 | train_acc=0.8375 | val_loss=0.0909 | val_acc=0.7397 | val_f1m=0.7388 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0630 | train_acc=0.8417 | val_loss=0.0999 | val_acc=0.7667 | val_f1m=0.7665 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0590 | train_acc=0.8554 | val_loss=0.1025 | val_acc=0.7508 | val_f1m=0.7508 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0624 | train_acc=0.8361 | val_loss=0.0914 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0614 | train_acc=0.8347 | val_loss=0.0964 | val_acc=0.7730 | val_f1m=0.7721 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0576 | train_acc=0.8543 | val_loss=0.0910 | val_acc=0.7667 | val_f1m=0.7664 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0579 | train_acc=0.8529 | val_loss=0.1002 | val_acc=0.7444 | val_f1m=0.7437 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0581 | train_acc=0.8484 | val_loss=0.0934 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0537 | train_acc=0.8704 | val_loss=0.0981 | val_acc=0.7778 | val_f1m=0.7773 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0622 | train_acc=0.8484 | val_loss=0.0957 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0547 | train_acc=0.8620 | val_loss=0.0980 | val_acc=0.7603 | val_f1m=0.7601 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0513 | train_acc=0.8761 | val_loss=0.0979 | val_acc=0.7603 | val_f1m=0.7601 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0590 | train_acc=0.8634 | val_loss=0.0978 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0480 | train_acc=0.8799 | val_loss=0.0978 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0486 | train_acc=0.8792 | val_loss=0.0980 | val_acc=0.7603 | val_f1m=0.7601 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0509 | train_acc=0.8729 | val_loss=0.0981 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0486 | train_acc=0.8813 | val_loss=0.0982 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000337\n",
      "  Early stopping en época 28 (mejor val_f1m=0.7773)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/model_global_fold5_nb0_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/training_curve_fold5_nb0_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/history_fold5_nb0_h6.npz\n",
      "[Fold 5/5] Global acc=0.8345 | f1_macro=0.8344\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8521    0.8095    0.8303       420\n",
      "       right     0.8186    0.8595    0.8386       420\n",
      "\n",
      "    accuracy                         0.8345       840\n",
      "   macro avg     0.8354    0.8345    0.8344       840\n",
      "weighted avg     0.8354    0.8345    0.8344       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[340  80]\n",
      " [ 59 361]]\n",
      "precision_macro=0.8354 | recall_macro=0.8345 | specificity_macro=0.8345 | sensitivity_macro=0.8345\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/confusion_global_fold5_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/topomap_saliency_fold5_nb0_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/topomap_log10p_fold5_nb0_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb0_h6/nb0_h6/fold5/tsne_cls_fold5_nb0_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=205,890 | params_trainable=205,890 | FLOPs~146.4M | latency/batch=0.88 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8345, F1=0.8344\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb0_h6:\n",
      "  F1 por fold: ['0.7910', '0.8231', '0.7856', '0.8295', '0.8344']\n",
      "  F1 Media ± Std: 0.8127 ± 0.0203\n",
      "  ACC Media ± Std: 0.8129 ± 0.0203\n",
      "  Parámetros: 205,890\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 4/9: nb2_h2\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 2\n",
      "  • Attention Heads: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.26it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.65it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1307 | train_acc=0.5370 | val_loss=0.1257 | val_acc=0.5000 | val_f1m=0.3333 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1226 | train_acc=0.5601 | val_loss=0.1171 | val_acc=0.6349 | val_f1m=0.6349 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1040 | train_acc=0.6997 | val_loss=0.1068 | val_acc=0.6857 | val_f1m=0.6847 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0964 | train_acc=0.7491 | val_loss=0.1090 | val_acc=0.6968 | val_f1m=0.6931 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0837 | train_acc=0.7914 | val_loss=0.0992 | val_acc=0.7286 | val_f1m=0.7285 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0770 | train_acc=0.8053 | val_loss=0.0983 | val_acc=0.7460 | val_f1m=0.7449 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0762 | train_acc=0.8092 | val_loss=0.0957 | val_acc=0.7381 | val_f1m=0.7364 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0694 | train_acc=0.8337 | val_loss=0.1078 | val_acc=0.7524 | val_f1m=0.7514 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0706 | train_acc=0.8316 | val_loss=0.0932 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0716 | train_acc=0.8152 | val_loss=0.0971 | val_acc=0.7556 | val_f1m=0.7528 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0689 | train_acc=0.8301 | val_loss=0.0962 | val_acc=0.7524 | val_f1m=0.7523 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0694 | train_acc=0.8291 | val_loss=0.0985 | val_acc=0.7444 | val_f1m=0.7444 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0705 | train_acc=0.8248 | val_loss=0.0936 | val_acc=0.7571 | val_f1m=0.7565 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0679 | train_acc=0.8316 | val_loss=0.0910 | val_acc=0.7397 | val_f1m=0.7380 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0639 | train_acc=0.8486 | val_loss=0.1018 | val_acc=0.7476 | val_f1m=0.7475 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0592 | train_acc=0.8504 | val_loss=0.1124 | val_acc=0.7540 | val_f1m=0.7528 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0661 | train_acc=0.8408 | val_loss=0.1018 | val_acc=0.7508 | val_f1m=0.7505 | LR=0.000451\n",
      "  Early stopping en época 17 (mejor val_f1m=0.7619)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/model_global_fold1_nb2_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/training_curve_fold1_nb2_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/history_fold1_nb2_h2.npz\n",
      "[Fold 1/5] Global acc=0.7732 | f1_macro=0.7731\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7603    0.7982    0.7788       441\n",
      "       right     0.7876    0.7483    0.7674       441\n",
      "\n",
      "    accuracy                         0.7732       882\n",
      "   macro avg     0.7739    0.7732    0.7731       882\n",
      "weighted avg     0.7739    0.7732    0.7731       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[352  89]\n",
      " [111 330]]\n",
      "precision_macro=0.7739 | recall_macro=0.7732 | specificity_macro=0.7732 | sensitivity_macro=0.7732\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/confusion_global_fold1_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/topomap_saliency_fold1_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/topomap_log10p_fold1_nb2_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold1/tsne_cls_fold1_nb2_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7732, F1=0.7731\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.01it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.01it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1295 | train_acc=0.5320 | val_loss=0.1203 | val_acc=0.6222 | val_f1m=0.6175 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1221 | train_acc=0.5810 | val_loss=0.1143 | val_acc=0.6571 | val_f1m=0.6551 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1100 | train_acc=0.6802 | val_loss=0.1101 | val_acc=0.6794 | val_f1m=0.6751 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0944 | train_acc=0.7427 | val_loss=0.0939 | val_acc=0.7317 | val_f1m=0.7317 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0972 | train_acc=0.7296 | val_loss=0.0977 | val_acc=0.7349 | val_f1m=0.7319 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0828 | train_acc=0.7896 | val_loss=0.0969 | val_acc=0.7492 | val_f1m=0.7479 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0800 | train_acc=0.7957 | val_loss=0.0916 | val_acc=0.7508 | val_f1m=0.7474 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0813 | train_acc=0.7811 | val_loss=0.0969 | val_acc=0.7619 | val_f1m=0.7614 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0724 | train_acc=0.8173 | val_loss=0.0872 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0762 | train_acc=0.8049 | val_loss=0.0921 | val_acc=0.7746 | val_f1m=0.7728 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0779 | train_acc=0.7960 | val_loss=0.0837 | val_acc=0.7730 | val_f1m=0.7725 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0757 | train_acc=0.8131 | val_loss=0.0892 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0715 | train_acc=0.8220 | val_loss=0.0916 | val_acc=0.7556 | val_f1m=0.7525 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0761 | train_acc=0.8113 | val_loss=0.0948 | val_acc=0.7587 | val_f1m=0.7555 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0726 | train_acc=0.8198 | val_loss=0.0876 | val_acc=0.7619 | val_f1m=0.7614 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0684 | train_acc=0.8266 | val_loss=0.0968 | val_acc=0.7635 | val_f1m=0.7615 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0731 | train_acc=0.8149 | val_loss=0.0910 | val_acc=0.7619 | val_f1m=0.7597 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0702 | train_acc=0.8216 | val_loss=0.0867 | val_acc=0.7810 | val_f1m=0.7805 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0662 | train_acc=0.8362 | val_loss=0.0923 | val_acc=0.7889 | val_f1m=0.7889 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0688 | train_acc=0.8266 | val_loss=0.0860 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0643 | train_acc=0.8525 | val_loss=0.0866 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0620 | train_acc=0.8422 | val_loss=0.0888 | val_acc=0.7825 | val_f1m=0.7822 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0624 | train_acc=0.8479 | val_loss=0.0893 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0651 | train_acc=0.8372 | val_loss=0.0892 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0638 | train_acc=0.8390 | val_loss=0.0891 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0631 | train_acc=0.8451 | val_loss=0.0890 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0640 | train_acc=0.8475 | val_loss=0.0890 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0635 | train_acc=0.8486 | val_loss=0.0890 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000337\n",
      "  Early stopping en época 28 (mejor val_f1m=0.7937)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/model_global_fold2_nb2_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/training_curve_fold2_nb2_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/history_fold2_nb2_h2.npz\n",
      "[Fold 2/5] Global acc=0.8118 | f1_macro=0.8118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8035    0.8254    0.8143       441\n",
      "       right     0.8205    0.7982    0.8092       441\n",
      "\n",
      "    accuracy                         0.8118       882\n",
      "   macro avg     0.8120    0.8118    0.8118       882\n",
      "weighted avg     0.8120    0.8118    0.8118       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[364  77]\n",
      " [ 89 352]]\n",
      "precision_macro=0.8120 | recall_macro=0.8118 | specificity_macro=0.8118 | sensitivity_macro=0.8118\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/confusion_global_fold2_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/topomap_saliency_fold2_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/topomap_log10p_fold2_nb2_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold2/tsne_cls_fold2_nb2_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8118, F1=0.8118\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 16.98it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.18it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1322 | train_acc=0.4940 | val_loss=0.1251 | val_acc=0.5190 | val_f1m=0.3975 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1237 | train_acc=0.5519 | val_loss=0.1294 | val_acc=0.5127 | val_f1m=0.3686 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1208 | train_acc=0.5885 | val_loss=0.1047 | val_acc=0.7032 | val_f1m=0.6971 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0976 | train_acc=0.7310 | val_loss=0.0928 | val_acc=0.7429 | val_f1m=0.7386 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0936 | train_acc=0.7445 | val_loss=0.1052 | val_acc=0.7190 | val_f1m=0.7064 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0871 | train_acc=0.7850 | val_loss=0.0869 | val_acc=0.7667 | val_f1m=0.7635 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0793 | train_acc=0.7964 | val_loss=0.0861 | val_acc=0.7635 | val_f1m=0.7591 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0803 | train_acc=0.7868 | val_loss=0.0788 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0809 | train_acc=0.7889 | val_loss=0.0891 | val_acc=0.7698 | val_f1m=0.7684 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0795 | train_acc=0.7942 | val_loss=0.0874 | val_acc=0.7587 | val_f1m=0.7535 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0747 | train_acc=0.8149 | val_loss=0.0785 | val_acc=0.7889 | val_f1m=0.7887 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0715 | train_acc=0.8170 | val_loss=0.0849 | val_acc=0.7905 | val_f1m=0.7903 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0748 | train_acc=0.8081 | val_loss=0.0833 | val_acc=0.7857 | val_f1m=0.7846 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0702 | train_acc=0.8248 | val_loss=0.0790 | val_acc=0.8000 | val_f1m=0.7992 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0670 | train_acc=0.8351 | val_loss=0.0835 | val_acc=0.8079 | val_f1m=0.8074 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0733 | train_acc=0.8184 | val_loss=0.0819 | val_acc=0.7825 | val_f1m=0.7821 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0674 | train_acc=0.8301 | val_loss=0.0856 | val_acc=0.7968 | val_f1m=0.7964 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0685 | train_acc=0.8223 | val_loss=0.0815 | val_acc=0.8159 | val_f1m=0.8159 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0676 | train_acc=0.8351 | val_loss=0.0859 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0643 | train_acc=0.8436 | val_loss=0.0855 | val_acc=0.8111 | val_f1m=0.8111 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0669 | train_acc=0.8372 | val_loss=0.0834 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0617 | train_acc=0.8468 | val_loss=0.0886 | val_acc=0.8032 | val_f1m=0.8028 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0623 | train_acc=0.8479 | val_loss=0.0880 | val_acc=0.8016 | val_f1m=0.8013 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0654 | train_acc=0.8365 | val_loss=0.0880 | val_acc=0.8016 | val_f1m=0.8013 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0593 | train_acc=0.8511 | val_loss=0.0880 | val_acc=0.8016 | val_f1m=0.8013 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0611 | train_acc=0.8550 | val_loss=0.0879 | val_acc=0.8016 | val_f1m=0.8013 | LR=0.000361\n",
      "  Early stopping en época 26 (mejor val_f1m=0.8159)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/model_global_fold3_nb2_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/training_curve_fold3_nb2_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/history_fold3_nb2_h2.npz\n",
      "[Fold 3/5] Global acc=0.7914 | f1_macro=0.7914\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7954    0.7846    0.7900       441\n",
      "       right     0.7875    0.7982    0.7928       441\n",
      "\n",
      "    accuracy                         0.7914       882\n",
      "   macro avg     0.7914    0.7914    0.7914       882\n",
      "weighted avg     0.7914    0.7914    0.7914       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[346  95]\n",
      " [ 89 352]]\n",
      "precision_macro=0.7914 | recall_macro=0.7914 | specificity_macro=0.7914 | sensitivity_macro=0.7914\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/confusion_global_fold3_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/topomap_saliency_fold3_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/topomap_log10p_fold3_nb2_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold3/tsne_cls_fold3_nb2_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.08 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.7914, F1=0.7914\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:04<00:00, 16.98it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.01it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1320 | train_acc=0.5161 | val_loss=0.1202 | val_acc=0.6143 | val_f1m=0.6128 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1274 | train_acc=0.5399 | val_loss=0.1186 | val_acc=0.6159 | val_f1m=0.5977 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1166 | train_acc=0.6085 | val_loss=0.1084 | val_acc=0.6952 | val_f1m=0.6952 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0964 | train_acc=0.7360 | val_loss=0.1023 | val_acc=0.7063 | val_f1m=0.7054 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0903 | train_acc=0.7640 | val_loss=0.1002 | val_acc=0.7238 | val_f1m=0.7207 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0908 | train_acc=0.7612 | val_loss=0.0976 | val_acc=0.7492 | val_f1m=0.7482 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0793 | train_acc=0.8060 | val_loss=0.1024 | val_acc=0.7190 | val_f1m=0.7169 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0834 | train_acc=0.7892 | val_loss=0.1050 | val_acc=0.7333 | val_f1m=0.7240 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0801 | train_acc=0.7973 | val_loss=0.0986 | val_acc=0.7206 | val_f1m=0.7167 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0790 | train_acc=0.7955 | val_loss=0.0947 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0723 | train_acc=0.8232 | val_loss=0.0943 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0779 | train_acc=0.8029 | val_loss=0.0945 | val_acc=0.7540 | val_f1m=0.7540 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0742 | train_acc=0.8085 | val_loss=0.0942 | val_acc=0.7508 | val_f1m=0.7498 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0692 | train_acc=0.8361 | val_loss=0.1015 | val_acc=0.7667 | val_f1m=0.7657 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0663 | train_acc=0.8337 | val_loss=0.0913 | val_acc=0.7556 | val_f1m=0.7548 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0679 | train_acc=0.8284 | val_loss=0.0902 | val_acc=0.7540 | val_f1m=0.7525 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0665 | train_acc=0.8379 | val_loss=0.0961 | val_acc=0.7635 | val_f1m=0.7624 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0666 | train_acc=0.8319 | val_loss=0.0946 | val_acc=0.7571 | val_f1m=0.7557 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0680 | train_acc=0.8312 | val_loss=0.0888 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0674 | train_acc=0.8312 | val_loss=0.0883 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0664 | train_acc=0.8295 | val_loss=0.0874 | val_acc=0.7714 | val_f1m=0.7712 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0639 | train_acc=0.8501 | val_loss=0.0923 | val_acc=0.7571 | val_f1m=0.7567 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0604 | train_acc=0.8459 | val_loss=0.0922 | val_acc=0.7603 | val_f1m=0.7599 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0613 | train_acc=0.8470 | val_loss=0.0922 | val_acc=0.7603 | val_f1m=0.7599 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0608 | train_acc=0.8456 | val_loss=0.0923 | val_acc=0.7587 | val_f1m=0.7583 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0631 | train_acc=0.8473 | val_loss=0.0923 | val_acc=0.7587 | val_f1m=0.7583 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0684 | train_acc=0.8305 | val_loss=0.0922 | val_acc=0.7587 | val_f1m=0.7583 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0584 | train_acc=0.8589 | val_loss=0.0924 | val_acc=0.7587 | val_f1m=0.7583 | LR=0.000337\n",
      "  Early stopping en época 28 (mejor val_f1m=0.7729)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/model_global_fold4_nb2_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/training_curve_fold4_nb2_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/history_fold4_nb2_h2.npz\n",
      "[Fold 4/5] Global acc=0.8321 | f1_macro=0.8321\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8237    0.8452    0.8343       420\n",
      "       right     0.8411    0.8190    0.8299       420\n",
      "\n",
      "    accuracy                         0.8321       840\n",
      "   macro avg     0.8324    0.8321    0.8321       840\n",
      "weighted avg     0.8324    0.8321    0.8321       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[355  65]\n",
      " [ 76 344]]\n",
      "precision_macro=0.8324 | recall_macro=0.8321 | specificity_macro=0.8321 | sensitivity_macro=0.8321\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/confusion_global_fold4_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/topomap_saliency_fold4_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/topomap_log10p_fold4_nb2_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold4/tsne_cls_fold4_nb2_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8321, F1=0.8321\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:04<00:00, 16.99it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.61it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1299 | train_acc=0.5245 | val_loss=0.1210 | val_acc=0.5333 | val_f1m=0.4672 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1255 | train_acc=0.5413 | val_loss=0.1189 | val_acc=0.5762 | val_f1m=0.5226 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1207 | train_acc=0.5837 | val_loss=0.1096 | val_acc=0.6667 | val_f1m=0.6654 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0964 | train_acc=0.7433 | val_loss=0.1062 | val_acc=0.6984 | val_f1m=0.6984 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0965 | train_acc=0.7279 | val_loss=0.0998 | val_acc=0.7302 | val_f1m=0.7273 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0834 | train_acc=0.7829 | val_loss=0.1057 | val_acc=0.7143 | val_f1m=0.7098 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0882 | train_acc=0.7728 | val_loss=0.0925 | val_acc=0.7460 | val_f1m=0.7458 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0818 | train_acc=0.7805 | val_loss=0.0914 | val_acc=0.7508 | val_f1m=0.7508 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0753 | train_acc=0.8144 | val_loss=0.0948 | val_acc=0.7349 | val_f1m=0.7324 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0798 | train_acc=0.7927 | val_loss=0.0965 | val_acc=0.7540 | val_f1m=0.7526 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0711 | train_acc=0.8235 | val_loss=0.0968 | val_acc=0.7556 | val_f1m=0.7533 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0761 | train_acc=0.8036 | val_loss=0.0937 | val_acc=0.7413 | val_f1m=0.7411 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0726 | train_acc=0.8169 | val_loss=0.0987 | val_acc=0.7429 | val_f1m=0.7417 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0755 | train_acc=0.8071 | val_loss=0.0942 | val_acc=0.7587 | val_f1m=0.7586 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0727 | train_acc=0.8151 | val_loss=0.0952 | val_acc=0.7317 | val_f1m=0.7316 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0694 | train_acc=0.8214 | val_loss=0.0945 | val_acc=0.7524 | val_f1m=0.7523 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0708 | train_acc=0.8253 | val_loss=0.0906 | val_acc=0.7413 | val_f1m=0.7411 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0696 | train_acc=0.8204 | val_loss=0.0915 | val_acc=0.7524 | val_f1m=0.7521 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0683 | train_acc=0.8288 | val_loss=0.0976 | val_acc=0.7460 | val_f1m=0.7453 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0706 | train_acc=0.8281 | val_loss=0.0894 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0680 | train_acc=0.8309 | val_loss=0.0920 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0676 | train_acc=0.8260 | val_loss=0.0897 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0685 | train_acc=0.8263 | val_loss=0.0898 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0641 | train_acc=0.8463 | val_loss=0.0898 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0629 | train_acc=0.8452 | val_loss=0.0898 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0634 | train_acc=0.8456 | val_loss=0.0898 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0643 | train_acc=0.8389 | val_loss=0.0898 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0669 | train_acc=0.8368 | val_loss=0.0899 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0613 | train_acc=0.8389 | val_loss=0.0899 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.7682)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/model_global_fold5_nb2_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/training_curve_fold5_nb2_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/history_fold5_nb2_h2.npz\n",
      "[Fold 5/5] Global acc=0.8310 | f1_macro=0.8309\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8458    0.8095    0.8273       420\n",
      "       right     0.8174    0.8524    0.8345       420\n",
      "\n",
      "    accuracy                         0.8310       840\n",
      "   macro avg     0.8316    0.8310    0.8309       840\n",
      "weighted avg     0.8316    0.8310    0.8309       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[340  80]\n",
      " [ 62 358]]\n",
      "precision_macro=0.8316 | recall_macro=0.8310 | specificity_macro=0.8310 | sensitivity_macro=0.8310\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/confusion_global_fold5_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/topomap_saliency_fold5_nb2_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/topomap_log10p_fold5_nb2_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h2/nb2_h2/fold5/tsne_cls_fold5_nb2_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.08 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8310, F1=0.8309\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb2_h2:\n",
      "  F1 por fold: ['0.7731', '0.8118', '0.7914', '0.8321', '0.8309']\n",
      "  F1 Media ± Std: 0.8078 ± 0.0229\n",
      "  ACC Media ± Std: 0.8079 ± 0.0228\n",
      "  Parámetros: 232,290\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 5/9: nb2_h4\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 2\n",
      "  • Attention Heads: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 16.97it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 16.85it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1315 | train_acc=0.5131 | val_loss=0.1242 | val_acc=0.4984 | val_f1m=0.3382 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1229 | train_acc=0.5579 | val_loss=0.1184 | val_acc=0.6127 | val_f1m=0.6113 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1105 | train_acc=0.6578 | val_loss=0.1202 | val_acc=0.6429 | val_f1m=0.6192 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0973 | train_acc=0.7406 | val_loss=0.1010 | val_acc=0.7190 | val_f1m=0.7190 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0843 | train_acc=0.7818 | val_loss=0.0964 | val_acc=0.7317 | val_f1m=0.7310 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0754 | train_acc=0.8099 | val_loss=0.1018 | val_acc=0.7413 | val_f1m=0.7377 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0747 | train_acc=0.8145 | val_loss=0.0987 | val_acc=0.7444 | val_f1m=0.7415 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0756 | train_acc=0.8070 | val_loss=0.1114 | val_acc=0.7270 | val_f1m=0.7202 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0693 | train_acc=0.8326 | val_loss=0.0899 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0685 | train_acc=0.8284 | val_loss=0.0978 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0620 | train_acc=0.8536 | val_loss=0.1004 | val_acc=0.7619 | val_f1m=0.7614 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0638 | train_acc=0.8475 | val_loss=0.1008 | val_acc=0.7333 | val_f1m=0.7283 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0639 | train_acc=0.8415 | val_loss=0.0947 | val_acc=0.7508 | val_f1m=0.7502 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0620 | train_acc=0.8504 | val_loss=0.0945 | val_acc=0.7603 | val_f1m=0.7586 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0589 | train_acc=0.8568 | val_loss=0.1099 | val_acc=0.7571 | val_f1m=0.7568 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0564 | train_acc=0.8721 | val_loss=0.1134 | val_acc=0.7413 | val_f1m=0.7383 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0588 | train_acc=0.8550 | val_loss=0.1151 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000451\n",
      "  Early stopping en época 17 (mejor val_f1m=0.7714)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/model_global_fold1_nb2_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/training_curve_fold1_nb2_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/history_fold1_nb2_h4.npz\n",
      "[Fold 1/5] Global acc=0.7789 | f1_macro=0.7788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7662    0.8027    0.7841       441\n",
      "       right     0.7929    0.7551    0.7735       441\n",
      "\n",
      "    accuracy                         0.7789       882\n",
      "   macro avg     0.7795    0.7789    0.7788       882\n",
      "weighted avg     0.7795    0.7789    0.7788       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[354  87]\n",
      " [108 333]]\n",
      "precision_macro=0.7795 | recall_macro=0.7789 | specificity_macro=0.7789 | sensitivity_macro=0.7789\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/confusion_global_fold1_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/topomap_saliency_fold1_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/topomap_log10p_fold1_nb2_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold1/tsne_cls_fold1_nb2_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7789, F1=0.7788\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.07it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.44it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1301 | train_acc=0.5192 | val_loss=0.1195 | val_acc=0.5857 | val_f1m=0.5856 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1216 | train_acc=0.5810 | val_loss=0.1160 | val_acc=0.6333 | val_f1m=0.6322 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1133 | train_acc=0.6443 | val_loss=0.1080 | val_acc=0.6921 | val_f1m=0.6918 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0965 | train_acc=0.7299 | val_loss=0.0964 | val_acc=0.7302 | val_f1m=0.7298 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0911 | train_acc=0.7541 | val_loss=0.0947 | val_acc=0.7476 | val_f1m=0.7407 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0854 | train_acc=0.7743 | val_loss=0.0930 | val_acc=0.7333 | val_f1m=0.7319 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0810 | train_acc=0.7868 | val_loss=0.0913 | val_acc=0.7587 | val_f1m=0.7557 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0800 | train_acc=0.7953 | val_loss=0.0957 | val_acc=0.7524 | val_f1m=0.7509 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0744 | train_acc=0.8149 | val_loss=0.0930 | val_acc=0.7683 | val_f1m=0.7679 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0790 | train_acc=0.7960 | val_loss=0.0868 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0761 | train_acc=0.8102 | val_loss=0.0829 | val_acc=0.7841 | val_f1m=0.7832 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0720 | train_acc=0.8177 | val_loss=0.0863 | val_acc=0.7698 | val_f1m=0.7682 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0734 | train_acc=0.8060 | val_loss=0.0895 | val_acc=0.7571 | val_f1m=0.7561 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0726 | train_acc=0.8163 | val_loss=0.0849 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0679 | train_acc=0.8312 | val_loss=0.0980 | val_acc=0.7571 | val_f1m=0.7531 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0737 | train_acc=0.8166 | val_loss=0.0875 | val_acc=0.7714 | val_f1m=0.7704 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0688 | train_acc=0.8323 | val_loss=0.0886 | val_acc=0.7794 | val_f1m=0.7787 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0707 | train_acc=0.8198 | val_loss=0.0849 | val_acc=0.7857 | val_f1m=0.7854 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0686 | train_acc=0.8259 | val_loss=0.0844 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0654 | train_acc=0.8383 | val_loss=0.0843 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0646 | train_acc=0.8408 | val_loss=0.0822 | val_acc=0.7889 | val_f1m=0.7887 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0596 | train_acc=0.8472 | val_loss=0.0874 | val_acc=0.7746 | val_f1m=0.7743 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0593 | train_acc=0.8515 | val_loss=0.0859 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0606 | train_acc=0.8522 | val_loss=0.0858 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0585 | train_acc=0.8557 | val_loss=0.0858 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0597 | train_acc=0.8625 | val_loss=0.0858 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0572 | train_acc=0.8596 | val_loss=0.0858 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0588 | train_acc=0.8518 | val_loss=0.0858 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0581 | train_acc=0.8600 | val_loss=0.0858 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.7887)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/model_global_fold2_nb2_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/training_curve_fold2_nb2_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/history_fold2_nb2_h4.npz\n",
      "[Fold 2/5] Global acc=0.8186 | f1_macro=0.8186\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8172    0.8209    0.8190       441\n",
      "       right     0.8200    0.8163    0.8182       441\n",
      "\n",
      "    accuracy                         0.8186       882\n",
      "   macro avg     0.8186    0.8186    0.8186       882\n",
      "weighted avg     0.8186    0.8186    0.8186       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[362  79]\n",
      " [ 81 360]]\n",
      "precision_macro=0.8186 | recall_macro=0.8186 | specificity_macro=0.8186 | sensitivity_macro=0.8186\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/confusion_global_fold2_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/topomap_saliency_fold2_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/topomap_log10p_fold2_nb2_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold2/tsne_cls_fold2_nb2_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8186, F1=0.8186\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 17.22it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.20it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1326 | train_acc=0.4964 | val_loss=0.1236 | val_acc=0.5079 | val_f1m=0.3802 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1236 | train_acc=0.5601 | val_loss=0.1317 | val_acc=0.5095 | val_f1m=0.3568 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1267 | train_acc=0.5601 | val_loss=0.1094 | val_acc=0.6778 | val_f1m=0.6718 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1074 | train_acc=0.6791 | val_loss=0.0976 | val_acc=0.7190 | val_f1m=0.7107 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0946 | train_acc=0.7392 | val_loss=0.1040 | val_acc=0.7095 | val_f1m=0.6964 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0866 | train_acc=0.7747 | val_loss=0.0949 | val_acc=0.7365 | val_f1m=0.7279 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0781 | train_acc=0.7989 | val_loss=0.0873 | val_acc=0.7778 | val_f1m=0.7775 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0726 | train_acc=0.8159 | val_loss=0.0922 | val_acc=0.7651 | val_f1m=0.7635 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0719 | train_acc=0.8230 | val_loss=0.0783 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0708 | train_acc=0.8301 | val_loss=0.0748 | val_acc=0.8175 | val_f1m=0.8175 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0674 | train_acc=0.8376 | val_loss=0.0802 | val_acc=0.7889 | val_f1m=0.7882 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0662 | train_acc=0.8397 | val_loss=0.0757 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0628 | train_acc=0.8500 | val_loss=0.0792 | val_acc=0.8000 | val_f1m=0.7998 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0619 | train_acc=0.8507 | val_loss=0.0773 | val_acc=0.8095 | val_f1m=0.8095 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0639 | train_acc=0.8426 | val_loss=0.0776 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0623 | train_acc=0.8522 | val_loss=0.0800 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0622 | train_acc=0.8472 | val_loss=0.0764 | val_acc=0.8016 | val_f1m=0.8016 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0623 | train_acc=0.8458 | val_loss=0.0855 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000443\n",
      "  Early stopping en época 18 (mejor val_f1m=0.8175)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/model_global_fold3_nb2_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/training_curve_fold3_nb2_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/history_fold3_nb2_h4.npz\n",
      "[Fold 3/5] Global acc=0.7857 | f1_macro=0.7856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7716    0.8118    0.7912       441\n",
      "       right     0.8014    0.7596    0.7800       441\n",
      "\n",
      "    accuracy                         0.7857       882\n",
      "   macro avg     0.7865    0.7857    0.7856       882\n",
      "weighted avg     0.7865    0.7857    0.7856       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[358  83]\n",
      " [106 335]]\n",
      "precision_macro=0.7865 | recall_macro=0.7857 | specificity_macro=0.7857 | sensitivity_macro=0.7857\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/confusion_global_fold3_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/topomap_saliency_fold3_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/topomap_log10p_fold3_nb2_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold3/tsne_cls_fold3_nb2_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.7857, F1=0.7856\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.22it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.44it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1317 | train_acc=0.5140 | val_loss=0.1205 | val_acc=0.5889 | val_f1m=0.5842 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1263 | train_acc=0.5536 | val_loss=0.1202 | val_acc=0.5635 | val_f1m=0.5022 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1184 | train_acc=0.5921 | val_loss=0.1118 | val_acc=0.6810 | val_f1m=0.6807 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0968 | train_acc=0.7339 | val_loss=0.0994 | val_acc=0.7095 | val_f1m=0.7095 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0867 | train_acc=0.7689 | val_loss=0.0987 | val_acc=0.7286 | val_f1m=0.7242 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0861 | train_acc=0.7700 | val_loss=0.0881 | val_acc=0.7556 | val_f1m=0.7556 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0764 | train_acc=0.8099 | val_loss=0.0904 | val_acc=0.7810 | val_f1m=0.7808 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0781 | train_acc=0.8001 | val_loss=0.0843 | val_acc=0.7778 | val_f1m=0.7775 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0732 | train_acc=0.8151 | val_loss=0.0865 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0696 | train_acc=0.8225 | val_loss=0.0850 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0723 | train_acc=0.8207 | val_loss=0.0869 | val_acc=0.7619 | val_f1m=0.7613 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0683 | train_acc=0.8305 | val_loss=0.0903 | val_acc=0.7730 | val_f1m=0.7725 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0670 | train_acc=0.8365 | val_loss=0.0849 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0648 | train_acc=0.8431 | val_loss=0.0849 | val_acc=0.7667 | val_f1m=0.7664 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0676 | train_acc=0.8305 | val_loss=0.0822 | val_acc=0.7841 | val_f1m=0.7838 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0617 | train_acc=0.8557 | val_loss=0.0856 | val_acc=0.7778 | val_f1m=0.7776 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0640 | train_acc=0.8442 | val_loss=0.0847 | val_acc=0.7635 | val_f1m=0.7628 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0614 | train_acc=0.8561 | val_loss=0.0871 | val_acc=0.7778 | val_f1m=0.7772 | LR=0.000443\n",
      "  Early stopping en época 18 (mejor val_f1m=0.7841)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/model_global_fold4_nb2_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/training_curve_fold4_nb2_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/history_fold4_nb2_h4.npz\n",
      "[Fold 4/5] Global acc=0.8143 | f1_macro=0.8141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7946    0.8476    0.8203       420\n",
      "       right     0.8367    0.7810    0.8079       420\n",
      "\n",
      "    accuracy                         0.8143       840\n",
      "   macro avg     0.8157    0.8143    0.8141       840\n",
      "weighted avg     0.8157    0.8143    0.8141       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[356  64]\n",
      " [ 92 328]]\n",
      "precision_macro=0.8157 | recall_macro=0.8143 | specificity_macro=0.8143 | sensitivity_macro=0.8143\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/confusion_global_fold4_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/topomap_saliency_fold4_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/topomap_log10p_fold4_nb2_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold4/tsne_cls_fold4_nb2_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8143, F1=0.8141\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.37it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.50it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1318 | train_acc=0.5140 | val_loss=0.1230 | val_acc=0.5143 | val_f1m=0.4089 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1256 | train_acc=0.5431 | val_loss=0.1191 | val_acc=0.5794 | val_f1m=0.5215 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1221 | train_acc=0.5812 | val_loss=0.1127 | val_acc=0.6635 | val_f1m=0.6513 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0983 | train_acc=0.7346 | val_loss=0.1069 | val_acc=0.6873 | val_f1m=0.6872 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0921 | train_acc=0.7560 | val_loss=0.0951 | val_acc=0.7333 | val_f1m=0.7333 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0811 | train_acc=0.7913 | val_loss=0.0974 | val_acc=0.7222 | val_f1m=0.7212 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0818 | train_acc=0.7910 | val_loss=0.0950 | val_acc=0.7222 | val_f1m=0.7222 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0751 | train_acc=0.8165 | val_loss=0.0963 | val_acc=0.7095 | val_f1m=0.7068 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0708 | train_acc=0.8246 | val_loss=0.1022 | val_acc=0.7540 | val_f1m=0.7536 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0700 | train_acc=0.8274 | val_loss=0.1033 | val_acc=0.7556 | val_f1m=0.7523 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0677 | train_acc=0.8333 | val_loss=0.1016 | val_acc=0.7540 | val_f1m=0.7523 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0662 | train_acc=0.8351 | val_loss=0.0912 | val_acc=0.7651 | val_f1m=0.7647 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0715 | train_acc=0.8246 | val_loss=0.0936 | val_acc=0.7413 | val_f1m=0.7412 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0657 | train_acc=0.8375 | val_loss=0.0971 | val_acc=0.7587 | val_f1m=0.7586 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0649 | train_acc=0.8316 | val_loss=0.0947 | val_acc=0.7540 | val_f1m=0.7537 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0628 | train_acc=0.8389 | val_loss=0.0991 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0668 | train_acc=0.8263 | val_loss=0.1005 | val_acc=0.7556 | val_f1m=0.7553 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0649 | train_acc=0.8484 | val_loss=0.0965 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0622 | train_acc=0.8480 | val_loss=0.0981 | val_acc=0.7524 | val_f1m=0.7523 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0642 | train_acc=0.8414 | val_loss=0.0986 | val_acc=0.7540 | val_f1m=0.7540 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0608 | train_acc=0.8547 | val_loss=0.1011 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0600 | train_acc=0.8526 | val_loss=0.1037 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0587 | train_acc=0.8554 | val_loss=0.1034 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0609 | train_acc=0.8529 | val_loss=0.1032 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0532 | train_acc=0.8708 | val_loss=0.1032 | val_acc=0.7587 | val_f1m=0.7587 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0558 | train_acc=0.8673 | val_loss=0.1032 | val_acc=0.7587 | val_f1m=0.7587 | LR=0.000361\n",
      "  Early stopping en época 26 (mejor val_f1m=0.7809)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/model_global_fold5_nb2_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/training_curve_fold5_nb2_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/history_fold5_nb2_h4.npz\n",
      "[Fold 5/5] Global acc=0.8405 | f1_macro=0.8405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8389    0.8429    0.8409       420\n",
      "       right     0.8421    0.8381    0.8401       420\n",
      "\n",
      "    accuracy                         0.8405       840\n",
      "   macro avg     0.8405    0.8405    0.8405       840\n",
      "weighted avg     0.8405    0.8405    0.8405       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[354  66]\n",
      " [ 68 352]]\n",
      "precision_macro=0.8405 | recall_macro=0.8405 | specificity_macro=0.8405 | sensitivity_macro=0.8405\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/confusion_global_fold5_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/topomap_saliency_fold5_nb2_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/topomap_log10p_fold5_nb2_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h4/nb2_h4/fold5/tsne_cls_fold5_nb2_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.08 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8405, F1=0.8405\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb2_h4:\n",
      "  F1 por fold: ['0.7788', '0.8186', '0.7856', '0.8141', '0.8405']\n",
      "  F1 Media ± Std: 0.8075 ± 0.0226\n",
      "  ACC Media ± Std: 0.8076 ± 0.0226\n",
      "  Parámetros: 232,290\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 6/9: nb2_h6\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 2\n",
      "  • Attention Heads: 6\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.34it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 16.92it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1318 | train_acc=0.5213 | val_loss=0.1249 | val_acc=0.5000 | val_f1m=0.3443 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1224 | train_acc=0.5729 | val_loss=0.1187 | val_acc=0.6190 | val_f1m=0.6166 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1102 | train_acc=0.6546 | val_loss=0.1111 | val_acc=0.6508 | val_f1m=0.6402 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0962 | train_acc=0.7416 | val_loss=0.1044 | val_acc=0.7206 | val_f1m=0.7198 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0841 | train_acc=0.7839 | val_loss=0.0987 | val_acc=0.7444 | val_f1m=0.7439 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0764 | train_acc=0.8003 | val_loss=0.0960 | val_acc=0.7556 | val_f1m=0.7539 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0721 | train_acc=0.8124 | val_loss=0.0919 | val_acc=0.7635 | val_f1m=0.7627 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0662 | train_acc=0.8348 | val_loss=0.1250 | val_acc=0.7190 | val_f1m=0.7119 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0641 | train_acc=0.8394 | val_loss=0.0944 | val_acc=0.7571 | val_f1m=0.7569 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0651 | train_acc=0.8340 | val_loss=0.0993 | val_acc=0.7683 | val_f1m=0.7678 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0614 | train_acc=0.8539 | val_loss=0.1028 | val_acc=0.7556 | val_f1m=0.7548 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0620 | train_acc=0.8490 | val_loss=0.0927 | val_acc=0.7683 | val_f1m=0.7673 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0606 | train_acc=0.8547 | val_loss=0.0891 | val_acc=0.7683 | val_f1m=0.7678 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0606 | train_acc=0.8497 | val_loss=0.0948 | val_acc=0.7540 | val_f1m=0.7510 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0583 | train_acc=0.8632 | val_loss=0.1093 | val_acc=0.7603 | val_f1m=0.7594 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0578 | train_acc=0.8561 | val_loss=0.1027 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0605 | train_acc=0.8515 | val_loss=0.1016 | val_acc=0.7746 | val_f1m=0.7745 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0591 | train_acc=0.8582 | val_loss=0.1005 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0565 | train_acc=0.8653 | val_loss=0.1005 | val_acc=0.7810 | val_f1m=0.7800 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0520 | train_acc=0.8699 | val_loss=0.1050 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0525 | train_acc=0.8738 | val_loss=0.1018 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0495 | train_acc=0.8778 | val_loss=0.1040 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0495 | train_acc=0.8767 | val_loss=0.1033 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0512 | train_acc=0.8714 | val_loss=0.1032 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0541 | train_acc=0.8582 | val_loss=0.1031 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0425 | train_acc=0.8969 | val_loss=0.1032 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0486 | train_acc=0.8824 | val_loss=0.1032 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0496 | train_acc=0.8738 | val_loss=0.1032 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0454 | train_acc=0.8877 | val_loss=0.1033 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000325\n",
      "  Época  30 | train_loss=0.0481 | train_acc=0.8799 | val_loss=0.1034 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000313\n",
      "  Época  31 | train_loss=0.0439 | train_acc=0.9019 | val_loss=0.1036 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000300\n",
      "  Época  32 | train_loss=0.0454 | train_acc=0.8927 | val_loss=0.1037 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000288\n",
      "  Época  33 | train_loss=0.0381 | train_acc=0.9129 | val_loss=0.1040 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000275\n",
      "  Época  34 | train_loss=0.0427 | train_acc=0.8994 | val_loss=0.1042 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000262\n",
      "  Época  35 | train_loss=0.0376 | train_acc=0.9115 | val_loss=0.1046 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000250\n",
      "  Época  36 | train_loss=0.0409 | train_acc=0.9055 | val_loss=0.1049 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000237\n",
      "  Época  37 | train_loss=0.0394 | train_acc=0.9087 | val_loss=0.1053 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000225\n",
      "  Época  38 | train_loss=0.0394 | train_acc=0.9101 | val_loss=0.1057 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000213\n",
      "  Época  39 | train_loss=0.0387 | train_acc=0.9033 | val_loss=0.1061 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000201\n",
      "  Época  40 | train_loss=0.0380 | train_acc=0.9115 | val_loss=0.1066 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000189\n",
      "  Época  41 | train_loss=0.0352 | train_acc=0.9186 | val_loss=0.1071 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000177\n",
      "  Early stopping en época 41 (mejor val_f1m=0.7968)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/model_global_fold1_nb2_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/training_curve_fold1_nb2_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/history_fold1_nb2_h6.npz\n",
      "[Fold 1/5] Global acc=0.8107 | f1_macro=0.8107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8114    0.8095    0.8104       441\n",
      "       right     0.8100    0.8118    0.8109       441\n",
      "\n",
      "    accuracy                         0.8107       882\n",
      "   macro avg     0.8107    0.8107    0.8107       882\n",
      "weighted avg     0.8107    0.8107    0.8107       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[357  84]\n",
      " [ 83 358]]\n",
      "precision_macro=0.8107 | recall_macro=0.8107 | specificity_macro=0.8107 | sensitivity_macro=0.8107\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/confusion_global_fold1_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/topomap_saliency_fold1_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/topomap_log10p_fold1_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold1/tsne_cls_fold1_nb2_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.11 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.8107, F1=0.8107\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.51it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.58it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1290 | train_acc=0.5267 | val_loss=0.1202 | val_acc=0.6032 | val_f1m=0.6029 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1214 | train_acc=0.5839 | val_loss=0.1159 | val_acc=0.6222 | val_f1m=0.6183 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1168 | train_acc=0.6276 | val_loss=0.1052 | val_acc=0.7095 | val_f1m=0.7095 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0987 | train_acc=0.7278 | val_loss=0.0958 | val_acc=0.7206 | val_f1m=0.7202 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0910 | train_acc=0.7594 | val_loss=0.0973 | val_acc=0.7175 | val_f1m=0.7028 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0808 | train_acc=0.7921 | val_loss=0.0942 | val_acc=0.7492 | val_f1m=0.7492 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0776 | train_acc=0.8042 | val_loss=0.0910 | val_acc=0.7476 | val_f1m=0.7417 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0771 | train_acc=0.8056 | val_loss=0.0823 | val_acc=0.7873 | val_f1m=0.7870 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0677 | train_acc=0.8316 | val_loss=0.0846 | val_acc=0.7857 | val_f1m=0.7854 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0691 | train_acc=0.8301 | val_loss=0.0821 | val_acc=0.8000 | val_f1m=0.8000 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0672 | train_acc=0.8333 | val_loss=0.0826 | val_acc=0.7952 | val_f1m=0.7951 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0662 | train_acc=0.8358 | val_loss=0.0840 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0671 | train_acc=0.8394 | val_loss=0.0854 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0637 | train_acc=0.8454 | val_loss=0.0850 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0649 | train_acc=0.8380 | val_loss=0.0878 | val_acc=0.7825 | val_f1m=0.7818 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0614 | train_acc=0.8500 | val_loss=0.0856 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0597 | train_acc=0.8568 | val_loss=0.0897 | val_acc=0.7825 | val_f1m=0.7821 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0624 | train_acc=0.8497 | val_loss=0.0885 | val_acc=0.7952 | val_f1m=0.7950 | LR=0.000443\n",
      "  Early stopping en época 18 (mejor val_f1m=0.8000)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/model_global_fold2_nb2_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/training_curve_fold2_nb2_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/history_fold2_nb2_h6.npz\n",
      "[Fold 2/5] Global acc=0.8356 | f1_macro=0.8353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8083    0.8798    0.8426       441\n",
      "       right     0.8682    0.7914    0.8280       441\n",
      "\n",
      "    accuracy                         0.8356       882\n",
      "   macro avg     0.8382    0.8356    0.8353       882\n",
      "weighted avg     0.8382    0.8356    0.8353       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[388  53]\n",
      " [ 92 349]]\n",
      "precision_macro=0.8382 | recall_macro=0.8356 | specificity_macro=0.8356 | sensitivity_macro=0.8356\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/confusion_global_fold2_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/topomap_saliency_fold2_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/topomap_log10p_fold2_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold2/tsne_cls_fold2_nb2_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8356, F1=0.8353\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 17.38it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.57it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1315 | train_acc=0.5174 | val_loss=0.1267 | val_acc=0.5079 | val_f1m=0.3685 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1251 | train_acc=0.5402 | val_loss=0.1324 | val_acc=0.5190 | val_f1m=0.3840 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1242 | train_acc=0.5547 | val_loss=0.1109 | val_acc=0.6810 | val_f1m=0.6809 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1067 | train_acc=0.6844 | val_loss=0.0947 | val_acc=0.7222 | val_f1m=0.7221 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0889 | train_acc=0.7633 | val_loss=0.0884 | val_acc=0.7651 | val_f1m=0.7621 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0765 | train_acc=0.7974 | val_loss=0.0827 | val_acc=0.8016 | val_f1m=0.8015 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0721 | train_acc=0.8259 | val_loss=0.0834 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0738 | train_acc=0.8223 | val_loss=0.0810 | val_acc=0.8063 | val_f1m=0.8063 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0656 | train_acc=0.8447 | val_loss=0.0795 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0677 | train_acc=0.8269 | val_loss=0.0765 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0634 | train_acc=0.8340 | val_loss=0.0907 | val_acc=0.7921 | val_f1m=0.7917 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0644 | train_acc=0.8387 | val_loss=0.0783 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0603 | train_acc=0.8557 | val_loss=0.0842 | val_acc=0.7794 | val_f1m=0.7777 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0598 | train_acc=0.8586 | val_loss=0.0823 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0597 | train_acc=0.8621 | val_loss=0.0857 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0584 | train_acc=0.8539 | val_loss=0.0815 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0598 | train_acc=0.8547 | val_loss=0.0823 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0627 | train_acc=0.8454 | val_loss=0.0810 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0563 | train_acc=0.8696 | val_loss=0.0901 | val_acc=0.8048 | val_f1m=0.8045 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0605 | train_acc=0.8525 | val_loss=0.0829 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0539 | train_acc=0.8735 | val_loss=0.0882 | val_acc=0.8111 | val_f1m=0.8110 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0514 | train_acc=0.8788 | val_loss=0.0900 | val_acc=0.7794 | val_f1m=0.7791 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0486 | train_acc=0.8852 | val_loss=0.0920 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0528 | train_acc=0.8738 | val_loss=0.0920 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0511 | train_acc=0.8738 | val_loss=0.0921 | val_acc=0.7889 | val_f1m=0.7885 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0510 | train_acc=0.8763 | val_loss=0.0922 | val_acc=0.7889 | val_f1m=0.7885 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0521 | train_acc=0.8795 | val_loss=0.0922 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0485 | train_acc=0.8852 | val_loss=0.0923 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0492 | train_acc=0.8852 | val_loss=0.0924 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.8110)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/model_global_fold3_nb2_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/training_curve_fold3_nb2_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/history_fold3_nb2_h6.npz\n",
      "[Fold 3/5] Global acc=0.8084 | f1_macro=0.8084\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8134    0.8005    0.8069       441\n",
      "       right     0.8036    0.8163    0.8099       441\n",
      "\n",
      "    accuracy                         0.8084       882\n",
      "   macro avg     0.8085    0.8084    0.8084       882\n",
      "weighted avg     0.8085    0.8084    0.8084       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[353  88]\n",
      " [ 81 360]]\n",
      "precision_macro=0.8085 | recall_macro=0.8084 | specificity_macro=0.8084 | sensitivity_macro=0.8084\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/confusion_global_fold3_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/topomap_saliency_fold3_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/topomap_log10p_fold3_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold3/tsne_cls_fold3_nb2_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.10 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.8084, F1=0.8084\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:04<00:00, 16.91it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.49it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1308 | train_acc=0.4972 | val_loss=0.1204 | val_acc=0.5651 | val_f1m=0.5476 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1254 | train_acc=0.5501 | val_loss=0.1177 | val_acc=0.6079 | val_f1m=0.6056 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1174 | train_acc=0.6008 | val_loss=0.1263 | val_acc=0.6508 | val_f1m=0.6418 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1039 | train_acc=0.6992 | val_loss=0.1061 | val_acc=0.6889 | val_f1m=0.6888 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0898 | train_acc=0.7626 | val_loss=0.1008 | val_acc=0.7349 | val_f1m=0.7327 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0802 | train_acc=0.7805 | val_loss=0.0876 | val_acc=0.7635 | val_f1m=0.7622 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0810 | train_acc=0.7920 | val_loss=0.0990 | val_acc=0.7286 | val_f1m=0.7182 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0737 | train_acc=0.8099 | val_loss=0.0873 | val_acc=0.7762 | val_f1m=0.7749 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0725 | train_acc=0.8253 | val_loss=0.0881 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0707 | train_acc=0.8165 | val_loss=0.1018 | val_acc=0.7492 | val_f1m=0.7479 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0702 | train_acc=0.8228 | val_loss=0.0897 | val_acc=0.7667 | val_f1m=0.7647 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0689 | train_acc=0.8347 | val_loss=0.0898 | val_acc=0.7492 | val_f1m=0.7482 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0657 | train_acc=0.8326 | val_loss=0.0864 | val_acc=0.7746 | val_f1m=0.7742 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0636 | train_acc=0.8424 | val_loss=0.0880 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0684 | train_acc=0.8347 | val_loss=0.0887 | val_acc=0.7667 | val_f1m=0.7650 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0602 | train_acc=0.8526 | val_loss=0.0867 | val_acc=0.7730 | val_f1m=0.7725 | LR=0.000459\n",
      "  Early stopping en época 16 (mejor val_f1m=0.7749)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/model_global_fold4_nb2_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/training_curve_fold4_nb2_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/history_fold4_nb2_h6.npz\n",
      "[Fold 4/5] Global acc=0.8119 | f1_macro=0.8098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7579    0.9167    0.8297       420\n",
      "       right     0.8946    0.7071    0.7899       420\n",
      "\n",
      "    accuracy                         0.8119       840\n",
      "   macro avg     0.8262    0.8119    0.8098       840\n",
      "weighted avg     0.8262    0.8119    0.8098       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[385  35]\n",
      " [123 297]]\n",
      "precision_macro=0.8262 | recall_macro=0.8119 | specificity_macro=0.8119 | sensitivity_macro=0.8119\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/confusion_global_fold4_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/topomap_saliency_fold4_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/topomap_log10p_fold4_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold4/tsne_cls_fold4_nb2_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8119, F1=0.8098\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.55it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.62it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1320 | train_acc=0.5035 | val_loss=0.1220 | val_acc=0.5095 | val_f1m=0.4079 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1241 | train_acc=0.5445 | val_loss=0.1177 | val_acc=0.5889 | val_f1m=0.5691 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1225 | train_acc=0.5795 | val_loss=0.1122 | val_acc=0.6619 | val_f1m=0.6540 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0968 | train_acc=0.7416 | val_loss=0.1055 | val_acc=0.7000 | val_f1m=0.6988 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0907 | train_acc=0.7560 | val_loss=0.1002 | val_acc=0.7127 | val_f1m=0.7107 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0747 | train_acc=0.8123 | val_loss=0.0961 | val_acc=0.7190 | val_f1m=0.7162 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0737 | train_acc=0.8200 | val_loss=0.1029 | val_acc=0.7286 | val_f1m=0.7273 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0708 | train_acc=0.8232 | val_loss=0.1032 | val_acc=0.7333 | val_f1m=0.7278 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0685 | train_acc=0.8239 | val_loss=0.0916 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0660 | train_acc=0.8351 | val_loss=0.0938 | val_acc=0.7333 | val_f1m=0.7315 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0686 | train_acc=0.8291 | val_loss=0.0903 | val_acc=0.7556 | val_f1m=0.7554 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0652 | train_acc=0.8319 | val_loss=0.0981 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0622 | train_acc=0.8435 | val_loss=0.0971 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0620 | train_acc=0.8456 | val_loss=0.0978 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0609 | train_acc=0.8410 | val_loss=0.0988 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0615 | train_acc=0.8494 | val_loss=0.0961 | val_acc=0.7460 | val_f1m=0.7460 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0585 | train_acc=0.8557 | val_loss=0.1158 | val_acc=0.7683 | val_f1m=0.7673 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0600 | train_acc=0.8512 | val_loss=0.1142 | val_acc=0.7476 | val_f1m=0.7463 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0597 | train_acc=0.8519 | val_loss=0.0966 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0584 | train_acc=0.8578 | val_loss=0.0998 | val_acc=0.7667 | val_f1m=0.7655 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0582 | train_acc=0.8508 | val_loss=0.1060 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0553 | train_acc=0.8666 | val_loss=0.1058 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0536 | train_acc=0.8704 | val_loss=0.1055 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0549 | train_acc=0.8662 | val_loss=0.1055 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0537 | train_acc=0.8676 | val_loss=0.1054 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0528 | train_acc=0.8761 | val_loss=0.1054 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0529 | train_acc=0.8739 | val_loss=0.1054 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000349\n",
      "  Early stopping en época 27 (mejor val_f1m=0.7777)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/model_global_fold5_nb2_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/training_curve_fold5_nb2_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/history_fold5_nb2_h6.npz\n",
      "[Fold 5/5] Global acc=0.8464 | f1_macro=0.8464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8540    0.8357    0.8448       420\n",
      "       right     0.8392    0.8571    0.8481       420\n",
      "\n",
      "    accuracy                         0.8464       840\n",
      "   macro avg     0.8466    0.8464    0.8464       840\n",
      "weighted avg     0.8466    0.8464    0.8464       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[351  69]\n",
      " [ 60 360]]\n",
      "precision_macro=0.8466 | recall_macro=0.8464 | specificity_macro=0.8464 | sensitivity_macro=0.8464\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/confusion_global_fold5_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/topomap_saliency_fold5_nb2_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/topomap_log10p_fold5_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb2_h6/nb2_h6/fold5/tsne_cls_fold5_nb2_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.09 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8464, F1=0.8464\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb2_h6:\n",
      "  F1 por fold: ['0.8107', '0.8353', '0.8084', '0.8098', '0.8464']\n",
      "  F1 Media ± Std: 0.8221 ± 0.0157\n",
      "  ACC Media ± Std: 0.8226 ± 0.0155\n",
      "  Parámetros: 232,290\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 7/9: nb4_h2\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 4\n",
      "  • Attention Heads: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.54it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.38it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1301 | train_acc=0.5238 | val_loss=0.1230 | val_acc=0.5365 | val_f1m=0.4667 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1240 | train_acc=0.5533 | val_loss=0.1191 | val_acc=0.5635 | val_f1m=0.5183 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1123 | train_acc=0.6525 | val_loss=0.1264 | val_acc=0.6540 | val_f1m=0.6376 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0929 | train_acc=0.7555 | val_loss=0.1088 | val_acc=0.6889 | val_f1m=0.6864 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0843 | train_acc=0.7907 | val_loss=0.1054 | val_acc=0.7111 | val_f1m=0.7110 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0825 | train_acc=0.7857 | val_loss=0.1028 | val_acc=0.7111 | val_f1m=0.7096 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0787 | train_acc=0.7985 | val_loss=0.1051 | val_acc=0.7111 | val_f1m=0.7077 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0803 | train_acc=0.7921 | val_loss=0.1051 | val_acc=0.7190 | val_f1m=0.7184 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0745 | train_acc=0.8106 | val_loss=0.1016 | val_acc=0.7222 | val_f1m=0.7220 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0752 | train_acc=0.8024 | val_loss=0.1154 | val_acc=0.7349 | val_f1m=0.7349 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0719 | train_acc=0.8166 | val_loss=0.1011 | val_acc=0.7444 | val_f1m=0.7440 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0718 | train_acc=0.8120 | val_loss=0.1034 | val_acc=0.7365 | val_f1m=0.7363 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0695 | train_acc=0.8205 | val_loss=0.1027 | val_acc=0.7397 | val_f1m=0.7397 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0684 | train_acc=0.8301 | val_loss=0.0991 | val_acc=0.7381 | val_f1m=0.7372 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0703 | train_acc=0.8255 | val_loss=0.1275 | val_acc=0.6984 | val_f1m=0.6909 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0673 | train_acc=0.8358 | val_loss=0.1041 | val_acc=0.7444 | val_f1m=0.7444 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0657 | train_acc=0.8404 | val_loss=0.1073 | val_acc=0.7603 | val_f1m=0.7601 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0660 | train_acc=0.8397 | val_loss=0.1104 | val_acc=0.7476 | val_f1m=0.7460 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0629 | train_acc=0.8475 | val_loss=0.1093 | val_acc=0.7571 | val_f1m=0.7570 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0593 | train_acc=0.8543 | val_loss=0.1155 | val_acc=0.7444 | val_f1m=0.7444 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0604 | train_acc=0.8564 | val_loss=0.1042 | val_acc=0.7571 | val_f1m=0.7570 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0575 | train_acc=0.8607 | val_loss=0.1088 | val_acc=0.7429 | val_f1m=0.7429 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0615 | train_acc=0.8468 | val_loss=0.1104 | val_acc=0.7413 | val_f1m=0.7412 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0560 | train_acc=0.8618 | val_loss=0.1103 | val_acc=0.7413 | val_f1m=0.7412 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0562 | train_acc=0.8618 | val_loss=0.1104 | val_acc=0.7444 | val_f1m=0.7444 | LR=0.000373\n",
      "  Early stopping en época 25 (mejor val_f1m=0.7601)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/model_global_fold1_nb4_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/training_curve_fold1_nb4_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/history_fold1_nb4_h2.npz\n",
      "[Fold 1/5] Global acc=0.7732 | f1_macro=0.7730\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7580    0.8027    0.7797       441\n",
      "       right     0.7904    0.7438    0.7664       441\n",
      "\n",
      "    accuracy                         0.7732       882\n",
      "   macro avg     0.7742    0.7732    0.7730       882\n",
      "weighted avg     0.7742    0.7732    0.7730       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[354  87]\n",
      " [113 328]]\n",
      "precision_macro=0.7742 | recall_macro=0.7732 | specificity_macro=0.7732 | sensitivity_macro=0.7732\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/confusion_global_fold1_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/topomap_saliency_fold1_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/topomap_log10p_fold1_nb4_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold1/tsne_cls_fold1_nb4_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7732, F1=0.7730\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.13it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.30it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1309 | train_acc=0.5131 | val_loss=0.1226 | val_acc=0.5698 | val_f1m=0.5017 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1230 | train_acc=0.5551 | val_loss=0.1170 | val_acc=0.6063 | val_f1m=0.6057 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1117 | train_acc=0.6429 | val_loss=0.1003 | val_acc=0.7032 | val_f1m=0.7031 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0965 | train_acc=0.7370 | val_loss=0.1146 | val_acc=0.7127 | val_f1m=0.7111 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0941 | train_acc=0.7463 | val_loss=0.1054 | val_acc=0.7460 | val_f1m=0.7455 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0851 | train_acc=0.7811 | val_loss=0.1066 | val_acc=0.7095 | val_f1m=0.6999 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0868 | train_acc=0.7768 | val_loss=0.0928 | val_acc=0.7476 | val_f1m=0.7476 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0802 | train_acc=0.7910 | val_loss=0.0907 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0833 | train_acc=0.7786 | val_loss=0.0999 | val_acc=0.7492 | val_f1m=0.7489 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0818 | train_acc=0.7857 | val_loss=0.0885 | val_acc=0.7540 | val_f1m=0.7536 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0767 | train_acc=0.8085 | val_loss=0.0945 | val_acc=0.7556 | val_f1m=0.7552 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0802 | train_acc=0.7918 | val_loss=0.0888 | val_acc=0.7635 | val_f1m=0.7630 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0713 | train_acc=0.8152 | val_loss=0.0911 | val_acc=0.7492 | val_f1m=0.7492 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0794 | train_acc=0.7992 | val_loss=0.0901 | val_acc=0.7476 | val_f1m=0.7465 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0734 | train_acc=0.8138 | val_loss=0.0922 | val_acc=0.7524 | val_f1m=0.7512 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0701 | train_acc=0.8156 | val_loss=0.0951 | val_acc=0.7603 | val_f1m=0.7602 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0673 | train_acc=0.8262 | val_loss=0.0909 | val_acc=0.7571 | val_f1m=0.7570 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0719 | train_acc=0.8198 | val_loss=0.0911 | val_acc=0.7524 | val_f1m=0.7520 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0668 | train_acc=0.8433 | val_loss=0.0957 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0673 | train_acc=0.8390 | val_loss=0.0957 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0675 | train_acc=0.8298 | val_loss=0.0895 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0583 | train_acc=0.8589 | val_loss=0.0889 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0659 | train_acc=0.8337 | val_loss=0.0899 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0643 | train_acc=0.8429 | val_loss=0.0899 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0611 | train_acc=0.8497 | val_loss=0.0899 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0609 | train_acc=0.8532 | val_loss=0.0899 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0617 | train_acc=0.8500 | val_loss=0.0899 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0608 | train_acc=0.8543 | val_loss=0.0899 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0643 | train_acc=0.8511 | val_loss=0.0899 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000325\n",
      "  Época  30 | train_loss=0.0612 | train_acc=0.8539 | val_loss=0.0900 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000313\n",
      "  Época  31 | train_loss=0.0531 | train_acc=0.8721 | val_loss=0.0902 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000300\n",
      "  Época  32 | train_loss=0.0608 | train_acc=0.8443 | val_loss=0.0903 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000288\n",
      "  Época  33 | train_loss=0.0567 | train_acc=0.8614 | val_loss=0.0904 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000275\n",
      "  Época  34 | train_loss=0.0594 | train_acc=0.8611 | val_loss=0.0905 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000262\n",
      "  Época  35 | train_loss=0.0519 | train_acc=0.8735 | val_loss=0.0907 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000250\n",
      "  Época  36 | train_loss=0.0554 | train_acc=0.8664 | val_loss=0.0909 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000237\n",
      "  Early stopping en época 36 (mejor val_f1m=0.7730)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/model_global_fold2_nb4_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/training_curve_fold2_nb4_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/history_fold2_nb4_h2.npz\n",
      "[Fold 2/5] Global acc=0.8186 | f1_macro=0.8186\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8200    0.8163    0.8182       441\n",
      "       right     0.8172    0.8209    0.8190       441\n",
      "\n",
      "    accuracy                         0.8186       882\n",
      "   macro avg     0.8186    0.8186    0.8186       882\n",
      "weighted avg     0.8186    0.8186    0.8186       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[360  81]\n",
      " [ 79 362]]\n",
      "precision_macro=0.8186 | recall_macro=0.8186 | specificity_macro=0.8186 | sensitivity_macro=0.8186\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/confusion_global_fold2_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/topomap_saliency_fold2_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/topomap_log10p_fold2_nb4_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold2/tsne_cls_fold2_nb4_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8186, F1=0.8186\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 16.98it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 16.88it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1318 | train_acc=0.5117 | val_loss=0.1207 | val_acc=0.5413 | val_f1m=0.4742 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1241 | train_acc=0.5547 | val_loss=0.1170 | val_acc=0.6175 | val_f1m=0.6169 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1249 | train_acc=0.5458 | val_loss=0.1141 | val_acc=0.6429 | val_f1m=0.6305 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1021 | train_acc=0.7225 | val_loss=0.0923 | val_acc=0.7460 | val_f1m=0.7452 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0902 | train_acc=0.7576 | val_loss=0.0867 | val_acc=0.7730 | val_f1m=0.7713 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0811 | train_acc=0.7878 | val_loss=0.0897 | val_acc=0.7540 | val_f1m=0.7480 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0789 | train_acc=0.7978 | val_loss=0.0807 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0752 | train_acc=0.8006 | val_loss=0.0774 | val_acc=0.7984 | val_f1m=0.7978 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0708 | train_acc=0.8181 | val_loss=0.0851 | val_acc=0.7714 | val_f1m=0.7692 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0697 | train_acc=0.8198 | val_loss=0.0818 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0712 | train_acc=0.8184 | val_loss=0.0826 | val_acc=0.7921 | val_f1m=0.7912 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0682 | train_acc=0.8241 | val_loss=0.0805 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0695 | train_acc=0.8220 | val_loss=0.0831 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0662 | train_acc=0.8298 | val_loss=0.0828 | val_acc=0.7841 | val_f1m=0.7833 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0635 | train_acc=0.8486 | val_loss=0.0901 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0690 | train_acc=0.8287 | val_loss=0.0790 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0624 | train_acc=0.8443 | val_loss=0.0873 | val_acc=0.7825 | val_f1m=0.7820 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0621 | train_acc=0.8461 | val_loss=0.0847 | val_acc=0.8063 | val_f1m=0.8056 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0594 | train_acc=0.8554 | val_loss=0.0899 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0648 | train_acc=0.8419 | val_loss=0.0858 | val_acc=0.8111 | val_f1m=0.8109 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0645 | train_acc=0.8461 | val_loss=0.0816 | val_acc=0.8063 | val_f1m=0.8062 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0554 | train_acc=0.8721 | val_loss=0.0839 | val_acc=0.8079 | val_f1m=0.8077 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0564 | train_acc=0.8692 | val_loss=0.0843 | val_acc=0.8079 | val_f1m=0.8076 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0599 | train_acc=0.8536 | val_loss=0.0843 | val_acc=0.8079 | val_f1m=0.8075 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0513 | train_acc=0.8756 | val_loss=0.0843 | val_acc=0.8095 | val_f1m=0.8092 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0545 | train_acc=0.8650 | val_loss=0.0844 | val_acc=0.8095 | val_f1m=0.8092 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0547 | train_acc=0.8699 | val_loss=0.0844 | val_acc=0.8095 | val_f1m=0.8092 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0579 | train_acc=0.8632 | val_loss=0.0845 | val_acc=0.8095 | val_f1m=0.8092 | LR=0.000337\n",
      "  Early stopping en época 28 (mejor val_f1m=0.8109)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/model_global_fold3_nb4_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/training_curve_fold3_nb4_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/history_fold3_nb4_h2.npz\n",
      "[Fold 3/5] Global acc=0.8005 | f1_macro=0.8004\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7978    0.8050    0.8014       441\n",
      "       right     0.8032    0.7959    0.7995       441\n",
      "\n",
      "    accuracy                         0.8005       882\n",
      "   macro avg     0.8005    0.8005    0.8004       882\n",
      "weighted avg     0.8005    0.8005    0.8004       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[355  86]\n",
      " [ 90 351]]\n",
      "precision_macro=0.8005 | recall_macro=0.8005 | specificity_macro=0.8005 | sensitivity_macro=0.8005\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/confusion_global_fold3_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/topomap_saliency_fold3_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/topomap_log10p_fold3_nb4_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold3/tsne_cls_fold3_nb4_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.8005, F1=0.8004\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.06it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.54it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1309 | train_acc=0.4961 | val_loss=0.1235 | val_acc=0.5222 | val_f1m=0.4304 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1247 | train_acc=0.5469 | val_loss=0.1202 | val_acc=0.6000 | val_f1m=0.5934 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1156 | train_acc=0.6254 | val_loss=0.1119 | val_acc=0.6794 | val_f1m=0.6760 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1005 | train_acc=0.7185 | val_loss=0.0992 | val_acc=0.7222 | val_f1m=0.7220 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0970 | train_acc=0.7251 | val_loss=0.1041 | val_acc=0.6952 | val_f1m=0.6950 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0979 | train_acc=0.7290 | val_loss=0.1153 | val_acc=0.6905 | val_f1m=0.6836 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0949 | train_acc=0.7482 | val_loss=0.1034 | val_acc=0.7159 | val_f1m=0.7157 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0845 | train_acc=0.7780 | val_loss=0.1098 | val_acc=0.7159 | val_f1m=0.7143 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0862 | train_acc=0.7766 | val_loss=0.1048 | val_acc=0.7270 | val_f1m=0.7268 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0870 | train_acc=0.7700 | val_loss=0.0939 | val_acc=0.7429 | val_f1m=0.7425 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0785 | train_acc=0.7948 | val_loss=0.1089 | val_acc=0.7111 | val_f1m=0.7071 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0809 | train_acc=0.7882 | val_loss=0.1049 | val_acc=0.7016 | val_f1m=0.6962 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0769 | train_acc=0.7990 | val_loss=0.0975 | val_acc=0.7492 | val_f1m=0.7490 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0748 | train_acc=0.8141 | val_loss=0.0960 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0746 | train_acc=0.8095 | val_loss=0.0940 | val_acc=0.7397 | val_f1m=0.7394 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0751 | train_acc=0.8092 | val_loss=0.1078 | val_acc=0.7381 | val_f1m=0.7375 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0753 | train_acc=0.8092 | val_loss=0.0970 | val_acc=0.7429 | val_f1m=0.7403 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0770 | train_acc=0.8057 | val_loss=0.0999 | val_acc=0.7397 | val_f1m=0.7387 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0733 | train_acc=0.8127 | val_loss=0.0924 | val_acc=0.7476 | val_f1m=0.7475 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0713 | train_acc=0.8193 | val_loss=0.0944 | val_acc=0.7524 | val_f1m=0.7523 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0680 | train_acc=0.8305 | val_loss=0.0973 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0668 | train_acc=0.8372 | val_loss=0.0962 | val_acc=0.7540 | val_f1m=0.7533 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0672 | train_acc=0.8319 | val_loss=0.0963 | val_acc=0.7524 | val_f1m=0.7517 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0662 | train_acc=0.8449 | val_loss=0.0962 | val_acc=0.7524 | val_f1m=0.7517 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0658 | train_acc=0.8382 | val_loss=0.0962 | val_acc=0.7524 | val_f1m=0.7517 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0651 | train_acc=0.8526 | val_loss=0.0962 | val_acc=0.7524 | val_f1m=0.7517 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0620 | train_acc=0.8491 | val_loss=0.0962 | val_acc=0.7556 | val_f1m=0.7549 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0640 | train_acc=0.8421 | val_loss=0.0963 | val_acc=0.7556 | val_f1m=0.7549 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0635 | train_acc=0.8396 | val_loss=0.0963 | val_acc=0.7556 | val_f1m=0.7549 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.7633)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/model_global_fold4_nb4_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/training_curve_fold4_nb4_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/history_fold4_nb4_h2.npz\n",
      "[Fold 4/5] Global acc=0.8274 | f1_macro=0.8274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8362    0.8143    0.8251       420\n",
      "       right     0.8190    0.8405    0.8296       420\n",
      "\n",
      "    accuracy                         0.8274       840\n",
      "   macro avg     0.8276    0.8274    0.8274       840\n",
      "weighted avg     0.8276    0.8274    0.8274       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[342  78]\n",
      " [ 67 353]]\n",
      "precision_macro=0.8276 | recall_macro=0.8274 | specificity_macro=0.8274 | sensitivity_macro=0.8274\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/confusion_global_fold4_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/topomap_saliency_fold4_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/topomap_log10p_fold4_nb4_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold4/tsne_cls_fold4_nb4_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8274, F1=0.8274\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:04<00:00, 16.79it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.00it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1320 | train_acc=0.5126 | val_loss=0.1220 | val_acc=0.5413 | val_f1m=0.4821 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1255 | train_acc=0.5315 | val_loss=0.1184 | val_acc=0.5984 | val_f1m=0.5739 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1186 | train_acc=0.6096 | val_loss=0.1076 | val_acc=0.6857 | val_f1m=0.6773 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1003 | train_acc=0.7167 | val_loss=0.1069 | val_acc=0.6952 | val_f1m=0.6900 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0875 | train_acc=0.7689 | val_loss=0.0949 | val_acc=0.7238 | val_f1m=0.7235 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0793 | train_acc=0.7959 | val_loss=0.1087 | val_acc=0.7270 | val_f1m=0.7218 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0787 | train_acc=0.8088 | val_loss=0.1016 | val_acc=0.7508 | val_f1m=0.7487 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0778 | train_acc=0.7973 | val_loss=0.0967 | val_acc=0.7381 | val_f1m=0.7381 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0688 | train_acc=0.8263 | val_loss=0.1093 | val_acc=0.7397 | val_f1m=0.7384 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0743 | train_acc=0.8092 | val_loss=0.1030 | val_acc=0.7444 | val_f1m=0.7444 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0705 | train_acc=0.8284 | val_loss=0.1022 | val_acc=0.7476 | val_f1m=0.7452 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0707 | train_acc=0.8274 | val_loss=0.1030 | val_acc=0.7587 | val_f1m=0.7586 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0697 | train_acc=0.8235 | val_loss=0.0953 | val_acc=0.7508 | val_f1m=0.7497 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0676 | train_acc=0.8351 | val_loss=0.0950 | val_acc=0.7587 | val_f1m=0.7585 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0694 | train_acc=0.8260 | val_loss=0.0980 | val_acc=0.7492 | val_f1m=0.7490 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0672 | train_acc=0.8288 | val_loss=0.0960 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0661 | train_acc=0.8277 | val_loss=0.1037 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0661 | train_acc=0.8305 | val_loss=0.0972 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0623 | train_acc=0.8435 | val_loss=0.0983 | val_acc=0.7460 | val_f1m=0.7460 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0631 | train_acc=0.8494 | val_loss=0.0964 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0605 | train_acc=0.8456 | val_loss=0.0997 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0616 | train_acc=0.8386 | val_loss=0.0963 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0601 | train_acc=0.8505 | val_loss=0.0962 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0607 | train_acc=0.8557 | val_loss=0.0961 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0571 | train_acc=0.8596 | val_loss=0.0961 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0532 | train_acc=0.8764 | val_loss=0.0961 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0570 | train_acc=0.8645 | val_loss=0.0961 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0586 | train_acc=0.8585 | val_loss=0.0961 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0531 | train_acc=0.8757 | val_loss=0.0961 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000325\n",
      "  Época  30 | train_loss=0.0533 | train_acc=0.8711 | val_loss=0.0962 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000313\n",
      "  Época  31 | train_loss=0.0544 | train_acc=0.8690 | val_loss=0.0963 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000300\n",
      "  Época  32 | train_loss=0.0537 | train_acc=0.8662 | val_loss=0.0964 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000288\n",
      "  Early stopping en época 32 (mejor val_f1m=0.7841)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/model_global_fold5_nb4_h2.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/training_curve_fold5_nb4_h2.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/history_fold5_nb4_h2.npz\n",
      "[Fold 5/5] Global acc=0.8214 | f1_macro=0.8214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8325    0.8048    0.8184       420\n",
      "       right     0.8111    0.8381    0.8244       420\n",
      "\n",
      "    accuracy                         0.8214       840\n",
      "   macro avg     0.8218    0.8214    0.8214       840\n",
      "weighted avg     0.8218    0.8214    0.8214       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[338  82]\n",
      " [ 68 352]]\n",
      "precision_macro=0.8218 | recall_macro=0.8214 | specificity_macro=0.8214 | sensitivity_macro=0.8214\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/confusion_global_fold5_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/topomap_saliency_fold5_nb4_h2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/topomap_log10p_fold5_nb4_h2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h2/nb4_h2/fold5/tsne_cls_fold5_nb4_h2.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8214, F1=0.8214\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb4_h2:\n",
      "  F1 por fold: ['0.7730', '0.8186', '0.8004', '0.8274', '0.8214']\n",
      "  F1 Media ± Std: 0.8082 ± 0.0197\n",
      "  ACC Media ± Std: 0.8082 ± 0.0197\n",
      "  Parámetros: 352,738\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 8/9: nb4_h4\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 4\n",
      "  • Attention Heads: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.35it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.34it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1299 | train_acc=0.5210 | val_loss=0.1231 | val_acc=0.5349 | val_f1m=0.4597 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1239 | train_acc=0.5522 | val_loss=0.1197 | val_acc=0.5540 | val_f1m=0.4988 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1148 | train_acc=0.6294 | val_loss=0.1302 | val_acc=0.6317 | val_f1m=0.6077 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0940 | train_acc=0.7498 | val_loss=0.1042 | val_acc=0.6952 | val_f1m=0.6951 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0824 | train_acc=0.7928 | val_loss=0.1038 | val_acc=0.7127 | val_f1m=0.7126 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0845 | train_acc=0.7886 | val_loss=0.1017 | val_acc=0.7063 | val_f1m=0.7053 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0775 | train_acc=0.8035 | val_loss=0.1191 | val_acc=0.7063 | val_f1m=0.6980 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0750 | train_acc=0.8156 | val_loss=0.1026 | val_acc=0.7286 | val_f1m=0.7268 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0706 | train_acc=0.8234 | val_loss=0.1046 | val_acc=0.7492 | val_f1m=0.7492 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0715 | train_acc=0.8276 | val_loss=0.1088 | val_acc=0.7540 | val_f1m=0.7540 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0682 | train_acc=0.8305 | val_loss=0.1025 | val_acc=0.7635 | val_f1m=0.7626 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0687 | train_acc=0.8234 | val_loss=0.1049 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0647 | train_acc=0.8454 | val_loss=0.0954 | val_acc=0.7619 | val_f1m=0.7600 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0649 | train_acc=0.8390 | val_loss=0.1087 | val_acc=0.7460 | val_f1m=0.7423 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0614 | train_acc=0.8611 | val_loss=0.1008 | val_acc=0.7571 | val_f1m=0.7570 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0630 | train_acc=0.8340 | val_loss=0.0964 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0596 | train_acc=0.8568 | val_loss=0.0994 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0590 | train_acc=0.8596 | val_loss=0.1113 | val_acc=0.7587 | val_f1m=0.7579 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0552 | train_acc=0.8653 | val_loss=0.1142 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0582 | train_acc=0.8571 | val_loss=0.1007 | val_acc=0.7603 | val_f1m=0.7600 | LR=0.000425\n",
      "  Early stopping en época 20 (mejor val_f1m=0.7714)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/model_global_fold1_nb4_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/training_curve_fold1_nb4_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/history_fold1_nb4_h4.npz\n",
      "[Fold 1/5] Global acc=0.7687 | f1_macro=0.7686\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7604    0.7846    0.7723       441\n",
      "       right     0.7775    0.7528    0.7650       441\n",
      "\n",
      "    accuracy                         0.7687       882\n",
      "   macro avg     0.7690    0.7687    0.7686       882\n",
      "weighted avg     0.7690    0.7687    0.7686       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[346  95]\n",
      " [109 332]]\n",
      "precision_macro=0.7690 | recall_macro=0.7687 | specificity_macro=0.7687 | sensitivity_macro=0.7687\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/confusion_global_fold1_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/topomap_saliency_fold1_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/topomap_log10p_fold1_nb4_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold1/tsne_cls_fold1_nb4_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.43 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7687, F1=0.7686\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 17.04it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 16.87it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1305 | train_acc=0.5103 | val_loss=0.1227 | val_acc=0.5603 | val_f1m=0.4805 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1231 | train_acc=0.5615 | val_loss=0.1181 | val_acc=0.6143 | val_f1m=0.6139 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1140 | train_acc=0.6297 | val_loss=0.1017 | val_acc=0.7079 | val_f1m=0.7079 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0963 | train_acc=0.7402 | val_loss=0.1192 | val_acc=0.6952 | val_f1m=0.6924 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0900 | train_acc=0.7591 | val_loss=0.1034 | val_acc=0.7159 | val_f1m=0.7156 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0857 | train_acc=0.7708 | val_loss=0.0919 | val_acc=0.7444 | val_f1m=0.7442 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0793 | train_acc=0.7974 | val_loss=0.0911 | val_acc=0.7540 | val_f1m=0.7538 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0750 | train_acc=0.8031 | val_loss=0.1023 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0780 | train_acc=0.8010 | val_loss=0.0953 | val_acc=0.7540 | val_f1m=0.7539 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0773 | train_acc=0.8077 | val_loss=0.0969 | val_acc=0.7635 | val_f1m=0.7631 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0725 | train_acc=0.8216 | val_loss=0.0937 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0692 | train_acc=0.8273 | val_loss=0.0855 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0734 | train_acc=0.8234 | val_loss=0.0926 | val_acc=0.7667 | val_f1m=0.7660 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0657 | train_acc=0.8337 | val_loss=0.0858 | val_acc=0.7619 | val_f1m=0.7616 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0647 | train_acc=0.8358 | val_loss=0.0891 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0640 | train_acc=0.8429 | val_loss=0.0861 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0657 | train_acc=0.8380 | val_loss=0.0835 | val_acc=0.7968 | val_f1m=0.7967 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0666 | train_acc=0.8429 | val_loss=0.0864 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0609 | train_acc=0.8607 | val_loss=0.0880 | val_acc=0.7714 | val_f1m=0.7712 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0635 | train_acc=0.8511 | val_loss=0.0870 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0634 | train_acc=0.8465 | val_loss=0.0884 | val_acc=0.7587 | val_f1m=0.7587 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0538 | train_acc=0.8678 | val_loss=0.0917 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0604 | train_acc=0.8543 | val_loss=0.0904 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0611 | train_acc=0.8507 | val_loss=0.0904 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0564 | train_acc=0.8596 | val_loss=0.0903 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000373\n",
      "  Early stopping en época 25 (mejor val_f1m=0.7967)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/model_global_fold2_nb4_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/training_curve_fold2_nb4_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/history_fold2_nb4_h4.npz\n",
      "[Fold 2/5] Global acc=0.8277 | f1_macro=0.8276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8384    0.8118    0.8249       441\n",
      "       right     0.8176    0.8435    0.8304       441\n",
      "\n",
      "    accuracy                         0.8277       882\n",
      "   macro avg     0.8280    0.8277    0.8276       882\n",
      "weighted avg     0.8280    0.8277    0.8276       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[358  83]\n",
      " [ 69 372]]\n",
      "precision_macro=0.8280 | recall_macro=0.8277 | specificity_macro=0.8277 | sensitivity_macro=0.8277\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/confusion_global_fold2_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/topomap_saliency_fold2_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/topomap_log10p_fold2_nb4_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold2/tsne_cls_fold2_nb4_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.28 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8277, F1=0.8276\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 17.10it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.36it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1320 | train_acc=0.5064 | val_loss=0.1205 | val_acc=0.5492 | val_f1m=0.4840 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1242 | train_acc=0.5533 | val_loss=0.1183 | val_acc=0.5857 | val_f1m=0.5856 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1253 | train_acc=0.5426 | val_loss=0.1135 | val_acc=0.6175 | val_f1m=0.6028 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1017 | train_acc=0.7018 | val_loss=0.0938 | val_acc=0.7540 | val_f1m=0.7522 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0890 | train_acc=0.7715 | val_loss=0.0879 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0821 | train_acc=0.7928 | val_loss=0.0847 | val_acc=0.7841 | val_f1m=0.7839 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0757 | train_acc=0.8141 | val_loss=0.0844 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0752 | train_acc=0.8120 | val_loss=0.0873 | val_acc=0.7698 | val_f1m=0.7690 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0745 | train_acc=0.8117 | val_loss=0.0835 | val_acc=0.7794 | val_f1m=0.7785 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0708 | train_acc=0.8234 | val_loss=0.0873 | val_acc=0.7905 | val_f1m=0.7896 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0680 | train_acc=0.8397 | val_loss=0.0875 | val_acc=0.7873 | val_f1m=0.7861 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0668 | train_acc=0.8305 | val_loss=0.0866 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0638 | train_acc=0.8447 | val_loss=0.0808 | val_acc=0.7968 | val_f1m=0.7964 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0676 | train_acc=0.8380 | val_loss=0.0825 | val_acc=0.7968 | val_f1m=0.7964 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0599 | train_acc=0.8600 | val_loss=0.0933 | val_acc=0.7921 | val_f1m=0.7920 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0664 | train_acc=0.8429 | val_loss=0.0827 | val_acc=0.7905 | val_f1m=0.7904 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0612 | train_acc=0.8539 | val_loss=0.0840 | val_acc=0.8000 | val_f1m=0.7998 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0627 | train_acc=0.8500 | val_loss=0.0773 | val_acc=0.8159 | val_f1m=0.8156 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0578 | train_acc=0.8710 | val_loss=0.0945 | val_acc=0.7841 | val_f1m=0.7835 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0625 | train_acc=0.8419 | val_loss=0.0832 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0655 | train_acc=0.8358 | val_loss=0.0775 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0554 | train_acc=0.8667 | val_loss=0.0855 | val_acc=0.8095 | val_f1m=0.8093 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0590 | train_acc=0.8618 | val_loss=0.0859 | val_acc=0.8032 | val_f1m=0.8029 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0594 | train_acc=0.8618 | val_loss=0.0859 | val_acc=0.8032 | val_f1m=0.8029 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0500 | train_acc=0.8806 | val_loss=0.0860 | val_acc=0.8032 | val_f1m=0.8029 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0516 | train_acc=0.8806 | val_loss=0.0861 | val_acc=0.8032 | val_f1m=0.8029 | LR=0.000361\n",
      "  Early stopping en época 26 (mejor val_f1m=0.8156)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/model_global_fold3_nb4_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/training_curve_fold3_nb4_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/history_fold3_nb4_h4.npz\n",
      "[Fold 3/5] Global acc=0.7993 | f1_macro=0.7991\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7809    0.8322    0.8057       441\n",
      "       right     0.8204    0.7664    0.7925       441\n",
      "\n",
      "    accuracy                         0.7993       882\n",
      "   macro avg     0.8006    0.7993    0.7991       882\n",
      "weighted avg     0.8006    0.7993    0.7991       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[367  74]\n",
      " [103 338]]\n",
      "precision_macro=0.8006 | recall_macro=0.7993 | specificity_macro=0.7993 | sensitivity_macro=0.7993\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/confusion_global_fold3_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/topomap_saliency_fold3_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/topomap_log10p_fold3_nb4_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold3/tsne_cls_fold3_nb4_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.7993, F1=0.7991\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.11it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.29it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1310 | train_acc=0.4951 | val_loss=0.1232 | val_acc=0.5222 | val_f1m=0.4268 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1249 | train_acc=0.5483 | val_loss=0.1204 | val_acc=0.6079 | val_f1m=0.5976 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1190 | train_acc=0.5970 | val_loss=0.1185 | val_acc=0.6222 | val_f1m=0.6103 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1036 | train_acc=0.6964 | val_loss=0.0993 | val_acc=0.7095 | val_f1m=0.7091 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0935 | train_acc=0.7395 | val_loss=0.1181 | val_acc=0.6921 | val_f1m=0.6784 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0836 | train_acc=0.7791 | val_loss=0.0922 | val_acc=0.7397 | val_f1m=0.7397 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0785 | train_acc=0.8022 | val_loss=0.0985 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0760 | train_acc=0.8081 | val_loss=0.0881 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0737 | train_acc=0.8095 | val_loss=0.0856 | val_acc=0.7556 | val_f1m=0.7553 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0760 | train_acc=0.8092 | val_loss=0.0922 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0707 | train_acc=0.8221 | val_loss=0.1037 | val_acc=0.7444 | val_f1m=0.7353 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0721 | train_acc=0.8172 | val_loss=0.0935 | val_acc=0.7857 | val_f1m=0.7855 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0685 | train_acc=0.8400 | val_loss=0.0902 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0641 | train_acc=0.8400 | val_loss=0.0827 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0658 | train_acc=0.8372 | val_loss=0.0933 | val_acc=0.7714 | val_f1m=0.7708 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0633 | train_acc=0.8459 | val_loss=0.0875 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0624 | train_acc=0.8396 | val_loss=0.0972 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0649 | train_acc=0.8365 | val_loss=0.0931 | val_acc=0.7778 | val_f1m=0.7772 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0623 | train_acc=0.8403 | val_loss=0.0905 | val_acc=0.7825 | val_f1m=0.7822 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0574 | train_acc=0.8620 | val_loss=0.0973 | val_acc=0.7873 | val_f1m=0.7868 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0588 | train_acc=0.8561 | val_loss=0.0954 | val_acc=0.7841 | val_f1m=0.7839 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0598 | train_acc=0.8610 | val_loss=0.0892 | val_acc=0.7857 | val_f1m=0.7854 | LR=0.000405\n",
      "  Early stopping en época 22 (mejor val_f1m=0.7936)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/model_global_fold4_nb4_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/training_curve_fold4_nb4_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/history_fold4_nb4_h4.npz\n",
      "[Fold 4/5] Global acc=0.8238 | f1_macro=0.8236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8049    0.8548    0.8291       420\n",
      "       right     0.8452    0.7929    0.8182       420\n",
      "\n",
      "    accuracy                         0.8238       840\n",
      "   macro avg     0.8251    0.8238    0.8236       840\n",
      "weighted avg     0.8251    0.8238    0.8236       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[359  61]\n",
      " [ 87 333]]\n",
      "precision_macro=0.8251 | recall_macro=0.8238 | specificity_macro=0.8238 | sensitivity_macro=0.8238\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/confusion_global_fold4_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/topomap_saliency_fold4_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/topomap_log10p_fold4_nb4_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold4/tsne_cls_fold4_nb4_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.28 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8238, F1=0.8236\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.32it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.34it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1316 | train_acc=0.5123 | val_loss=0.1213 | val_acc=0.5460 | val_f1m=0.4985 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1253 | train_acc=0.5235 | val_loss=0.1198 | val_acc=0.5952 | val_f1m=0.5677 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1221 | train_acc=0.5711 | val_loss=0.1111 | val_acc=0.6746 | val_f1m=0.6664 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1011 | train_acc=0.7220 | val_loss=0.1036 | val_acc=0.6905 | val_f1m=0.6903 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0883 | train_acc=0.7731 | val_loss=0.0984 | val_acc=0.7302 | val_f1m=0.7302 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0794 | train_acc=0.8008 | val_loss=0.1046 | val_acc=0.7238 | val_f1m=0.7183 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0795 | train_acc=0.8036 | val_loss=0.1033 | val_acc=0.7190 | val_f1m=0.7173 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0788 | train_acc=0.7987 | val_loss=0.0989 | val_acc=0.7587 | val_f1m=0.7586 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0714 | train_acc=0.8141 | val_loss=0.1088 | val_acc=0.7206 | val_f1m=0.7165 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0750 | train_acc=0.8085 | val_loss=0.0947 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0704 | train_acc=0.8263 | val_loss=0.1099 | val_acc=0.7333 | val_f1m=0.7333 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0695 | train_acc=0.8284 | val_loss=0.1015 | val_acc=0.7571 | val_f1m=0.7569 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0688 | train_acc=0.8288 | val_loss=0.0969 | val_acc=0.7429 | val_f1m=0.7400 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0664 | train_acc=0.8393 | val_loss=0.0983 | val_acc=0.7746 | val_f1m=0.7745 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0665 | train_acc=0.8386 | val_loss=0.0973 | val_acc=0.7683 | val_f1m=0.7683 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0639 | train_acc=0.8389 | val_loss=0.1013 | val_acc=0.7603 | val_f1m=0.7583 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0663 | train_acc=0.8270 | val_loss=0.0960 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0643 | train_acc=0.8396 | val_loss=0.0996 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0617 | train_acc=0.8470 | val_loss=0.0949 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0611 | train_acc=0.8575 | val_loss=0.0995 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0594 | train_acc=0.8491 | val_loss=0.1045 | val_acc=0.7762 | val_f1m=0.7761 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0584 | train_acc=0.8571 | val_loss=0.0998 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0571 | train_acc=0.8620 | val_loss=0.0997 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0605 | train_acc=0.8582 | val_loss=0.0996 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0519 | train_acc=0.8761 | val_loss=0.0998 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0555 | train_acc=0.8645 | val_loss=0.0999 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0570 | train_acc=0.8554 | val_loss=0.0999 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0567 | train_acc=0.8610 | val_loss=0.1000 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0586 | train_acc=0.8585 | val_loss=0.1001 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.7761)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/model_global_fold5_nb4_h4.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/training_curve_fold5_nb4_h4.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/history_fold5_nb4_h4.npz\n",
      "[Fold 5/5] Global acc=0.8202 | f1_macro=0.8202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8273    0.8095    0.8183       420\n",
      "       right     0.8135    0.8310    0.8221       420\n",
      "\n",
      "    accuracy                         0.8202       840\n",
      "   macro avg     0.8204    0.8202    0.8202       840\n",
      "weighted avg     0.8204    0.8202    0.8202       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[340  80]\n",
      " [ 71 349]]\n",
      "precision_macro=0.8204 | recall_macro=0.8202 | specificity_macro=0.8202 | sensitivity_macro=0.8202\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/confusion_global_fold5_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/topomap_saliency_fold5_nb4_h4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/topomap_log10p_fold5_nb4_h4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h4/nb4_h4/fold5/tsne_cls_fold5_nb4_h4.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8202, F1=0.8202\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb4_h4:\n",
      "  F1 por fold: ['0.7686', '0.8276', '0.7991', '0.8236', '0.8202']\n",
      "  F1 Media ± Std: 0.8078 ± 0.0219\n",
      "  ACC Media ± Std: 0.8079 ± 0.0219\n",
      "  Parámetros: 352,738\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "ARQUITECTURA 9/9: nb4_h6\n",
      "================================================================================\n",
      "  • Depthwise Blocks: 4\n",
      "  • Attention Heads: 6\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.00it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.32it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1303 | train_acc=0.5114 | val_loss=0.1230 | val_acc=0.5175 | val_f1m=0.4273 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1240 | train_acc=0.5430 | val_loss=0.1201 | val_acc=0.5540 | val_f1m=0.5056 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1176 | train_acc=0.6091 | val_loss=0.1275 | val_acc=0.6016 | val_f1m=0.5691 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0972 | train_acc=0.7335 | val_loss=0.1091 | val_acc=0.7175 | val_f1m=0.7141 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0833 | train_acc=0.7854 | val_loss=0.1022 | val_acc=0.7048 | val_f1m=0.7043 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0873 | train_acc=0.7672 | val_loss=0.0997 | val_acc=0.6937 | val_f1m=0.6823 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0725 | train_acc=0.8213 | val_loss=0.1084 | val_acc=0.7571 | val_f1m=0.7547 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0660 | train_acc=0.8397 | val_loss=0.0946 | val_acc=0.7778 | val_f1m=0.7776 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0620 | train_acc=0.8468 | val_loss=0.1035 | val_acc=0.7825 | val_f1m=0.7821 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0670 | train_acc=0.8362 | val_loss=0.1109 | val_acc=0.7524 | val_f1m=0.7522 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0603 | train_acc=0.8415 | val_loss=0.1001 | val_acc=0.7698 | val_f1m=0.7690 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0613 | train_acc=0.8493 | val_loss=0.0983 | val_acc=0.7603 | val_f1m=0.7601 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0599 | train_acc=0.8532 | val_loss=0.1060 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0629 | train_acc=0.8451 | val_loss=0.0964 | val_acc=0.7794 | val_f1m=0.7790 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0606 | train_acc=0.8500 | val_loss=0.0977 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0554 | train_acc=0.8635 | val_loss=0.1130 | val_acc=0.7587 | val_f1m=0.7574 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0562 | train_acc=0.8635 | val_loss=0.1136 | val_acc=0.7508 | val_f1m=0.7499 | LR=0.000451\n",
      "  Early stopping en época 17 (mejor val_f1m=0.7821)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/model_global_fold1_nb4_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/training_curve_fold1_nb4_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/history_fold1_nb4_h6.npz\n",
      "[Fold 1/5] Global acc=0.7789 | f1_macro=0.7784\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7552    0.8254    0.7887       441\n",
      "       right     0.8075    0.7324    0.7681       441\n",
      "\n",
      "    accuracy                         0.7789       882\n",
      "   macro avg     0.7813    0.7789    0.7784       882\n",
      "weighted avg     0.7813    0.7789    0.7784       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[364  77]\n",
      " [118 323]]\n",
      "precision_macro=0.7813 | recall_macro=0.7789 | specificity_macro=0.7789 | sensitivity_macro=0.7789\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/confusion_global_fold1_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/topomap_saliency_fold1_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/topomap_log10p_fold1_nb4_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold1/tsne_cls_fold1_nb4_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.28 ms (B=8)\n",
      "✓ Fold 1 completado: ACC=0.7789, F1=0.7784\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 16.89it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 16.58it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1309 | train_acc=0.5085 | val_loss=0.1226 | val_acc=0.5667 | val_f1m=0.4952 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1232 | train_acc=0.5537 | val_loss=0.1184 | val_acc=0.6048 | val_f1m=0.6042 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1157 | train_acc=0.6230 | val_loss=0.1037 | val_acc=0.7222 | val_f1m=0.7207 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0977 | train_acc=0.7260 | val_loss=0.1142 | val_acc=0.7270 | val_f1m=0.7262 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0898 | train_acc=0.7679 | val_loss=0.1095 | val_acc=0.7508 | val_f1m=0.7505 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0781 | train_acc=0.7946 | val_loss=0.0967 | val_acc=0.7476 | val_f1m=0.7457 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0802 | train_acc=0.7875 | val_loss=0.0924 | val_acc=0.7492 | val_f1m=0.7488 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0707 | train_acc=0.8266 | val_loss=0.0939 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0732 | train_acc=0.8177 | val_loss=0.0859 | val_acc=0.7714 | val_f1m=0.7708 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0703 | train_acc=0.8266 | val_loss=0.0937 | val_acc=0.7508 | val_f1m=0.7501 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0715 | train_acc=0.8230 | val_loss=0.0895 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0656 | train_acc=0.8422 | val_loss=0.0937 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0717 | train_acc=0.8213 | val_loss=0.1039 | val_acc=0.7556 | val_f1m=0.7556 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0655 | train_acc=0.8365 | val_loss=0.0944 | val_acc=0.7460 | val_f1m=0.7448 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0627 | train_acc=0.8436 | val_loss=0.0997 | val_acc=0.7730 | val_f1m=0.7730 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0607 | train_acc=0.8493 | val_loss=0.0967 | val_acc=0.7635 | val_f1m=0.7635 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0655 | train_acc=0.8433 | val_loss=0.0874 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0664 | train_acc=0.8380 | val_loss=0.0994 | val_acc=0.7651 | val_f1m=0.7651 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0621 | train_acc=0.8536 | val_loss=0.0972 | val_acc=0.7571 | val_f1m=0.7568 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0621 | train_acc=0.8465 | val_loss=0.0917 | val_acc=0.7667 | val_f1m=0.7667 | LR=0.000425\n",
      "  Early stopping en época 20 (mejor val_f1m=0.7777)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/model_global_fold2_nb4_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/training_curve_fold2_nb4_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/history_fold2_nb4_h6.npz\n",
      "[Fold 2/5] Global acc=0.8175 | f1_macro=0.8175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8153    0.8209    0.8181       441\n",
      "       right     0.8196    0.8141    0.8168       441\n",
      "\n",
      "    accuracy                         0.8175       882\n",
      "   macro avg     0.8175    0.8175    0.8175       882\n",
      "weighted avg     0.8175    0.8175    0.8175       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[362  79]\n",
      " [ 82 359]]\n",
      "precision_macro=0.8175 | recall_macro=0.8175 | specificity_macro=0.8175 | sensitivity_macro=0.8175\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/confusion_global_fold2_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/topomap_saliency_fold2_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/topomap_log10p_fold2_nb4_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold2/tsne_cls_fold2_nb4_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.28 ms (B=8)\n",
      "✓ Fold 2 completado: ACC=0.8175, F1=0.8175\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 16.88it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.46it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1314 | train_acc=0.5071 | val_loss=0.1205 | val_acc=0.5524 | val_f1m=0.4863 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1238 | train_acc=0.5522 | val_loss=0.1166 | val_acc=0.6190 | val_f1m=0.6190 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1255 | train_acc=0.5398 | val_loss=0.1152 | val_acc=0.6063 | val_f1m=0.5859 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1105 | train_acc=0.6585 | val_loss=0.0941 | val_acc=0.7460 | val_f1m=0.7429 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0884 | train_acc=0.7704 | val_loss=0.0828 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0813 | train_acc=0.7967 | val_loss=0.1069 | val_acc=0.7317 | val_f1m=0.7204 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0737 | train_acc=0.8149 | val_loss=0.0928 | val_acc=0.7508 | val_f1m=0.7425 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0763 | train_acc=0.8109 | val_loss=0.0824 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0689 | train_acc=0.8269 | val_loss=0.0790 | val_acc=0.8016 | val_f1m=0.8007 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0714 | train_acc=0.8237 | val_loss=0.0873 | val_acc=0.7794 | val_f1m=0.7767 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0649 | train_acc=0.8447 | val_loss=0.0874 | val_acc=0.7889 | val_f1m=0.7887 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0656 | train_acc=0.8433 | val_loss=0.0869 | val_acc=0.7778 | val_f1m=0.7764 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0613 | train_acc=0.8443 | val_loss=0.0877 | val_acc=0.7937 | val_f1m=0.7929 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0602 | train_acc=0.8536 | val_loss=0.0814 | val_acc=0.8143 | val_f1m=0.8143 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0611 | train_acc=0.8490 | val_loss=0.0895 | val_acc=0.8000 | val_f1m=0.7998 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0601 | train_acc=0.8529 | val_loss=0.0923 | val_acc=0.8048 | val_f1m=0.8045 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0633 | train_acc=0.8475 | val_loss=0.0828 | val_acc=0.7889 | val_f1m=0.7882 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0586 | train_acc=0.8515 | val_loss=0.0864 | val_acc=0.8016 | val_f1m=0.8007 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0584 | train_acc=0.8628 | val_loss=0.0834 | val_acc=0.8000 | val_f1m=0.7994 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0596 | train_acc=0.8511 | val_loss=0.0769 | val_acc=0.8032 | val_f1m=0.8029 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0564 | train_acc=0.8603 | val_loss=0.0836 | val_acc=0.8111 | val_f1m=0.8110 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0547 | train_acc=0.8586 | val_loss=0.0852 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000405\n",
      "  Early stopping en época 22 (mejor val_f1m=0.8143)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/model_global_fold3_nb4_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/training_curve_fold3_nb4_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/history_fold3_nb4_h6.npz\n",
      "[Fold 3/5] Global acc=0.7846 | f1_macro=0.7845\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7967    0.7642    0.7801       441\n",
      "       right     0.7734    0.8050    0.7889       441\n",
      "\n",
      "    accuracy                         0.7846       882\n",
      "   macro avg     0.7851    0.7846    0.7845       882\n",
      "weighted avg     0.7851    0.7846    0.7845       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[337 104]\n",
      " [ 86 355]]\n",
      "precision_macro=0.7851 | recall_macro=0.7846 | specificity_macro=0.7846 | sensitivity_macro=0.7846\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/confusion_global_fold3_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/topomap_saliency_fold3_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/topomap_log10p_fold3_nb4_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold3/tsne_cls_fold3_nb4_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.27 ms (B=8)\n",
      "✓ Fold 3 completado: ACC=0.7846, F1=0.7845\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:04<00:00, 16.98it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 16.90it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1312 | train_acc=0.4909 | val_loss=0.1225 | val_acc=0.5317 | val_f1m=0.4590 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1246 | train_acc=0.5455 | val_loss=0.1201 | val_acc=0.6016 | val_f1m=0.5915 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1181 | train_acc=0.6078 | val_loss=0.1147 | val_acc=0.6603 | val_f1m=0.6508 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1015 | train_acc=0.7101 | val_loss=0.1010 | val_acc=0.6968 | val_f1m=0.6968 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0906 | train_acc=0.7532 | val_loss=0.1073 | val_acc=0.7063 | val_f1m=0.6986 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0860 | train_acc=0.7717 | val_loss=0.0953 | val_acc=0.7365 | val_f1m=0.7364 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0754 | train_acc=0.8130 | val_loss=0.1069 | val_acc=0.7381 | val_f1m=0.7364 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0741 | train_acc=0.8099 | val_loss=0.0888 | val_acc=0.7556 | val_f1m=0.7551 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0740 | train_acc=0.8130 | val_loss=0.0878 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0725 | train_acc=0.8221 | val_loss=0.1058 | val_acc=0.7349 | val_f1m=0.7267 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0678 | train_acc=0.8295 | val_loss=0.1022 | val_acc=0.7571 | val_f1m=0.7561 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0664 | train_acc=0.8382 | val_loss=0.0849 | val_acc=0.7587 | val_f1m=0.7587 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0674 | train_acc=0.8344 | val_loss=0.0871 | val_acc=0.7746 | val_f1m=0.7744 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0628 | train_acc=0.8407 | val_loss=0.0932 | val_acc=0.7524 | val_f1m=0.7523 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0649 | train_acc=0.8480 | val_loss=0.0900 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0662 | train_acc=0.8410 | val_loss=0.0853 | val_acc=0.7762 | val_f1m=0.7759 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0637 | train_acc=0.8452 | val_loss=0.0916 | val_acc=0.7603 | val_f1m=0.7597 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0633 | train_acc=0.8501 | val_loss=0.0957 | val_acc=0.7841 | val_f1m=0.7837 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0616 | train_acc=0.8435 | val_loss=0.0902 | val_acc=0.7667 | val_f1m=0.7658 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0612 | train_acc=0.8589 | val_loss=0.0893 | val_acc=0.7651 | val_f1m=0.7647 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0592 | train_acc=0.8571 | val_loss=0.0895 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0560 | train_acc=0.8673 | val_loss=0.0898 | val_acc=0.7762 | val_f1m=0.7757 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0575 | train_acc=0.8673 | val_loss=0.0897 | val_acc=0.7778 | val_f1m=0.7773 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0577 | train_acc=0.8620 | val_loss=0.0897 | val_acc=0.7778 | val_f1m=0.7773 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0498 | train_acc=0.8785 | val_loss=0.0897 | val_acc=0.7778 | val_f1m=0.7773 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0512 | train_acc=0.8796 | val_loss=0.0898 | val_acc=0.7794 | val_f1m=0.7789 | LR=0.000361\n",
      "  Early stopping en época 26 (mejor val_f1m=0.7837)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/model_global_fold4_nb4_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/training_curve_fold4_nb4_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/history_fold4_nb4_h6.npz\n",
      "[Fold 4/5] Global acc=0.8274 | f1_macro=0.8274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8282    0.8262    0.8272       420\n",
      "       right     0.8266    0.8286    0.8276       420\n",
      "\n",
      "    accuracy                         0.8274       840\n",
      "   macro avg     0.8274    0.8274    0.8274       840\n",
      "weighted avg     0.8274    0.8274    0.8274       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[347  73]\n",
      " [ 72 348]]\n",
      "precision_macro=0.8274 | recall_macro=0.8274 | specificity_macro=0.8274 | sensitivity_macro=0.8274\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/confusion_global_fold4_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/topomap_saliency_fold4_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/topomap_log10p_fold4_nb4_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold4/tsne_cls_fold4_nb4_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.29 ms (B=8)\n",
      "✓ Fold 4 completado: ACC=0.8274, F1=0.8274\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:04<00:00, 16.82it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.25it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1319 | train_acc=0.5154 | val_loss=0.1214 | val_acc=0.5476 | val_f1m=0.4917 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1253 | train_acc=0.5368 | val_loss=0.1188 | val_acc=0.6127 | val_f1m=0.5920 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1217 | train_acc=0.5749 | val_loss=0.1109 | val_acc=0.6651 | val_f1m=0.6559 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1013 | train_acc=0.7171 | val_loss=0.1091 | val_acc=0.6778 | val_f1m=0.6775 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0893 | train_acc=0.7630 | val_loss=0.0960 | val_acc=0.7159 | val_f1m=0.7130 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0797 | train_acc=0.7959 | val_loss=0.1083 | val_acc=0.7317 | val_f1m=0.7277 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0826 | train_acc=0.7868 | val_loss=0.0938 | val_acc=0.7476 | val_f1m=0.7466 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0706 | train_acc=0.8267 | val_loss=0.1090 | val_acc=0.7413 | val_f1m=0.7398 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0717 | train_acc=0.8246 | val_loss=0.0963 | val_acc=0.7381 | val_f1m=0.7372 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0693 | train_acc=0.8221 | val_loss=0.1038 | val_acc=0.7365 | val_f1m=0.7350 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0677 | train_acc=0.8256 | val_loss=0.1017 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0660 | train_acc=0.8323 | val_loss=0.0977 | val_acc=0.7556 | val_f1m=0.7549 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0655 | train_acc=0.8319 | val_loss=0.0992 | val_acc=0.7524 | val_f1m=0.7523 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0682 | train_acc=0.8242 | val_loss=0.0952 | val_acc=0.7714 | val_f1m=0.7714 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0640 | train_acc=0.8410 | val_loss=0.0864 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0613 | train_acc=0.8445 | val_loss=0.0940 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0603 | train_acc=0.8519 | val_loss=0.0929 | val_acc=0.7857 | val_f1m=0.7856 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0620 | train_acc=0.8491 | val_loss=0.0914 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0605 | train_acc=0.8515 | val_loss=0.0934 | val_acc=0.7778 | val_f1m=0.7775 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0572 | train_acc=0.8568 | val_loss=0.0974 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0552 | train_acc=0.8652 | val_loss=0.0998 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0530 | train_acc=0.8718 | val_loss=0.0993 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0562 | train_acc=0.8599 | val_loss=0.0992 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0541 | train_acc=0.8708 | val_loss=0.0992 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000384\n",
      "  Early stopping en época 24 (mejor val_f1m=0.7984)\n",
      "↳ Modelo global guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/model_global_fold5_nb4_h6.pth\n",
      "↳ Training curve saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/training_curve_fold5_nb4_h6.png\n",
      "↳ History saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/history_fold5_nb4_h6.npz\n",
      "[Fold 5/5] Global acc=0.8369 | f1_macro=0.8369\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8426    0.8286    0.8355       420\n",
      "       right     0.8314    0.8452    0.8383       420\n",
      "\n",
      "    accuracy                         0.8369       840\n",
      "   macro avg     0.8370    0.8369    0.8369       840\n",
      "weighted avg     0.8370    0.8369    0.8369       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[348  72]\n",
      " [ 65 355]]\n",
      "precision_macro=0.8370 | recall_macro=0.8369 | specificity_macro=0.8369 | sensitivity_macro=0.8369\n",
      "↳ Confusion matrix saved: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/confusion_global_fold5_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/topomap_saliency_fold5_nb4_h6.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/topomap_log10p_fold5_nb4_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/nb4_h6/nb4_h6/fold5/tsne_cls_fold5_nb4_h6.png\n",
      "  [LITE] FT desactivado (do_ft=False).\n",
      "[Consumo] params_total=352,738 | params_trainable=352,738 | FLOPs~5.4M | latency/batch=1.29 ms (B=8)\n",
      "✓ Fold 5 completado: ACC=0.8369, F1=0.8369\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "RESUMEN nb4_h6:\n",
      "  F1 por fold: ['0.7784', '0.8175', '0.7845', '0.8274', '0.8369']\n",
      "  F1 Media ± Std: 0.8089 ± 0.0233\n",
      "  ACC Media ± Std: 0.8090 ± 0.0232\n",
      "  Parámetros: 352,738\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "================================================================================\n",
      "SWEEP ARQUITECTÓNICO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Resultados guardados en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/arch_sweep_5fold_results.csv\n",
      "\n",
      "Mejor arquitectura:\n",
      "  • Arch ID: nb0_h4\n",
      "  • Blocks: 0, Heads: 4\n",
      "  • F1 Score: 0.8223 ± 0.0186\n",
      "  • Accuracy: 0.8223 ± 0.0185\n",
      "  • Parámetros: 205,890\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PASO 2: Análisis estadístico de resultados\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS ESTADÍSTICO DEL SWEEP ARQUITECTÓNICO\n",
      "================================================================================\n",
      "\n",
      "Arquitectura Baseline: nb2_h6\n",
      "  F1 Scores: ['0.8107', '0.8353', '0.8084', '0.8098', '0.8464']\n",
      "  Media: 0.8221 ± 0.0157\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST DE WILCOXON PAREADO (cada arquitectura vs baseline)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "nb0_h4:\n",
      "  F1: 0.8223 ± 0.0186\n",
      "  Δ vs baseline: +0.0002\n",
      "  Wilcoxon stat: 5.0000, p-value: 0.6250 \n",
      "  No significativo\n",
      "\n",
      "nb0_h6:\n",
      "  F1: 0.8127 ± 0.0203\n",
      "  Δ vs baseline: -0.0094\n",
      "  Wilcoxon stat: 3.0000, p-value: 0.3125 \n",
      "  No significativo\n",
      "\n",
      "nb4_h6:\n",
      "  F1: 0.8089 ± 0.0233\n",
      "  Δ vs baseline: -0.0132\n",
      "  Wilcoxon stat: 2.0000, p-value: 0.1875 \n",
      "  No significativo\n",
      "\n",
      "nb0_h2:\n",
      "  F1: 0.8084 ± 0.0173\n",
      "  Δ vs baseline: -0.0137\n",
      "  Wilcoxon stat: 0.0000, p-value: 0.0625 \n",
      "  No significativo\n",
      "\n",
      "nb4_h2:\n",
      "  F1: 0.8082 ± 0.0197\n",
      "  Δ vs baseline: -0.0139\n",
      "  Wilcoxon stat: 3.0000, p-value: 0.3125 \n",
      "  No significativo\n",
      "\n",
      "nb4_h4:\n",
      "  F1: 0.8078 ± 0.0219\n",
      "  Δ vs baseline: -0.0143\n",
      "  Wilcoxon stat: 3.0000, p-value: 0.3125 \n",
      "  No significativo\n",
      "\n",
      "nb2_h2:\n",
      "  F1: 0.8078 ± 0.0229\n",
      "  Δ vs baseline: -0.0143\n",
      "  Wilcoxon stat: 3.0000, p-value: 0.3125 \n",
      "  No significativo\n",
      "\n",
      "nb2_h4:\n",
      "  F1: 0.8075 ± 0.0226\n",
      "  Δ vs baseline: -0.0146\n",
      "  Wilcoxon stat: 1.0000, p-value: 0.1250 \n",
      "  No significativo\n",
      "\n",
      "Resultados de Wilcoxon guardados en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/arch_sweep_5fold/wilcoxon_results.csv\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST DE FRIEDMAN (comparación múltiple)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Friedman χ² statistic: 14.4107\n",
      "p-value: 0.071669\n",
      "\n",
      "✗ NO SIGNIFICATIVO (p ≥ 0.05)\n",
      "Conclusión: No hay evidencia de diferencias significativas entre arquitecturas.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type bool is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-51cf92e96e94>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[INFO] Baseline ajustado a: {baseline_arch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     statistical_results = analyze_arch_sweep_statistical(\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mdf_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_arch_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbaseline_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a8be8db6c471>\u001b[0m in \u001b[0;36manalyze_arch_sweep_statistical\u001b[0;34m(df_results, baseline_arch, output_dir, alpha)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0msummary_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'statistical_summary.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{'='*80}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    181\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type bool is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# EJECUTAR SWEEP ARQUITECTÓNICO COMPLETO\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SWEEP ARQUITECTÓNICO CON ANÁLISIS ESTADÍSTICO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # ========================================\n",
    "    # PASO 1: Ejecutar el sweep con 5 folds\n",
    "    # ========================================\n",
    "    print(\"PASO 1: Ejecutando sweep arquitectónico con 5-fold CV\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    # Configuración del sweep\n",
    "    base_blocks = 2\n",
    "    deltas = (-2, 0, +2)  # Probará: 0, 2, 4 bloques\n",
    "    head_set = (2, 4, 6)   # Probará: 2, 4, 6 attention heads\n",
    "    \n",
    "    print(\"Configuración:\")\n",
    "    print(f\"  • Base blocks: {base_blocks}\")\n",
    "    print(f\"  • Deltas: {deltas}\")\n",
    "    print(f\"  • Head set: {head_set}\")\n",
    "    print(f\"  • Total de arquitecturas: {len(deltas) * len(head_set)} (máximo)\")\n",
    "    print(f\"\\nADVERTENCIA: Este proceso tomará varias horas.\")\n",
    "    print(f\"  Tiempo estimado: ~6-10 horas (depende del hardware)\\n\")\n",
    "    \n",
    "    # Ejecutar sweep\n",
    "    df_arch_results = run_arch_sweep_5folds(\n",
    "        device=DEVICE,\n",
    "        base_blocks=base_blocks,\n",
    "        deltas=deltas,\n",
    "        head_set=head_set,\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold'\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # PASO 2: Análisis estadístico\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PASO 2: Análisis estadístico de resultados\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    # Identificar baseline (típicamente nb2_h6 o la configuración central)\n",
    "    baseline_arch = 'nb2_h6'  # Ajustar según tu modelo ganador\n",
    "    \n",
    "    # Si el baseline no existe, usar el mejor\n",
    "    if baseline_arch not in df_arch_results['arch_id'].values:\n",
    "        baseline_arch = df_arch_results.iloc[0]['arch_id']\n",
    "        print(f\"[INFO] Baseline ajustado a: {baseline_arch}\")\n",
    "    \n",
    "    statistical_results = analyze_arch_sweep_statistical(\n",
    "        df_results=df_arch_results,\n",
    "        baseline_arch=baseline_arch,\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold',\n",
    "        alpha=0.05\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # PASO 3: Visualizaciones\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PASO 3: Generando visualizaciones\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    plot_arch_sweep_results(\n",
    "        df_results=df_arch_results,\n",
    "        df_wilcoxon=statistical_results['wilcoxon_results'],\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold'\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # PASO 4: Identificar y ejecutar ganador\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PASO 4: Ejecutar arquitectura ganadora\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    winner_arch = df_arch_results.iloc[0]['arch_id']\n",
    "    \n",
    "    print(f\"Arquitectura ganadora identificada: {winner_arch}\")\n",
    "    print(f\"  • F1-Score: {df_arch_results.iloc[0]['mean_f1']:.4f} ± {df_arch_results.iloc[0]['std_f1']:.4f}\")\n",
    "    print(f\"  • Accuracy: {df_arch_results.iloc[0]['mean_acc']:.4f} ± {df_arch_results.iloc[0]['std_acc']:.4f}\")\n",
    "    print(f\"\\n¿Deseas ejecutar el ganador con todos los artefactos y fine-tuning?\")\n",
    "    print(f\"  (Los resultados ya están disponibles del sweep)\")\n",
    "    print(f\"  Si deseas re-ejecutar, descomenta la siguiente línea:\\n\")\n",
    "    \n",
    "    # Descomenta para ejecutar el ganador con todos los artefactos\n",
    "    # winner_results = run_winner_architecture(\n",
    "    #     device=DEVICE,\n",
    "    #     arch_id=winner_arch,\n",
    "    #     output_dir=PROJ / 'models' / '04_hybrid' / 'winner_architecture'\n",
    "    # )\n",
    "    \n",
    "    # ========================================\n",
    "    # RESUMEN FINAL\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SWEEP ARQUITECTÓNICO COMPLETADO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(\"Resumen de Resultados:\")\n",
    "    print(f\"  • Total arquitecturas evaluadas: {len(df_arch_results)}\")\n",
    "    print(f\"  • Mejor arquitectura: {winner_arch}\")\n",
    "    print(f\"  • F1-Score: {df_arch_results.iloc[0]['mean_f1']:.4f} ± {df_arch_results.iloc[0]['std_f1']:.4f}\")\n",
    "    \n",
    "    # Contar arquitecturas significativas\n",
    "    if 'wilcoxon_results' in statistical_results:\n",
    "        n_significant = int(statistical_results['wilcoxon_results']['significant'].sum())\n",
    "        print(f\"  • Arquitecturas significativas vs baseline: {n_significant}\")\n",
    "    \n",
    "    print(f\"\\nTest de Friedman:\")\n",
    "    print(f\"  • χ² = {statistical_results['friedman_stat']:.4f}\")\n",
    "    print(f\"  • p-value = {statistical_results['friedman_p_value']:.6f}\")\n",
    "    print(f\"  • {'SIGNIFICATIVO' if statistical_results['friedman_significant'] else 'No significativo'}\")\n",
    "    \n",
    "    print(f\"\\nArchivos generados en: {PROJ / 'models' / '04_hybrid' / 'arch_sweep_5fold'}\")\n",
    "    print(\"  • arch_sweep_5fold_results.csv - Resultados completos\")\n",
    "    print(\"  • wilcoxon_results.csv - Tests estadísticos\")\n",
    "    print(\"  • statistical_summary.json - Resumen estadístico\")\n",
    "    print(\"  • arch_sweep_comparison.png - Gráfico comparativo\")\n",
    "    print(\"  • arch_sweep_heatmaps.png - Heatmaps de configuraciones\")\n",
    "    print(\"  • arch_sweep_pvalues.png - Gráfico de p-values\")\n",
    "    print(\"  • arch_sweep_table.png - Tabla resumen\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS COMPLETADO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Mostrar top 3 arquitecturas\n",
    "    print(\"Top 3 Arquitecturas:\")\n",
    "    print(\"-\"*80)\n",
    "    for i in range(min(3, len(df_arch_results))):\n",
    "        row = df_arch_results.iloc[i]\n",
    "        print(f\"{i+1}. {row['arch_id']}\")\n",
    "        print(f\"   F1: {row['mean_f1']:.4f} ± {row['std_f1']:.4f}\")\n",
    "        print(f\"   ACC: {row['mean_acc']:.4f} ± {row['std_acc']:.4f}\")\n",
    "        print(f\"   Params: {int(row['n_params']):,}\")\n",
    "        \n",
    "        # Mostrar si es significativo vs baseline\n",
    "        if 'wilcoxon_results' in statistical_results:\n",
    "            wilcox_row = statistical_results['wilcoxon_results'][\n",
    "                statistical_results['wilcoxon_results']['arch_id'] == row['arch_id']\n",
    "            ]\n",
    "            if len(wilcox_row) > 0:\n",
    "                is_sig = wilcox_row.iloc[0]['significant']\n",
    "                p_val = wilcox_row.iloc[0]['p_value']\n",
    "                print(f\"   vs baseline: {'SIGNIFICATIVO' if is_sig else 'No significativo'} (p={p_val:.4f})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838ec88",
   "metadata": {},
   "source": [
    "---\n",
    "## Documentación del Sweep Arquitectónico\n",
    "\n",
    "### 📋 Características del Análisis:\n",
    "\n",
    "#### Variaciones Arquitectónicas:\n",
    "- **Bloques Depthwise**: Probará 0, 2, 4 bloques (base=2, deltas=(-2,0,+2))\n",
    "- **Attention Heads**: Probará 2, 4, 6 cabezas\n",
    "- **Total de configuraciones**: Hasta 9 arquitecturas diferentes\n",
    "\n",
    "#### Metodología:\n",
    "1. **5-Fold Cross-Validation** por cada arquitectura\n",
    "2. **Test de Wilcoxon Pareado**: Compara cada arquitectura vs baseline\n",
    "3. **Test de Friedman**: Comparación múltiple de todas las arquitecturas\n",
    "4. **Visualizaciones**: Gráficos, heatmaps y tablas comprehensivas\n",
    "\n",
    "### ⏱️ Tiempo Estimado:\n",
    "- **Por fold**: ~5-10 minutos\n",
    "- **Por arquitectura**: ~25-50 minutos (5 folds)\n",
    "- **Total**: ~4-8 horas (9 arquitecturas × 5 folds)\n",
    "\n",
    "### 📊 Resultados Generados:\n",
    "\n",
    "#### 1. **Datos (CSV/JSON)**:\n",
    "- `arch_sweep_5fold_results.csv`: Resultados completos con F1 y Accuracy por fold\n",
    "- `wilcoxon_results.csv`: Tests estadísticos de cada arquitectura vs baseline\n",
    "- `statistical_summary.json`: Resumen con test de Friedman y estadísticas globales\n",
    "\n",
    "#### 2. **Visualizaciones (PNG)**:\n",
    "- `arch_sweep_comparison.png`: Gráfico de barras con errorbars y significancia\n",
    "- `arch_sweep_heatmaps.png`: 2 heatmaps (F1-score y parámetros por configuración)\n",
    "- `arch_sweep_pvalues.png`: Gráfico de -log₁₀(p-value) para significancia visual\n",
    "- `arch_sweep_table.png`: Tabla formateada con todos los resultados\n",
    "\n",
    "#### 3. **Modelos Guardados**:\n",
    "- Cada fold de cada arquitectura se guarda en: `arch_sweep_5fold/<arch_id>/<arch_id>/fold{X}/`\n",
    "\n",
    "### 🧪 Tests Estadísticos:\n",
    "\n",
    "#### Test de Wilcoxon (pareado):\n",
    "- **Hipótesis nula**: No hay diferencia entre la arquitectura y el baseline\n",
    "- **Alternativa**: Hay diferencia significativa (two-sided)\n",
    "- **Nivel de significancia**: α = 0.05\n",
    "- **Ventaja**: No asume normalidad, apropiado para n=5 folds\n",
    "\n",
    "#### Test de Friedman:\n",
    "- **Hipótesis nula**: No hay diferencias entre ninguna de las arquitecturas\n",
    "- **Alternativa**: Al menos una arquitectura es diferente\n",
    "- **Ventaja**: Alternativa no paramétrica a ANOVA para medidas repetidas\n",
    "\n",
    "### 🔬 Para tu Tesis:\n",
    "\n",
    "#### Preguntas de investigación que puedes responder:\n",
    "1. **¿El número de bloques depthwise afecta el rendimiento?**\n",
    "   - Analiza el heatmap de F1 vs bloques\n",
    "   \n",
    "2. **¿Más attention heads siempre es mejor?**\n",
    "   - Compara columnas del heatmap (heads fijos, variar bloques)\n",
    "   \n",
    "3. **¿Existe un trade-off entre complejidad y rendimiento?**\n",
    "   - Compara heatmap de F1 vs heatmap de parámetros\n",
    "   \n",
    "4. **¿Qué arquitectura es estadísticamente superior?**\n",
    "   - Usa los resultados del test de Wilcoxon\n",
    "   \n",
    "5. **¿Las diferencias son significativas en general?**\n",
    "   - Usa el resultado del test de Friedman\n",
    "\n",
    "#### Cómo reportar en la tesis:\n",
    "```\n",
    "Se evaluaron 9 configuraciones arquitectónicas diferentes utilizando 5-fold \n",
    "subject-independent cross-validation. El test de Friedman reveló diferencias \n",
    "significativas entre las arquitecturas (χ² = X.XX, p < 0.05). \n",
    "\n",
    "El análisis post-hoc mediante test de Wilcoxon pareado identificó que la \n",
    "arquitectura nb2_h6 (2 bloques depthwise, 6 attention heads) obtuvo el mejor \n",
    "rendimiento con F1-score = 0.XXXX ± 0.XXXX, siendo significativamente superior \n",
    "al baseline (p = 0.XXX).\n",
    "```\n",
    "\n",
    "### 📝 Uso Básico:\n",
    "\n",
    "```python\n",
    "# 1. Ejecutar sweep completo\n",
    "df_results = run_arch_sweep_5folds(\n",
    "    device=DEVICE,\n",
    "    base_blocks=2,\n",
    "    deltas=(-2, 0, +2),\n",
    "    head_set=(2, 4, 6)\n",
    ")\n",
    "\n",
    "# 2. Análisis estadístico\n",
    "stats = analyze_arch_sweep_statistical(\n",
    "    df_results=df_results,\n",
    "    baseline_arch='nb2_h6',\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "# 3. Visualizar resultados\n",
    "plot_arch_sweep_results(\n",
    "    df_results=df_results,\n",
    "    df_wilcoxon=stats['wilcoxon_results']\n",
    ")\n",
    "\n",
    "# 4. Ejecutar ganador con todos los artefactos\n",
    "winner = df_results.iloc[0]['arch_id']\n",
    "winner_results = run_winner_architecture(\n",
    "    device=DEVICE,\n",
    "    arch_id=winner\n",
    ")\n",
    "```\n",
    "\n",
    "### ⚠️ Notas Importantes:\n",
    "\n",
    "1. **Reproducibilidad**: La semilla se fija por fold (RANDOM_STATE + fold_idx)\n",
    "2. **Comparabilidad**: Todas las arquitecturas usan los mismos 5 folds\n",
    "3. **Artefactos**: Se guardan modelos, métricas, y visualizaciones por fold\n",
    "4. **Memoria**: El proceso limpia GPU después de cada fold\n",
    "5. **Errores**: Maneja excepciones y continúa con siguiente arquitectura\n",
    "\n",
    "### 🎯 Arquitectura Baseline Recomendada:\n",
    "\n",
    "Por defecto se usa **nb2_h6** como baseline (2 bloques, 6 heads), pero puedes cambiarlo:\n",
    "- Si ya tienes un modelo entrenado, usa ese como baseline\n",
    "- Si no, el sweep identificará automáticamente el mejor\n",
    "\n",
    "### 📈 Interpretación de Resultados:\n",
    "\n",
    "- **p < 0.01**: Evidencia muy fuerte de diferencia\n",
    "- **p < 0.05**: Evidencia moderada de diferencia\n",
    "- **p ≥ 0.05**: No hay evidencia de diferencia significativa\n",
    "\n",
    "Los gráficos están codificados por colores:\n",
    "- 🔴 **Rojo/Salmon**: Diferencias significativas\n",
    "- 🔵 **Azul**: No significativas\n",
    "- 🟢 **Verde**: Mejor arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bb134",
   "metadata": {},
   "source": [
    "---\n",
    "## BÚSQUEDA ESTADÍSTICA DE HIPERPARÁMETROS (Grid Search)\n",
    "\n",
    "Esta sección implementa una búsqueda exhaustiva robusta sobre el modelo ganador **nb2_h6** utilizando 5-fold Cross-Validation para cada combinación de hiperparámetros.\n",
    "\n",
    "### Objetivo:\n",
    "Evaluar sistemáticamente variaciones estadísticas del modelo base para encontrar la configuración óptima y preparar datos para análisis estadístico (test de Wilcoxon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c5b0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de Grid Search estadístico definidas\n",
      "✓ Funciones de Grid Search y Entrenamiento de Modelo Ganador definidas\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# GRID SEARCH ESTADÍSTICO\n",
    "# =========================\n",
    "\n",
    "def run_statistical_grid_search(device, folds_json=None, output_dir=None, metric='f1'):\n",
    "    \"\"\"\n",
    "    Realiza búsqueda exhaustiva (Grid Search) robusta sobre el modelo ganador nb2_h6.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from itertools import product\n",
    "    \n",
    "    # Configuración\n",
    "    if folds_json is None:\n",
    "        folds_json = FOLDS_JSON\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'grid_search'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    # ========================================\n",
    "    # PARÁMETROS FIJOS (BASELINE nb2_h6)\n",
    "    # ========================================\n",
    "    FIXED_PARAMS = {\n",
    "        'model_name': 'nb2_h6',\n",
    "        'd_model': 144,\n",
    "        'n_blocks': 2,\n",
    "        'n_heads': 6,\n",
    "        'warmup_epochs': 4,\n",
    "        'patience': 12,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs': EPOCHS,\n",
    "    }\n",
    "    \n",
    "    # ========================================\n",
    "    # ESPACIO DE BÚSQUEDA (GRID)\n",
    "    # ========================================\n",
    "    GRID_PARAMS = {\n",
    "        'learning_rates': [5e-4, 1e-3],\n",
    "        'dropouts': [0.1, 0.2],\n",
    "        'encoder_layers': [1, 2]\n",
    "    }\n",
    "    \n",
    "    # Generar todas las combinaciones\n",
    "    param_combinations = list(product(\n",
    "        GRID_PARAMS['learning_rates'],\n",
    "        GRID_PARAMS['dropouts'],\n",
    "        GRID_PARAMS['encoder_layers']\n",
    "    ))\n",
    "    \n",
    "    total_configs = len(param_combinations)\n",
    "    total_runs = total_configs * 5  # 5 folds por combinación\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"GRID SEARCH ESTADÍSTICO - Modelo Ganador nb2_h6\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nParámetros Fijos:\")\n",
    "    for k, v in FIXED_PARAMS.items():\n",
    "        print(f\"  • {k}: {v}\")\n",
    "    \n",
    "    print(f\"\\nEspacio de Búsqueda:\")\n",
    "    for k, v in GRID_PARAMS.items():\n",
    "        print(f\"  • {k}: {v}\")\n",
    "    \n",
    "    print(f\"\\nTotal de configuraciones: {total_configs}\")\n",
    "    print(f\"Total de entrenamientos: {total_runs} ({total_configs} configs × 5 folds)\")\n",
    "    print(f\"Métrica objetivo: {metric.upper()}\")\n",
    "    print(f\"Directorio de salida: {output_dir}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    results = []\n",
    "    \n",
    "    # ========================================\n",
    "    # GRID SEARCH LOOP\n",
    "    # ========================================\n",
    "    for config_idx, (lr, dropout, n_layers) in enumerate(param_combinations, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CONFIGURACIÓN {config_idx}/{total_configs}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Learning Rate: {lr}\")\n",
    "        print(f\"Dropout: {dropout} (CNN + Encoder)\")\n",
    "        print(f\"Encoder Layers: {n_layers}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Crear configuración completa\n",
    "        config = {\n",
    "            'config_id': f'config_{config_idx:02d}',\n",
    "            'learning_rate': lr,\n",
    "            'dropout': dropout,\n",
    "            'encoder_layers': n_layers,\n",
    "            **FIXED_PARAMS\n",
    "        }\n",
    "        \n",
    "        # Resultados de los 5 folds\n",
    "        fold_scores = []\n",
    "        n_params = None\n",
    "        \n",
    "        # ========================================\n",
    "        # 5-FOLD CROSS-VALIDATION\n",
    "        # ========================================\n",
    "        for fold_idx in range(1, 6):\n",
    "            print(f\"\\n--- Fold {fold_idx}/5 ---\")\n",
    "            seed_everything(RANDOM_STATE + fold_idx)\n",
    "            \n",
    "            try:\n",
    "                # Cargar datos del fold\n",
    "                train_subs, test_subs = load_fold_subjects(folds_json, fold_idx)\n",
    "                print(f\"Train: {len(train_subs)} sujetos | Test: {len(test_subs)} sujetos\")\n",
    "                \n",
    "                # Cargar y preparar datos\n",
    "                X_train_list, y_train_list = [], []\n",
    "                for sid in tqdm(train_subs, desc=\"Cargando train\", leave=False):\n",
    "                    X, y, _ = load_subject_epochs(\n",
    "                        sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS,\n",
    "                        DO_CAR, BP_LO, BP_HI\n",
    "                    )\n",
    "                    if X.shape[0] > 0:\n",
    "                        X_train_list.append(X)\n",
    "                        y_train_list.append(y)\n",
    "                \n",
    "                X_test_list, y_test_list = [], []\n",
    "                for sid in tqdm(test_subs, desc=\"Cargando test\", leave=False):\n",
    "                    X, y, _ = load_subject_epochs(\n",
    "                        sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS,\n",
    "                        DO_CAR, BP_LO, BP_HI\n",
    "                    )\n",
    "                    if X.shape[0] > 0:\n",
    "                        X_test_list.append(X)\n",
    "                        y_test_list.append(y)\n",
    "                \n",
    "                X_train = np.concatenate(X_train_list, axis=0)\n",
    "                y_train = np.concatenate(y_train_list, axis=0)\n",
    "                X_test = np.concatenate(X_test_list, axis=0)\n",
    "                y_test = np.concatenate(y_test_list, axis=0)\n",
    "                \n",
    "                # Estandarizar\n",
    "                X_train, X_test = standardize_per_channel(X_train, X_test)\n",
    "                \n",
    "                print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")\n",
    "                \n",
    "                # Crear modelo con la configuración actual\n",
    "                model = EEGCNNTransformer(\n",
    "                    n_ch=8,\n",
    "                    n_cls=2,\n",
    "                    d_model=config['d_model'],\n",
    "                    n_heads=config['n_heads'],\n",
    "                    n_layers=n_layers,\n",
    "                    p_drop=dropout,\n",
    "                    p_drop_encoder=dropout,\n",
    "                    n_dw_blocks=config['n_blocks'],\n",
    "                    capture_attn=False\n",
    "                ).to(device)\n",
    "                \n",
    "                if n_params is None:\n",
    "                    n_params = count_params(model)\n",
    "                    print(f\"Parámetros del modelo: {n_params:,}\")\n",
    "                \n",
    "                # Preparar DataLoader\n",
    "                train_dataset = TensorDataset(\n",
    "                    torch.tensor(X_train, dtype=torch.float32),\n",
    "                    torch.tensor(y_train, dtype=torch.long)\n",
    "                )\n",
    "                \n",
    "                if USE_WEIGHTED_SAMPLER:\n",
    "                    class_counts = np.bincount(y_train)\n",
    "                    class_weights = 1.0 / (class_counts + 1e-6)\n",
    "                    sample_weights = class_weights[y_train]\n",
    "                    sampler = WeightedRandomSampler(\n",
    "                        weights=sample_weights,\n",
    "                        num_samples=len(sample_weights),\n",
    "                        replacement=True\n",
    "                    )\n",
    "                    train_loader = DataLoader(\n",
    "                        train_dataset, batch_size=config['batch_size'],\n",
    "                        sampler=sampler, worker_init_fn=seed_worker,\n",
    "                        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                    )\n",
    "                else:\n",
    "                    train_loader = DataLoader(\n",
    "                        train_dataset, batch_size=config['batch_size'], shuffle=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                    )\n",
    "                \n",
    "                # Pérdida y optimizador\n",
    "                alpha = torch.tensor([1.0, 1.0], device=device)\n",
    "                criterion = FocalLoss(alpha=alpha, gamma=1.5)\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer, T_max=config['epochs'], eta_min=1e-6\n",
    "                )\n",
    "                \n",
    "                # EMA\n",
    "                ema = ModelEMA(model, decay=EMA_DECAY, device=device) if USE_EMA else None\n",
    "                \n",
    "                # ========================================\n",
    "                # TRAINING LOOP\n",
    "                # ========================================\n",
    "                best_val_score = 0.0\n",
    "                patience_counter = 0\n",
    "                \n",
    "                for epoch in range(config['epochs']):\n",
    "                    model.train()\n",
    "                    train_loss = 0.0\n",
    "                    \n",
    "                    for xb, yb in train_loader:\n",
    "                        xb, yb = xb.to(device), yb.to(device)\n",
    "                        \n",
    "                        # Augmentación después de warmup\n",
    "                        if epoch >= config['warmup_epochs']:\n",
    "                            xb = augment_batch(xb)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model(xb)\n",
    "                        loss = criterion(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if ema is not None:\n",
    "                            ema.update(model)\n",
    "                        \n",
    "                        train_loss += loss.item()\n",
    "                    \n",
    "                    scheduler.step()\n",
    "                    \n",
    "                    # Validación\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                        logits = model(X_test_t)\n",
    "                        y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                        \n",
    "                        if metric == 'f1':\n",
    "                            val_score = f1_score(y_test, y_pred, average='macro')\n",
    "                        else:\n",
    "                            val_score = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    # Logging cada 10 epochs\n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        print(f\"Epoch {epoch+1}/{config['epochs']} | \"\n",
    "                              f\"Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "                              f\"Val {metric}: {val_score:.4f}\")\n",
    "                    \n",
    "                    # Early stopping\n",
    "                    if val_score > best_val_score:\n",
    "                        best_val_score = val_score\n",
    "                        patience_counter = 0\n",
    "                        # Guardar mejor modelo\n",
    "                        model_path = output_dir / f\"{config['config_id']}_fold{fold_idx}.pt\"\n",
    "                        torch.save(model.state_dict(), model_path)\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        if patience_counter >= config['patience']:\n",
    "                            print(f\"Early stopping en epoch {epoch+1}\")\n",
    "                            break\n",
    "                \n",
    "                # Cargar mejor modelo y evaluar\n",
    "                model.load_state_dict(torch.load(output_dir / f\"{config['config_id']}_fold{fold_idx}.pt\"))\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                    logits = model(X_test_t)\n",
    "                    y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                \n",
    "                # Calcular métricas finales\n",
    "                if metric == 'f1':\n",
    "                    final_score = f1_score(y_test, y_pred, average='macro')\n",
    "                else:\n",
    "                    final_score = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                fold_scores.append(final_score)\n",
    "                \n",
    "                print(f\"✓ Fold {fold_idx} completado: {metric} = {final_score:.4f}\")\n",
    "                \n",
    "                # Limpiar memoria\n",
    "                del model, optimizer, scheduler, train_loader, X_train, y_train\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ ERROR en Fold {fold_idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                fold_scores.append(0.0)\n",
    "        \n",
    "        # ========================================\n",
    "        # COMPILAR RESULTADOS DE ESTA CONFIG\n",
    "        # ========================================\n",
    "        result_row = {\n",
    "            'config_id': config['config_id'],\n",
    "            'learning_rate': lr,\n",
    "            'dropout': dropout,\n",
    "            'encoder_layers': n_layers,\n",
    "            'fold_1': fold_scores[0] if len(fold_scores) > 0 else 0.0,\n",
    "            'fold_2': fold_scores[1] if len(fold_scores) > 1 else 0.0,\n",
    "            'fold_3': fold_scores[2] if len(fold_scores) > 2 else 0.0,\n",
    "            'fold_4': fold_scores[3] if len(fold_scores) > 3 else 0.0,\n",
    "            'fold_5': fold_scores[4] if len(fold_scores) > 4 else 0.0,\n",
    "            'mean_score': np.mean(fold_scores) if fold_scores else 0.0,\n",
    "            'std_score': np.std(fold_scores) if fold_scores else 0.0,\n",
    "            'n_params': n_params if n_params else 0\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(f\"RESUMEN CONFIG {config_idx}:\")\n",
    "        print(f\"  Scores por fold: {[f'{s:.4f}' for s in fold_scores]}\")\n",
    "        print(f\"  Media ± Std: {result_row['mean_score']:.4f} ± {result_row['std_score']:.4f}\")\n",
    "        print(f\"{'─'*80}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # COMPILAR RESULTADOS FINALES\n",
    "    # ========================================\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Ordenar por mean_score descendente\n",
    "    df_results = df_results.sort_values('mean_score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    csv_path = output_dir / 'grid_search_results.csv'\n",
    "    df_results.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GRID SEARCH COMPLETADO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nResultados guardados en: {csv_path}\")\n",
    "    print(f\"\\nMejor configuración:\")\n",
    "    best = df_results.iloc[0]\n",
    "    print(f\"  • Config ID: {best['config_id']}\")\n",
    "    print(f\"  • Learning Rate: {best['learning_rate']}\")\n",
    "    print(f\"  • Dropout: {best['dropout']}\")\n",
    "    print(f\"  • Encoder Layers: {int(best['encoder_layers'])}\")\n",
    "    print(f\"  • {metric.capitalize()} Score: {best['mean_score']:.4f} ± {best['std_score']:.4f}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "def plot_grid_search_results(df_results, output_dir=None, metric='f1'):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones de los resultados del grid search.\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'grid_search'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    # Crear etiquetas descriptivas\n",
    "    df_results['config_label'] = df_results.apply(\n",
    "        lambda row: f\"LR={row['learning_rate']:.0e}\\nDO={row['dropout']}\\nL={int(row['encoder_layers'])}\",\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # GRÁFICO 1: Barras con errorbar\n",
    "    # ========================================\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    x = np.arange(len(df_results))\n",
    "    ax.bar(x, df_results['mean_score'], yerr=df_results['std_score'],\n",
    "           capsize=5, color='steelblue', alpha=0.8, edgecolor='navy')\n",
    "    \n",
    "    ax.set_xlabel('Configuración', fontsize=12)\n",
    "    ax.set_ylabel(f'{metric.upper()} Score', fontsize=12)\n",
    "    ax.set_title(f'Comparación de Configuraciones - Grid Search (nb2_h6)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_results['config_label'], rotation=45, ha='right', fontsize=9)\n",
    "    ax.axhline(y=df_results['mean_score'].iloc[0], color='red', linestyle='--', alpha=0.5, label='Mejor')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = output_dir / 'grid_search_comparison.png'\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Gráfico guardado: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # ========================================\n",
    "    # GRÁFICO 2: Heatmap de interacciones\n",
    "    # ========================================\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # LR vs Dropout (promediando layers)\n",
    "    pivot1 = df_results.pivot_table(\n",
    "        values='mean_score',\n",
    "        index='dropout',\n",
    "        columns='learning_rate',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    im1 = axes[0].imshow(pivot1, cmap='YlOrRd', aspect='auto')\n",
    "    axes[0].set_title('LR vs Dropout')\n",
    "    axes[0].set_xlabel('Learning Rate')\n",
    "    axes[0].set_ylabel('Dropout')\n",
    "    axes[0].set_xticks(range(len(pivot1.columns)))\n",
    "    axes[0].set_xticklabels([f'{v:.0e}' for v in pivot1.columns], rotation=45)\n",
    "    axes[0].set_yticks(range(len(pivot1.index)))\n",
    "    axes[0].set_yticklabels(pivot1.index)\n",
    "    for i in range(len(pivot1.index)):\n",
    "        for j in range(len(pivot1.columns)):\n",
    "            axes[0].text(j, i, f'{pivot1.iloc[i, j]:.3f}',\n",
    "                         ha='center', va='center', color='black', fontsize=10)\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # LR vs Layers (promediando dropout)\n",
    "    pivot2 = df_results.pivot_table(\n",
    "        values='mean_score',\n",
    "        index='encoder_layers',\n",
    "        columns='learning_rate',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    im2 = axes[1].imshow(pivot2, cmap='YlOrRd', aspect='auto')\n",
    "    axes[1].set_title('LR vs Encoder Layers')\n",
    "    axes[1].set_xlabel('Learning Rate')\n",
    "    axes[1].set_ylabel('Encoder Layers')\n",
    "    axes[1].set_xticks(range(len(pivot2.columns)))\n",
    "    axes[1].set_xticklabels([f'{v:.0e}' for v in pivot2.columns], rotation=45)\n",
    "    axes[1].set_yticks(range(len(pivot2.index)))\n",
    "    axes[1].set_yticklabels([int(v) for v in pivot2.index])\n",
    "    for i in range(len(pivot2.index)):\n",
    "        for j in range(len(pivot2.columns)):\n",
    "            axes[1].text(j, i, f'{pivot2.iloc[i, j]:.3f}',\n",
    "                         ha='center', va='center', color='black', fontsize=10)\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    \n",
    "    # Dropout vs Layers (promediando LR)\n",
    "    pivot3 = df_results.pivot_table(\n",
    "        values='mean_score',\n",
    "        index='encoder_layers',\n",
    "        columns='dropout',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    im3 = axes[2].imshow(pivot3, cmap='YlOrRd', aspect='auto')\n",
    "    axes[2].set_title('Dropout vs Encoder Layers')\n",
    "    axes[2].set_xlabel('Dropout')\n",
    "    axes[2].set_ylabel('Encoder Layers')\n",
    "    axes[2].set_xticks(range(len(pivot3.columns)))\n",
    "    axes[2].set_xticklabels(pivot3.columns)\n",
    "    axes[2].set_yticks(range(len(pivot3.index)))\n",
    "    axes[2].set_yticklabels([int(v) for v in pivot3.index])\n",
    "    for i in range(len(pivot3.index)):\n",
    "        for j in range(len(pivot3.columns)):\n",
    "            axes[2].text(j, i, f'{pivot3.iloc[i, j]:.3f}',\n",
    "                         ha='center', va='center', color='black', fontsize=10)\n",
    "    plt.colorbar(im3, ax=axes[2])\n",
    "    \n",
    "    plt.suptitle('Heatmaps de Interacciones entre Hiperparámetros', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    heatmap_path = output_dir / 'grid_search_heatmaps.png'\n",
    "    plt.savefig(heatmap_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Heatmaps guardados: {heatmap_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # ========================================\n",
    "    # TABLA RESUMEN\n",
    "    # ========================================\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = []\n",
    "    for idx, row in df_results.iterrows():\n",
    "        table_data.append([\n",
    "            row['config_id'],\n",
    "            f\"{row['learning_rate']:.0e}\",\n",
    "            f\"{row['dropout']:.1f}\",\n",
    "            f\"{int(row['encoder_layers'])}\",\n",
    "            f\"{row['mean_score']:.4f} ± {row['std_score']:.4f}\",\n",
    "            f\"{row['n_params']:,}\"\n",
    "        ])\n",
    "    \n",
    "    table = ax.table(cellText=table_data,\n",
    "                     colLabels=['Config ID', 'LR', 'Dropout', 'Layers', f'{metric.upper()} Score', 'Params'],\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Colorear la mejor fila\n",
    "    for i in range(6):\n",
    "        table[(1, i)].set_facecolor('#90EE90')\n",
    "    \n",
    "    plt.title('Tabla Resumen - Grid Search nb2_h6', fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    table_path = output_dir / 'grid_search_table.png'\n",
    "    plt.savefig(table_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Tabla guardada: {table_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "print(\"✓ Funciones de Grid Search estadístico definidas\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ENTRENAR MODELO GANADOR CON HIPERPARÁMETROS PERSONALIZADOS\n",
    "# =========================\n",
    "\n",
    "def train_winner_model(\n",
    "    device,\n",
    "    learning_rate=1e-3,\n",
    "    dropout=0.2,\n",
    "    encoder_layers=1,\n",
    "    warmup_epochs=4,\n",
    "    patience=12,\n",
    "    d_model=144,\n",
    "    n_heads=6,\n",
    "    n_blocks=2,\n",
    "    batch_size=None,\n",
    "    epochs=None,\n",
    "    folds_json=None,\n",
    "    output_dir=None,\n",
    "    model_tag='winner'\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena el modelo ganador con hiperparámetros personalizados en los 5 folds.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    import shutil # Import necesario para copiar archivos\n",
    "    \n",
    "    # Configuración\n",
    "    if batch_size is None:\n",
    "        batch_size = BATCH_SIZE\n",
    "    if epochs is None:\n",
    "        epochs = EPOCHS\n",
    "    if folds_json is None:\n",
    "        folds_json = FOLDS_JSON\n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'winner_model'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    tag = f\"{model_tag}_lr{learning_rate:.0e}_do{dropout}_el{encoder_layers}\"\n",
    "    base_dir = ensure_dir(output_dir / tag)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ENTRENAR MODELO GANADOR - Configuración Personalizada\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nHiperparámetros del Modelo:\")\n",
    "    print(f\"  • Learning Rate: {learning_rate}\")\n",
    "    print(f\"  • Dropout (CNN + Encoder): {dropout}\")\n",
    "    print(f\"  • Encoder Layers: {encoder_layers}\")\n",
    "    print(f\"  • Warmup Epochs: {warmup_epochs}\")\n",
    "    print(f\"  • Patience: {patience}\")\n",
    "    print(f\"  • d_model: {d_model}\")\n",
    "    print(f\"  • Attention Heads: {n_heads}\")\n",
    "    print(f\"  • Depthwise Blocks: {n_blocks}\")\n",
    "    print(f\"  • Batch Size: {batch_size}\")\n",
    "    print(f\"  • Max Epochs: {epochs}\")\n",
    "    print(f\"\\nDirectorio de salida: {base_dir}\")\n",
    "    print(f\"Tag del modelo: {tag}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Resultados por fold\n",
    "    acc_folds, f1_folds = [], []\n",
    "    fold_results = []\n",
    "    \n",
    "    # Acumuladores para visualizaciones globales\n",
    "    global_cm = np.zeros((2, 2), dtype=int)\n",
    "    saliency_list = []\n",
    "    pvals_log_list = []\n",
    "    \n",
    "    # Factory del modelo con los hiperparámetros personalizados\n",
    "    def model_factory():\n",
    "        return EEGCNNTransformer(\n",
    "            n_ch=8,\n",
    "            n_cls=2,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            n_layers=encoder_layers,\n",
    "            p_drop=dropout,\n",
    "            p_drop_encoder=dropout,\n",
    "            n_dw_blocks=n_blocks,\n",
    "            capture_attn=True\n",
    "        ).to(device)\n",
    "    \n",
    "    # ========================================\n",
    "    # ENTRENAR LOS 5 FOLDS\n",
    "    # ========================================\n",
    "    for fold_idx in range(1, 6):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"FOLD {fold_idx}/5\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        seed_everything(RANDOM_STATE + fold_idx)\n",
    "        fold_dir = ensure_dir(base_dir / f\"fold{fold_idx}\")\n",
    "        \n",
    "        try:\n",
    "            # Cargar datos del fold\n",
    "            train_subs, test_subs = load_fold_subjects(folds_json, fold_idx)\n",
    "            print(f\"Train: {len(train_subs)} sujetos | Test: {len(test_subs)} sujetos\")\n",
    "            \n",
    "            # Cargar datos\n",
    "            X_train_list, y_train_list = [], []\n",
    "            for sid in tqdm(train_subs, desc=\"Cargando train\", leave=False):\n",
    "                X, y, _ = load_subject_epochs(\n",
    "                    sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS,\n",
    "                    DO_CAR, BP_LO, BP_HI\n",
    "                )\n",
    "                if X.shape[0] > 0:\n",
    "                    X_train_list.append(X)\n",
    "                    y_train_list.append(y)\n",
    "            \n",
    "            X_test_list, y_test_list = [], []\n",
    "            for sid in tqdm(test_subs, desc=\"Cargando test\", leave=False):\n",
    "                X, y, _ = load_subject_epochs(\n",
    "                    sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS,\n",
    "                    DO_CAR, BP_LO, BP_HI\n",
    "                )\n",
    "                if X.shape[0] > 0:\n",
    "                    X_test_list.append(X)\n",
    "                    y_test_list.append(y)\n",
    "            \n",
    "            X_train = np.concatenate(X_train_list, axis=0)\n",
    "            y_train = np.concatenate(y_train_list, axis=0)\n",
    "            X_test = np.concatenate(X_test_list, axis=0)\n",
    "            y_test = np.concatenate(y_test_list, axis=0)\n",
    "            \n",
    "            # Estandarizar\n",
    "            X_train, X_test = standardize_per_channel(X_train, X_test)\n",
    "            \n",
    "            print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")\n",
    "            \n",
    "            # Guardar datos de test para visualizaciones posteriores\n",
    "            np.save(fold_dir / \"y_test.npy\", y_test)\n",
    "            \n",
    "            # Crear modelo\n",
    "            model = model_factory()\n",
    "            n_params = count_params(model)\n",
    "            print(f\"Parámetros del modelo: {n_params:,}\")\n",
    "            \n",
    "            # DataLoader\n",
    "            train_dataset = TensorDataset(\n",
    "                torch.tensor(X_train, dtype=torch.float32),\n",
    "                torch.tensor(y_train, dtype=torch.long)\n",
    "            )\n",
    "            \n",
    "            if USE_WEIGHTED_SAMPLER:\n",
    "                class_counts = np.bincount(y_train)\n",
    "                class_weights = 1.0 / (class_counts + 1e-6)\n",
    "                sample_weights = class_weights[y_train]\n",
    "                sampler = WeightedRandomSampler(\n",
    "                    weights=sample_weights,\n",
    "                    num_samples=len(sample_weights),\n",
    "                    replacement=True\n",
    "                )\n",
    "                train_loader = DataLoader(\n",
    "                    train_dataset, batch_size=batch_size,\n",
    "                    sampler=sampler, worker_init_fn=seed_worker,\n",
    "                    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                )\n",
    "            else:\n",
    "                train_loader = DataLoader(\n",
    "                    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                    worker_init_fn=seed_worker,\n",
    "                    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                )\n",
    "            \n",
    "            # Optimizador y scheduler\n",
    "            alpha = torch.tensor([1.0, 1.0], device=device)\n",
    "            criterion = FocalLoss(alpha=alpha, gamma=1.5)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "            \n",
    "            # Scheduler con warmup\n",
    "            def lr_lambda(current_epoch):\n",
    "                if current_epoch < warmup_epochs:\n",
    "                    return (current_epoch + 1) / warmup_epochs\n",
    "                progress = (current_epoch - warmup_epochs) / max(1, (epochs - warmup_epochs))\n",
    "                progress = min(1.0, max(0.0, progress))\n",
    "                return 0.1 + 0.5 * (1.0 - 0.1) * (1.0 + np.cos(np.pi * progress))\n",
    "            \n",
    "            scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "            \n",
    "            # EMA\n",
    "            ema = ModelEMA(model, decay=EMA_DECAY, device=device) if USE_EMA else None\n",
    "            \n",
    "            # ========================================\n",
    "            # TRAINING LOOP\n",
    "            # ========================================\n",
    "            best_val_f1 = 0.0\n",
    "            patience_counter = 0\n",
    "            history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": [], \"lr\": []}\n",
    "            \n",
    "            # Medir tiempo y memoria de entrenamiento\n",
    "            import time\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.reset_peak_memory_stats(device)\n",
    "            t_train_start = time.time()\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "                n_train_batches = 0\n",
    "                \n",
    "                for xb, yb in train_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    \n",
    "                    # Augmentación después de warmup\n",
    "                    if epoch >= warmup_epochs:\n",
    "                        xb = augment_batch(xb)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    if ema is not None:\n",
    "                        ema.update(model)\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                    n_train_batches += 1\n",
    "                \n",
    "                scheduler.step()\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                \n",
    "                # Validación\n",
    "                eval_model = ema.ema if (ema is not None) else model\n",
    "                eval_model.eval()\n",
    "                \n",
    "                val_loss = 0.0\n",
    "                n_val_batches = 0\n",
    "                y_pred_list = []\n",
    "                y_true_list = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # Evaluar por batches para calcular val_loss\n",
    "                    for i in range(0, len(X_test), batch_size):\n",
    "                        X_batch = X_test[i:i+batch_size]\n",
    "                        y_batch = y_test[i:i+batch_size]\n",
    "                        \n",
    "                        X_batch_t = torch.tensor(X_batch, dtype=torch.float32, device=device)\n",
    "                        y_batch_t = torch.tensor(y_batch, dtype=torch.long, device=device)\n",
    "                        \n",
    "                        logits = eval_model(X_batch_t)\n",
    "                        loss = criterion(logits, y_batch_t)\n",
    "                        val_loss += loss.item()\n",
    "                        n_val_batches += 1\n",
    "                        \n",
    "                        y_pred_batch = logits.argmax(dim=1).cpu().numpy()\n",
    "                        y_pred_list.append(y_pred_batch)\n",
    "                        y_true_list.append(y_batch)\n",
    "                    \n",
    "                    y_pred = np.concatenate(y_pred_list)\n",
    "                    y_true = np.concatenate(y_true_list)\n",
    "                    \n",
    "                    val_acc = accuracy_score(y_true, y_pred)\n",
    "                    val_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "                \n",
    "                # Guardar historia\n",
    "                history[\"epoch\"].append(epoch + 1)\n",
    "                history[\"train_loss\"].append(train_loss / n_train_batches)\n",
    "                history[\"val_loss\"].append(val_loss / n_val_batches)\n",
    "                history[\"val_acc\"].append(val_acc)\n",
    "                history[\"val_f1\"].append(val_f1)\n",
    "                history[\"lr\"].append(current_lr)\n",
    "                \n",
    "                # Logging cada 10 epochs\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "                          f\"TrLoss: {train_loss/n_train_batches:.4f} | ValLoss: {val_loss/n_val_batches:.4f} | \"\n",
    "                          f\"ValAcc: {val_acc:.4f} | ValF1: {val_f1:.4f} | LR: {current_lr:.2e}\")\n",
    "                \n",
    "                # Early stopping\n",
    "                if val_f1 > best_val_f1:\n",
    "                    best_val_f1 = val_f1\n",
    "                    patience_counter = 0\n",
    "                    # Guardar mejor modelo\n",
    "                    model_path = fold_dir / f\"best_model_fold{fold_idx}.pt\"\n",
    "                    torch.save(eval_model.state_dict(), model_path)\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping en epoch {epoch+1}\")\n",
    "                        break\n",
    "            \n",
    "            # Medir tiempo de entrenamiento\n",
    "            t_train_end = time.time()\n",
    "            train_time_s = t_train_end - t_train_start\n",
    "            train_mem_mb = 0.0\n",
    "            if torch.cuda.is_available():\n",
    "                train_mem_mb = torch.cuda.max_memory_allocated(device) / (1024.0 ** 2)\n",
    "            \n",
    "            # Guardar historia\n",
    "            history_path = fold_dir / f\"history_fold{fold_idx}_{tag}.npz\"\n",
    "            np.savez(\n",
    "                history_path,\n",
    "                ep=np.array(history[\"epoch\"]),\n",
    "                tr_loss=np.array(history[\"train_loss\"]),\n",
    "                val_loss=np.array(history[\"val_loss\"]),\n",
    "                val_acc=np.array(history[\"val_acc\"]),\n",
    "                val_f1=np.array(history[\"val_f1\"]),\n",
    "                lr=np.array(history[\"lr\"])\n",
    "            )\n",
    "            \n",
    "            # ========================================\n",
    "            # GENERAR CURVAS DE LOSS POR FOLD\n",
    "            # ========================================\n",
    "            try:\n",
    "                fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "                ax.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
    "                ax.plot(history[\"epoch\"], history[\"val_loss\"], label=\"Val Loss\", linewidth=2)\n",
    "                ax.set_xlabel(\"Epoch\")\n",
    "                ax.set_ylabel(\"Loss\")\n",
    "                ax.set_title(f\"Loss Curve — Fold {fold_idx} [{tag}]\")\n",
    "                ax.legend()\n",
    "                ax.grid(alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                fig_path = fold_dir / f\"loss_curve_fold{fold_idx}_{tag}.png\"\n",
    "                plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Error al generar curva de loss fold {fold_idx}: {e}\")\n",
    "            \n",
    "            # Medir tiempo y memoria de TEST\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.reset_peak_memory_stats(device)\n",
    "            t_test_start = time.time()\n",
    "            with torch.no_grad():\n",
    "                X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                logits = model(X_test_t)\n",
    "                y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            # Cerrar cronómetro de TEST\n",
    "            t_test_end = time.time()\n",
    "            test_time_s = t_test_end - t_test_start\n",
    "            test_mem_mb = 0.0\n",
    "            if torch.cuda.is_available():\n",
    "                test_mem_mb = torch.cuda.max_memory_allocated(device) / (1024.0 ** 2)\n",
    "            \n",
    "            # Métricas finales\n",
    "            final_acc = accuracy_score(y_test, y_pred)\n",
    "            final_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            acc_folds.append(final_acc)\n",
    "            f1_folds.append(final_f1)\n",
    "            \n",
    "            # Matriz de confusión\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "            global_cm += cm\n",
    "            \n",
    "            # Guardar matriz de confusión del fold\n",
    "            cm_png = fold_dir / f\"confusion_fold{fold_idx}.png\"\n",
    "            plot_confusion_with_text(\n",
    "                cm=cm,\n",
    "                class_names=CLASS_NAMES,\n",
    "                title=f\"Confusion Matrix — Fold {fold_idx} [{tag}]\",\n",
    "                out_path=cm_png,\n",
    "                cmap='Blues'\n",
    "            )\n",
    "            \n",
    "            # Classification report\n",
    "            report = classification_report(\n",
    "                y_test, y_pred,\n",
    "                target_names=[c.replace('_', ' ') for c in CLASS_NAMES],\n",
    "                digits=4\n",
    "            )\n",
    "            print(f\"\\nClassification Report - Fold {fold_idx}:\")\n",
    "            print(report)\n",
    "            \n",
    "            # Guardar report\n",
    "            with open(fold_dir / f\"classification_report_fold{fold_idx}.txt\", 'w') as f:\n",
    "                f.write(report)\n",
    "            \n",
    "            # ========================================\n",
    "            # INTERPRETABILIDAD\n",
    "            # ========================================\n",
    "            try:\n",
    "                # Channel saliency\n",
    "                xb_ex = X_test[:1]\n",
    "                xb_ex_t = torch.tensor(xb_ex, dtype=torch.float32, device=device)\n",
    "                pred_cls = int(model(xb_ex_t).argmax(1).item())\n",
    "                \n",
    "                saliency_ch = channel_saliency(model, xb_ex_t, target_class=pred_cls)\n",
    "                np.save(fold_dir / f\"saliency_channels_fold{fold_idx}.npy\", saliency_ch)\n",
    "                saliency_list.append(saliency_ch)\n",
    "                \n",
    "                # Topomap de saliency\n",
    "                info_topo = make_mne_info_8ch(sfreq=160.0)\n",
    "                topo_sal_png = fold_dir / f\"topomap_saliency_fold{fold_idx}.png\"\n",
    "                plot_topomap_from_values(\n",
    "                    saliency_ch,\n",
    "                    info_topo,\n",
    "                    title=f\"Channel Saliency — Fold {fold_idx} [{tag}]\",\n",
    "                    out_path=topo_sal_png,\n",
    "                    cmap=\"Reds\",\n",
    "                    cbar_label=\"Normalized saliency\"\n",
    "                )\n",
    "                \n",
    "                # -log10(p) left vs right\n",
    "                pvals = compute_channel_pvalues_lr(X_test, y_test)\n",
    "                pvals_log = -np.log10(pvals + 1e-12)\n",
    "                np.save(fold_dir / f\"pvals_log_channels_fold{fold_idx}.npy\", pvals_log)\n",
    "                pvals_log_list.append(pvals_log)\n",
    "                \n",
    "                # Topomap de -log10(p)\n",
    "                topo_p_png = fold_dir / f\"topomap_log10p_fold{fold_idx}.png\"\n",
    "                plot_topomap_from_values(\n",
    "                    pvals_log,\n",
    "                    info_topo,\n",
    "                    title=f\"-log10(p) Left vs Right — Fold {fold_idx} [{tag}]\",\n",
    "                    out_path=topo_p_png,\n",
    "                    cmap=\"viridis\",\n",
    "                    cbar_label=\"-log10(p)\"\n",
    "                )\n",
    "                \n",
    "                print(f\"✓ Interpretabilidad generada para fold {fold_idx}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Error en interpretabilidad fold {fold_idx}: {e}\")\n",
    "            \n",
    "            # ========================================\n",
    "            # MÉTRICAS DE CONSUMO COMPUTACIONAL\n",
    "            # ========================================\n",
    "            # Estimar FLOPs y latencia ( solo la primera vez)\n",
    "            flops_est = 0\n",
    "            latency_s = 0.0\n",
    "            \n",
    "            if fold_idx == 1:  # Solo calcular una vez  (mismo modelo para todos los folds)\n",
    "                try:\n",
    "                    # Calcular dimensiones para FLOPs\n",
    "                    with torch.no_grad():\n",
    "                        x_dummy = torch.randn(1, 8, X_test.shape[-1], device=device)\n",
    "                        z = model.conv_t(x_dummy)\n",
    "                        z = model.proj(z).transpose(1, 2)\n",
    "                        L, d = z.shape[1], z.shape[2]\n",
    "                    \n",
    "                    flops_est = estimate_transformer_flops(L=L, d=d, n_heads=n_heads, n_layers=encoder_layers)\n",
    "                    \n",
    "                    # Benchmark latencia\n",
    "                    x_sample = X_test[:min(8, len(X_test))]\n",
    "                    x_sample_t = torch.tensor(x_sample, dtype=torch.float32, device=device)\n",
    "                    latency_s = benchmark_latency(model, x_sample_t, device, n_warm=10, n_runs=50)\n",
    "                    \n",
    "                    print(f\"  ✓ FLOPs estimados: {flops_est/1e9:.2f} G\")\n",
    "                    print(f\"  ✓ Latencia: {latency_s*1000:.2f} ms\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠ Error al calcular FLOPs/latencia: {e}\")\n",
    "            \n",
    "            # Resultado del fold con métricas de consumo\n",
    "            fold_result = {\n",
    "                'fold': fold_idx,\n",
    "                'accuracy': final_acc,\n",
    "                'f1_macro': final_f1,\n",
    "                'n_params': n_params,\n",
    "                'best_epoch': len(history[\"epoch\"]),\n",
    "                'train_time_s': train_time_s,\n",
    "                'train_mem_mb': train_mem_mb,\n",
    "                'test_time_s': test_time_s,\n",
    "                'test_mem_mb': test_mem_mb,\n",
    "                'flops_est': flops_est if fold_idx == 1 else 0,\n",
    "                'latency_s': latency_s if fold_idx == 1 else 0.0\n",
    "            }\n",
    "            fold_results.append(fold_result)\n",
    "            \n",
    "            print(f\"\\n✓ Fold {fold_idx} completado:\")\n",
    "            print(f\"  Accuracy: {final_acc:.4f}\")\n",
    "            print(f\"  F1-score: {final_f1:.4f}\")\n",
    "            \n",
    "            # Limpiar memoria\n",
    "            del model, optimizer, scheduler, train_loader, X_train, y_train\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ ERROR en Fold {fold_idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            acc_folds.append(0.0)\n",
    "            f1_folds.append(0.0)\n",
    "    \n",
    "    # ========================================\n",
    "    # RESULTADOS GLOBALES\n",
    "    # ========================================\n",
    "    mean_acc = np.mean(acc_folds)\n",
    "    std_acc = np.std(acc_folds)\n",
    "    mean_f1 = np.mean(f1_folds)\n",
    "    std_f1 = np.std(f1_folds)\n",
    "    best_fold = np.argmax(f1_folds) + 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTADOS FINALES - MODELO GANADOR\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nAccuracy por fold: {[f'{a:.4f}' for a in acc_folds]}\")\n",
    "    print(f\"Accuracy promedio: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"\\nF1-score por fold: {[f'{f:.4f}' for f in f1_folds]}\")\n",
    "    print(f\"F1-score promedio: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "    print(f\"\\nMejor fold: {best_fold} (F1 = {f1_folds[best_fold-1]:.4f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Guardar resumen\n",
    "    summary_df = pd.DataFrame(fold_results)\n",
    "    summary_df.to_csv(base_dir / f\"summary_{tag}.csv\", index=False)\n",
    "    print(f\"\\n✓ Resumen guardado: {base_dir / f'summary_{tag}.csv'}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # VISUALIZACIONES GLOBALES\n",
    "    # ========================================\n",
    "    print(\"\\nGenerando visualizaciones globales...\")\n",
    "    \n",
    "    # 1. Matriz de confusión global\n",
    "    try:\n",
    "        cm_global_png = base_dir / f\"confusion_global_{tag}.png\"\n",
    "        plot_confusion_with_text(\n",
    "            cm=global_cm,\n",
    "            class_names=CLASS_NAMES,\n",
    "            title=f\"Confusion Matrix — Global (5 folds) [{tag}]\",\n",
    "            out_path=cm_global_png,\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        print(f\"  ✓ Matriz de confusión global: {cm_global_png.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Error en matriz de confusión: {e}\")\n",
    "    \n",
    "    # 2. Curvas de entrenamiento\n",
    "    try:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        for fold_idx in range(1, 6):\n",
    "            hist_path = base_dir / f\"fold{fold_idx}\" / f\"history_fold{fold_idx}_{tag}.npz\"\n",
    "            if hist_path.exists():\n",
    "                data = np.load(hist_path)\n",
    "                axes[0].plot(data[\"ep\"], data[\"tr_loss\"], alpha=0.5, label=f\"Fold {fold_idx}\")\n",
    "                axes[1].plot(data[\"ep\"], data[\"val_f1\"], alpha=0.5, label=f\"Fold {fold_idx}\")\n",
    "        \n",
    "        axes[0].set_xlabel(\"Epoch\")\n",
    "        axes[0].set_ylabel(\"Training Loss\")\n",
    "        axes[0].set_title(\"Training Loss Evolution\")\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(alpha=0.3)\n",
    "        \n",
    "        axes[1].set_xlabel(\"Epoch\")\n",
    "        axes[1].set_ylabel(\"Validation F1-score\")\n",
    "        axes[1].set_title(\"Validation F1-score Evolution\")\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        training_curves_png = base_dir / f\"training_curves_{tag}.png\"\n",
    "        plt.savefig(training_curves_png, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Curvas de entrenamiento: {training_curves_png.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Error en curvas de entrenamiento: {e}\")\n",
    "    \n",
    "    # 3. Topomaps globales (promedio de los 5 folds)\n",
    "    try:\n",
    "        info_topo_global = make_mne_info_8ch(sfreq=160.0)\n",
    "        \n",
    "        if len(saliency_list) > 0:\n",
    "            sal_mean = np.mean(np.stack(saliency_list, axis=0), axis=0)\n",
    "            topo_sal_global_png = base_dir / f\"topomap_saliency_GLOBAL_{tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                sal_mean,\n",
    "                info_topo_global,\n",
    "                title=f\"Channel Saliency — GLOBAL (5 folds) [{tag}]\",\n",
    "                out_path=topo_sal_global_png,\n",
    "                cmap=\"Reds\",\n",
    "                cbar_label=\"Normalized saliency\"\n",
    "            )\n",
    "            print(f\"  ✓ Topomap global de saliency: {topo_sal_global_png.name}\")\n",
    "        \n",
    "        if len(pvals_log_list) > 0:\n",
    "            pvals_log_mean = np.mean(np.stack(pvals_log_list, axis=0), axis=0)\n",
    "            topo_p_global_png = base_dir / f\"topomap_log10p_GLOBAL_{tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                pvals_log_mean,\n",
    "                info_topo_global,\n",
    "                title=f\"-log10(p) Left vs Right — GLOBAL (5 folds) [{tag}]\",\n",
    "                out_path=topo_p_global_png,\n",
    "                cmap=\"viridis\",\n",
    "                cbar_label=\"-log10(p)\"\n",
    "            )\n",
    "            print(f\"  ✓ Topomap global de -log10(p): {topo_p_global_png.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Error en topomaps globales: {e}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # GUARDAR MÉTRICAS COMPUTACIONALES Y RETORNAR\n",
    "    # ========================================\n",
    "    try:\n",
    "        # Calcular promedios de consumo\n",
    "        train_times = [fr['train_time_s'] for fr in fold_results if fr['train_time_s'] > 0]\n",
    "        train_mems = [fr['train_mem_mb'] for fr in fold_results if fr['train_mem_mb'] > 0]\n",
    "        test_times = [fr['test_time_s'] for fr in fold_results if fr['test_time_s'] > 0]\n",
    "        test_mems = [fr['test_mem_mb'] for fr in fold_results if fr['test_mem_mb'] > 0]\n",
    "        \n",
    "        train_time_mean = np.mean(train_times) if train_times else 0.0\n",
    "        train_time_std = np.std(train_times) if train_times else 0.0\n",
    "        train_mem_mean = np.mean(train_mems) if train_mems else 0.0\n",
    "        train_mem_std = np.std(train_mems) if train_mems else 0.0\n",
    "        test_time_mean = np.mean(test_times) if test_times else 0.0\n",
    "        test_time_std = np.std(test_times) if test_times else 0.0\n",
    "        test_mem_mean = np.mean(test_mems) if test_mems else 0.0\n",
    "        test_mem_std = np.std(test_mems) if test_mems else 0.0\n",
    "        \n",
    "        # FLOPs y latencia (del primer fold)\n",
    "        flops_est = fold_results[0]['flops_est'] if fold_results else 0\n",
    "        latency_s = fold_results[0]['latency_s'] if fold_results else 0.0\n",
    "        n_params_total = fold_results[0]['n_params'] if fold_results else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MÉTRICAS DE CONSUMO COMPUTACIONAL\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nModelo: {tag}\")\n",
    "        print(f\"Parámetros: {n_params_total:,} ({n_params_total/1e6:.2f}M)\")\n",
    "        print(f\"FLOPs estimados: {flops_est/1e9:.2f} G\")\n",
    "        print(f\"Latencia: {latency_s*1000:.2f} ms\")\n",
    "        print(f\"\\nTiempo de entrenamiento: {train_time_mean:.2f} ± {train_time_std:.2f} s\")\n",
    "        print(f\"Memoria de entrenamiento: {train_mem_mean:.1f} ± {train_mem_std:.1f} MB\")\n",
    "        print(f\"Tiempo de test: {test_time_mean:.2f} ± {test_time_std:.2f} s\")\n",
    "        print(f\"Memoria de test: {test_mem_mean:.1f} ± {test_mem_std:.1f} MB\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        consumption_df = pd.DataFrame([{\n",
    "            'model_tag': tag,\n",
    "            'n_params': n_params_total,\n",
    "            'params_M': n_params_total / 1e6,\n",
    "            'flops_G': flops_est / 1e9,\n",
    "            'latency_ms': latency_s * 1000,\n",
    "            'train_time_mean_s': train_time_mean,\n",
    "            'train_time_std_s': train_time_std,\n",
    "            'train_mem_mean_mb': train_mem_mean,\n",
    "            'train_mem_std_mb': train_mem_std,\n",
    "            'test_time_mean_s': test_time_mean,\n",
    "            'test_time_std_s': test_time_std,\n",
    "            'test_mem_mean_mb': test_mem_mean,\n",
    "            'test_mem_std_mb': test_mem_std\n",
    "        }])\n",
    "        \n",
    "        consumption_path = base_dir / f'computational_metrics_{tag}.csv'\n",
    "        consumption_df.to_csv(consumption_path, index=False)\n",
    "        print(f\"\\n  ✓ Métricas de consumo guardadas: {consumption_path.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Error al generar métricas de consumo: {e}\")\n",
    "        n_params_total = 0\n",
    "\n",
    "    # Construir diccionario de resultados final\n",
    "    results = {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_acc': mean_acc,\n",
    "        'std_acc': std_acc,\n",
    "        'mean_f1': mean_f1,\n",
    "        'std_f1': std_f1,\n",
    "        'best_fold': best_fold,\n",
    "        'output_dir': base_dir,\n",
    "        'model_tag': tag,\n",
    "        'n_params': n_params_total\n",
    "    }\n",
    "    \n",
    "    # Copiar mejor modelo\n",
    "    try:\n",
    "        best_model_src = base_dir / f\"fold{best_fold}\" / f\"best_model_fold{best_fold}.pt\"\n",
    "        best_model_dst = base_dir / f\"final_model_{tag}.pt\"\n",
    "        \n",
    "        if best_model_src.exists():\n",
    "            shutil.copy(best_model_src, best_model_dst)\n",
    "            print(f\"\\n✓ Modelo final guardado: {best_model_dst.name}\")\n",
    "            print(f\"  (Copiado del mejor fold: {best_fold})\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ No se encontró el modelo del fold {best_fold}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠ Error al copiar modelo final: {e}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"✓ ENTRENAMIENTO COMPLETADO\")\n",
    "    print(f\"  Directorio: {base_dir}\")\n",
    "    print(f\"  Modelo final: final_model_{tag}.pt\")\n",
    "    print(f\"  Resultados: summary_{tag}.csv\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Funciones de Grid Search y Entrenamiento de Modelo Ganador definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380f343",
   "metadata": {},
   "source": [
    "### Ejecución del Grid Search\n",
    "\n",
    "Ejecuta la búsqueda estadística de hiperparámetros sobre el modelo ganador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cac99d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRID SEARCH ESTADÍSTICO - Modelo Ganador nb2_h6\n",
      "================================================================================\n",
      "\n",
      "ADVERTENCIA: Este proceso puede tardar varias horas.\n",
      "  • 8 configuraciones × 5 folds = 40 entrenamientos completos\n",
      "  • Tiempo estimado: ~4-6 horas (depende de GPU/hardware)\n",
      "\n",
      "================================================================================\n",
      "GRID SEARCH ESTADÍSTICO - Modelo Ganador nb2_h6\n",
      "================================================================================\n",
      "\n",
      "Parámetros Fijos:\n",
      "  • model_name: nb2_h6\n",
      "  • d_model: 144\n",
      "  • n_blocks: 2\n",
      "  • n_heads: 6\n",
      "  • warmup_epochs: 4\n",
      "  • patience: 12\n",
      "  • batch_size: 64\n",
      "  • epochs: 60\n",
      "\n",
      "Espacio de Búsqueda:\n",
      "  • learning_rates: [0.0005, 0.001]\n",
      "  • dropouts: [0.1, 0.2]\n",
      "  • encoder_layers: [1, 2]\n",
      "\n",
      "Total de configuraciones: 8\n",
      "Total de entrenamientos: 40 (8 configs × 5 folds)\n",
      "Métrica objetivo: F1\n",
      "Directorio de salida: /root/Proyecto/EEG_Clasificador/models/04_hybrid/grid_search\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CONFIGURACIÓN 1/8\n",
      "================================================================================\n",
      "Learning Rate: 0.0005\n",
      "Dropout: 0.1 (CNN + Encoder)\n",
      "Encoder Layers: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Train: 82 sujetos | Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961) | Test: (882, 8, 961)\n",
      "Parámetros del modelo: 232,290\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-41c525d2d544>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Ejecutar grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     df_grid_results = run_statistical_grid_search(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mfolds_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOLDS_JSON\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-512dd44de985>\u001b[0m in \u001b[0;36mrun_statistical_grid_search\u001b[0;34m(device, folds_json, output_dir, metric)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-359cf97cc42d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# Encoder Transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-359cf97cc42d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlyr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mattn_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-359cf97cc42d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msa_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_attn_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6371\u001b[0m             )\n\u001b[1;32m   6372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6373\u001b[0;31m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6374\u001b[0m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# EJECUTAR GRID SEARCH\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GRID SEARCH ESTADÍSTICO - Modelo Ganador nb2_h6\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Configuración\n",
    "    metric_to_optimize = 'f1'  # Opciones: 'f1' o 'accuracy'\n",
    "    \n",
    "    print(\"ADVERTENCIA: Este proceso puede tardar varias horas.\")\n",
    "    print(f\"  • 8 configuraciones × 5 folds = 40 entrenamientos completos\")\n",
    "    print(f\"  • Tiempo estimado: ~4-6 horas (depende de GPU/hardware)\\n\")\n",
    "    \n",
    "    # Ejecutar grid search\n",
    "    df_grid_results = run_statistical_grid_search(\n",
    "        device=DEVICE,\n",
    "        folds_json=FOLDS_JSON,\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'grid_search',\n",
    "        metric=metric_to_optimize\n",
    "    )\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTADOS DEL GRID SEARCH\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_grid_results.to_string(index=False))\n",
    "    \n",
    "    # Generar visualizaciones\n",
    "    print(\"\\nGenerando visualizaciones...\")\n",
    "    plot_grid_search_results(\n",
    "        df_grid_results,\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'grid_search',\n",
    "        metric=metric_to_optimize\n",
    "    )\n",
    "    \n",
    "    # Análisis estadístico comparativo\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS ESTADÍSTICO COMPARATIVO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Comparar mejor vs baseline (primera config)\n",
    "    best_config = df_grid_results.iloc[0]\n",
    "    baseline_config = df_grid_results[df_grid_results['config_id'] == 'config_01'].iloc[0]\n",
    "    \n",
    "    print(\"Mejor configuración:\")\n",
    "    print(f\"  • LR: {best_config['learning_rate']:.0e}\")\n",
    "    print(f\"  • Dropout: {best_config['dropout']}\")\n",
    "    print(f\"  • Layers: {int(best_config['encoder_layers'])}\")\n",
    "    print(f\"  • Score: {best_config['mean_score']:.4f} ± {best_config['std_score']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBaseline (config_01):\")\n",
    "    print(f\"  • LR: {baseline_config['learning_rate']:.0e}\")\n",
    "    print(f\"  • Dropout: {baseline_config['dropout']}\")\n",
    "    print(f\"  • Layers: {int(baseline_config['encoder_layers'])}\")\n",
    "    print(f\"  • Score: {baseline_config['mean_score']:.4f} ± {baseline_config['std_score']:.4f}\")\n",
    "    \n",
    "    improvement = ((best_config['mean_score'] - baseline_config['mean_score']) / baseline_config['mean_score']) * 100\n",
    "    print(f\"\\nMejora relativa: {improvement:+.2f}%\")\n",
    "    \n",
    "    # Preparar datos para test de Wilcoxon\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATOS PARA TEST DE WILCOXON\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(\"Para comparar la mejor configuración vs baseline usando test de Wilcoxon:\")\n",
    "    print(\"\\nScores por fold - Mejor configuración:\")\n",
    "    best_scores = [best_config[f'fold_{i}'] for i in range(1, 6)]\n",
    "    print(f\"  {best_scores}\")\n",
    "    \n",
    "    print(\"\\nScores por fold - Baseline:\")\n",
    "    baseline_scores = [baseline_config[f'fold_{i}'] for i in range(1, 6)]\n",
    "    print(f\"  {baseline_scores}\")\n",
    "    \n",
    "    # Test de Wilcoxon\n",
    "    from scipy.stats import wilcoxon\n",
    "    \n",
    "    try:\n",
    "        stat, p_value = wilcoxon(best_scores, baseline_scores)\n",
    "        print(f\"\\nResultado del Test de Wilcoxon:\")\n",
    "        print(f\"  • Estadístico: {stat:.4f}\")\n",
    "        print(f\"  • p-valor: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"  • Conclusión: Diferencia SIGNIFICATIVA (p < 0.05) ✓\")\n",
    "        else:\n",
    "            print(f\"  • Conclusión: Diferencia NO significativa (p ≥ 0.05)\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nNo se pudo realizar el test de Wilcoxon: {e}\")\n",
    "        print(\"(Puede ocurrir si las diferencias son todas cero)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GRID SEARCH COMPLETADO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nResultados guardados en: {PROJ / 'models' / '04_hybrid' / 'grid_search'}\")\n",
    "    print(\"  • grid_search_results.csv - Datos completos\")\n",
    "    print(\"  • grid_search_comparison.png - Gráfico de barras\")\n",
    "    print(\"  • grid_search_heatmaps.png - Heatmaps de interacciones\")\n",
    "    print(\"  • grid_search_table.png - Tabla resumen\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559ae64",
   "metadata": {},
   "source": [
    "---\n",
    "## ENTRENAR MODELO GANADOR\n",
    "\n",
    "Esta sección permite entrenar directamente el modelo ganador con hiperparámetros personalizados, ejecutar los 5 folds y generar todos los artefactos y visualizaciones.\n",
    "\n",
    "### 🏆 Modelo Ganador (nb2_h6):\n",
    "\n",
    "**Arquitectura Base**:\n",
    "- **Embedding dimension** (`d_model`): 144\n",
    "- **Attention Heads**: 6\n",
    "- **Depthwise Blocks**: 2\n",
    "- **Encoder Layers**: 1\n",
    "\n",
    "**Hiperparámetros Optimizados**:\n",
    "- **Learning Rate**: 1e-3 (0.001)\n",
    "- **Dropout**: 0.2 (aplicado a CNN y Encoder)\n",
    "- **Warmup Epochs**: 4\n",
    "- **Patience**: 12\n",
    "\n",
    "### 📊 Artefactos Generados:\n",
    "\n",
    "1. **Modelos Guardados**:\n",
    "   - `best_model_fold{1-5}.pt`: Mejor modelo de cada fold\n",
    "   - `final_model_<tag>.pt`: Modelo final (copiado del mejor fold)\n",
    "\n",
    "2. **Métricas y Resultados**:\n",
    "   - `summary_<tag>.csv`: Resultados por fold en formato CSV\n",
    "   - `classification_report_fold{1-5}.txt`: Reporte completo de clasificación\n",
    "   - `history_fold{1-5}_<tag>.npz`: Historial de entrenamiento (loss, acc, f1, lr)\n",
    "\n",
    "3. **Visualizaciones Globales**:\n",
    "   - `confusion_global_<tag>.png`: Matriz de confusión agregada de los 5 folds\n",
    "   - `training_curves_<tag>.png`: Curvas de loss y F1 por fold\n",
    "   - `metrics_per_fold_<tag>.png`: Barras comparativas de accuracy y F1 por fold\n",
    "   - `topomap_saliency_GLOBAL_<tag>.png`: Topomap promedio de saliency\n",
    "   - `topomap_log10p_GLOBAL_<tag>.png`: Topomap promedio de -log10(p)\n",
    "\n",
    "4. **Visualizaciones por Fold**:\n",
    "   - `confusion_fold{1-5}.png`: Matriz de confusión de cada fold\n",
    "   - `topomap_saliency_fold{1-5}.png`: Canal saliency por fold\n",
    "   - `topomap_log10p_fold{1-5}.png`: Significancia estadística por canal\n",
    "\n",
    "### ⏱️ Tiempo Estimado:\n",
    "- **Por fold**: ~5-10 minutos\n",
    "- **Total (5 folds)**: ~25-50 minutos (depende del hardware)\n",
    "\n",
    "### 📝 Uso Básico:\n",
    "\n",
    "```python\n",
    "# Entrenar con hiperparámetros por defecto (modelo ganador)\n",
    "results = train_winner_model(\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Entrenar con hiperparámetros personalizados\n",
    "results = train_winner_model(\n",
    "    device=DEVICE,\n",
    "    learning_rate=1e-3,\n",
    "    dropout=0.2,\n",
    "    encoder_layers=1,\n",
    "    warmup_epochs=4,\n",
    "    patience=12,\n",
    "    d_model=144,\n",
    "    n_heads=6,\n",
    "    n_blocks=2,\n",
    "    model_tag='winner_custom'\n",
    ")\n",
    "```\n",
    "\n",
    "### 🔍 Estructura de Resultados:\n",
    "\n",
    "```python\n",
    "results = {\n",
    "    'fold_results': [     # Lista con resultados de cada fold\n",
    "        {\n",
    "            'fold': 1,\n",
    "            'accuracy': 0.XXXX,\n",
    "            'f1_macro': 0.XXXX,\n",
    "            'n_params': XXXXX,\n",
    "            'best_epoch': XX\n",
    "        },\n",
    "        ...\n",
    "    ],\n",
    "    'mean_acc': 0.XXXX,   # Accuracy promedio\n",
    "    'std_acc': 0.XXXX,    # Desviación estándar de accuracy\n",
    "    'mean_f1': 0.XXXX,    # F1-score promedio\n",
    "    'std_f1': 0.XXXX,     # Desviación estándar de F1\n",
    "    'best_fold': X,       # Número del mejor fold\n",
    "    'output_dir': Path,   # Directorio con todos los archivos\n",
    "    'model_tag': 'winner' # Tag del modelo\n",
    "}\n",
    "```\n",
    "\n",
    "### ⚠️ Notas Importantes:\n",
    "\n",
    "1. **Reproducibilidad**: Usa semillas fijas por fold (RANDOM_STATE + fold_idx)\n",
    "2. **Memoria**: Limpia GPU automáticamente después de cada fold\n",
    "3. **Early Stopping**: Se aplica con la paciencia configurada\n",
    "4. **Scheduler**: Usa warmup + cosine annealing\n",
    "5. **Augmentación**: Se activa después de los epochs de warmup\n",
    "6. **EMA**: Se usa Model EMA si USE_EMA=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2956acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTRENAR MODELO GANADOR - Configuración Personalizada\n",
      "================================================================================\n",
      "\n",
      "Hiperparámetros del Modelo:\n",
      "  • Learning Rate: 0.001\n",
      "  • Dropout (CNN + Encoder): 0.2\n",
      "  • Encoder Layers: 1\n",
      "  • Warmup Epochs: 4\n",
      "  • Patience: 12\n",
      "  • d_model: 144\n",
      "  • Attention Heads: 6\n",
      "  • Depthwise Blocks: 2\n",
      "  • Batch Size: 64\n",
      "  • Max Epochs: 60\n",
      "\n",
      "Directorio de salida: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "Tag del modelo: winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1/5\n",
      "================================================================================\n",
      "Train: 82 sujetos | Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961) | Test: (882, 8, 961)\n",
      "Parámetros del modelo: 232,290\n",
      "Epoch 10/60 | TrLoss: 0.0695 | ValLoss: 0.0820 | ValAcc: 0.7993 | ValF1: 0.7993 | LR: 9.75e-04\n",
      "Epoch 20/60 | TrLoss: 0.0601 | ValLoss: 0.0801 | ValAcc: 0.7993 | ValF1: 0.7993 | LR: 8.31e-04\n",
      "Epoch 30/60 | TrLoss: 0.0553 | ValLoss: 0.0804 | ValAcc: 0.7959 | ValF1: 0.7959 | LR: 6.00e-04\n",
      "Early stopping en epoch 35\n",
      "\n",
      "Classification Report - Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7946    0.8073    0.8009       441\n",
      "       right     0.8041    0.7914    0.7977       441\n",
      "\n",
      "    accuracy                         0.7993       882\n",
      "   macro avg     0.7994    0.7993    0.7993       882\n",
      "weighted avg     0.7994    0.7993    0.7993       882\n",
      "\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold1/topomap_saliency_fold1.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold1/topomap_log10p_fold1.png\n",
      "✓ Interpretabilidad generada para fold 1\n",
      "  ✓ FLOPs estimados: 0.02 G\n",
      "  ✓ Latencia: 1.13 ms\n",
      "\n",
      "✓ Fold 1 completado:\n",
      "  Accuracy: 0.7993\n",
      "  F1-score: 0.7993\n",
      "\n",
      "================================================================================\n",
      "FOLD 2/5\n",
      "================================================================================\n",
      "Train: 82 sujetos | Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961) | Test: (882, 8, 961)\n",
      "Parámetros del modelo: 232,290\n",
      "Epoch 10/60 | TrLoss: 0.0680 | ValLoss: 0.0718 | ValAcc: 0.8333 | ValF1: 0.8333 | LR: 9.75e-04\n",
      "Epoch 20/60 | TrLoss: 0.0578 | ValLoss: 0.0717 | ValAcc: 0.8367 | ValF1: 0.8367 | LR: 8.31e-04\n",
      "Early stopping en epoch 28\n",
      "\n",
      "Classification Report - Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7923    0.8912    0.8388       441\n",
      "       right     0.8756    0.7664    0.8174       441\n",
      "\n",
      "    accuracy                         0.8288       882\n",
      "   macro avg     0.8340    0.8288    0.8281       882\n",
      "weighted avg     0.8340    0.8288    0.8281       882\n",
      "\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold2/topomap_saliency_fold2.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold2/topomap_log10p_fold2.png\n",
      "✓ Interpretabilidad generada para fold 2\n",
      "\n",
      "✓ Fold 2 completado:\n",
      "  Accuracy: 0.8288\n",
      "  F1-score: 0.8281\n",
      "\n",
      "================================================================================\n",
      "FOLD 3/5\n",
      "================================================================================\n",
      "Train: 82 sujetos | Test: 21 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3444, 8, 961) | Test: (882, 8, 961)\n",
      "Parámetros del modelo: 232,290\n",
      "Epoch 10/60 | TrLoss: 0.0718 | ValLoss: 0.0811 | ValAcc: 0.7971 | ValF1: 0.7959 | LR: 9.75e-04\n",
      "Epoch 20/60 | TrLoss: 0.0599 | ValLoss: 0.0840 | ValAcc: 0.8084 | ValF1: 0.8084 | LR: 8.31e-04\n",
      "Epoch 30/60 | TrLoss: 0.0516 | ValLoss: 0.0843 | ValAcc: 0.8095 | ValF1: 0.8095 | LR: 6.00e-04\n",
      "Early stopping en epoch 39\n",
      "\n",
      "Classification Report - Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8176    0.8027    0.8101       441\n",
      "       right     0.8062    0.8209    0.8135       441\n",
      "\n",
      "    accuracy                         0.8118       882\n",
      "   macro avg     0.8119    0.8118    0.8118       882\n",
      "weighted avg     0.8119    0.8118    0.8118       882\n",
      "\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold3/topomap_saliency_fold3.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold3/topomap_log10p_fold3.png\n",
      "✓ Interpretabilidad generada para fold 3\n",
      "\n",
      "✓ Fold 3 completado:\n",
      "  Accuracy: 0.8118\n",
      "  F1-score: 0.8118\n",
      "\n",
      "================================================================================\n",
      "FOLD 4/5\n",
      "================================================================================\n",
      "Train: 83 sujetos | Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961) | Test: (840, 8, 961)\n",
      "Parámetros del modelo: 232,290\n",
      "Epoch 10/60 | TrLoss: 0.0731 | ValLoss: 0.0726 | ValAcc: 0.8298 | ValF1: 0.8296 | LR: 9.75e-04\n",
      "Early stopping en epoch 16\n",
      "\n",
      "Classification Report - Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8139    0.8643    0.8383       420\n",
      "       right     0.8553    0.8024    0.8280       420\n",
      "\n",
      "    accuracy                         0.8333       840\n",
      "   macro avg     0.8346    0.8333    0.8332       840\n",
      "weighted avg     0.8346    0.8333    0.8332       840\n",
      "\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold4/topomap_saliency_fold4.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold4/topomap_log10p_fold4.png\n",
      "✓ Interpretabilidad generada para fold 4\n",
      "\n",
      "✓ Fold 4 completado:\n",
      "  Accuracy: 0.8333\n",
      "  F1-score: 0.8332\n",
      "\n",
      "================================================================================\n",
      "FOLD 5/5\n",
      "================================================================================\n",
      "Train: 83 sujetos | Test: 20 sujetos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3486, 8, 961) | Test: (840, 8, 961)\n",
      "Parámetros del modelo: 232,290\n",
      "Epoch 10/60 | TrLoss: 0.0718 | ValLoss: 0.0795 | ValAcc: 0.8036 | ValF1: 0.8006 | LR: 9.75e-04\n",
      "Epoch 20/60 | TrLoss: 0.0604 | ValLoss: 0.0665 | ValAcc: 0.8512 | ValF1: 0.8512 | LR: 8.31e-04\n",
      "Early stopping en epoch 20\n",
      "\n",
      "Classification Report - Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8801    0.7690    0.8208       420\n",
      "       right     0.7949    0.8952    0.8421       420\n",
      "\n",
      "    accuracy                         0.8321       840\n",
      "   macro avg     0.8375    0.8321    0.8315       840\n",
      "weighted avg     0.8375    0.8321    0.8315       840\n",
      "\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold5/topomap_saliency_fold5.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/fold5/topomap_log10p_fold5.png\n",
      "✓ Interpretabilidad generada para fold 5\n",
      "\n",
      "✓ Fold 5 completado:\n",
      "  Accuracy: 0.8321\n",
      "  F1-score: 0.8315\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS FINALES - MODELO GANADOR\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.7993', '0.8288', '0.8118', '0.8333', '0.8321']\n",
      "Accuracy promedio: 0.8211 ± 0.0134\n",
      "\n",
      "F1-score por fold: ['0.7993', '0.8281', '0.8118', '0.8332', '0.8315']\n",
      "F1-score promedio: 0.8208 ± 0.0131\n",
      "\n",
      "Mejor fold: 4 (F1 = 0.8332)\n",
      "================================================================================\n",
      "\n",
      "✓ Resumen guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/summary_winner_nb2_h6_lr1e-03_do0.2_el1.csv\n",
      "\n",
      "Generando visualizaciones globales...\n",
      "  ✓ Matriz de confusión global: confusion_global_winner_nb2_h6_lr1e-03_do0.2_el1.png\n",
      "  ✓ Curvas de entrenamiento: training_curves_winner_nb2_h6_lr1e-03_do0.2_el1.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/topomap_saliency_GLOBAL_winner_nb2_h6_lr1e-03_do0.2_el1.png\n",
      "  ✓ Topomap global de saliency: topomap_saliency_GLOBAL_winner_nb2_h6_lr1e-03_do0.2_el1.png\n",
      "↳ Topomap guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/topomap_log10p_GLOBAL_winner_nb2_h6_lr1e-03_do0.2_el1.png\n",
      "  ✓ Topomap global de -log10(p): topomap_log10p_GLOBAL_winner_nb2_h6_lr1e-03_do0.2_el1.png\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS DE CONSUMO COMPUTACIONAL\n",
      "================================================================================\n",
      "\n",
      "Modelo: winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "Parámetros: 232,290 (0.23M)\n",
      "FLOPs estimados: 0.02 G\n",
      "Latencia: 1.13 ms\n",
      "\n",
      "Tiempo de entrenamiento: 14.11 ± 4.47 s\n",
      "Memoria de entrenamiento: 1074.4 ± 551.0 MB\n",
      "Tiempo de test: 0.01 ± 0.00 s\n",
      "Memoria de test: 1175.4 ± 35.1 MB\n",
      "================================================================================\n",
      "\n",
      "  ✓ Métricas de consumo guardadas: computational_metrics_winner_nb2_h6_lr1e-03_do0.2_el1.csv\n",
      "\n",
      "✓ Modelo final guardado: final_model_winner_nb2_h6_lr1e-03_do0.2_el1.pt\n",
      "  (Copiado del mejor fold: 4)\n",
      "\n",
      "================================================================================\n",
      "✓ ENTRENAMIENTO COMPLETADO\n",
      "  Directorio: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "  Modelo final: final_model_winner_nb2_h6_lr1e-03_do0.2_el1.pt\n",
      "  Resultados: summary_winner_nb2_h6_lr1e-03_do0.2_el1.csv\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "Modelo: winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "Directorio: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "\n",
      "Accuracy: 0.8211 ± 0.0134\n",
      "F1-Score: 0.8208 ± 0.0131\n",
      "\n",
      "Mejor Fold: 4\n",
      "F1 del mejor fold: 0.8332\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Resultados detallados por fold:\n",
      "--------------------------------------------------------------------------------\n",
      "Fold 1: ACC=0.7993, F1=0.7993, Params=232,290, Best Epoch=35\n",
      "Fold 2: ACC=0.8288, F1=0.8281, Params=232,290, Best Epoch=28\n",
      "Fold 3: ACC=0.8118, F1=0.8118, Params=232,290, Best Epoch=39\n",
      "Fold 4: ACC=0.8333, F1=0.8332, Params=232,290, Best Epoch=16\n",
      "Fold 5: ACC=0.8321, F1=0.8315, Params=232,290, Best Epoch=20\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Modelo final guardado en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1/final_model_winner_nb2_h6_lr1e-03_do0.2_el1.pt\n",
      "✓ Todos los gráficos y métricas disponibles en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/winner_model/winner_nb2_h6_lr1e-03_do0.2_el1\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ENTRENAR MODELO GANADOR\n",
    "# =========================\n",
    "\n",
    "# Entrenar el modelo ganador con los hiperparámetros optimizados\n",
    "# Ejecuta los 5 folds y genera todos los gráficos y artefactos\n",
    "\n",
    "results = train_winner_model(\n",
    "    device=DEVICE,\n",
    "    # Hiperparámetros del modelo ganador\n",
    "    learning_rate=1e-3,        # 0.001\n",
    "    dropout=0.2,               # 20% dropout en CNN y Encoder\n",
    "    encoder_layers=1,          # 1 capa de Transformer\n",
    "    warmup_epochs=4,           # 4 épocas de warmup\n",
    "    patience=12,               # Early stopping con paciencia 12\n",
    "    # Arquitectura base (nb2_h6)\n",
    "    d_model=144,               # Dimensión de embedding\n",
    "    n_heads=6,                 # 6 attention heads\n",
    "    n_blocks=2,                # 2 bloques depthwise\n",
    "    # Configuración de entrenamiento\n",
    "    batch_size=BATCH_SIZE,     # Usa batch_size global\n",
    "    epochs=EPOCHS,             # Usa epochs global\n",
    "    # Output\n",
    "    output_dir=PROJ / 'models' / '04_hybrid' / 'winner_model',\n",
    "    model_tag='winner_nb2_h6'  # Tag identificador\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelo: {results['model_tag']}\")\n",
    "print(f\"Directorio: {results['output_dir']}\")\n",
    "print(f\"\\nAccuracy: {results['mean_acc']:.4f} ± {results['std_acc']:.4f}\")\n",
    "print(f\"F1-Score: {results['mean_f1']:.4f} ± {results['std_f1']:.4f}\")\n",
    "print(f\"\\nMejor Fold: {results['best_fold']}\")\n",
    "print(f\"F1 del mejor fold: {results['fold_results'][results['best_fold']-1]['f1_macro']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Mostrar resultados por fold\n",
    "print(\"\\nResultados detallados por fold:\")\n",
    "print(\"-\"*80)\n",
    "for fold_res in results['fold_results']:\n",
    "    print(f\"Fold {fold_res['fold']}: ACC={fold_res['accuracy']:.4f}, F1={fold_res['f1_macro']:.4f}, \"\n",
    "          f\"Params={fold_res['n_params']:,}, Best Epoch={fold_res['best_epoch']}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "final_model_path = results[\"output_dir\"] / f\"final_model_{results['model_tag']}.pt\"\n",
    "print(f\"\\n✓ Modelo final guardado en: {final_model_path}\")\n",
    "print(f\"✓ Todos los gráficos y métricas disponibles en: {results['output_dir']}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
