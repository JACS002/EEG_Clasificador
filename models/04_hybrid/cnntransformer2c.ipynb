{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fe1413",
   "metadata": {},
   "source": [
    "# EEG Motor Imagery (Left/Right) — CNN + Transformer\n",
    "Este notebook entrena y evalúa un modelo CNN+Transformer para clasificación binaria (left/right)\n",
    "en EEG usando K-Fold por sujeto, con opciones de:\n",
    "- Preprocesamiento\n",
    "- Balanceo (WeightedRandomSampler)\n",
    "- EMA de pesos\n",
    "- Inferencia con TTA y/o subventanas\n",
    "- Interpretabilidad\n",
    "- Barrido de arquitectura y evaluación final 5-fold del mejor set de hiperparámetros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f54465",
   "metadata": {},
   "source": [
    "### Configuración Inicial y Reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "959034aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random, copy, time, csv\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, classification_report,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from scipy import stats\n",
    "from sklearn.manifold import TSNE  # Añadido para t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccfe22",
   "metadata": {},
   "source": [
    "### Configuración de Reproducibilidad\n",
    "\n",
    "Esta sección establece las semillas y configuraciones necesarias para garantizar resultados reproducibles en el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc7acf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Establece semillas para todas las bibliotecas de aleatoriedad\n",
    "    para garantizar reproducibilidad completa.\n",
    "    \"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"\n",
    "    Función para inicializar workers de DataLoader con semilla.\n",
    "    \"\"\"\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba0543",
   "metadata": {},
   "source": [
    "### Configuración de Hiperparámetros\n",
    "\n",
    "Definición de todos los hiperparámetros del modelo y preprocesamiento de datos EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ca907ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Usando dispositivo: cuda\n",
      " INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto)\n",
      " Config: 2c (L/R), 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.0005 | ZSCORE_PER_EPOCH=False\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / '00_folds' / 'Kfold5.json'\n",
    "\n",
    "# Hiperparámetros de entrenamiento\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "BASE_LR = 5e-4\n",
    "WARMUP_EPOCHS = 4\n",
    "PATIENCE = 8\n",
    "\n",
    "# Split de validación por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18\n",
    "VAL_STRAT_SUBJECT = True\n",
    "\n",
    "# Prepro global\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Parámetros del modelo\n",
    "D_MODEL = 144\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 1\n",
    "P_DROP = 0.1\n",
    "P_DROP_ENCODER = 0.1\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA / SUBWINDOW en TEST\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.075, -0.05, -0.025, 0.0, 0.025, 0.05, 0.075]\n",
    "SW_LEN, SW_STRIDE = 4.5, 1.5\n",
    "COMBINE_TTA_AND_SUBWIN = False\n",
    "\n",
    "# Sampler balanceado\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# EMA (solo GLOBAL). En FT se desactiva.\n",
    "USE_EMA = True\n",
    "EMA_DECAY = 0.9995\n",
    "\n",
    "# Fine-tuning (por sujeto) — sigue activo, pero ahora con n_cls=2\n",
    "FT_N_FOLDS = 4\n",
    "FT_FREEZE_EPOCHS = 8\n",
    "FT_UNFREEZE_EPOCHS = 8\n",
    "FT_PATIENCE = 6\n",
    "FT_BATCH = 64\n",
    "FT_LR_HEAD = 1e-3\n",
    "FT_LR_BACKBONE = 2e-4\n",
    "FT_WD = 1e-3\n",
    "FT_AUG = dict(p_jitter=0.25, p_noise=0.25, p_chdrop=0.10, max_jitter_frac=0.02, noise_std=0.02, max_chdrop=1)\n",
    "\n",
    "# Configuración de sujetos y canales\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right']  # <-- 2 clases\n",
    "\n",
    "# Solo runs de imaginación L/R\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Usando dispositivo: {DEVICE}\")\n",
    "print(\" INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto)\")\n",
    "print(f\" Config: 2c (L/R), 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a5652",
   "metadata": {},
   "source": [
    "### Funciones de Utilidad para I/O\n",
    "\n",
    "Funciones para manejar la carga y normalización de datos EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06db0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza nombres de canales eliminando caracteres especiales.\n",
    "    \"\"\"\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    \"\"\"\n",
    "    Selecciona los 8 canales motores específicos del dataset.\n",
    "    \"\"\"\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    \"\"\"\n",
    "    Lista archivos EDF de imaginación motora para un sujeto.\n",
    "    \"\"\"\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    \"\"\"\n",
    "    Convierte ID de sujeto de string a entero.\n",
    "    \"\"\"\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    \"\"\"\n",
    "    Carga y preprocesa épocas EEG para un sujeto específico.\n",
    "    \"\"\"\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        # Usar SOLO runs L/R\n",
    "        if run not in IMAGERY_RUNS_LR:\n",
    "            continue\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "\n",
    "        sfreq = raw.info['sfreq']\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = np.array([0 if inv[c] == 'T1' else 1 for c in ev_codes], dtype=int)\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y_run)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    \"\"\"\n",
    "    Carga sujetos de train y test para un fold específico.\n",
    "    \"\"\"\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    \"\"\"\n",
    "    Estandariza datos por canal usando estadísticas del conjunto de entrenamiento.\n",
    "    \"\"\"\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :] = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77134da",
   "metadata": {},
   "source": [
    "### Arquitectura del Modelo: CNN + Transformer\n",
    "\n",
    "Implementación del modelo híbrido CNN-Transformer para clasificación de EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ddb7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MODELO (GroupNorm en conv) con capturas y variaciones\n",
    "# =========================\n",
    "def make_gn(num_channels, num_groups=8):\n",
    "    \"\"\"\n",
    "    Crea capa GroupNorm adaptativa que garantiza divisibilidad.\n",
    "    \"\"\"\n",
    "    g = min(num_groups, num_channels)\n",
    "    while num_channels % g != 0 and g > 1:\n",
    "        g -= 1\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolución depthwise separable para reducción de parámetros.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class _CustomEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Capa personalizada del encoder Transformer con atención multi-cabeza.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout, batch_first, norm_first, return_attn=True):\n",
    "        super().__init__()\n",
    "        self.return_attn = return_attn\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "        self.norm_first = norm_first\n",
    "\n",
    "    def forward(self, src):\n",
    "        sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
    "        src = self.norm1(src + self.dropout1(sa_out))\n",
    "        ff = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = self.norm2(src + self.dropout2(ff))\n",
    "        return src, attn_weights  # [B, heads, T, T]\n",
    "\n",
    "class _CustomEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder Transformer compuesto por múltiples capas.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, src):\n",
    "        attn_list = []\n",
    "        out = src\n",
    "        for lyr in self.layers:\n",
    "            out, attn = lyr(out)\n",
    "            attn_list.append(attn)\n",
    "        return out, attn_list\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo híbrido CNN-Transformer para clasificación de señales EEG.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem convolucional inicial\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise separable\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head de clasificación\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        \"\"\"\n",
    "        Codificación posicional sinusoidal para secuencias.\n",
    "        \"\"\"\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Capas convolucionales\n",
    "        z = self.conv_t(x)           # (B, C', T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        \n",
    "        # Codificación posicional\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # Añadir token CLS\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)  # (B, 1+L, D)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        # Clasificación usando token CLS\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        \"\"\"\n",
    "        Retorna mapas de atención de la última pasada forward.\n",
    "        \"\"\"\n",
    "        return self._last_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac343e4",
   "metadata": {},
   "source": [
    "### Funciones de Pérdida y Aumentación de Datos\n",
    "\n",
    "Implementación de Focal Loss y técnicas de aumentación de datos para EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbe5aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FOCAL LOSS (2 clases)\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss para manejar desbalance de clases.\n",
    "    Reduce la contribución de ejemplos fáciles y enfoca en los difíciles.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS\n",
    "# =========================\n",
    "def augment_batch(xb, p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "                  max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1):\n",
    "    \"\"\"\n",
    "    Aplica aumentación de datos a un batch de señales EEG.\n",
    "    Técnicas: jitter temporal, ruido gaussiano, drop de canales.\n",
    "    \"\"\"\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "def augment_batch_ft(xb):\n",
    "    \"\"\"\n",
    "    Aplica aumentación específica para fine-tuning.\n",
    "    \"\"\"\n",
    "    return augment_batch(xb, **FT_AUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619874d",
   "metadata": {},
   "source": [
    "### EMA y Técnicas de Inferencia\n",
    "\n",
    "Implementación de Exponential Moving Average y técnicas de inferencia robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "980460a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EMA de pesos (solo global)\n",
    "# =========================\n",
    "class ModelEMA:\n",
    "    \"\"\"\n",
    "    Exponential Moving Average para estabilizar el entrenamiento.\n",
    "    Mantiene una versión suavizada de los pesos del modelo.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.9995, device=None):\n",
    "        self.ema = self._clone(model).to(device if device is not None else next(model.parameters()).device)\n",
    "        self.decay = decay\n",
    "        self._updates = 0\n",
    "        self.update(model, force=True)\n",
    "\n",
    "    def _clone(self, model):\n",
    "        import copy\n",
    "        ema = copy.deepcopy(model)\n",
    "        for p in ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        return ema\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module, force: bool = False):\n",
    "        d = self.decay\n",
    "        if self._updates < 1000:\n",
    "            d = (self._updates / 1000.0) * self.decay\n",
    "        msd = model.state_dict()\n",
    "        esd = self.ema.state_dict()\n",
    "        for k in esd.keys():\n",
    "            if esd[k].dtype.is_floating_point:\n",
    "                esd[k].mul_(d).add_(msd[k].detach(), alpha=1.0 - d)\n",
    "            else:\n",
    "                esd[k] = msd[k]\n",
    "        self._updates += 1\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    \"\"\"\n",
    "    Inferencia usando subventanas para capturar información temporal.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(2, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    \"\"\"\n",
    "    Test Time Augmentation usando desplazamientos temporales.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72ab9f",
   "metadata": {},
   "source": [
    "### Métricas y Herramientas de Visualización\n",
    "\n",
    "Funciones para calcular métricas y visualizar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b68aec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Métricas extendidas\n",
    "# =========================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula métricas extendidas de clasificación.\n",
    "    \"\"\"\n",
    "    prec_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec_macro  = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro   = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    TN0 = cm[1,1]; FP0 = cm[1,0]\n",
    "    spec0 = TN0 / (TN0 + FP0 + 1e-12)\n",
    "    TN1 = cm[0,0]; FP1 = cm[0,1]\n",
    "    spec1 = TN1 / (TN1 + FP1 + 1e-12)\n",
    "    spec_macro = (spec0 + spec1) / 2.0\n",
    "\n",
    "    recs = recall_score(y_true, y_pred, labels=[0,1], average=None, zero_division=0)\n",
    "    sens_macro = float(recs.mean())\n",
    "\n",
    "    return {\n",
    "        \"precision_macro\": float(prec_macro),\n",
    "        \"recall_macro\": float(rec_macro),\n",
    "        \"f1_macro\": float(f1_macro),\n",
    "        \"specificity_macro\": float(spec_macro),\n",
    "        \"sensitivity_macro\": float(sens_macro),\n",
    "        \"cm\": cm.tolist()\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Helper: matriz de confusión con anotaciones\n",
    "# =========================\n",
    "def plot_confusion_with_text(cm, class_names, title, out_path, cmap='Blues'):\n",
    "    \"\"\"\n",
    "    Plota matriz de confusión con valores anotados.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(4.8, 4.2))\n",
    "    im = ax.imshow(cm, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_xticks(range(len(class_names))); ax.set_xticklabels(class_names)\n",
    "    ax.set_yticks(range(len(class_names))); ax.set_yticklabels(class_names)\n",
    "\n",
    "    vmax = cm.max() if cm.size else 1\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]),\n",
    "                    ha='center', va='center',\n",
    "                    color='white' if cm[i, j] > vmax/2 else 'black',\n",
    "                    fontsize=11, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=140)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc2f68",
   "metadata": {},
   "source": [
    "### Herramientas de Interpretabilidad\n",
    "\n",
    "Funciones para analizar y visualizar el comportamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "213a71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FUNCIONES DE INTERPRETABILIDAD (SOLO LAS QUE PIDES)\n",
    "# =========================\n",
    "\n",
    "# ===== Saliency por canal =====\n",
    "def channel_saliency(model, xb, target_class=None):\n",
    "    \"\"\"\n",
    "    Importancia por canal basada en |∂score/∂x| promedio en el tiempo.\n",
    "    xb: tensor (1, C, T) en GPU.\n",
    "    Devuelve: vector (C,) normalizado [0,1].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    xb = xb.clone().detach().requires_grad_(True)\n",
    "\n",
    "    logits = model(xb)\n",
    "    if target_class is None:\n",
    "        cls = logits.argmax(1)\n",
    "    else:\n",
    "        cls = torch.tensor([int(target_class)], device=xb.device)\n",
    "    score = logits[0, cls]\n",
    "\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    if xb.grad is not None:\n",
    "        xb.grad.zero_()\n",
    "    score.backward()\n",
    "\n",
    "    grad = xb.grad.detach()[0]     # (C, T)\n",
    "    sal = grad.abs().mean(dim=1)   # (C,)\n",
    "    sal = (sal - sal.min()) / (sal.max() - sal.min() + 1e-8)\n",
    "    return sal.cpu().numpy()\n",
    "\n",
    "# ===== Topomaps =====\n",
    "def make_mne_info_8ch(sfreq: float):\n",
    "    \"\"\"\n",
    "    Crea un Info de MNE con tus 8 canales motores.\n",
    "    \"\"\"\n",
    "    info = mne.create_info(\n",
    "        ch_names=EXPECTED_8,\n",
    "        sfreq=float(sfreq),\n",
    "        ch_types=\"eeg\"\n",
    "    )\n",
    "    try:\n",
    "        montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "        info.set_montage(montage)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def plot_topomap_from_values(values, info, title: str, out_path: Path,\n",
    "                             cmap=\"Reds\", cbar_label=\"Value\",\n",
    "                             vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Dibuja y guarda un topomap dado un vector de valores por canal.\n",
    "    values: array (n_channels,)\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 4.0))\n",
    "    im, _ = mne.viz.plot_topomap(\n",
    "        values, info, axes=ax, show=False, cmap=cmap\n",
    "    )\n",
    "    if (vmin is not None) or (vmax is not None):\n",
    "        im.set_clim(vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    cbar = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "    cbar.set_label(cbar_label, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"↳ Topomap guardado: {out_path}\")\n",
    "\n",
    "# ===== -log10(p) análisis estadístico =====\n",
    "def compute_channel_pvalues_lr(X, y):\n",
    "    \"\"\"\n",
    "    P-values por canal para la diferencia left vs right.\n",
    "    Usa potencia media (X^2) promediada en el tiempo como feature.\n",
    "    X: (N, C, T)  | y: (N,) con labels 0=left, 1=right\n",
    "    Devuelve: vector (C,) con p-values (ttest_ind Welch).\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    left = X[y == 0]\n",
    "    right = X[y == 1]\n",
    "\n",
    "    if (left.size == 0) or (right.size == 0):\n",
    "        return np.ones(X.shape[1], dtype=float)\n",
    "\n",
    "    feat_left = (left ** 2).mean(axis=2)   # (N_left, C)\n",
    "    feat_right = (right ** 2).mean(axis=2)\n",
    "\n",
    "    pvals = []\n",
    "    for ch in range(feat_left.shape[1]):\n",
    "        _, p = stats.ttest_ind(\n",
    "            feat_left[:, ch],\n",
    "            feat_right[:, ch],\n",
    "            equal_var=False\n",
    "        )\n",
    "        pvals.append(p)\n",
    "    return np.array(pvals, dtype=float)\n",
    "\n",
    "# ===== t-SNE de CLS embeddings =====\n",
    "def compute_cls_embeddings(model, X_data, device):\n",
    "    \"\"\"\n",
    "    Calcula embeddings CLS del modelo.\n",
    "    X_data: (N, C, T)\n",
    "    Devuelve: (N, d_model) embeddings CLS\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_data), 64):\n",
    "            xb = torch.tensor(X_data[i:i+64], dtype=torch.float32, device=device)\n",
    "            # Pasar por el modelo completo para obtener CLS token\n",
    "            z = model.conv_t(xb)           # (B, C', T')\n",
    "            z = model.proj(z)              # (B, d_model, T')\n",
    "            z = z.transpose(1, 2)          # (B, T', d_model)\n",
    "            \n",
    "            # Añadir positional encoding (simulando forward)\n",
    "            B, L, D = z.shape\n",
    "            if model.pos_encoding is None or model.pos_encoding.shape[0] != L or model.pos_encoding.shape[1] != D:\n",
    "                pos_enc = model._positional_encoding(L, D).to(z.device)\n",
    "            else:\n",
    "                pos_enc = model.pos_encoding\n",
    "            z = z + pos_enc[None, :, :]\n",
    "            \n",
    "            # Añadir CLS token y pasar por encoder\n",
    "            cls_tok = model.cls.expand(B, -1, -1)\n",
    "            z_with_cls = torch.cat([cls_tok, z], dim=1)  # (B, 1+L, D)\n",
    "            \n",
    "            # Pasar por encoder (solo necesitamos CLS)\n",
    "            z_encoder, _ = model.encoder(z_with_cls)\n",
    "            cls_embedding = z_encoder[:, 0, :]  # CLS token (B, D)\n",
    "            embeddings.append(cls_embedding.cpu().numpy())\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings\n",
    "\n",
    "def compute_tsne_embeddings(model, X_data, device, n_components=2, perplexity=30):\n",
    "    \"\"\"\n",
    "    Calcula embeddings CLS y luego aplica t-SNE.\n",
    "    X_data: (N, C, T)\n",
    "    \"\"\"\n",
    "    # Obtener embeddings CLS\n",
    "    embeddings = compute_cls_embeddings(model, X_data, device)\n",
    "    \n",
    "    # Aplicar t-SNE\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, \n",
    "                random_state=RANDOM_STATE, init='pca', n_iter=1000)\n",
    "    tsne_result = tsne.fit_transform(embeddings)\n",
    "    return tsne_result, embeddings\n",
    "\n",
    "def plot_tsne(tsne_result, y_true, title, out_path: Path):\n",
    "    \"\"\"\n",
    "    Grafica t-SNE con colores según clase.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    \n",
    "    # Colores para cada clase\n",
    "    colors = ['green', 'blue']  # 0:left (verde), 1:right (azul)\n",
    "    \n",
    "    for cls_idx in range(2):\n",
    "        mask = y_true == cls_idx\n",
    "        if mask.any():\n",
    "            ax.scatter(tsne_result[mask, 0], tsne_result[mask, 1], \n",
    "                      c=colors[cls_idx], label=CLASS_NAMES[cls_idx], \n",
    "                      alpha=0.7, s=25, edgecolors='w', linewidth=0.5)\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(\"t-SNE 1\")\n",
    "    ax.set_ylabel(\"t-SNE 2\")\n",
    "    ax.legend(title=\"Clase\", fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Añadir información adicional\n",
    "    n_samples = len(y_true)\n",
    "    n_left = np.sum(y_true == 0)\n",
    "    n_right = np.sum(y_true == 1)\n",
    "    info_text = f\"Total: {n_samples} | Left: {n_left} | Right: {n_right}\"\n",
    "    ax.text(0.02, 0.98, info_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"↳ t-SNE (CLS embeddings) guardado: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7e8e",
   "metadata": {},
   "source": [
    "### Métricas de Consumo y Hiperparámetros\n",
    "\n",
    "Funciones para calcular consumo computacional y gestionar hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3dc0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Consumo / hiperparámetros\n",
    "# =========================\n",
    "def count_params(model, trainable_only=False):\n",
    "    \"\"\"\n",
    "    Cuenta parámetros del modelo.\n",
    "    \"\"\"\n",
    "    if trainable_only:\n",
    "        return int(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    return int(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "def estimate_transformer_flops(L, d, n_heads, n_layers):\n",
    "    \"\"\"\n",
    "    Estima FLOPs del encoder Transformer.\n",
    "    \"\"\"\n",
    "    d_ff = 2*d\n",
    "    proj = 4 * L * (d*d)         # Q,K,V,Out\n",
    "    attn = 2 * (L*L*d)           # scores + aplicar a V\n",
    "    ff   = 2 * L * (d * d_ff)    # FFN (2 lineales)\n",
    "    return n_layers * (proj + attn + ff)\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_latency(model, X_sample, device, n_warm=10, n_runs=50):\n",
    "    \"\"\"\n",
    "    Mide latencia de inferencia del modelo.\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(X_sample):\n",
    "        xb = X_sample.clone().detach().to(device)\n",
    "    else:\n",
    "        xb = torch.tensor(X_sample, dtype=torch.float32, device=device).clone().detach()\n",
    "\n",
    "    for _ in range(n_warm):\n",
    "        _ = model(xb)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(n_runs):\n",
    "        _ = model(xb)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    return (time.time() - t0) / n_runs\n",
    "\n",
    "def current_hparams():\n",
    "    \"\"\"\n",
    "    Retorna diccionario con todos los hiperparámetros actuales.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"EPOCHS\": EPOCHS, \"BATCH_SIZE\": BATCH_SIZE, \"BASE_LR\": BASE_LR,\n",
    "        \"WARMUP_EPOCHS\": WARMUP_EPOCHS, \"PATIENCE\": PATIENCE,\n",
    "        \"RESAMPLE_HZ\": RESAMPLE_HZ, \"DO_NOTCH\": DO_NOTCH, \"DO_BANDPASS\": DO_BANDPASS,\n",
    "        \"BP_LO\": BP_LO, \"BP_HI\": BP_HI, \"DO_CAR\": DO_CAR, \"ZSCORE_PER_EPOCH\": ZSCORE_PER_EPOCH,\n",
    "        \"D_MODEL\": D_MODEL, \"N_HEADS\": N_HEADS, \"N_LAYERS\": N_LAYERS,\n",
    "        \"P_DROP\": P_DROP, \"P_DROP_ENCODER\": P_DROP_ENCODER,\n",
    "        \"TMIN\": TMIN, \"TMAX\": TMAX, \"SW_MODE\": SW_MODE, \"SW_ENABLE\": SW_ENABLE,\n",
    "        \"TTA_SHIFTS_S\": TTA_SHIFTS_S, \"SW_LEN\": SW_LEN, \"SW_STRIDE\": SW_STRIDE,\n",
    "        \"COMBINE_TTA_AND_SUBWIN\": COMBINE_TTA_AND_SUBWIN,\n",
    "        \"USE_WEIGHTED_SAMPLER\": USE_WEIGHTED_SAMPLER,\n",
    "        \"USE_EMA\": USE_EMA, \"EMA_DECAY\": EMA_DECAY,\n",
    "        \"FT_N_FOLDS\": FT_N_FOLDS, \"FT_FREEZE_EPOCHS\": FT_FREEZE_EPOCHS, \"FT_UNFREEZE_EPOCHS\": FT_UNFREEZE_EPOCHS,\n",
    "        \"FT_PATIENCE\": FT_PATIENCE, \"FT_BATCH\": FT_BATCH, \"FT_LR_HEAD\": FT_LR_HEAD,\n",
    "        \"FT_LR_BACKBONE\": FT_LR_BACKBONE, \"FT_WD\": FT_WD, \"FT_AUG\": FT_AUG,\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Helpers de salida/archivos\n",
    "# =========================\n",
    "def ensure_dir(p: Path):\n",
    "    \"\"\"\n",
    "    Crea directorio si no existe.\n",
    "    \"\"\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def make_run_dirs(base_dir: Path, tag: str, fold: int):\n",
    "    \"\"\"\n",
    "    Devuelve (run_dir, fold_dir).\n",
    "    \"\"\"\n",
    "    run_dir = ensure_dir(base_dir / tag)\n",
    "    fold_dir = ensure_dir(run_dir / f\"fold{fold}\")\n",
    "    return run_dir, fold_dir\n",
    "\n",
    "def save_csv_rows(csv_path: Path, fieldnames: list, rows: list):\n",
    "    \"\"\"\n",
    "    Guarda filas en archivo CSV.\n",
    "    \"\"\"\n",
    "    write_header = not csv_path.exists()\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if write_header:\n",
    "            w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbf6b0",
   "metadata": {},
   "source": [
    "### Función Principal de Entrenamiento\n",
    "\n",
    "Función que entrena un fold completo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9773a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TRAIN/EVAL GLOBAL POR FOLD\n",
    "# =========================\n",
    "def train_one_fold(\n",
    "    fold:int,\n",
    "    device,\n",
    "    model_factory=None,\n",
    "    run_tag=\"base\",\n",
    "    out_dir: Path = None,\n",
    "    seed=None,\n",
    "    save_artifacts: bool = True,  \n",
    "    do_ft: bool = True            \n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa el modelo para un fold específico.\n",
    "    \n",
    "    Args:\n",
    "        fold: Número del fold (1-5)\n",
    "        device: Dispositivo para entrenamiento (CPU/GPU)\n",
    "        model_factory: Función que crea instancia del modelo\n",
    "        run_tag: Identificador de la ejecución\n",
    "        out_dir: Directorio de salida\n",
    "        seed: Semilla para reproducibilidad\n",
    "        save_artifacts: Si guarda artefactos de entrenamiento\n",
    "        do_ft: Si realiza fine-tuning por sujeto\n",
    "    \"\"\"\n",
    "    # Semilla fija por corrida (justa entre combos/folds)\n",
    "    base = RANDOM_STATE if seed is None else int(seed)\n",
    "    seed_everything(base)\n",
    "\n",
    "    def load_fold_subjects_local(folds_json: Path, fold: int):\n",
    "        return load_fold_subjects(folds_json, fold)\n",
    "\n",
    "    # --- directorios de salida ---\n",
    "    if save_artifacts:\n",
    "        base_out = Path(\".\") if out_dir is None else Path(out_dir)\n",
    "        run_dir, fold_dir = make_run_dirs(base_out, run_tag, fold)\n",
    "        print(f\"[IO] Guardando artefactos en: {fold_dir.resolve()}\")\n",
    "    else:\n",
    "        run_dir = None\n",
    "        fold_dir = None\n",
    "        print(\"[LITE] GridSearch: no se guardarán artefactos por combinación.\")\n",
    "\n",
    "    # --- split de sujetos ---\n",
    "    train_sub, test_sub = load_fold_subjects_local(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # --- carga de datos ---\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # Normalización por canal\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    # Weighted sampler\n",
    "    def make_weighted_sampler(dataset: TensorDataset):\n",
    "        _Xb, yb, sb = dataset.tensors\n",
    "        yb_np = yb.numpy()\n",
    "        sb_np = sb.numpy()\n",
    "        uniq_s, cnt_s = np.unique(sb_np, return_counts=True)\n",
    "        map_s = {s:c for s,c in zip(uniq_s, cnt_s)}\n",
    "        key = sb_np.astype(np.int64) * 10 + yb_np.astype(np.int64)\n",
    "        uniq_k, cnt_k = np.unique(key, return_counts=True)\n",
    "        map_k = {k:c for k,c in zip(uniq_k, cnt_k)}\n",
    "        a, b = 0.8, 1.0\n",
    "        w = []\n",
    "        for s, y in zip(sb_np, yb_np):\n",
    "            k = int(s)*10 + int(y)\n",
    "            ws = float(map_s[int(s)])\n",
    "            wk = float(map_k[k])\n",
    "            w.append((ws ** (-a)) * (wk ** (-b)))\n",
    "        w = np.array(w, dtype=np.float64)\n",
    "        w = w / (w.mean() + 1e-12)\n",
    "        sampler = WeightedRandomSampler(weights=torch.tensor(w, dtype=torch.double),\n",
    "                                        num_samples=len(yb_np), replacement=True)\n",
    "        return sampler\n",
    "\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        tr_sampler = make_weighted_sampler(tr_ds)\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, sampler=tr_sampler, drop_last=False, worker_init_fn=seed_worker)\n",
    "    else:\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # --- Medidores de tiempo/memoria por fase ---\n",
    "    train_time_s = None\n",
    "    train_mem_mb = None\n",
    "    test_time_s  = None\n",
    "    test_mem_mb  = None\n",
    "\n",
    "    # Modelo\n",
    "    if model_factory is None:\n",
    "        model = EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                                  n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                                  n_dw_blocks=2, capture_attn=True).to(device)\n",
    "    else:\n",
    "        model = model_factory()\n",
    "\n",
    "    # Opt + Loss\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "    class_counts = np.bincount(y_tr, minlength=2).astype(np.float32)\n",
    "    inv = class_counts.sum() / (2.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # LR scheduler Warmup+Cosine\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # EMA\n",
    "    ema = ModelEMA(model, decay=EMA_DECAY, device=device) if USE_EMA else None\n",
    "\n",
    "    # Entrenamiento global (con tracking de GAP)\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"val_loss\": [], \"lr\": []}\n",
    "\n",
    "    # NUEVO: métricas en la época de mejor valid F1\n",
    "    best_val_acc = float('nan')\n",
    "    best_val_f1  = float('nan')\n",
    "    best_tr_acc  = float('nan')\n",
    "    best_tr_f1   = float('nan')\n",
    "\n",
    "    def evaluate_on(loader, use_ema=True, loss_fn=None):\n",
    "        mdl = ema.ema if (ema is not None and use_ema) else model\n",
    "        mdl.eval()\n",
    "        preds, gts = [], []\n",
    "        tot_loss, n_seen = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in loader:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                logits = mdl(xb)\n",
    "                if loss_fn is not None:\n",
    "                    L = loss_fn(logits, yb).item()\n",
    "                    tot_loss += L * len(yb); n_seen += len(yb)\n",
    "                p = logits.argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.cpu().numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "        vloss = (tot_loss / max(1,n_seen)) if n_seen>0 else float('nan')\n",
    "        return acc, f1m, vloss, preds, gts\n",
    "\n",
    "    # === NUEVO: iniciar cronómetro + memoria de ENTRENAMIENTO ===\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "    t_train_start = time.time()\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "            if ema is not None:\n",
    "                ema.update(model)\n",
    "\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        acc, f1m, vloss, _, _ = evaluate_on(val_ld, use_ema=True, loss_fn=crit)\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"val_loss\"].append(vloss)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Época {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_loss={vloss:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            ref_model = ema.ema if ema is not None else model\n",
    "            best_state = {k: v.detach().cpu() for k, v in ref_model.state_dict().items()}\n",
    "            wait = 0\n",
    "\n",
    "            # NUEVO: computar train en el mismo modelo/época p/ medir gap\n",
    "            tr_acc_eval, tr_f1_eval, _, _, _ = evaluate_on(tr_ld, use_ema=True, loss_fn=None)\n",
    "            best_tr_acc = tr_acc_eval\n",
    "            best_tr_f1  = tr_f1_eval\n",
    "            best_val_acc = acc\n",
    "            best_val_f1  = f1m\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en época {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    # === cerrar cronómetro de ENTRENAMIENTO ===\n",
    "    t_train_end = time.time()\n",
    "    train_time_s = t_train_end - t_train_start\n",
    "    if torch.cuda.is_available():\n",
    "        train_mem_mb = torch.cuda.max_memory_allocated(device) / (1024.0 ** 2)\n",
    "\n",
    "    # Restaurar mejor estado\n",
    "    if best_state is not None:\n",
    "        (ema.ema if (ema is not None) else model).load_state_dict(best_state)\n",
    "        model.load_state_dict(best_state)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(True)\n",
    "\n",
    "    if save_artifacts and fold_dir is not None:\n",
    "        torch.save(best_state, fold_dir / f\"model_global_fold{fold}_{run_tag}.pth\")\n",
    "        print(f\"↳ Modelo global guardado en: {fold_dir / f'model_global_fold{fold}_{run_tag}.pth'}\")\n",
    "\n",
    "    # ---- Curvas (sólo si se guardan artefactos) ----\n",
    "    if save_artifacts:\n",
    "        # ONLY train_loss and val_loss, correct scale\n",
    "        fig = plt.figure(figsize=(8, 4.5))\n",
    "        ax1 = plt.gca()\n",
    "        ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "        ax1.plot(hist[\"ep\"], hist[\"val_loss\"], label=\"val_loss\")\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.set_title(f\"Fold {fold} — Training Curve (2 classes) [{run_tag}]\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        out_png = fold_dir / f\"training_curve_fold{fold}_{run_tag}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=140)\n",
    "        plt.close(fig)\n",
    "        print(f\"↳ Training curve saved: {out_png}\")\n",
    "        # Guardar historial de curvas (epoch, train_loss, val_loss) para curva global\n",
    "        hist_path = fold_dir / f\"history_fold{fold}_{run_tag}.npz\"\n",
    "        np.savez(\n",
    "            hist_path,\n",
    "            ep=np.array(hist[\"ep\"], dtype=np.int32),\n",
    "            tr_loss=np.array(hist[\"tr_loss\"], dtype=np.float32),\n",
    "            val_loss=np.array(hist[\"val_loss\"], dtype=np.float32),\n",
    "        )\n",
    "        print(f\"↳ History saved: {hist_path}\")\n",
    "\n",
    "    # ---- Evaluación final en TEST (global) ----\n",
    "    eval_model = ema.ema if (ema is not None) else model\n",
    "    eval_model.eval()\n",
    "\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    # === NUEVO: cronómetro + memoria de TEST ===\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "    t_test_start = time.time()\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = eval_model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE in ('subwin', 'tta'):\n",
    "        logits_tta = None\n",
    "        logits_sw  = None\n",
    "        if SW_MODE == 'subwin':\n",
    "            logits_sw = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        elif SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        logits = logits_tta if logits_tta is not None else logits_sw\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    # === NUEVO: cerrar cronómetro de TEST ===\n",
    "    t_test_end = time.time()\n",
    "    test_time_s = t_test_end - t_test_start\n",
    "    if torch.cuda.is_available():\n",
    "        test_mem_mb = torch.cuda.max_memory_allocated(device) / (1024.0 ** 2)\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f} | f1_macro={f1m:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1])\n",
    "    print(cm)\n",
    "\n",
    "    # Métricas extendidas SIEMPRE (aunque no guardes artefactos)\n",
    "    met = compute_metrics(gts, preds)\n",
    "    print(\n",
    "        f\"precision_macro={met['precision_macro']:.4f} | \"\n",
    "        f\"recall_macro={met['recall_macro']:.4f} | \"\n",
    "        f\"specificity_macro={met['specificity_macro']:.4f} | \"\n",
    "        f\"sensitivity_macro={met['sensitivity_macro']:.4f}\"\n",
    "    )\n",
    "\n",
    "    if save_artifacts:\n",
    "        cm_png = fold_dir / f\"confusion_global_fold{fold}_{run_tag}.png\"\n",
    "        plot_confusion_with_text(\n",
    "            cm=cm,\n",
    "            class_names=CLASS_NAMES,\n",
    "            title=f\"Confusion — Fold {fold} Global (2 classes) [{run_tag}]\",\n",
    "            out_path=cm_png,\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        print(f\"↳ Confusion matrix saved: {cm_png}\")\n",
    "\n",
    "    # =========================\n",
    "    # INTERPRETABILIDAD\n",
    "    # =========================\n",
    "    if save_artifacts:\n",
    "        try:\n",
    "            model_to_probe = model\n",
    "            model_to_probe.eval()\n",
    "\n",
    "            # Minibatch de validación para ejemplos ilustrativos\n",
    "            with torch.no_grad():\n",
    "                xb_val, yb_val, _ = next(iter(val_ld))\n",
    "            xb_val = xb_val[:8].to(device)\n",
    "\n",
    "            # --- 1. Mapas de atención (Transformer) ---\n",
    "            _ = model_to_probe(xb_val)\n",
    "            attn_list = model_to_probe.get_last_attention_maps()\n",
    "            if attn_list and len(attn_list) > 0:\n",
    "                # attn_list[0]: [B, heads, T, T]\n",
    "                A = attn_list[0][0].mean(dim=0).detach().cpu().numpy()\n",
    "                plt.figure(figsize=(5, 4))\n",
    "                plt.imshow(A, aspect=\"auto\")\n",
    "                plt.title(f\"Attention (layer1, mean heads) [{run_tag}]\")\n",
    "                plt.colorbar()\n",
    "                plt.tight_layout()\n",
    "                attn_png = fold_dir / f\"attention_map_fold{fold}_{run_tag}.png\"\n",
    "                plt.savefig(attn_png, dpi=140)\n",
    "                plt.close()\n",
    "                print(f\"↳ Mapa de atención: {attn_png}\")\n",
    "\n",
    "            # Tomamos UN ejemplo para todos los mapas\n",
    "            xb_ex = xb_val[:1]\n",
    "            pred_cls = int(model_to_probe(xb_ex).argmax(1).item())\n",
    "\n",
    "            # --- 2. Topomap de saliency por canal ---\n",
    "            saliency_ch = channel_saliency(model_to_probe, xb_ex, target_class=pred_cls)\n",
    "\n",
    "            sfreq_topo = sfreq_used if sfreq_used is not None else int(\n",
    "                round(X_te_std.shape[-1] / (TMAX - TMIN))\n",
    "            )\n",
    "            info_topo = make_mne_info_8ch(sfreq_topo)\n",
    "\n",
    "            topo_sal_png = fold_dir / f\"topomap_saliency_fold{fold}_{run_tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                saliency_ch,\n",
    "                info_topo,\n",
    "                title=f\"Channel saliency — Fold {fold} [{run_tag}]\",\n",
    "                out_path=topo_sal_png,\n",
    "                cmap=\"Reds\",\n",
    "                cbar_label=\"Normalized saliency\"\n",
    "            )\n",
    "            # Guardar saliency numérica por canal para promedio GLOBAL\n",
    "            saliency_path = fold_dir / f\"saliency_channels_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(saliency_path, saliency_ch)\n",
    "\n",
    "            # --- 3. Topomap de -log10(p) left vs right (TEST) ---\n",
    "            pvals = compute_channel_pvalues_lr(X_te_std, y_te)\n",
    "            pvals_log = -np.log10(pvals + 1e-12)\n",
    "\n",
    "            topo_p_png = fold_dir / f\"topomap_log10p_fold{fold}_{run_tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                pvals_log,\n",
    "                info_topo,\n",
    "                title=f\"-log10(p) Left vs Right — Fold {fold} [{run_tag}]\",\n",
    "                out_path=topo_p_png,\n",
    "                cmap=\"viridis\",\n",
    "                cbar_label=\"-log10(p)\"\n",
    "            )\n",
    "\n",
    "            # Guardar valores numéricos por canal para promedio GLOBAL\n",
    "            pvals_log_path = fold_dir / f\"pvals_log_channels_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(pvals_log_path, pvals_log)\n",
    "\n",
    "            # --- 4. t-SNE de embeddings del modelo ---\n",
    "            # Usar un subconjunto de TEST para t-SNE (máximo 1000 muestras)\n",
    "            n_tsne_samples = min(1000, len(X_te_std))\n",
    "            indices = rng.choice(len(X_te_std), n_tsne_samples, replace=False)\n",
    "            X_tsne = X_te_std[indices]\n",
    "            y_tsne = y_te[indices]\n",
    "\n",
    "            tsne_result, cls_embeddings = compute_tsne_embeddings(\n",
    "                model_to_probe, X_tsne, DEVICE, n_components=2, perplexity=30\n",
    "            )\n",
    "            \n",
    "            tsne_png = fold_dir / f\"tsne_cls_fold{fold}_{run_tag}.png\"\n",
    "            plot_tsne(\n",
    "                tsne_result, \n",
    "                y_tsne,\n",
    "                title=f\"t-SNE CLS embeddings — Fold {fold} [{run_tag}]\",\n",
    "                out_path=tsne_png\n",
    "            )\n",
    "            \n",
    "            # Guardar t-SNE resultados y embeddings CLS\n",
    "            tsne_path = fold_dir / f\"tsne_results_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(tsne_path, tsne_result)\n",
    "            \n",
    "            cls_emb_path = fold_dir / f\"cls_embeddings_fold{fold}_{run_tag}.npy\"\n",
    "            np.save(cls_emb_path, cls_embeddings)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Interpretabilidad no generada: {e}\")\n",
    "\n",
    "    # =========================\n",
    "    # Fine-tuning progresivo por sujeto (opcional)\n",
    "    # =========================\n",
    "    if do_ft:\n",
    "        subjects = np.unique(sub_te)\n",
    "        subj_to_idx = {s: np.where(sub_te == s)[0] for s in subjects}\n",
    "\n",
    "        def make_ft_optimizer(model_ft):\n",
    "            head_params = list(model_ft.head.parameters())\n",
    "            backbone_params = [p for n,p in model_ft.named_parameters() if not n.startswith('head.')]\n",
    "            return torch.optim.AdamW([\n",
    "                {'params': backbone_params, 'lr': FT_LR_BACKBONE},\n",
    "                {'params': head_params,     'lr': FT_LR_HEAD}\n",
    "            ], weight_decay=FT_WD)\n",
    "\n",
    "        def freeze_backbone(model_ft, freeze=True):\n",
    "            for n,p in model_ft.named_parameters():\n",
    "                if not n.startswith('head.'):\n",
    "                    p.requires_grad_(not freeze)\n",
    "\n",
    "        def ft_make_criterion_from_counts(counts):\n",
    "            inv = counts.sum() / (2.0 * np.maximum(counts.astype(np.float32), 1.0))\n",
    "            a = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "            return FocalLoss(alpha=a, gamma=1.5, reduction='mean')\n",
    "\n",
    "        def evaluate_tensor(model_t, X, y):\n",
    "            model_t.eval()\n",
    "            with torch.no_grad():\n",
    "                xb = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "                p = model_t(xb).argmax(1).cpu().numpy()\n",
    "            return accuracy_score(y, p), f1_score(y, p, average='macro'), p\n",
    "\n",
    "        all_true, all_pred = [], []\n",
    "        base_state = (ema.ema if (ema is not None) else model).state_dict()\n",
    "\n",
    "        for s in subjects:\n",
    "            idx = subj_to_idx[s]\n",
    "            Xs, ys = X_te_std[idx], y_te[idx]\n",
    "            if len(np.unique(ys)) < 2 or len(ys) < 20:\n",
    "                eval_model2 = model_factory() if model_factory is not None else EEGCNNTransformer(\n",
    "                    n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                    n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                    n_dw_blocks=2, capture_attn=False).to(device)\n",
    "                eval_model2.load_state_dict(base_state)\n",
    "                _, _, pred_s = evaluate_tensor(eval_model2, Xs, ys)\n",
    "                all_true.append(ys); all_pred.append(pred_s)\n",
    "                continue\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=FT_N_FOLDS, shuffle=True, random_state=RANDOM_STATE + fold + int(s))\n",
    "            for tr_idx, te_idx in skf.split(Xs, ys):\n",
    "                Xtr, ytr = Xs[tr_idx].copy(), ys[tr_idx].copy()\n",
    "                Xte_s, yte_s = Xs[te_idx].copy(), ys[te_idx].copy()\n",
    "                Xtr_std, Xte_std = standardize_per_channel(Xtr, Xte_s)\n",
    "\n",
    "                ft_model = model_factory() if model_factory is not None else EEGCNNTransformer(\n",
    "                    n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                    n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                    n_dw_blocks=2, capture_attn=False).to(device)\n",
    "                ft_model.load_state_dict(base_state)\n",
    "\n",
    "                opt_ft = make_ft_optimizer(ft_model)\n",
    "                alpha_counts = np.bincount(ytr, minlength=2)\n",
    "                ft_crit = ft_make_criterion_from_counts(alpha_counts)\n",
    "\n",
    "                ds_tr = TensorDataset(torch.tensor(Xtr_std), torch.tensor(ytr).long())\n",
    "                ds_te = TensorDataset(torch.tensor(Xte_std), torch.tensor(yte_s).long())\n",
    "                ld_tr = DataLoader(ds_tr, batch_size=FT_BATCH, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "                ld_te = DataLoader(ds_te, batch_size=FT_BATCH, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "                # freeze\n",
    "                freeze_backbone(ft_model, True)\n",
    "                best_f1_s, best_state_s, wait_s = -1, None, 0\n",
    "                for _ep in range(1, FT_FREEZE_EPOCHS+1):\n",
    "                    ft_model.train()\n",
    "                    for xb, yb in ld_tr:\n",
    "                        xb = xb.to(device); yb = yb.to(device)\n",
    "                        xb = augment_batch_ft(xb)\n",
    "                        opt_ft.zero_grad()\n",
    "                        logits = ft_model(xb)\n",
    "                        loss = ft_crit(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                        opt_ft.step()\n",
    "                    acc_s, f1_s, _ = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "                    if f1_s > best_f1_s + 1e-4:\n",
    "                        best_f1_s = f1_s\n",
    "                        best_state_s = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                        wait_s = 0\n",
    "                    else:\n",
    "                        wait_s += 1\n",
    "                    if wait_s >= FT_PATIENCE: break\n",
    "                if best_state_s is not None:\n",
    "                    ft_model.load_state_dict(best_state_s)\n",
    "\n",
    "                # unfreeze\n",
    "                freeze_backbone(ft_model, False)\n",
    "                best_f1_s2, best_state_s2, wait_s2 = -1, None, 0\n",
    "                for _ep in range(1, FT_UNFREEZE_EPOCHS+1):\n",
    "                    ft_model.train()\n",
    "                    for xb, yb in ld_tr:\n",
    "                        xb = xb.to(device); yb = yb.to(device)\n",
    "                        xb = augment_batch_ft(xb)\n",
    "                        opt_ft.zero_grad()\n",
    "                        logits = ft_model(xb)\n",
    "                        loss = ft_crit(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                        opt_ft.step()\n",
    "                    acc_s, f1_s, _ = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "                    if f1_s > best_f1_s2 + 1e-4:\n",
    "                        best_f1_s2 = f1_s\n",
    "                        best_state_s2 = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                        wait_s2 = 0\n",
    "                    else:\n",
    "                        wait_s2 += 1\n",
    "                    if wait_s2 >= FT_PATIENCE: break\n",
    "                if best_state_s2 is not None:\n",
    "                    ft_model.load_state_dict(best_state_s2)\n",
    "\n",
    "                _, _, pred_s = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "                all_true.append(yte_s); all_pred.append(pred_s)\n",
    "\n",
    "        all_true = np.concatenate(all_true) if len(all_true) else np.array([], dtype=int)\n",
    "        all_pred = np.concatenate(all_pred) if len(all_pred) else np.array([], dtype=int)\n",
    "        if len(all_true) > 0:\n",
    "            ft_acc = accuracy_score(all_true, all_pred)\n",
    "            ft_f1m = f1_score(all_true, all_pred, average='macro')\n",
    "            print(f\"  Fine-tuning PROGRESIVO (por sujeto, {FT_N_FOLDS}-fold CV) acc={ft_acc:.4f} | f1_macro={ft_f1m:.4f}\")\n",
    "            if save_artifacts:\n",
    "                cm_ft = confusion_matrix(all_true, all_pred, labels=[0,1])\n",
    "                ft_png = fold_dir / f\"confusion_ft_fold{fold}_{run_tag}.png\"\n",
    "                plot_confusion_with_text(\n",
    "                    cm=cm_ft,\n",
    "                    class_names=CLASS_NAMES,\n",
    "                    title=f\"Confusion — Fold {fold} FT (2 clases) [{run_tag}]\",\n",
    "                    out_path=ft_png,\n",
    "                    cmap='Greens'\n",
    "                )\n",
    "                print(f\"↳ Matriz de confusión FT guardada: {ft_png}\")\n",
    "        else:\n",
    "            ft_acc = float('nan')\n",
    "            print(\"  Fine-tuning PROGRESIVO: no se generaron splits válidos.\")\n",
    "    else:\n",
    "        ft_acc = float('nan')\n",
    "        print(\"  [LITE] FT desactivado (do_ft=False).\")\n",
    "\n",
    "    # =========================\n",
    "    # Consumo (siempre calculado); guardar JSON sólo si save_artifacts\n",
    "    # =========================\n",
    "    cons = {}\n",
    "    try:\n",
    "        eval_model.eval()\n",
    "        with torch.no_grad():\n",
    "            xb_small, _, _ = next(iter(val_ld))\n",
    "        xb_small = xb_small[:8].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = eval_model.conv_t(xb_small)\n",
    "            z = eval_model.proj(z).transpose(1, 2)  # (B, L, D)\n",
    "            L, d = z.shape[1], z.shape[2]\n",
    "\n",
    "        params_total = count_params(eval_model, trainable_only=False)\n",
    "        params_train = count_params(model, trainable_only=True)\n",
    "        flops = estimate_transformer_flops(L=L, d=d, n_heads=N_HEADS, n_layers=N_LAYERS)\n",
    "        lat   = benchmark_latency(eval_model, xb_small, DEVICE)\n",
    "\n",
    "        cons = dict(\n",
    "            params_total=params_total,\n",
    "            params_trainable=params_train,\n",
    "            flops_est=int(flops),\n",
    "            latency_s=float(lat),\n",
    "            L=L, d=d,\n",
    "            n_heads=N_HEADS, n_layers=N_LAYERS,\n",
    "            run_tag=run_tag, fold=fold,\n",
    "            # GAP val-train en la mejor época de valid F1\n",
    "            val_best_acc=float(best_val_acc),\n",
    "            val_best_f1=float(best_val_f1),\n",
    "            tr_at_best_acc=float(best_tr_acc),\n",
    "            tr_at_best_f1=float(best_tr_f1),\n",
    "            # === NUEVO: métricas de tiempo/memoria por fase ===\n",
    "            train_time_s=float(train_time_s) if train_time_s is not None else None,\n",
    "            train_mem_mb=float(train_mem_mb) if train_mem_mb is not None else None,\n",
    "            test_time_s=float(test_time_s) if test_time_s is not None else None,\n",
    "            test_mem_mb=float(test_mem_mb) if test_mem_mb is not None else None,\n",
    "        )\n",
    "\n",
    "        if save_artifacts and (fold_dir is not None):\n",
    "            cons_json = fold_dir / f\"consumption_fold{fold}_{run_tag}.json\"\n",
    "            with open(cons_json, \"w\") as f:\n",
    "                json.dump(cons, f, indent=2)\n",
    "\n",
    "        print(f\"[Consumo] params_total={params_total:,} | params_trainable={params_train:,} | \"\n",
    "              f\"FLOPs~{flops/1e6:.1f}M | latency/batch={lat*1000:.2f} ms (B={xb_small.size(0)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Métricas de consumo no generadas: {e}\")\n",
    "\n",
    "    return acc, f1m, ft_acc, cons, met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9081e9",
   "metadata": {},
   "source": [
    "### Utilidades de Splits y Configuraciones Adicionales\n",
    "\n",
    "Funciones auxiliares para manejar splits de datos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba22a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utilidades splits estratificados por sujeto\n",
    "# =========================\n",
    "def build_subject_label_map(subject_ids):\n",
    "    \"\"\"\n",
    "    Construye mapa de etiquetas dominantes por sujeto para estratificación.\n",
    "    \"\"\"\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=2)\n",
    "        y_dom = int(np.argmax(binc))\n",
    "        y_dom_list.append(y_dom)\n",
    "    return np.array(y_dom_list, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02534dca",
   "metadata": {},
   "source": [
    "### Funciones de Barrido de Hiperparámetros\n",
    "\n",
    "Funciones para realizar búsqueda de hiperparámetros y entrenamiento completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93bd57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Barrido (con carpetas y resumen)\n",
    "# =========================\n",
    "def run_arch_sweep(device, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=1):\n",
    "    \"\"\"\n",
    "    Realiza barrido de hiperparámetros (número de bloques y cabezas de atención).\n",
    "    \"\"\"\n",
    "    base_dir = ensure_dir(Path(\"Barrido\"))\n",
    "    results = []\n",
    "    run_id = 0\n",
    "    for dlt in deltas:\n",
    "        n_blocks = int(np.clip(base_blocks + dlt, 0, 4))\n",
    "        for nh in head_set:\n",
    "            if D_MODEL % nh != 0:\n",
    "                print(f\"[SKIP] n_heads={nh} incompatible con D_MODEL={D_MODEL} (no divisible).\")\n",
    "                continue\n",
    "            run_id += 1\n",
    "            run_tag = f\"nb{n_blocks}_h{nh}\"\n",
    "            print(f\"\\n=== RUN {run_id} | n_dw_blocks={n_blocks} | n_heads={nh} ===\")\n",
    "\n",
    "            def make_model_for_fold():\n",
    "                return EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=nh,\n",
    "                                         n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                                         n_dw_blocks=n_blocks, capture_attn=True).to(device)\n",
    "            acc, f1m, ft_acc, cons, met = train_one_fold(\n",
    "                fold=sweep_fold, device=device,\n",
    "                model_factory=make_model_for_fold, run_tag=run_tag, out_dir=base_dir,\n",
    "                save_artifacts=False, do_ft=False\n",
    "            )\n",
    "            results.append(dict(\n",
    "                run=run_id,\n",
    "                n_dw_blocks=n_blocks,\n",
    "                n_heads=nh,\n",
    "                fold=sweep_fold,\n",
    "                acc=acc,\n",
    "                f1_macro=f1m,\n",
    "                ft_acc=ft_acc,\n",
    "                # === MÉTRICAS EXTENDIDAS EN TEST ===\n",
    "                precision_macro=met[\"precision_macro\"],\n",
    "                recall_macro=met[\"recall_macro\"],\n",
    "                specificity_macro=met[\"specificity_macro\"],\n",
    "                sensitivity_macro=met[\"sensitivity_macro\"],\n",
    "                # === CONSUMO ===\n",
    "                tag=run_tag,\n",
    "                params_total=cons.get(\"params_total\"),\n",
    "                params_trainable=cons.get(\"params_trainable\"),\n",
    "                flops_est=cons.get(\"flops_est\"),\n",
    "                latency_s=cons.get(\"latency_s\"),\n",
    "                L=cons.get(\"L\"),\n",
    "                d=cons.get(\"d\"),\n",
    "                enc_heads=cons.get(\"n_heads\"),\n",
    "                enc_layers=cons.get(\"n_layers\"),\n",
    "            ))\n",
    "\n",
    "    if len(results):\n",
    "        summary_path = Path(\"Barrido\") / \"summary_sweep.csv\"\n",
    "        fields = list(results[0].keys())\n",
    "        save_csv_rows(summary_path, fields, results)\n",
    "        print(f\"↳ Resumen de barrido (con consumo) actualizado: {summary_path.resolve()}\")\n",
    "    return results\n",
    "\n",
    "# =========================\n",
    "# 5 Folds del ganador (con carpetas y resumen)\n",
    "# =========================\n",
    "def run_full_5fold_for_config(device, n_blocks, n_heads):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa el modelo en los 5 folds para una configuración específica.\n",
    "    \"\"\"\n",
    "    tag = f\"nb{n_blocks}_h{n_heads}\"\n",
    "    base_dir = ensure_dir(Path(\"ModeloW\") / tag)\n",
    "\n",
    "    acc_folds, f1_folds, ft_acc_folds = [], [], []\n",
    "    rows = []\n",
    "\n",
    "    # === NUEVO: listas para costo computacional por fold ===\n",
    "    train_times, train_mems = [], []\n",
    "    test_times,  test_mems  = [], []\n",
    "    params_list, flops_list = [], []\n",
    "\n",
    "    # Acumuladores para mapas GLOBALES\n",
    "    saliency_list = []   # Para saliency por fold\n",
    "    pvals_log_list = []  # Para -log10(p) por fold\n",
    "    tsne_results_list = []  # Para t-SNE por fold (solo guardamos, no promediamos)\n",
    "\n",
    "    # Acumulador para matriz de confusión global (suma de las de cada fold)\n",
    "    global_cm = np.zeros((2, 2), dtype=int)\n",
    "    \n",
    "    def factory():\n",
    "        return EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=n_heads,\n",
    "                                 n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                                 n_dw_blocks=n_blocks, capture_attn=True).to(device)\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m, ft_acc, cons, met = train_one_fold(\n",
    "            fold, device, model_factory=factory, run_tag=tag, out_dir=base_dir\n",
    "        )\n",
    "        # Acumular matriz de confusión de este fold en la matriz GLOBAL\n",
    "        if met is not None and \"cm\" in met:\n",
    "            global_cm += np.array(met[\"cm\"], dtype=int)\n",
    "        acc_folds.append(acc); f1_folds.append(f1m)\n",
    "        ft_acc_folds.append(ft_acc if ft_acc == ft_acc else np.nan)\n",
    "\n",
    "        # === NUEVO: guardar consumo de este fold ===\n",
    "        train_times.append(cons.get(\"train_time_s\"))\n",
    "        train_mems.append(cons.get(\"train_mem_mb\"))\n",
    "        test_times.append(cons.get(\"test_time_s\"))\n",
    "        test_mems.append(cons.get(\"test_mem_mb\"))\n",
    "        params_list.append(cons.get(\"params_total\"))\n",
    "        flops_list.append(cons.get(\"flops_est\"))\n",
    "\n",
    "        rows.append(dict(\n",
    "            tag=tag, fold=fold, acc=acc, f1_macro=f1m, ft_acc=ft_acc,\n",
    "            params_total=cons.get(\"params_total\"),\n",
    "            params_trainable=cons.get(\"params_trainable\"),\n",
    "            flops_est=cons.get(\"flops_est\"),\n",
    "            latency_s=cons.get(\"latency_s\"),\n",
    "            L=cons.get(\"L\"), d=cons.get(\"d\"),\n",
    "            enc_heads=cons.get(\"n_heads\"), enc_layers=cons.get(\"n_layers\")\n",
    "        ))\n",
    "\n",
    "        # Cargar mapas de interpretabilidad de este fold para promedio GLOBAL\n",
    "        try:\n",
    "            fold_dir = base_dir / tag / f\"fold{fold}\"\n",
    "            # Cargar saliency\n",
    "            sal_path = fold_dir / f\"saliency_channels_fold{fold}_{tag}.npy\"\n",
    "            if sal_path.exists():\n",
    "                saliency_list.append(np.load(sal_path))\n",
    "            \n",
    "            # Cargar -log10(p)\n",
    "            pvals_path = fold_dir / f\"pvals_log_channels_fold{fold}_{tag}.npy\"\n",
    "            if pvals_path.exists():\n",
    "                pvals_log_list.append(np.load(pvals_path))\n",
    "                \n",
    "            # Cargar t-SNE (solo para referencia, no promediamos)\n",
    "            tsne_path = fold_dir / f\"tsne_results_fold{fold}_{tag}.npy\"\n",
    "            if tsne_path.exists():\n",
    "                tsne_results_list.append(np.load(tsne_path))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] No se pudieron cargar mapas para fold {fold}: {e}\")\n",
    "\n",
    "    acc_mean = float(np.nanmean(acc_folds))\n",
    "    f1_mean  = float(np.nanmean(f1_folds))\n",
    "    ft_mean  = float(np.nanmean(ft_acc_folds))\n",
    "    delta_mean = float(ft_mean - acc_mean) if not np.isnan(ft_mean) else np.nan\n",
    "\n",
    "    summary_path = base_dir / f\"summary_{tag}.csv\"\n",
    "    save_csv_rows(summary_path, list(rows[0].keys()), rows)\n",
    "    print(f\"↳ Resumen 5-fold guardado: {summary_path.resolve()}\")\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(f\"RESULTADOS FINALES [{tag}] (2 clases: left/right)\")\n",
    "    print(\"============================================================\")\n",
    "    print(\"Global folds (ACC):\", [f\"{a:.4f}\" for a in acc_folds])\n",
    "    print(\"Global mean ACC:   \", f\"{acc_mean:.4f}\")\n",
    "    print(\"F1 folds (MACRO):  \", [f\"{f:.4f}\" for f in f1_folds])\n",
    "    print(\"F1 mean (MACRO):   \", f\"{f1_mean:.4f}\")\n",
    "    if not np.isnan(ft_mean):\n",
    "        print(\"FT folds (ACC):    \", [(\"nan\" if np.isnan(a) else f\"{a:.4f}\") for a in ft_acc_folds])\n",
    "        print(\"FT mean (ACC):     \", f\"{ft_mean:.4f}\")\n",
    "        print(\"Δ(FT-Global) mean: \", f\"{delta_mean:+.4f}\")\n",
    "    else:\n",
    "        print(\"FT mean (ACC): N/A\")\n",
    "\n",
    "    # ========================================================\n",
    "    # Tabla de métricas computacionales tipo paper\n",
    "    # ========================================================\n",
    "\n",
    "    tt = np.array([t for t in train_times if t is not None], dtype=float)\n",
    "    tm = np.array([m for m in train_mems if m is not None], dtype=float)\n",
    "\n",
    "    train_time_mean = float(tt.mean()) if len(tt) else float('nan')\n",
    "    train_time_std  = float(tt.std(ddof=0)) if len(tt) else float('nan')\n",
    "    train_mem_mean  = float(tm.mean()) if len(tm) else float('nan')\n",
    "    train_mem_std   = float(tm.std(ddof=0)) if len(tm) else float('nan')\n",
    "\n",
    "    # Para test tomamos el primer fold válido (single run)\n",
    "    test_time = next((float(t) for t in test_times if t is not None), float('nan'))\n",
    "    test_mem  = next((float(m) for m in test_mems if m is not None), float('nan'))\n",
    "\n",
    "    # Modelo (mismo en todos los folds)\n",
    "    params_total = next((p for p in params_list if p is not None), 0)\n",
    "    flops_est    = next((f for f in flops_list if f is not None), 0)\n",
    "\n",
    "    params_m = params_total / 1e6\n",
    "    flops_g  = flops_est / 1e9\n",
    "\n",
    "    print(\"\\n================ Computational metrics ================\")\n",
    "    print(f\"Model tag: {tag}\")\n",
    "    print(\"Phase        time (s)           memory (MB)        FLOPs (g)   params (m)\")\n",
    "    print(\"-----------  -----------------  -----------------  ----------  ----------\")\n",
    "    print(f\"model specs  N/A                N/A                 {flops_g:8.3f}   {params_m:8.3f}\")\n",
    "    print(f\"train        {train_time_mean:6.2f} ({train_time_std:5.2f})   {train_mem_mean:7.1f} ({train_mem_std:5.1f})     N/A        N/A\")\n",
    "    print(f\"test         {test_time:6.2f}              {test_mem:7.1f}              N/A        N/A\")\n",
    "\n",
    "    comp_rows = [\n",
    "        dict(phase=\"model_specs\",\n",
    "             time_mean_s=None, time_std_s=None,\n",
    "             mem_mean_mb=None, mem_std_mb=None,\n",
    "             flops_g=flops_g, params_m=params_m),\n",
    "        dict(phase=\"train\",\n",
    "             time_mean_s=train_time_mean, time_std_s=train_time_std,\n",
    "             mem_mean_mb=train_mem_mean, mem_std_mb=train_mem_std,\n",
    "             flops_g=None, params_m=None),\n",
    "        dict(phase=\"test\",\n",
    "             time_mean_s=test_time, time_std_s=None,\n",
    "             mem_mean_mb=test_mem, mem_std_mb=None,\n",
    "             flops_g=None, params_m=None),\n",
    "    ]\n",
    "\n",
    "    comp_path = base_dir / f\"computational_{tag}.csv\"\n",
    "    save_csv_rows(comp_path,\n",
    "                  fieldnames=list(comp_rows[0].keys()),\n",
    "                  rows=comp_rows)\n",
    "    print(f\"↳ Tabla de métricas computacionales guardada en: {comp_path.resolve()}\")\n",
    "    \n",
    "    # ========================================================\n",
    "    # Matriz de confusión GLOBAL (5 folds concatenados)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        cm_global_png = base_dir / f\"confusion_global_allfolds_{tag}.png\"\n",
    "        plot_confusion_with_text(\n",
    "            cm=global_cm,\n",
    "            class_names=CLASS_NAMES,\n",
    "            title=f\"Confusion — Global (5-fold) [{tag}]\",\n",
    "            out_path=cm_global_png,\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        print(f\"↳ Matriz de confusión GLOBAL guardada: {cm_global_png}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudo generar la matriz de confusión global: {e}\")\n",
    "\n",
    "    # ========================================================\n",
    "    # Curva de LOSS GLOBAL (promedio sobre los 5 folds)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        histories = []\n",
    "        for fold in range(1, 6):\n",
    "            hist_path = base_dir / tag / f\"fold{fold}\" / f\"history_fold{fold}_{tag}.npz\"\n",
    "            if not hist_path.exists():\n",
    "                print(f\"[WARN] History no encontrado para fold {fold}: {hist_path}\")\n",
    "                continue\n",
    "            data = np.load(hist_path)\n",
    "            hist = {\n",
    "                \"ep\":      data[\"ep\"],\n",
    "                \"tr_loss\": data[\"tr_loss\"],\n",
    "                \"val_loss\": data[\"val_loss\"],\n",
    "            }\n",
    "            histories.append(hist)\n",
    "\n",
    "        if len(histories) > 0:\n",
    "            # Longitud máxima de epochs entre los folds\n",
    "            max_len = max(h[\"ep\"].shape[0] for h in histories)\n",
    "            epochs = np.arange(1, max_len + 1)\n",
    "\n",
    "            mean_tr = []\n",
    "            mean_val = []\n",
    "\n",
    "            for i in range(max_len):\n",
    "                tr_vals = [h[\"tr_loss\"][i] for h in histories if h[\"tr_loss\"].shape[0] > i]\n",
    "                val_vals = [h[\"val_loss\"][i] for h in histories if h[\"val_loss\"].shape[0] > i]\n",
    "                if len(tr_vals) == 0 or len(val_vals) == 0:\n",
    "                    break  # ya no hay más epochs comunes\n",
    "                mean_tr.append(np.mean(tr_vals))\n",
    "                mean_val.append(np.mean(val_vals))\n",
    "\n",
    "            epochs = epochs[:len(mean_tr)]\n",
    "            mean_tr = np.array(mean_tr)\n",
    "            mean_val = np.array(mean_val)\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 4.5))\n",
    "            ax = plt.gca()\n",
    "            ax.plot(epochs, mean_tr, label=\"Train loss (mean across folds)\")\n",
    "            ax.plot(epochs, mean_val, label=\"Val loss (mean across folds)\")\n",
    "            ax.set_xlabel(\"Epoch\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.set_title(f\"Global Training Curve — 5-fold mean [{tag}]\")\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            out_png = base_dir / f\"training_curve_global_{tag}.png\"\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(out_png, dpi=140)\n",
    "            plt.close(fig)\n",
    "            print(f\"↳ Curva de loss GLOBAL guardada: {out_png}\")\n",
    "        else:\n",
    "            print(\"[WARN] No se encontraron historiales para construir curva global.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudo generar la curva de loss global: {e}\")\n",
    "\n",
    "    # ========================================================\n",
    "    # MAPAS GLOBALES (promedio de los 5 folds)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        # Crear info para topomaps\n",
    "        info_topo_global = make_mne_info_8ch(sfreq=160.0)\n",
    "        \n",
    "        # 1. Topomap GLOBAL de saliency (promedio 5 folds)\n",
    "        if len(saliency_list) > 0:\n",
    "            sal_mean = np.mean(np.stack(saliency_list, axis=0), axis=0)   # (C,)\n",
    "            topo_sal_global_png = base_dir / f\"topomap_saliency_GLOBAL_{tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                sal_mean,\n",
    "                info_topo_global,\n",
    "                title=f\"Channel saliency — GLOBAL (5 folds) [{tag}]\",\n",
    "                out_path=topo_sal_global_png,\n",
    "                cmap=\"Reds\",\n",
    "                cbar_label=\"Normalized saliency\"\n",
    "            )\n",
    "            print(f\"↳ Topomap GLOBAL de saliency guardado: {topo_sal_global_png}\")\n",
    "        \n",
    "        # 2. Topomap GLOBAL de -log10(p) (promedio 5 folds)\n",
    "        if len(pvals_log_list) > 0:\n",
    "            pvals_log_mean = np.mean(np.stack(pvals_log_list, axis=0), axis=0)   # (C,)\n",
    "            topo_p_global_png = base_dir / f\"topomap_log10p_GLOBAL_{tag}.png\"\n",
    "            plot_topomap_from_values(\n",
    "                pvals_log_mean,\n",
    "                info_topo_global,\n",
    "                title=f\"-log10(p) Left vs Right — GLOBAL (5 folds) [{tag}]\",\n",
    "                out_path=topo_p_global_png,\n",
    "                cmap=\"viridis\",\n",
    "                cbar_label=\"-log10(p)\"\n",
    "            )\n",
    "            print(f\"↳ Topomap GLOBAL de -log10(p) guardado: {topo_p_global_png}\")\n",
    "        \n",
    "        # 3. t-SNE GLOBAL usando CLS embeddings del último fold\n",
    "        if len(tsne_results_list) > 0:\n",
    "            # Usar el t-SNE del último fold como representativo\n",
    "            tsne_representative = tsne_results_list[-1]\n",
    "            \n",
    "            # Cargar etiquetas correspondientes (del último fold)\n",
    "            fold_dir = base_dir / tag / f\"fold5\"\n",
    "            \n",
    "            # Cargar y_te del fold 5 (si existe guardado)\n",
    "            y_te_fold5_path = fold_dir / \"y_te.npy\"\n",
    "            if y_te_fold5_path.exists():\n",
    "                y_te_fold5 = np.load(y_te_fold5_path)\n",
    "                # Tomar las mismas muestras que usamos para t-SNE\n",
    "                rng = np.random.RandomState(RANDOM_STATE)\n",
    "                n_tsne_samples = min(1000, len(y_te_fold5))\n",
    "                indices = rng.choice(len(y_te_fold5), n_tsne_samples, replace=False)\n",
    "                y_tsne_global = y_te_fold5[indices]\n",
    "                \n",
    "                tsne_global_png = base_dir / f\"tsne_cls_GLOBAL_{tag}.png\"\n",
    "                plot_tsne(\n",
    "                    tsne_representative,\n",
    "                    y_tsne_global,\n",
    "                    title=f\"t-SNE CLS embeddings — GLOBAL (Fold 5 representative) [{tag}]\",\n",
    "                    out_path=tsne_global_png\n",
    "                )\n",
    "                print(f\"↳ t-SNE GLOBAL (CLS embeddings) guardado: {tsne_global_png}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No se pudieron generar mapas GLOBALES: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179864e5",
   "metadata": {},
   "source": [
    "### Main y Ejecución Principal\n",
    "\n",
    "Función principal para ejecutar el pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c24d9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|██████████| 67/67 [00:03<00:00, 17.43it/s]\n",
      "Cargando val fold1: 100%|██████████| 15/15 [00:00<00:00, 17.44it/s]\n",
      "Cargando test fold1: 100%|██████████| 21/21 [00:01<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1318 | train_acc=0.5213 | val_loss=0.1249 | val_acc=0.5000 | val_f1m=0.3443 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1224 | train_acc=0.5729 | val_loss=0.1187 | val_acc=0.6190 | val_f1m=0.6166 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1102 | train_acc=0.6546 | val_loss=0.1111 | val_acc=0.6508 | val_f1m=0.6402 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0962 | train_acc=0.7416 | val_loss=0.1044 | val_acc=0.7206 | val_f1m=0.7198 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0841 | train_acc=0.7839 | val_loss=0.0987 | val_acc=0.7444 | val_f1m=0.7439 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0764 | train_acc=0.8003 | val_loss=0.0960 | val_acc=0.7556 | val_f1m=0.7539 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0721 | train_acc=0.8124 | val_loss=0.0919 | val_acc=0.7635 | val_f1m=0.7627 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0662 | train_acc=0.8348 | val_loss=0.1250 | val_acc=0.7190 | val_f1m=0.7119 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0641 | train_acc=0.8394 | val_loss=0.0944 | val_acc=0.7571 | val_f1m=0.7569 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0651 | train_acc=0.8340 | val_loss=0.0993 | val_acc=0.7683 | val_f1m=0.7678 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0614 | train_acc=0.8539 | val_loss=0.1028 | val_acc=0.7556 | val_f1m=0.7548 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0620 | train_acc=0.8490 | val_loss=0.0927 | val_acc=0.7683 | val_f1m=0.7673 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0606 | train_acc=0.8547 | val_loss=0.0891 | val_acc=0.7683 | val_f1m=0.7678 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0606 | train_acc=0.8497 | val_loss=0.0948 | val_acc=0.7540 | val_f1m=0.7510 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0583 | train_acc=0.8632 | val_loss=0.1093 | val_acc=0.7603 | val_f1m=0.7594 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0578 | train_acc=0.8561 | val_loss=0.1027 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0605 | train_acc=0.8515 | val_loss=0.1016 | val_acc=0.7746 | val_f1m=0.7745 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0591 | train_acc=0.8582 | val_loss=0.1005 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0565 | train_acc=0.8653 | val_loss=0.1005 | val_acc=0.7810 | val_f1m=0.7800 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0520 | train_acc=0.8699 | val_loss=0.1050 | val_acc=0.7794 | val_f1m=0.7794 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0525 | train_acc=0.8738 | val_loss=0.1018 | val_acc=0.7667 | val_f1m=0.7666 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0495 | train_acc=0.8778 | val_loss=0.1040 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0495 | train_acc=0.8767 | val_loss=0.1033 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0512 | train_acc=0.8714 | val_loss=0.1032 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0541 | train_acc=0.8582 | val_loss=0.1031 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0425 | train_acc=0.8969 | val_loss=0.1032 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0486 | train_acc=0.8824 | val_loss=0.1032 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0496 | train_acc=0.8738 | val_loss=0.1032 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0454 | train_acc=0.8877 | val_loss=0.1033 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000325\n",
      "  Época  30 | train_loss=0.0481 | train_acc=0.8799 | val_loss=0.1034 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000313\n",
      "  Época  31 | train_loss=0.0439 | train_acc=0.9019 | val_loss=0.1036 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000300\n",
      "  Época  32 | train_loss=0.0454 | train_acc=0.8927 | val_loss=0.1037 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000288\n",
      "  Época  33 | train_loss=0.0381 | train_acc=0.9129 | val_loss=0.1040 | val_acc=0.7968 | val_f1m=0.7968 | LR=0.000275\n",
      "  Época  34 | train_loss=0.0427 | train_acc=0.8994 | val_loss=0.1042 | val_acc=0.7952 | val_f1m=0.7952 | LR=0.000262\n",
      "  Época  35 | train_loss=0.0376 | train_acc=0.9115 | val_loss=0.1046 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000250\n",
      "  Época  36 | train_loss=0.0409 | train_acc=0.9055 | val_loss=0.1049 | val_acc=0.7937 | val_f1m=0.7937 | LR=0.000237\n",
      "  Época  37 | train_loss=0.0394 | train_acc=0.9087 | val_loss=0.1053 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000225\n",
      "  Época  38 | train_loss=0.0394 | train_acc=0.9101 | val_loss=0.1057 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000213\n",
      "  Época  39 | train_loss=0.0387 | train_acc=0.9033 | val_loss=0.1061 | val_acc=0.7921 | val_f1m=0.7921 | LR=0.000201\n",
      "  Época  40 | train_loss=0.0380 | train_acc=0.9115 | val_loss=0.1066 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000189\n",
      "  Época  41 | train_loss=0.0352 | train_acc=0.9186 | val_loss=0.1071 | val_acc=0.7905 | val_f1m=0.7905 | LR=0.000177\n",
      "  Early stopping en época 41 (mejor val_f1m=0.7968)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold1/model_global_fold1_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold1/training_curve_fold1_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold1/history_fold1_nb2_h6.npz\n",
      "[Fold 1/5] Global acc=0.8107 | f1_macro=0.8107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8114    0.8095    0.8104       441\n",
      "       right     0.8100    0.8118    0.8109       441\n",
      "\n",
      "    accuracy                         0.8107       882\n",
      "   macro avg     0.8107    0.8107    0.8107       882\n",
      "weighted avg     0.8107    0.8107    0.8107       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[357  84]\n",
      " [ 83 358]]\n",
      "precision_macro=0.8107 | recall_macro=0.8107 | specificity_macro=0.8107 | sensitivity_macro=0.8107\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold1/confusion_global_fold1_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold1/attention_map_fold1_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold1/topomap_saliency_fold1_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold1/topomap_log10p_fold1_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold1/tsne_cls_fold1_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8526 | f1_macro=0.8526\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold1/confusion_ft_fold1_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.11 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|██████████| 67/67 [00:03<00:00, 16.97it/s]\n",
      "Cargando val fold2: 100%|██████████| 15/15 [00:00<00:00, 17.25it/s]\n",
      "Cargando test fold2: 100%|██████████| 21/21 [00:01<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1290 | train_acc=0.5267 | val_loss=0.1202 | val_acc=0.6032 | val_f1m=0.6029 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1214 | train_acc=0.5839 | val_loss=0.1159 | val_acc=0.6222 | val_f1m=0.6183 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1168 | train_acc=0.6276 | val_loss=0.1052 | val_acc=0.7095 | val_f1m=0.7095 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0987 | train_acc=0.7278 | val_loss=0.0958 | val_acc=0.7206 | val_f1m=0.7202 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0910 | train_acc=0.7594 | val_loss=0.0973 | val_acc=0.7175 | val_f1m=0.7028 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0808 | train_acc=0.7921 | val_loss=0.0942 | val_acc=0.7492 | val_f1m=0.7492 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0776 | train_acc=0.8042 | val_loss=0.0910 | val_acc=0.7476 | val_f1m=0.7417 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0771 | train_acc=0.8056 | val_loss=0.0823 | val_acc=0.7873 | val_f1m=0.7870 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0677 | train_acc=0.8316 | val_loss=0.0846 | val_acc=0.7857 | val_f1m=0.7854 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0691 | train_acc=0.8301 | val_loss=0.0821 | val_acc=0.8000 | val_f1m=0.8000 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0672 | train_acc=0.8333 | val_loss=0.0826 | val_acc=0.7952 | val_f1m=0.7951 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0662 | train_acc=0.8358 | val_loss=0.0840 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0671 | train_acc=0.8394 | val_loss=0.0854 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0637 | train_acc=0.8454 | val_loss=0.0850 | val_acc=0.7984 | val_f1m=0.7984 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0649 | train_acc=0.8380 | val_loss=0.0878 | val_acc=0.7825 | val_f1m=0.7818 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0614 | train_acc=0.8500 | val_loss=0.0856 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0597 | train_acc=0.8568 | val_loss=0.0897 | val_acc=0.7825 | val_f1m=0.7821 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0624 | train_acc=0.8497 | val_loss=0.0885 | val_acc=0.7952 | val_f1m=0.7950 | LR=0.000443\n",
      "  Early stopping en época 18 (mejor val_f1m=0.8000)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold2/model_global_fold2_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold2/training_curve_fold2_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold2/history_fold2_nb2_h6.npz\n",
      "[Fold 2/5] Global acc=0.8356 | f1_macro=0.8353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8083    0.8798    0.8426       441\n",
      "       right     0.8682    0.7914    0.8280       441\n",
      "\n",
      "    accuracy                         0.8356       882\n",
      "   macro avg     0.8382    0.8356    0.8353       882\n",
      "weighted avg     0.8382    0.8356    0.8353       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[388  53]\n",
      " [ 92 349]]\n",
      "precision_macro=0.8382 | recall_macro=0.8356 | specificity_macro=0.8356 | sensitivity_macro=0.8356\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold2/confusion_global_fold2_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold2/attention_map_fold2_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold2/topomap_saliency_fold2_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold2/topomap_log10p_fold2_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold2/tsne_cls_fold2_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8878 | f1_macro=0.8877\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold2/confusion_ft_fold2_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.12 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|██████████| 67/67 [00:03<00:00, 16.92it/s]\n",
      "Cargando val fold3: 100%|██████████| 15/15 [00:00<00:00, 17.52it/s]\n",
      "Cargando test fold3: 100%|██████████| 21/21 [00:01<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Época   1 | train_loss=0.1315 | train_acc=0.5174 | val_loss=0.1267 | val_acc=0.5079 | val_f1m=0.3685 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1251 | train_acc=0.5402 | val_loss=0.1324 | val_acc=0.5190 | val_f1m=0.3840 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1242 | train_acc=0.5547 | val_loss=0.1109 | val_acc=0.6810 | val_f1m=0.6809 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1067 | train_acc=0.6844 | val_loss=0.0947 | val_acc=0.7222 | val_f1m=0.7221 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0889 | train_acc=0.7633 | val_loss=0.0884 | val_acc=0.7651 | val_f1m=0.7621 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0765 | train_acc=0.7974 | val_loss=0.0827 | val_acc=0.8016 | val_f1m=0.8015 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0721 | train_acc=0.8259 | val_loss=0.0834 | val_acc=0.7937 | val_f1m=0.7936 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0738 | train_acc=0.8223 | val_loss=0.0810 | val_acc=0.8063 | val_f1m=0.8063 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0656 | train_acc=0.8447 | val_loss=0.0795 | val_acc=0.7778 | val_f1m=0.7778 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0677 | train_acc=0.8269 | val_loss=0.0765 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0634 | train_acc=0.8340 | val_loss=0.0907 | val_acc=0.7921 | val_f1m=0.7917 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0644 | train_acc=0.8387 | val_loss=0.0783 | val_acc=0.8048 | val_f1m=0.8047 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0603 | train_acc=0.8557 | val_loss=0.0842 | val_acc=0.7794 | val_f1m=0.7777 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0598 | train_acc=0.8586 | val_loss=0.0823 | val_acc=0.8079 | val_f1m=0.8079 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0597 | train_acc=0.8621 | val_loss=0.0857 | val_acc=0.7873 | val_f1m=0.7872 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0584 | train_acc=0.8539 | val_loss=0.0815 | val_acc=0.7889 | val_f1m=0.7888 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0598 | train_acc=0.8547 | val_loss=0.0823 | val_acc=0.7873 | val_f1m=0.7873 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0627 | train_acc=0.8454 | val_loss=0.0810 | val_acc=0.8032 | val_f1m=0.8032 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0563 | train_acc=0.8696 | val_loss=0.0901 | val_acc=0.8048 | val_f1m=0.8045 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0605 | train_acc=0.8525 | val_loss=0.0829 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0539 | train_acc=0.8735 | val_loss=0.0882 | val_acc=0.8111 | val_f1m=0.8110 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0514 | train_acc=0.8788 | val_loss=0.0900 | val_acc=0.7794 | val_f1m=0.7791 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0486 | train_acc=0.8852 | val_loss=0.0920 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0528 | train_acc=0.8738 | val_loss=0.0920 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0511 | train_acc=0.8738 | val_loss=0.0921 | val_acc=0.7889 | val_f1m=0.7885 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0510 | train_acc=0.8763 | val_loss=0.0922 | val_acc=0.7889 | val_f1m=0.7885 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0521 | train_acc=0.8795 | val_loss=0.0922 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000349\n",
      "  Época  28 | train_loss=0.0485 | train_acc=0.8852 | val_loss=0.0923 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000337\n",
      "  Época  29 | train_loss=0.0492 | train_acc=0.8852 | val_loss=0.0924 | val_acc=0.7889 | val_f1m=0.7886 | LR=0.000325\n",
      "  Early stopping en época 29 (mejor val_f1m=0.8110)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold3/model_global_fold3_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold3/training_curve_fold3_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold3/history_fold3_nb2_h6.npz\n",
      "[Fold 3/5] Global acc=0.8084 | f1_macro=0.8084\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8134    0.8005    0.8069       441\n",
      "       right     0.8036    0.8163    0.8099       441\n",
      "\n",
      "    accuracy                         0.8084       882\n",
      "   macro avg     0.8085    0.8084    0.8084       882\n",
      "weighted avg     0.8085    0.8084    0.8084       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[353  88]\n",
      " [ 81 360]]\n",
      "precision_macro=0.8085 | recall_macro=0.8084 | specificity_macro=0.8084 | sensitivity_macro=0.8084\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold3/confusion_global_fold3_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold3/attention_map_fold3_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold3/topomap_saliency_fold3_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold3/topomap_log10p_fold3_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold3/tsne_cls_fold3_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8469 | f1_macro=0.8469\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold3/confusion_ft_fold3_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.14 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|██████████| 68/68 [00:03<00:00, 17.37it/s]\n",
      "Cargando val fold4: 100%|██████████| 15/15 [00:00<00:00, 17.29it/s]\n",
      "Cargando test fold4: 100%|██████████| 20/20 [00:01<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1308 | train_acc=0.4972 | val_loss=0.1204 | val_acc=0.5651 | val_f1m=0.5476 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1254 | train_acc=0.5501 | val_loss=0.1177 | val_acc=0.6079 | val_f1m=0.6056 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1174 | train_acc=0.6008 | val_loss=0.1263 | val_acc=0.6508 | val_f1m=0.6418 | LR=0.000375\n",
      "  Época   4 | train_loss=0.1039 | train_acc=0.6992 | val_loss=0.1061 | val_acc=0.6889 | val_f1m=0.6888 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0898 | train_acc=0.7626 | val_loss=0.1008 | val_acc=0.7349 | val_f1m=0.7327 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0802 | train_acc=0.7805 | val_loss=0.0876 | val_acc=0.7635 | val_f1m=0.7622 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0810 | train_acc=0.7920 | val_loss=0.0990 | val_acc=0.7286 | val_f1m=0.7182 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0737 | train_acc=0.8099 | val_loss=0.0873 | val_acc=0.7762 | val_f1m=0.7749 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0725 | train_acc=0.8253 | val_loss=0.0881 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0707 | train_acc=0.8165 | val_loss=0.1018 | val_acc=0.7492 | val_f1m=0.7479 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0702 | train_acc=0.8228 | val_loss=0.0897 | val_acc=0.7667 | val_f1m=0.7647 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0689 | train_acc=0.8347 | val_loss=0.0898 | val_acc=0.7492 | val_f1m=0.7482 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0657 | train_acc=0.8326 | val_loss=0.0864 | val_acc=0.7746 | val_f1m=0.7742 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0636 | train_acc=0.8424 | val_loss=0.0880 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0684 | train_acc=0.8347 | val_loss=0.0887 | val_acc=0.7667 | val_f1m=0.7650 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0602 | train_acc=0.8526 | val_loss=0.0867 | val_acc=0.7730 | val_f1m=0.7725 | LR=0.000459\n",
      "  Early stopping en época 16 (mejor val_f1m=0.7749)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold4/model_global_fold4_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold4/training_curve_fold4_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold4/history_fold4_nb2_h6.npz\n",
      "[Fold 4/5] Global acc=0.8119 | f1_macro=0.8098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7579    0.9167    0.8297       420\n",
      "       right     0.8946    0.7071    0.7899       420\n",
      "\n",
      "    accuracy                         0.8119       840\n",
      "   macro avg     0.8262    0.8119    0.8098       840\n",
      "weighted avg     0.8262    0.8119    0.8098       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[385  35]\n",
      " [123 297]]\n",
      "precision_macro=0.8262 | recall_macro=0.8119 | specificity_macro=0.8119 | sensitivity_macro=0.8119\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold4/confusion_global_fold4_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold4/attention_map_fold4_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold4/topomap_saliency_fold4_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold4/topomap_log10p_fold4_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold4/tsne_cls_fold4_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8738 | f1_macro=0.8738\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold4/confusion_ft_fold4_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.13 ms (B=8)\n",
      "[IO] Guardando artefactos en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/nb2_h6/fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|██████████| 68/68 [00:03<00:00, 17.14it/s]\n",
      "Cargando val fold5: 100%|██████████| 15/15 [00:00<00:00, 17.27it/s]\n",
      "Cargando test fold5: 100%|██████████| 20/20 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Época   1 | train_loss=0.1320 | train_acc=0.5035 | val_loss=0.1220 | val_acc=0.5095 | val_f1m=0.4079 | LR=0.000125\n",
      "  Época   2 | train_loss=0.1241 | train_acc=0.5445 | val_loss=0.1177 | val_acc=0.5889 | val_f1m=0.5691 | LR=0.000250\n",
      "  Época   3 | train_loss=0.1225 | train_acc=0.5795 | val_loss=0.1122 | val_acc=0.6619 | val_f1m=0.6540 | LR=0.000375\n",
      "  Época   4 | train_loss=0.0968 | train_acc=0.7416 | val_loss=0.1055 | val_acc=0.7000 | val_f1m=0.6988 | LR=0.000500\n",
      "  Época   5 | train_loss=0.0907 | train_acc=0.7560 | val_loss=0.1002 | val_acc=0.7127 | val_f1m=0.7107 | LR=0.000500\n",
      "  Época   6 | train_loss=0.0747 | train_acc=0.8123 | val_loss=0.0961 | val_acc=0.7190 | val_f1m=0.7162 | LR=0.000500\n",
      "  Época   7 | train_loss=0.0737 | train_acc=0.8200 | val_loss=0.1029 | val_acc=0.7286 | val_f1m=0.7273 | LR=0.000499\n",
      "  Época   8 | train_loss=0.0708 | train_acc=0.8232 | val_loss=0.1032 | val_acc=0.7333 | val_f1m=0.7278 | LR=0.000497\n",
      "  Época   9 | train_loss=0.0685 | train_acc=0.8239 | val_loss=0.0916 | val_acc=0.7556 | val_f1m=0.7555 | LR=0.000494\n",
      "  Época  10 | train_loss=0.0660 | train_acc=0.8351 | val_loss=0.0938 | val_acc=0.7333 | val_f1m=0.7315 | LR=0.000491\n",
      "  Época  11 | train_loss=0.0686 | train_acc=0.8291 | val_loss=0.0903 | val_acc=0.7556 | val_f1m=0.7554 | LR=0.000487\n",
      "  Época  12 | train_loss=0.0652 | train_acc=0.8319 | val_loss=0.0981 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000483\n",
      "  Época  13 | train_loss=0.0622 | train_acc=0.8435 | val_loss=0.0971 | val_acc=0.7619 | val_f1m=0.7618 | LR=0.000478\n",
      "  Época  14 | train_loss=0.0620 | train_acc=0.8456 | val_loss=0.0978 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.000472\n",
      "  Época  15 | train_loss=0.0609 | train_acc=0.8410 | val_loss=0.0988 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000466\n",
      "  Época  16 | train_loss=0.0615 | train_acc=0.8494 | val_loss=0.0961 | val_acc=0.7460 | val_f1m=0.7460 | LR=0.000459\n",
      "  Época  17 | train_loss=0.0585 | train_acc=0.8557 | val_loss=0.1158 | val_acc=0.7683 | val_f1m=0.7673 | LR=0.000451\n",
      "  Época  18 | train_loss=0.0600 | train_acc=0.8512 | val_loss=0.1142 | val_acc=0.7476 | val_f1m=0.7463 | LR=0.000443\n",
      "  Época  19 | train_loss=0.0597 | train_acc=0.8519 | val_loss=0.0966 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000434\n",
      "  Época  20 | train_loss=0.0584 | train_acc=0.8578 | val_loss=0.0998 | val_acc=0.7667 | val_f1m=0.7655 | LR=0.000425\n",
      "  Época  21 | train_loss=0.0582 | train_acc=0.8508 | val_loss=0.1060 | val_acc=0.7683 | val_f1m=0.7680 | LR=0.000415\n",
      "  Época  22 | train_loss=0.0553 | train_acc=0.8666 | val_loss=0.1058 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000405\n",
      "  Época  23 | train_loss=0.0536 | train_acc=0.8704 | val_loss=0.1055 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000395\n",
      "  Época  24 | train_loss=0.0549 | train_acc=0.8662 | val_loss=0.1055 | val_acc=0.7651 | val_f1m=0.7649 | LR=0.000384\n",
      "  Época  25 | train_loss=0.0537 | train_acc=0.8676 | val_loss=0.1054 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000373\n",
      "  Época  26 | train_loss=0.0528 | train_acc=0.8761 | val_loss=0.1054 | val_acc=0.7619 | val_f1m=0.7617 | LR=0.000361\n",
      "  Época  27 | train_loss=0.0529 | train_acc=0.8739 | val_loss=0.1054 | val_acc=0.7635 | val_f1m=0.7633 | LR=0.000349\n",
      "  Early stopping en época 27 (mejor val_f1m=0.7777)\n",
      "↳ Modelo global guardado en: ModeloW/nb2_h6/nb2_h6/fold5/model_global_fold5_nb2_h6.pth\n",
      "↳ Training curve saved: ModeloW/nb2_h6/nb2_h6/fold5/training_curve_fold5_nb2_h6.png\n",
      "↳ History saved: ModeloW/nb2_h6/nb2_h6/fold5/history_fold5_nb2_h6.npz\n",
      "[Fold 5/5] Global acc=0.8464 | f1_macro=0.8464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8540    0.8357    0.8448       420\n",
      "       right     0.8392    0.8571    0.8481       420\n",
      "\n",
      "    accuracy                         0.8464       840\n",
      "   macro avg     0.8466    0.8464    0.8464       840\n",
      "weighted avg     0.8466    0.8464    0.8464       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[351  69]\n",
      " [ 60 360]]\n",
      "precision_macro=0.8466 | recall_macro=0.8464 | specificity_macro=0.8464 | sensitivity_macro=0.8464\n",
      "↳ Confusion matrix saved: ModeloW/nb2_h6/nb2_h6/fold5/confusion_global_fold5_nb2_h6.png\n",
      "↳ Mapa de atención: ModeloW/nb2_h6/nb2_h6/fold5/attention_map_fold5_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold5/topomap_saliency_fold5_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/nb2_h6/fold5/topomap_log10p_fold5_nb2_h6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↳ t-SNE (CLS embeddings) guardado: ModeloW/nb2_h6/nb2_h6/fold5/tsne_cls_fold5_nb2_h6.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8786 | f1_macro=0.8786\n",
      "↳ Matriz de confusión FT guardada: ModeloW/nb2_h6/nb2_h6/fold5/confusion_ft_fold5_nb2_h6.png\n",
      "[Consumo] params_total=232,290 | params_trainable=232,290 | FLOPs~24.3M | latency/batch=1.12 ms (B=8)\n",
      "↳ Resumen 5-fold guardado: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/summary_nb2_h6.csv\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES [nb2_h6] (2 clases: left/right)\n",
      "============================================================\n",
      "Global folds (ACC): ['0.8107', '0.8356', '0.8084', '0.8119', '0.8464']\n",
      "Global mean ACC:    0.8226\n",
      "F1 folds (MACRO):   ['0.8107', '0.8353', '0.8084', '0.8098', '0.8464']\n",
      "F1 mean (MACRO):    0.8221\n",
      "FT folds (ACC):     ['0.8526', '0.8878', '0.8469', '0.8738', '0.8786']\n",
      "FT mean (ACC):      0.8679\n",
      "Δ(FT-Global) mean:  +0.0453\n",
      "\n",
      "================ Computational metrics ================\n",
      "Model tag: nb2_h6\n",
      "Phase        time (s)           memory (MB)        FLOPs (g)   params (m)\n",
      "-----------  -----------------  -----------------  ----------  ----------\n",
      "model specs  N/A                N/A                    0.024      0.232\n",
      "train         18.02 ( 6.03)    3288.6 (  1.4)     N/A        N/A\n",
      "test           8.46                168.3              N/A        N/A\n",
      "↳ Tabla de métricas computacionales guardada en: /root/Proyecto/EEG_Clasificador/models/04_hybrid/ModeloW/nb2_h6/computational_nb2_h6.csv\n",
      "↳ Matriz de confusión GLOBAL guardada: ModeloW/nb2_h6/confusion_global_allfolds_nb2_h6.png\n",
      "↳ Curva de loss GLOBAL guardada: ModeloW/nb2_h6/training_curve_global_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/topomap_saliency_GLOBAL_nb2_h6.png\n",
      "↳ Topomap GLOBAL de saliency guardado: ModeloW/nb2_h6/topomap_saliency_GLOBAL_nb2_h6.png\n",
      "↳ Topomap guardado: ModeloW/nb2_h6/topomap_log10p_GLOBAL_nb2_h6.png\n",
      "↳ Topomap GLOBAL de -log10(p) guardado: ModeloW/nb2_h6/topomap_log10p_GLOBAL_nb2_h6.png\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"MODELO\")\n",
    "    # 1) Barrido con UN SOLO FOLD (fold=1). Ajusta deltas y head_set si quieres.\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=1)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=2)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=3)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=4)\n",
    "    # sweep = run_arch_sweep(DEVICE, base_blocks=2, deltas=(-2,0,+2), head_set=(2,4,6), sweep_fold=5)\n",
    "\n",
    "    # 2) (Luego) con los GANADORES corre los 5 folds:\n",
    "    run_full_5fold_for_config(DEVICE, n_blocks=2, n_heads=6)\n",
    "\n",
    "    # 3) (Opcional) imprimir hiperparámetros contados:\n",
    "    # hp = current_hparams()\n",
    "    # print(f\"\\nHiperparámetros (n={len(hp)}):\")\n",
    "    # for k,v in hp.items():\n",
    "    #     print(f\" - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3391ab",
   "metadata": {},
   "source": [
    "---\n",
    "## ESTUDIO DE ABLACIÓN\n",
    "\n",
    "Esta sección implementa un estudio de ablación sistemático para evaluar la contribución de cada componente del modelo híbrido CNN-Transformer.\n",
    "\n",
    "### Variantes evaluadas:\n",
    "1. **Baseline**: Modelo completo con todos los componentes\n",
    "2. **Sin Depthwise Blocks**: Solo stem convolucional (n_dw_blocks=0)\n",
    "3. **Sin Codificación Posicional**: Elimina positional encoding\n",
    "4. **Sin Token CLS**: Usa average pooling en vez del token de clasificación\n",
    "5. **Con BatchNorm**: Reemplaza GroupNorm por BatchNorm\n",
    "6. **Con ReLU**: Reemplaza activaciones ELU/GELU por ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db544524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# VARIANTES DEL MODELO PARA ABLACIÓN\n",
    "# =========================\n",
    "\n",
    "# VARIANTE 1: Sin bloques depthwise (solo stem)\n",
    "class EEGCNNTransformer_NoDepthwise(nn.Module):\n",
    "    \"\"\"Variante sin bloques depthwise separable\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Solo stem, sin bloques depthwise\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        )\n",
    "        \n",
    "        self.proj = nn.Conv1d(32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # CLS token\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 2: Sin codificación posicional\n",
    "class EEGCNNTransformer_NoPosEncoding(nn.Module):\n",
    "    \"\"\"Variante sin positional encoding\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "\n",
    "        # Stem convolucional\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # SIN positional encoding\n",
    "        \n",
    "        # CLS token\n",
    "        B = z.shape[0]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 3: Sin token CLS (average pooling)\n",
    "class EEGCNNTransformer_NoCLS(nn.Module):\n",
    "    \"\"\"Variante sin token CLS, usa average pooling\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem convolucional\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Head (sin CLS token)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # SIN CLS token\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        # Average pooling en lugar de CLS\n",
    "        pooled = z.mean(dim=1)  # (B, D)\n",
    "        return self.head(pooled)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 4: Con BatchNorm en vez de GroupNorm\n",
    "def make_bn(num_channels):\n",
    "    \"\"\"Crea capa BatchNorm1d\"\"\"\n",
    "    return nn.BatchNorm1d(num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv_BN(nn.Module):\n",
    "    \"\"\"Convolución depthwise separable con BatchNorm\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_bn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class EEGCNNTransformer_BatchNorm(nn.Module):\n",
    "    \"\"\"Variante con BatchNorm en vez de GroupNorm\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem con BatchNorm\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_bn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise con BatchNorm\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv_BN(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer\n",
    "        enc = _CustomEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                  dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # CLS token\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "\n",
    "# VARIANTE 5: Con ReLU en vez de ELU/GELU\n",
    "class DepthwiseSeparableConv_ReLU(nn.Module):\n",
    "    \"\"\"Convolución depthwise separable con ReLU\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ReLU()  # ReLU en vez de ELU\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class _CustomEncoderLayer_ReLU(nn.Module):\n",
    "    \"\"\"Encoder Transformer con ReLU en FFN\"\"\"\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout, batch_first, norm_first, return_attn=True):\n",
    "        super().__init__()\n",
    "        self.return_attn = return_attn\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()  # ReLU en vez de GELU\n",
    "        self.norm_first = norm_first\n",
    "\n",
    "    def forward(self, src):\n",
    "        sa_out, attn_weights = self.self_attn(src, src, src, need_weights=True, average_attn_weights=False)\n",
    "        src = self.norm1(src + self.dropout1(sa_out))\n",
    "        ff = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = self.norm2(src + self.dropout2(ff))\n",
    "        return src, attn_weights\n",
    "\n",
    "class EEGCNNTransformer_ReLU(nn.Module):\n",
    "    \"\"\"Variante con ReLU en vez de ELU/GELU\"\"\"\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3, n_dw_blocks=2,\n",
    "                 k_list=(31,15,7), s_list=(2,2,2), p_list=(15,7,3), capture_attn=False):\n",
    "        super().__init__()\n",
    "        self.capture_attn = capture_attn\n",
    "        self._last_attn = None\n",
    "        self.pos_encoding = None\n",
    "\n",
    "        # Stem con ReLU\n",
    "        stem = [\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ReLU(),  # ReLU en vez de ELU\n",
    "            nn.Dropout(p=p_drop),\n",
    "        ]\n",
    "        \n",
    "        # Bloques depthwise con ReLU\n",
    "        blocks = []\n",
    "        in_c, out_cs = 32, [64, 128, 256, 256, 256]\n",
    "        n_dw_blocks = int(np.clip(n_dw_blocks, 0, len(out_cs)))\n",
    "        for i in range(n_dw_blocks):\n",
    "            k = k_list[i] if i < len(k_list) else 7\n",
    "            s = s_list[i] if i < len(s_list) else 2\n",
    "            p = p_list[i] if i < len(p_list) else k//2\n",
    "            blocks.append(DepthwiseSeparableConv_ReLU(in_c, out_cs[i], k=k, s=s, p=p, p_drop=p_drop))\n",
    "            in_c = out_cs[i]\n",
    "\n",
    "        self.conv_t = nn.Sequential(*stem, *blocks)\n",
    "        self.proj = nn.Conv1d(in_c if n_dw_blocks>0 else 32, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "\n",
    "        # Encoder Transformer con ReLU\n",
    "        enc = _CustomEncoderLayer_ReLU(d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "                                       dropout=0.1, batch_first=True, norm_first=False, return_attn=True)\n",
    "        self.encoder = _CustomEncoder(enc, num_layers=n_layers)\n",
    "\n",
    "        # Token CLS y head\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)\n",
    "        z = self.proj(z)\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        \n",
    "        # CLS token\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "\n",
    "        z, attn_list = self.encoder(z)\n",
    "        if self.capture_attn:\n",
    "            self._last_attn = attn_list\n",
    "\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "    def get_last_attention_maps(self):\n",
    "        return self._last_attn\n",
    "\n",
    "print(\"✓ Variantes del modelo definidas para estudio de ablación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe6e20",
   "metadata": {},
   "source": [
    "### Función de Entrenamiento del Estudio de Ablación\n",
    "\n",
    "Esta función entrena cada variante del modelo y recopila métricas para comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ESTUDIO DE ABLACIÓN - FUNCIÓN PRINCIPAL\n",
    "# =========================\n",
    "\n",
    "def run_ablation_study(device, fold_list=[1], base_dir=None):\n",
    "    \"\"\"\n",
    "    Ejecuta estudio de ablación entrenando todas las variantes del modelo.\n",
    "    \n",
    "    Args:\n",
    "        device: Dispositivo para entrenamiento (cuda/cpu)\n",
    "        fold_list: Lista de folds a evaluar (default: [1])\n",
    "        base_dir: Directorio base para guardar resultados\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con resultados comparativos\n",
    "    \"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    else:\n",
    "        base_dir = Path(base_dir)\n",
    "    \n",
    "    ensure_dir(base_dir)\n",
    "    \n",
    "    # Definir variantes del modelo\n",
    "    variants = {\n",
    "        'baseline': {\n",
    "            'name': 'Baseline (Completo)',\n",
    "            'factory': lambda: EEGCNNTransformer(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS, \n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'Modelo completo con todos los componentes'\n",
    "        },\n",
    "        'no_depthwise': {\n",
    "            'name': 'Sin Depthwise Blocks',\n",
    "            'factory': lambda: EEGCNNTransformer_NoDepthwise(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                capture_attn=False\n",
    "            ),\n",
    "            'description': 'Solo stem convolucional, sin bloques depthwise'\n",
    "        },\n",
    "        'no_posenc': {\n",
    "            'name': 'Sin Codificación Posicional',\n",
    "            'factory': lambda: EEGCNNTransformer_NoPosEncoding(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'Sin positional encoding en Transformer'\n",
    "        },\n",
    "        'no_cls': {\n",
    "            'name': 'Sin Token CLS',\n",
    "            'factory': lambda: EEGCNNTransformer_NoCLS(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'Usa average pooling en vez de token CLS'\n",
    "        },\n",
    "        'batchnorm': {\n",
    "            'name': 'Con BatchNorm',\n",
    "            'factory': lambda: EEGCNNTransformer_BatchNorm(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'BatchNorm en vez de GroupNorm'\n",
    "        },\n",
    "        'relu': {\n",
    "            'name': 'Con ReLU',\n",
    "            'factory': lambda: EEGCNNTransformer_ReLU(\n",
    "                n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER,\n",
    "                n_dw_blocks=2, capture_attn=False\n",
    "            ),\n",
    "            'description': 'ReLU en vez de ELU/GELU'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    results = []\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"INICIANDO ESTUDIO DE ABLACIÓN\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Variantes a evaluar: {len(variants)}\")\n",
    "    print(f\"Folds: {fold_list}\")\n",
    "    print(f\"Directorio de salida: {base_dir}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Entrenar cada variante\n",
    "    for variant_key, variant_info in variants.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"VARIANTE: {variant_info['name']}\")\n",
    "        print(f\"Descripción: {variant_info['description']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        variant_dir = base_dir / variant_key\n",
    "        ensure_dir(variant_dir)\n",
    "        \n",
    "        # Resultados de esta variante\n",
    "        variant_results = {\n",
    "            'variant': variant_key,\n",
    "            'name': variant_info['name'],\n",
    "            'description': variant_info['description']\n",
    "        }\n",
    "        \n",
    "        # Métricas acumuladas por fold\n",
    "        fold_accs = []\n",
    "        fold_f1s = []\n",
    "        fold_params = []\n",
    "        \n",
    "        for fold in fold_list:\n",
    "            print(f\"\\n--- Fold {fold} ---\")\n",
    "            seed_everything(RANDOM_STATE + fold)\n",
    "            \n",
    "            try:\n",
    "                # Cargar datos\n",
    "                train_subs, test_subs = load_fold_subjects(FOLDS_JSON, fold)\n",
    "                print(f\"Train: {len(train_subs)} sujetos, Test: {len(test_subs)} sujetos\")\n",
    "                \n",
    "                # Cargar épocas\n",
    "                X_train_list, y_train_list = [], []\n",
    "                for sid in tqdm(train_subs, desc=\"Cargando train\"):\n",
    "                    X, y, _ = load_subject_epochs(\n",
    "                        sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, \n",
    "                        DO_CAR, BP_LO, BP_HI\n",
    "                    )\n",
    "                    if X.shape[0] > 0:\n",
    "                        X_train_list.append(X)\n",
    "                        y_train_list.append(y)\n",
    "                \n",
    "                X_test_list, y_test_list = [], []\n",
    "                for sid in tqdm(test_subs, desc=\"Cargando test\"):\n",
    "                    X, y, _ = load_subject_epochs(\n",
    "                        sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS,\n",
    "                        DO_CAR, BP_LO, BP_HI\n",
    "                    )\n",
    "                    if X.shape[0] > 0:\n",
    "                        X_test_list.append(X)\n",
    "                        y_test_list.append(y)\n",
    "                \n",
    "                X_train = np.concatenate(X_train_list, axis=0)\n",
    "                y_train = np.concatenate(y_train_list, axis=0)\n",
    "                X_test = np.concatenate(X_test_list, axis=0)\n",
    "                y_test = np.concatenate(y_test_list, axis=0)\n",
    "                \n",
    "                # Estandarizar\n",
    "                X_train, X_test = standardize_per_channel(X_train, X_test)\n",
    "                \n",
    "                print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "                \n",
    "                # Crear modelo\n",
    "                model = variant_info['factory']().to(device)\n",
    "                n_params = count_params(model)\n",
    "                fold_params.append(n_params)\n",
    "                print(f\"Parámetros: {n_params:,}\")\n",
    "                \n",
    "                # Preparar DataLoader\n",
    "                train_dataset = TensorDataset(\n",
    "                    torch.tensor(X_train, dtype=torch.float32),\n",
    "                    torch.tensor(y_train, dtype=torch.long)\n",
    "                )\n",
    "                \n",
    "                if USE_WEIGHTED_SAMPLER:\n",
    "                    class_counts = np.bincount(y_train)\n",
    "                    class_weights = 1.0 / (class_counts + 1e-6)\n",
    "                    sample_weights = class_weights[y_train]\n",
    "                    sampler = WeightedRandomSampler(\n",
    "                        weights=sample_weights,\n",
    "                        num_samples=len(sample_weights),\n",
    "                        replacement=True\n",
    "                    )\n",
    "                    train_loader = DataLoader(\n",
    "                        train_dataset, batch_size=BATCH_SIZE,\n",
    "                        sampler=sampler, worker_init_fn=seed_worker,\n",
    "                        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                    )\n",
    "                else:\n",
    "                    train_loader = DataLoader(\n",
    "                        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "                    )\n",
    "                \n",
    "                # Pérdida y optimizador\n",
    "                alpha = torch.tensor([1.0, 1.0], device=device)\n",
    "                criterion = FocalLoss(alpha=alpha, gamma=1.5)\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-4)\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer, T_max=EPOCHS, eta_min=1e-6\n",
    "                )\n",
    "                \n",
    "                # EMA\n",
    "                ema = ModelEMA(model, decay=EMA_DECAY, device=device) if USE_EMA else None\n",
    "                \n",
    "                # Entrenamiento\n",
    "                best_val_acc = 0.0\n",
    "                patience_counter = 0\n",
    "                \n",
    "                for epoch in range(EPOCHS):\n",
    "                    model.train()\n",
    "                    train_loss = 0.0\n",
    "                    \n",
    "                    for xb, yb in train_loader:\n",
    "                        xb, yb = xb.to(device), yb.to(device)\n",
    "                        \n",
    "                        # Augmentación\n",
    "                        if epoch > WARMUP_EPOCHS:\n",
    "                            xb = augment_batch(xb)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model(xb)\n",
    "                        loss = criterion(logits, yb)\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if ema is not None:\n",
    "                            ema.update(model)\n",
    "                        \n",
    "                        train_loss += loss.item()\n",
    "                    \n",
    "                    scheduler.step()\n",
    "                    \n",
    "                    # Validación en test set (simplificado)\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                        logits = model(X_test_t)\n",
    "                        y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                        val_acc = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {train_loss/len(train_loader):.4f}, Val Acc: {val_acc:.4f}\")\n",
    "                    \n",
    "                    # Early stopping\n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = val_acc\n",
    "                        patience_counter = 0\n",
    "                        # Guardar mejor modelo\n",
    "                        torch.save(model.state_dict(), variant_dir / f\"best_fold{fold}.pt\")\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        if patience_counter >= PATIENCE:\n",
    "                            print(f\"Early stopping en epoch {epoch+1}\")\n",
    "                            break\n",
    "                \n",
    "                # Evaluación final\n",
    "                model.load_state_dict(torch.load(variant_dir / f\"best_fold{fold}.pt\"))\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "                    logits = model(X_test_t)\n",
    "                    y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "                \n",
    "                # Métricas\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                metrics = compute_metrics(y_test, y_pred)\n",
    "                \n",
    "                fold_accs.append(acc)\n",
    "                fold_f1s.append(f1)\n",
    "                \n",
    "                print(f\"Fold {fold} - Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "                \n",
    "                # Limpiar memoria\n",
    "                del model, optimizer, scheduler, train_loader, X_train, y_train\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR en fold {fold}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                fold_accs.append(0.0)\n",
    "                fold_f1s.append(0.0)\n",
    "                fold_params.append(0)\n",
    "        \n",
    "        # Compilar resultados de la variante\n",
    "        variant_results['mean_accuracy'] = np.mean(fold_accs) if fold_accs else 0.0\n",
    "        variant_results['std_accuracy'] = np.std(fold_accs) if fold_accs else 0.0\n",
    "        variant_results['mean_f1'] = np.mean(fold_f1s) if fold_f1s else 0.0\n",
    "        variant_results['std_f1'] = np.std(fold_f1s) if fold_f1s else 0.0\n",
    "        variant_results['n_params'] = fold_params[0] if fold_params else 0\n",
    "        variant_results['folds'] = fold_list\n",
    "        variant_results['fold_accs'] = fold_accs\n",
    "        variant_results['fold_f1s'] = fold_f1s\n",
    "        \n",
    "        results.append(variant_results)\n",
    "        \n",
    "        print(f\"\\n{variant_info['name']} - Resumen:\")\n",
    "        print(f\"  Accuracy: {variant_results['mean_accuracy']:.4f} ± {variant_results['std_accuracy']:.4f}\")\n",
    "        print(f\"  F1-Score: {variant_results['mean_f1']:.4f} ± {variant_results['std_f1']:.4f}\")\n",
    "        print(f\"  Parámetros: {variant_results['n_params']:,}\")\n",
    "    \n",
    "    # Crear DataFrame con resultados\n",
    "    import pandas as pd\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_csv = base_dir / 'ablation_results.csv'\n",
    "    df_results.to_csv(results_csv, index=False)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Resultados guardados en: {results_csv}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "def plot_ablation_results(df_results, output_dir=None):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones de los resultados del estudio de ablación.\n",
    "    \n",
    "    Args:\n",
    "        df_results: DataFrame con resultados\n",
    "        output_dir: Directorio para guardar gráficos\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    # Ordenar por accuracy\n",
    "    df_sorted = df_results.sort_values('mean_accuracy', ascending=False)\n",
    "    \n",
    "    # Gráfico de barras con accuracy y F1\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.barh(df_sorted['name'], df_sorted['mean_accuracy'], \n",
    "             xerr=df_sorted['std_accuracy'], capsize=5, color='steelblue')\n",
    "    ax1.set_xlabel('Accuracy')\n",
    "    ax1.set_title('Comparación de Accuracy por Variante')\n",
    "    ax1.set_xlim([0, 1.0])\n",
    "    ax1.axvline(x=df_sorted.iloc[0]['mean_accuracy'], color='red', \n",
    "                linestyle='--', alpha=0.5, label='Mejor')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # F1-Score\n",
    "    ax2.barh(df_sorted['name'], df_sorted['mean_f1'], \n",
    "             xerr=df_sorted['std_f1'], capsize=5, color='coral')\n",
    "    ax2.set_xlabel('F1-Score (Macro)')\n",
    "    ax2.set_title('Comparación de F1-Score por Variante')\n",
    "    ax2.set_xlim([0, 1.0])\n",
    "    ax2.axvline(x=df_sorted.iloc[0]['mean_f1'], color='red', \n",
    "                linestyle='--', alpha=0.5, label='Mejor')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = output_dir / 'ablation_comparison.png'\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Gráfico guardado en: {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Tabla de comparación\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = []\n",
    "    for _, row in df_sorted.iterrows():\n",
    "        table_data.append([\n",
    "            row['name'],\n",
    "            f\"{row['mean_accuracy']:.4f} ± {row['std_accuracy']:.4f}\",\n",
    "            f\"{row['mean_f1']:.4f} ± {row['std_f1']:.4f}\",\n",
    "            f\"{row['n_params']:,}\"\n",
    "        ])\n",
    "    \n",
    "    table = ax.table(cellText=table_data,\n",
    "                     colLabels=['Variante', 'Accuracy', 'F1-Score', 'Parámetros'],\n",
    "                     cellLoc='left',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Colorear la mejor fila\n",
    "    for i in range(4):\n",
    "        table[(1, i)].set_facecolor('#90EE90')\n",
    "    \n",
    "    plt.title('Resumen de Resultados - Estudio de Ablación', \n",
    "              fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    table_path = output_dir / 'ablation_table.png'\n",
    "    plt.savefig(table_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Tabla guardada en: {table_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "print(\"✓ Funciones de estudio de ablación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2996ec",
   "metadata": {},
   "source": [
    "### Ejecución del Estudio de Ablación\n",
    "\n",
    "Ejecuta el estudio de ablación y genera visualizaciones comparativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5eab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EJECUTAR ESTUDIO DE ABLACIÓN\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuración del estudio\n",
    "    # Puedes cambiar fold_list para evaluar en múltiples folds\n",
    "    # Por defecto usa solo fold 1 para rapidez (para pruebas)\n",
    "    # Para resultados finales, usar fold_list=[1, 2, 3, 4, 5]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTUDIO DE ABLACIÓN - CNN+Transformer para EEG Motor Imagery\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # OPCIÓN 1: Prueba rápida con 1 fold\n",
    "    fold_list = [1]\n",
    "    \n",
    "    # OPCIÓN 2: Evaluación completa con 5 folds (descomenta para usar)\n",
    "    # fold_list = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    # Ejecutar estudio de ablación\n",
    "    print(f\"Ejecutando estudio con {len(fold_list)} fold(s): {fold_list}\")\n",
    "    print(\"Esto puede tardar varios minutos dependiendo del número de folds...\\n\")\n",
    "    \n",
    "    df_results = run_ablation_study(\n",
    "        device=DEVICE,\n",
    "        fold_list=fold_list,\n",
    "        base_dir=PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    )\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTADOS DEL ESTUDIO DE ABLACIÓN\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_results[['name', 'mean_accuracy', 'std_accuracy', 'mean_f1', 'std_f1', 'n_params']].to_string(index=False))\n",
    "    \n",
    "    # Generar gráficos\n",
    "    print(\"\\nGenerando visualizaciones...\")\n",
    "    df_sorted = plot_ablation_results(\n",
    "        df_results,\n",
    "        output_dir=PROJ / 'models' / '04_hybrid' / 'ablation_study'\n",
    "    )\n",
    "    \n",
    "    # Análisis de contribución relativa (vs baseline)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS DE CONTRIBUCIÓN RELATIVA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    baseline_acc = df_results[df_results['variant'] == 'baseline']['mean_accuracy'].values[0]\n",
    "    \n",
    "    print(f\"\\nBaseline Accuracy: {baseline_acc:.4f}\\n\")\n",
    "    print(\"Variante                      | Acc ± Std          | Δ vs Baseline | % Change\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for _, row in df_sorted.iterrows():\n",
    "        delta = row['mean_accuracy'] - baseline_acc\n",
    "        pct_change = (delta / baseline_acc) * 100 if baseline_acc > 0 else 0\n",
    "        sign = \"+\" if delta >= 0 else \"\"\n",
    "        \n",
    "        print(f\"{row['name']:30s} | {row['mean_accuracy']:.4f} ± {row['std_accuracy']:.4f} | \"\n",
    "              f\"{sign}{delta:+.4f}    | {sign}{pct_change:+.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERPRETACIÓN:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"• Δ positivo: El componente REDUCE el rendimiento (su eliminación mejora)\")\n",
    "    print(\"• Δ negativo: El componente MEJORA el rendimiento (su eliminación empeora)\")\n",
    "    print(\"• Δ cercano a 0: El componente tiene impacto mínimo\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Identificar componentes más importantes\n",
    "    contributions = []\n",
    "    for _, row in df_results.iterrows():\n",
    "        if row['variant'] != 'baseline':\n",
    "            delta = baseline_acc - row['mean_accuracy']  # Invertido: pérdida de rendimiento\n",
    "            contributions.append({\n",
    "                'component': row['name'],\n",
    "                'contribution': delta,\n",
    "                'abs_contribution': abs(delta)\n",
    "            })\n",
    "    \n",
    "    contributions_sorted = sorted(contributions, key=lambda x: x['abs_contribution'], reverse=True)\n",
    "    \n",
    "    print(\"Ranking de componentes por impacto (mayor a menor):\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, comp in enumerate(contributions_sorted, 1):\n",
    "        impact = \"BENEFICIOSO\" if comp['contribution'] > 0 else \"PERJUDICIAL\" if comp['contribution'] < 0 else \"NEUTRAL\"\n",
    "        print(f\"{i}. {comp['component']:30s} | Contribución: {comp['contribution']:+.4f} | {impact}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTUDIO COMPLETADO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Resultados guardados en: {PROJ / 'models' / '04_hybrid' / 'ablation_study'}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9a4df",
   "metadata": {},
   "source": [
    "---\n",
    "## Instrucciones de Uso\n",
    "\n",
    "### Configuración rápida:\n",
    "1. **Prueba rápida** (1 fold): Deja `fold_list = [1]` en la celda anterior\n",
    "2. **Evaluación completa** (5 folds): Cambia a `fold_list = [1, 2, 3, 4, 5]`\n",
    "\n",
    "### Tiempo estimado:\n",
    "- **1 fold**: ~10-15 minutos por variante (total ~60-90 minutos para 6 variantes)\n",
    "- **5 folds**: ~50-75 minutos por variante (total ~5-7.5 horas para 6 variantes)\n",
    "\n",
    "### Resultados generados:\n",
    "- **CSV**: `ablation_results.csv` - Tabla con todas las métricas\n",
    "- **Gráficos**: \n",
    "  - `ablation_comparison.png` - Comparación visual de accuracy y F1\n",
    "  - `ablation_table.png` - Tabla formateada con resultados\n",
    "- **Modelos**: Guardados en `ablation_study/<variante>/best_fold{X}.pt`\n",
    "\n",
    "### Interpretación de resultados:\n",
    "- **Baseline** es tu modelo completo (referencia)\n",
    "- Si al **eliminar un componente** el accuracy **baja** → ese componente es **beneficioso**\n",
    "- Si al **eliminar un componente** el accuracy **sube** → ese componente puede estar **perjudicando**\n",
    "- Diferencias < 1-2% pueden ser ruido estadístico\n",
    "\n",
    "### Para tu tesis:\n",
    "Puedes usar los gráficos y tablas generadas directamente en tu documento. La tabla de \"Contribución Relativa\" te ayudará a argumentar qué componentes son esenciales para tu modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
