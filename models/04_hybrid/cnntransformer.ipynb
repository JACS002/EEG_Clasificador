{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6185bcc",
   "metadata": {},
   "source": [
    "## 4 CLASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce70980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.001 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:09<00:00,  6.82it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.23it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  Ã‰poca   1 | train_loss=0.2326 | train_acc=0.2772 | val_acc=0.2627 | val_f1m=0.2225 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2126 | train_acc=0.3257 | val_acc=0.3825 | val_f1m=0.3362 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1839 | train_acc=0.4577 | val_acc=0.4381 | val_f1m=0.4333 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1797 | train_acc=0.4844 | val_acc=0.4571 | val_f1m=0.4561 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1724 | train_acc=0.5137 | val_acc=0.4508 | val_f1m=0.4461 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1673 | train_acc=0.5348 | val_acc=0.4476 | val_f1m=0.4405 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1650 | train_acc=0.5311 | val_acc=0.4397 | val_f1m=0.4288 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1653 | train_acc=0.5359 | val_acc=0.4611 | val_f1m=0.4632 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1664 | train_acc=0.5226 | val_acc=0.4484 | val_f1m=0.4503 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1582 | train_acc=0.5414 | val_acc=0.4571 | val_f1m=0.4575 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1579 | train_acc=0.5458 | val_acc=0.4635 | val_f1m=0.4634 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1565 | train_acc=0.5576 | val_acc=0.4683 | val_f1m=0.4682 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1520 | train_acc=0.5618 | val_acc=0.4675 | val_f1m=0.4676 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1534 | train_acc=0.5684 | val_acc=0.4683 | val_f1m=0.4684 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1531 | train_acc=0.5730 | val_acc=0.4675 | val_f1m=0.4676 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1471 | train_acc=0.5832 | val_acc=0.4706 | val_f1m=0.4706 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1446 | train_acc=0.5855 | val_acc=0.4746 | val_f1m=0.4744 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1466 | train_acc=0.5732 | val_acc=0.4762 | val_f1m=0.4761 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1452 | train_acc=0.5876 | val_acc=0.4778 | val_f1m=0.4776 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1438 | train_acc=0.5864 | val_acc=0.4802 | val_f1m=0.4799 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1454 | train_acc=0.5823 | val_acc=0.4794 | val_f1m=0.4787 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1424 | train_acc=0.5904 | val_acc=0.4770 | val_f1m=0.4760 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1415 | train_acc=0.5885 | val_acc=0.4762 | val_f1m=0.4752 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1392 | train_acc=0.6025 | val_acc=0.4794 | val_f1m=0.4785 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1388 | train_acc=0.6016 | val_acc=0.4794 | val_f1m=0.4786 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.1380 | train_acc=0.6111 | val_acc=0.4794 | val_f1m=0.4783 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.1313 | train_acc=0.6171 | val_acc=0.4817 | val_f1m=0.4806 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.1351 | train_acc=0.6125 | val_acc=0.4778 | val_f1m=0.4766 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.1328 | train_acc=0.6103 | val_acc=0.4770 | val_f1m=0.4758 | LR=0.000710\n",
      "  Ã‰poca  30 | train_loss=0.1260 | train_acc=0.6317 | val_acc=0.4802 | val_f1m=0.4788 | LR=0.000684\n",
      "  Ã‰poca  31 | train_loss=0.1248 | train_acc=0.6276 | val_acc=0.4770 | val_f1m=0.4757 | LR=0.000658\n",
      "  Ã‰poca  32 | train_loss=0.1287 | train_acc=0.6190 | val_acc=0.4794 | val_f1m=0.4781 | LR=0.000631\n",
      "  Ã‰poca  33 | train_loss=0.1243 | train_acc=0.6338 | val_acc=0.4778 | val_f1m=0.4765 | LR=0.000604\n",
      "  Ã‰poca  34 | train_loss=0.1203 | train_acc=0.6354 | val_acc=0.4802 | val_f1m=0.4788 | LR=0.000577\n",
      "  Ã‰poca  35 | train_loss=0.1205 | train_acc=0.6468 | val_acc=0.4802 | val_f1m=0.4785 | LR=0.000550\n",
      "  Ã‰poca  36 | train_loss=0.1166 | train_acc=0.6507 | val_acc=0.4817 | val_f1m=0.4801 | LR=0.000523\n",
      "  Ã‰poca  37 | train_loss=0.1126 | train_acc=0.6672 | val_acc=0.4817 | val_f1m=0.4803 | LR=0.000496\n",
      "  Ã‰poca  38 | train_loss=0.1103 | train_acc=0.6693 | val_acc=0.4770 | val_f1m=0.4758 | LR=0.000469\n",
      "  Ã‰poca  39 | train_loss=0.1107 | train_acc=0.6622 | val_acc=0.4762 | val_f1m=0.4751 | LR=0.000442\n",
      "  Early stopping en Ã©poca 39 (mejor val_f1m=0.4806)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4994\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6199    0.5510    0.5834       441\n",
      "       right     0.5441    0.5601    0.5520       441\n",
      "  both fists     0.3892    0.4422    0.4140       441\n",
      "   both feet     0.4700    0.4444    0.4569       441\n",
      "\n",
      "    accuracy                         0.4994      1764\n",
      "   macro avg     0.5058    0.4994    0.5016      1764\n",
      "weighted avg     0.5058    0.4994    0.5016      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[243  42 101  55]\n",
      " [ 28 247 100  66]\n",
      " [ 63  83 195 100]\n",
      " [ 58  82 105 196]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold1.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5686\n",
      "  Î”(FT-Global) = +0.0692\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[273  32  85  51]\n",
      " [ 29 254  88  70]\n",
      " [ 56  59 246  80]\n",
      " [ 57  56  98 230]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:09<00:00,  7.07it/s]\n",
      "Cargando val fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  7.26it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  Ã‰poca   1 | train_loss=0.2279 | train_acc=0.2733 | val_acc=0.3056 | val_f1m=0.2554 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2164 | train_acc=0.3218 | val_acc=0.3889 | val_f1m=0.3563 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1937 | train_acc=0.4271 | val_acc=0.4349 | val_f1m=0.4283 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1842 | train_acc=0.4701 | val_acc=0.4603 | val_f1m=0.4592 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1778 | train_acc=0.4989 | val_acc=0.4667 | val_f1m=0.4591 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1776 | train_acc=0.4893 | val_acc=0.4619 | val_f1m=0.4597 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1742 | train_acc=0.5032 | val_acc=0.4770 | val_f1m=0.4738 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1750 | train_acc=0.4957 | val_acc=0.4746 | val_f1m=0.4715 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1705 | train_acc=0.5215 | val_acc=0.4730 | val_f1m=0.4739 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1645 | train_acc=0.5270 | val_acc=0.4881 | val_f1m=0.4889 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1688 | train_acc=0.5215 | val_acc=0.4944 | val_f1m=0.4952 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1625 | train_acc=0.5350 | val_acc=0.5000 | val_f1m=0.5009 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1608 | train_acc=0.5297 | val_acc=0.5024 | val_f1m=0.5029 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1645 | train_acc=0.5316 | val_acc=0.5016 | val_f1m=0.5023 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1593 | train_acc=0.5458 | val_acc=0.5024 | val_f1m=0.5033 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1612 | train_acc=0.5359 | val_acc=0.5000 | val_f1m=0.5006 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1580 | train_acc=0.5366 | val_acc=0.5032 | val_f1m=0.5041 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1545 | train_acc=0.5617 | val_acc=0.5032 | val_f1m=0.5036 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1566 | train_acc=0.5482 | val_acc=0.5024 | val_f1m=0.5031 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1469 | train_acc=0.5853 | val_acc=0.5032 | val_f1m=0.5038 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1570 | train_acc=0.5421 | val_acc=0.5040 | val_f1m=0.5044 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1501 | train_acc=0.5757 | val_acc=0.5040 | val_f1m=0.5045 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1498 | train_acc=0.5697 | val_acc=0.5063 | val_f1m=0.5066 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1481 | train_acc=0.5766 | val_acc=0.5063 | val_f1m=0.5067 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1472 | train_acc=0.5736 | val_acc=0.5048 | val_f1m=0.5052 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.1436 | train_acc=0.5780 | val_acc=0.4992 | val_f1m=0.5001 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.1422 | train_acc=0.5796 | val_acc=0.4944 | val_f1m=0.4952 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.1430 | train_acc=0.5819 | val_acc=0.4952 | val_f1m=0.4958 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.1498 | train_acc=0.5638 | val_acc=0.4968 | val_f1m=0.4976 | LR=0.000710\n",
      "  Ã‰poca  30 | train_loss=0.1377 | train_acc=0.5928 | val_acc=0.4937 | val_f1m=0.4943 | LR=0.000684\n",
      "  Ã‰poca  31 | train_loss=0.1371 | train_acc=0.6032 | val_acc=0.4960 | val_f1m=0.4969 | LR=0.000658\n",
      "  Ã‰poca  32 | train_loss=0.1327 | train_acc=0.6098 | val_acc=0.4968 | val_f1m=0.4978 | LR=0.000631\n",
      "  Ã‰poca  33 | train_loss=0.1354 | train_acc=0.6055 | val_acc=0.4976 | val_f1m=0.4986 | LR=0.000604\n",
      "  Ã‰poca  34 | train_loss=0.1300 | train_acc=0.6221 | val_acc=0.4992 | val_f1m=0.5006 | LR=0.000577\n",
      "  Ã‰poca  35 | train_loss=0.1283 | train_acc=0.6217 | val_acc=0.4984 | val_f1m=0.4999 | LR=0.000550\n",
      "  Early stopping en Ã©poca 35 (mejor val_f1m=0.5066)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5816\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6379    0.6871    0.6616       441\n",
      "       right     0.6353    0.6281    0.6317       441\n",
      "  both fists     0.5112    0.5170    0.5141       441\n",
      "   both feet     0.5356    0.4943    0.5142       441\n",
      "\n",
      "    accuracy                         0.5816      1764\n",
      "   macro avg     0.5800    0.5816    0.5804      1764\n",
      "weighted avg     0.5800    0.5816    0.5804      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[303  25  72  41]\n",
      " [ 35 277  64  65]\n",
      " [ 74  56 228  83]\n",
      " [ 63  78  82 218]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold2.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.6417\n",
      "  Î”(FT-Global) = +0.0601\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[315  14  80  32]\n",
      " [ 31 293  67  50]\n",
      " [ 58  36 274  73]\n",
      " [ 50  54  87 250]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:09<00:00,  7.00it/s]\n",
      "Cargando val fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.89it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:03<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  Ã‰poca   1 | train_loss=0.2271 | train_acc=0.2788 | val_acc=0.3048 | val_f1m=0.2318 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2121 | train_acc=0.3431 | val_acc=0.4151 | val_f1m=0.4163 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1900 | train_acc=0.4437 | val_acc=0.4508 | val_f1m=0.4547 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1801 | train_acc=0.4813 | val_acc=0.4635 | val_f1m=0.4623 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1720 | train_acc=0.5146 | val_acc=0.4849 | val_f1m=0.4840 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1697 | train_acc=0.5251 | val_acc=0.4937 | val_f1m=0.4964 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1700 | train_acc=0.5229 | val_acc=0.4857 | val_f1m=0.4877 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1673 | train_acc=0.5393 | val_acc=0.4937 | val_f1m=0.4947 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1642 | train_acc=0.5304 | val_acc=0.5143 | val_f1m=0.5126 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1624 | train_acc=0.5418 | val_acc=0.4976 | val_f1m=0.4990 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1576 | train_acc=0.5570 | val_acc=0.5111 | val_f1m=0.5127 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1584 | train_acc=0.5551 | val_acc=0.5103 | val_f1m=0.5128 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1601 | train_acc=0.5396 | val_acc=0.5119 | val_f1m=0.5146 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1559 | train_acc=0.5597 | val_acc=0.5127 | val_f1m=0.5153 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1563 | train_acc=0.5640 | val_acc=0.5151 | val_f1m=0.5177 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1562 | train_acc=0.5563 | val_acc=0.5175 | val_f1m=0.5201 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1541 | train_acc=0.5698 | val_acc=0.5206 | val_f1m=0.5234 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1506 | train_acc=0.5794 | val_acc=0.5198 | val_f1m=0.5224 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1509 | train_acc=0.5695 | val_acc=0.5198 | val_f1m=0.5224 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1492 | train_acc=0.5684 | val_acc=0.5159 | val_f1m=0.5184 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1457 | train_acc=0.5842 | val_acc=0.5159 | val_f1m=0.5181 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1446 | train_acc=0.5956 | val_acc=0.5167 | val_f1m=0.5189 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1463 | train_acc=0.5798 | val_acc=0.5175 | val_f1m=0.5196 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1480 | train_acc=0.5796 | val_acc=0.5143 | val_f1m=0.5163 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.1422 | train_acc=0.5979 | val_acc=0.5119 | val_f1m=0.5137 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.1381 | train_acc=0.6029 | val_acc=0.5119 | val_f1m=0.5137 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.1398 | train_acc=0.5963 | val_acc=0.5143 | val_f1m=0.5161 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.1420 | train_acc=0.5917 | val_acc=0.5127 | val_f1m=0.5144 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.1320 | train_acc=0.6192 | val_acc=0.5119 | val_f1m=0.5134 | LR=0.000710\n",
      "  Early stopping en Ã©poca 29 (mejor val_f1m=0.5234)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4870\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.5603    0.5374    0.5486       441\n",
      "       right     0.6324    0.4875    0.5506       441\n",
      "  both fists     0.3859    0.4331    0.4081       441\n",
      "   both feet     0.4269    0.4898    0.4562       441\n",
      "\n",
      "    accuracy                         0.4870      1764\n",
      "   macro avg     0.5013    0.4870    0.4909      1764\n",
      "weighted avg     0.5013    0.4870    0.4909      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[237  24 113  67]\n",
      " [ 31 215  93 102]\n",
      " [ 88  41 191 121]\n",
      " [ 67  60  98 216]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold3.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5527\n",
      "  Î”(FT-Global) = +0.0658\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[261  30  93  57]\n",
      " [ 31 267  78  65]\n",
      " [ 77  43 229  92]\n",
      " [ 68  65  90 218]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Cargando val fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  7.35it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n",
      "  Ã‰poca   1 | train_loss=0.2284 | train_acc=0.2549 | val_acc=0.2794 | val_f1m=0.1887 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2121 | train_acc=0.3410 | val_acc=0.3960 | val_f1m=0.3735 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1935 | train_acc=0.4301 | val_acc=0.4429 | val_f1m=0.4377 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1836 | train_acc=0.4729 | val_acc=0.4794 | val_f1m=0.4802 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1762 | train_acc=0.5051 | val_acc=0.4865 | val_f1m=0.4867 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1741 | train_acc=0.5068 | val_acc=0.4794 | val_f1m=0.4797 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1763 | train_acc=0.5009 | val_acc=0.4825 | val_f1m=0.4826 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1705 | train_acc=0.5254 | val_acc=0.4817 | val_f1m=0.4722 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1674 | train_acc=0.5205 | val_acc=0.4929 | val_f1m=0.4927 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1648 | train_acc=0.5277 | val_acc=0.4944 | val_f1m=0.4971 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1627 | train_acc=0.5418 | val_acc=0.5119 | val_f1m=0.5133 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1670 | train_acc=0.5313 | val_acc=0.5127 | val_f1m=0.5141 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1628 | train_acc=0.5357 | val_acc=0.5127 | val_f1m=0.5141 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1603 | train_acc=0.5488 | val_acc=0.5095 | val_f1m=0.5107 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1571 | train_acc=0.5523 | val_acc=0.5079 | val_f1m=0.5088 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1585 | train_acc=0.5518 | val_acc=0.5063 | val_f1m=0.5072 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1575 | train_acc=0.5592 | val_acc=0.5040 | val_f1m=0.5050 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1577 | train_acc=0.5527 | val_acc=0.5040 | val_f1m=0.5050 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1589 | train_acc=0.5467 | val_acc=0.5048 | val_f1m=0.5060 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.1578 | train_acc=0.5515 | val_acc=0.5048 | val_f1m=0.5060 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.1543 | train_acc=0.5623 | val_acc=0.5032 | val_f1m=0.5046 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.1536 | train_acc=0.5574 | val_acc=0.5040 | val_f1m=0.5056 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.1488 | train_acc=0.5765 | val_acc=0.5056 | val_f1m=0.5073 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.1484 | train_acc=0.5842 | val_acc=0.5048 | val_f1m=0.5066 | LR=0.000828\n",
      "  Early stopping en Ã©poca 24 (mejor val_f1m=0.5141)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.5268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6375    0.6071    0.6220       420\n",
      "       right     0.5688    0.5905    0.5794       420\n",
      "  both fists     0.4350    0.5500    0.4858       420\n",
      "   both feet     0.4824    0.3595    0.4120       420\n",
      "\n",
      "    accuracy                         0.5268      1680\n",
      "   macro avg     0.5309    0.5268    0.5248      1680\n",
      "weighted avg     0.5309    0.5268    0.5248      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[255  17 109  39]\n",
      " [ 30 248  78  64]\n",
      " [ 59  71 231  59]\n",
      " [ 56 100 113 151]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold4.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5976\n",
      "  Î”(FT-Global) = +0.0708\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[281  19  77  43]\n",
      " [ 27 269  65  59]\n",
      " [ 52  55 245  68]\n",
      " [ 57  71  83 209]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:09<00:00,  6.85it/s]\n",
      "Cargando val fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.87it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n",
      "  Ã‰poca   1 | train_loss=0.2280 | train_acc=0.2640 | val_acc=0.2659 | val_f1m=0.2042 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.2091 | train_acc=0.3528 | val_acc=0.4159 | val_f1m=0.4055 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.1839 | train_acc=0.4732 | val_acc=0.4254 | val_f1m=0.4233 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.1776 | train_acc=0.4839 | val_acc=0.4413 | val_f1m=0.4399 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.1759 | train_acc=0.4998 | val_acc=0.4571 | val_f1m=0.4528 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.1751 | train_acc=0.4989 | val_acc=0.4325 | val_f1m=0.4330 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.1735 | train_acc=0.5019 | val_acc=0.4683 | val_f1m=0.4706 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.1705 | train_acc=0.5075 | val_acc=0.4571 | val_f1m=0.4602 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.1692 | train_acc=0.5131 | val_acc=0.4476 | val_f1m=0.4471 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.1681 | train_acc=0.5173 | val_acc=0.4603 | val_f1m=0.4612 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.1635 | train_acc=0.5264 | val_acc=0.4595 | val_f1m=0.4626 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.1636 | train_acc=0.5247 | val_acc=0.4611 | val_f1m=0.4636 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.1569 | train_acc=0.5637 | val_acc=0.4627 | val_f1m=0.4652 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.1622 | train_acc=0.5413 | val_acc=0.4635 | val_f1m=0.4659 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.1630 | train_acc=0.5292 | val_acc=0.4627 | val_f1m=0.4646 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.1550 | train_acc=0.5502 | val_acc=0.4603 | val_f1m=0.4619 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.1561 | train_acc=0.5508 | val_acc=0.4603 | val_f1m=0.4621 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.1544 | train_acc=0.5579 | val_acc=0.4595 | val_f1m=0.4613 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.1540 | train_acc=0.5553 | val_acc=0.4595 | val_f1m=0.4613 | LR=0.000920\n",
      "  Early stopping en Ã©poca 19 (mejor val_f1m=0.4706)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5518\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.6206    0.6310    0.6257       420\n",
      "       right     0.6071    0.5738    0.5900       420\n",
      "  both fists     0.4697    0.4976    0.4832       420\n",
      "   both feet     0.5158    0.5048    0.5102       420\n",
      "\n",
      "    accuracy                         0.5518      1680\n",
      "   macro avg     0.5533    0.5518    0.5523      1680\n",
      "weighted avg     0.5533    0.5518    0.5523      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[265  20  80  55]\n",
      " [ 29 241  71  79]\n",
      " [ 81  65 209  65]\n",
      " [ 52  71  85 212]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold5.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.6238\n",
      "  Î”(FT-Global) = +0.0720\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[279  17  78  46]\n",
      " [ 20 277  68  55]\n",
      " [ 59  53 244  64]\n",
      " [ 44  58  70 248]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold5.png\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4994', '0.5816', '0.4870', '0.5268', '0.5518']\n",
      "Global mean ACC: 0.5293\n",
      "F1 folds (MACRO): ['0.5016', '0.5804', '0.4909', '0.5248', '0.5523']\n",
      "F1 mean (MACRO): 0.5300\n",
      "Fine-tune PROGRESIVO folds: ['0.5686', '0.6417', '0.5527', '0.5976', '0.6238']\n",
      "Fine-tune PROGRESIVO mean: 0.5969\n",
      "Î”(FT-Global) mean: +0.0676\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / '00_folds' / 'Kfold5.json'\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "BASE_LR = 1e-3\n",
    "WARMUP_EPOCHS = 8\n",
    "PATIENCE = 12\n",
    "\n",
    "# Split de validaciÃ³n por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18\n",
    "VAL_STRAT_SUBJECT = True\n",
    "\n",
    "# Prepro global\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2\n",
    "P_DROP_ENCODER = 0.3\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA / SUBWINDOW en TEST\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.075, -0.05, -0.025, 0.0, 0.025, 0.05, 0.075]\n",
    "SW_LEN, SW_STRIDE = 4.5, 1.5\n",
    "COMBINE_TTA_AND_SUBWIN = False\n",
    "\n",
    "# Sampler balanceado\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# EMA (solo GLOBAL). En FT se desactiva.\n",
    "USE_EMA = True\n",
    "EMA_DECAY = 0.9995\n",
    "\n",
    "# Fine-tuning (por sujeto)\n",
    "FT_N_FOLDS = 4\n",
    "FT_FREEZE_EPOCHS = 8           # etapa 1 (congelar backbone)\n",
    "FT_UNFREEZE_EPOCHS = 8         # etapa 2 (descongelar)\n",
    "FT_PATIENCE = 6                # early stopping en FT\n",
    "FT_BATCH = 64\n",
    "FT_LR_HEAD = 1e-3              # cabeza (5x aprox del backbone)\n",
    "FT_LR_BACKBONE = 2e-4          # backbone\n",
    "FT_WD = 1e-3                   # weight decay menor en FT\n",
    "FT_AUG = dict(p_jitter=0.25, p_noise=0.25, p_chdrop=0.10, max_jitter_frac=0.02, noise_std=0.02, max_chdrop=1)\n",
    "FT_ALPHA_BOOST_FISTS = 1.25\n",
    "FT_ALPHA_BOOST_FEET  = 1.05\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right', 'both_fists', 'both_feet']\n",
    "\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto como EEGNet)\")\n",
    "print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "\n",
    "        sfreq = raw.info['sfreq']\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        X_list.append(X[mask])\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :] = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X\n",
    "\n",
    "# =========================\n",
    "# MODELO (GroupNorm en conv)\n",
    "# =========================\n",
    "def make_gn(num_channels, num_groups=8):\n",
    "    g = min(num_groups, num_channels)\n",
    "    while num_channels % g != 0 and g > 1:\n",
    "        g -= 1\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=4, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15, p_drop=p_drop),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7,  p_drop=p_drop),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "        self.pos_encoding = None\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=False\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "        z = self.encoder(z)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# FOCAL LOSS\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS\n",
    "# =========================\n",
    "def augment_batch(\n",
    "    xb,\n",
    "    p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "    max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1\n",
    "):\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "# VersiÃ³n suave para FT\n",
    "def augment_batch_ft(xb):\n",
    "    return augment_batch(xb, **FT_AUG)\n",
    "\n",
    "# =========================\n",
    "# EMA de pesos (solo global)\n",
    "# =========================\n",
    "class ModelEMA:\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.9995, device=None):\n",
    "        self.ema = self._clone(model).to(device if device is not None else next(model.parameters()).device)\n",
    "        self.decay = decay\n",
    "        self._updates = 0\n",
    "        self.update(model, force=True)\n",
    "\n",
    "    def _clone(self, model):\n",
    "        ema = type(model)()\n",
    "        ema.load_state_dict(model.state_dict())\n",
    "        for p in ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        return ema\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module, force: bool = False):\n",
    "        d = self.decay\n",
    "        if self._updates < 1000:\n",
    "            d = (self._updates / 1000.0) * self.decay\n",
    "        msd = model.state_dict()\n",
    "        esd = self.ema.state_dict()\n",
    "        for k in esd.keys():\n",
    "            if esd[k].dtype.is_floating_point:\n",
    "                esd[k].mul_(d).add_(msd[k].detach(), alpha=1.0 - d)\n",
    "            else:\n",
    "                esd[k] = msd[k]\n",
    "        self._updates += 1\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(4, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# Utilidades splits estratificados por sujeto\n",
    "# =========================\n",
    "def build_subject_label_map(subject_ids):\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=4)\n",
    "        y_dom = int(np.argmax(binc))\n",
    "        y_dom_list.append(y_dom)\n",
    "    return np.array(y_dom_list, dtype=int)\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL GLOBAL POR FOLD\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    def load_fold_subjects_local(folds_json: Path, fold: int):\n",
    "        return load_fold_subjects(folds_json, fold)\n",
    "\n",
    "    train_sub, test_sub = load_fold_subjects_local(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # Carga TRAIN/VAL/TEST\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # NormalizaciÃ³n por canal (fit en TRAIN y aplicar a VAL/TEST)\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    # Weighted sampler templado: w = (1/ws)^a * (1/wk)^b\n",
    "    def make_weighted_sampler(dataset: TensorDataset):\n",
    "        _Xb, yb, sb = dataset.tensors\n",
    "        yb_np = yb.numpy()\n",
    "        sb_np = sb.numpy()\n",
    "        uniq_s, cnt_s = np.unique(sb_np, return_counts=True)\n",
    "        map_s = {s:c for s,c in zip(uniq_s, cnt_s)}\n",
    "        key = sb_np.astype(np.int64) * 10 + yb_np.astype(np.int64)\n",
    "        uniq_k, cnt_k = np.unique(key, return_counts=True)\n",
    "        map_k = {k:c for k,c in zip(uniq_k, cnt_k)}\n",
    "        a, b = 0.8, 1.0\n",
    "        w = []\n",
    "        for s, y in zip(sb_np, yb_np):\n",
    "            k = int(s)*10 + int(y)\n",
    "            ws = float(map_s[int(s)])\n",
    "            wk = float(map_k[k])\n",
    "            w.append((ws ** (-a)) * (wk ** (-b)))\n",
    "        w = np.array(w, dtype=np.float64)\n",
    "        w = w / (w.mean() + 1e-12)\n",
    "        sampler = WeightedRandomSampler(weights=torch.tensor(w, dtype=torch.double),\n",
    "                                        num_samples=len(yb_np), replacement=True)\n",
    "        return sampler\n",
    "\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        tr_sampler = make_weighted_sampler(tr_ds)\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, sampler=tr_sampler, drop_last=False, worker_init_fn=seed_worker)\n",
    "    else:\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # Modelo\n",
    "    model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                              n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "\n",
    "    # Optimizador + Focal Loss\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "    class_counts = np.bincount(y_tr, minlength=4).astype(np.float32)\n",
    "    inv = class_counts.sum() / (4.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    alpha_mean = alpha.mean().item()\n",
    "    alpha[2] = 1.25 * alpha_mean  # both_fists\n",
    "    alpha[3] = 1.05 * alpha_mean  # both_feet\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # LR scheduler Warmup+Cosine\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # EMA (solo global)\n",
    "    if USE_EMA:\n",
    "        ema = ModelEMA(model, decay=EMA_DECAY, device=device)\n",
    "    else:\n",
    "        ema = None\n",
    "\n",
    "    # Entrenamiento global con early stopping por F1 macro\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"lr\": []}\n",
    "\n",
    "    def evaluate_on(loader, use_ema=True):\n",
    "        mdl = ema.ema if (ema is not None and use_ema) else model\n",
    "        mdl.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in loader:\n",
    "                xb = xb.to(device)\n",
    "                p = mdl(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "        return acc, f1m\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "            if ema is not None:\n",
    "                ema.update(model)\n",
    "\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        acc, f1m = evaluate_on(val_ld, use_ema=True)\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            ref_model = ema.ema if ema is not None else model\n",
    "            best_state = {k: v.detach().cpu() for k, v in ref_model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        (ema.ema if (ema is not None) else model).load_state_dict(best_state)\n",
    "\n",
    "    # ---- Guardar curva ----\n",
    "    fig = plt.figure(figsize=(8,4.5))\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_acc\"], label=\"tr_acc\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_acc\"], label=\"val_acc\")\n",
    "    ax1.set_xlabel(\"Ã‰poca\"); ax1.set_title(f\"Fold {fold} â€” Curva de entrenamiento\")\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "    out_png = f\"training_curve_fold{fold}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.close(fig)\n",
    "    print(f\"â†³ Curva de entrenamiento guardada: {out_png}\")\n",
    "\n",
    "    # ---- EvaluaciÃ³n final en TEST (global) ----\n",
    "    eval_model = ema.ema if (ema is not None) else model\n",
    "    eval_model.eval()\n",
    "\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = eval_model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE in ('subwin', 'tta'):\n",
    "        logits_tta = None\n",
    "        logits_sw  = None\n",
    "        if SW_MODE == 'subwin':\n",
    "            logits_sw = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        elif SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "\n",
    "        if COMBINE_TTA_AND_SUBWIN:\n",
    "            if logits_tta is None:\n",
    "                logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "            if logits_sw is None:\n",
    "                logits_sw  = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "            logits = 0.5 * logits_tta + 0.5 * logits_sw\n",
    "        else:\n",
    "            logits = logits_tta if logits_tta is not None else logits_sw\n",
    "\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1,2,3])\n",
    "    print(cm)\n",
    "    print(f\"â†³ Matriz de confusiÃ³n guardada: confusion_global_fold{fold}.png\")\n",
    "    # plot cm\n",
    "    fig = plt.figure(figsize=(4.8,4.2))\n",
    "    plt.imshow(cm, cmap='Blues'); plt.title(f\"Confusion â€” Fold {fold} Global\")\n",
    "    plt.xlabel(\"pred\"); plt.ylabel(\"true\")\n",
    "    plt.colorbar(); plt.tight_layout()\n",
    "    plt.savefig(f\"confusion_global_fold{fold}.png\", dpi=140); plt.close(fig)\n",
    "\n",
    "    # =========================\n",
    "    # FINE-TUNING PROGRESIVO POR SUJETO (4-fold CV interno)\n",
    "    # =========================\n",
    "    # agrupamos por sujeto en el TEST\n",
    "    subjects = np.unique(sub_te)\n",
    "    subj_to_idx = {s: np.where(sub_te == s)[0] for s in subjects}\n",
    "\n",
    "    def make_ft_optimizer(model):\n",
    "        # dos grupos de params: head (lr alto), backbone (lr bajo)\n",
    "        head_params = list(model.head.parameters())\n",
    "        backbone_params = [p for n,p in model.named_parameters() if not n.startswith('head.')]\n",
    "        return torch.optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': FT_LR_BACKBONE},\n",
    "            {'params': head_params,     'lr': FT_LR_HEAD}\n",
    "        ], weight_decay=FT_WD)\n",
    "\n",
    "    def freeze_backbone(model, freeze=True):\n",
    "        for n,p in model.named_parameters():\n",
    "            if not n.startswith('head.'):\n",
    "                p.requires_grad_(not freeze)\n",
    "\n",
    "    def ft_make_criterion_from_counts(counts):\n",
    "        inv = counts.sum() / (4.0 * np.maximum(counts.astype(np.float32), 1.0))\n",
    "        a = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "        am = a.mean().item()\n",
    "        a[2] = FT_ALPHA_BOOST_FISTS * am\n",
    "        a[3] = FT_ALPHA_BOOST_FEET  * am\n",
    "        return FocalLoss(alpha=a, gamma=1.5, reduction='mean')\n",
    "\n",
    "    def evaluate_tensor(model_t, X, y):\n",
    "        model_t.eval()\n",
    "        with torch.no_grad():\n",
    "            xb = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "            p = model_t(xb).argmax(1).cpu().numpy()\n",
    "        return accuracy_score(y, p), f1_score(y, p, average='macro'), p\n",
    "\n",
    "    # Para reporte agregado\n",
    "    ft_correct, ft_total = 0, 0\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    # usamos como base los pesos del mejor global (EMA si existÃ­a)\n",
    "    base_state = (ema.ema if (ema is not None) else model).state_dict()\n",
    "\n",
    "    for s in subjects:\n",
    "        idx = subj_to_idx[s]\n",
    "        Xs, ys = X_te_std[idx], y_te[idx]\n",
    "\n",
    "        if len(np.unique(ys)) < 2 or len(ys) < 20:\n",
    "            # sujeto con muy pocos ejemplos/clases: eval directo\n",
    "            eval_model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                                           n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "            eval_model.load_state_dict(base_state)\n",
    "            acc_s, f1_s, pred_s = evaluate_tensor(eval_model, Xs, ys)\n",
    "            ft_correct += int(acc_s*len(ys)); ft_total += len(ys)\n",
    "            all_true.append(ys); all_pred.append(pred_s)\n",
    "            continue\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=FT_N_FOLDS, shuffle=True, random_state=RANDOM_STATE + fold + int(s))\n",
    "        for tr_idx, te_idx in skf.split(Xs, ys):\n",
    "            Xtr, ytr = Xs[tr_idx].copy(), ys[tr_idx].copy()\n",
    "            Xte_s, yte_s = Xs[te_idx].copy(), ys[te_idx].copy()\n",
    "\n",
    "            # estandarizaciÃ³n por sujeto (fit en FT-train, aplicar a FT-test)\n",
    "            Xtr_std, Xte_std = standardize_per_channel(Xtr, Xte_s)\n",
    "\n",
    "            # modelo fresh desde el global\n",
    "            ft_model = EEGCNNTransformer(n_ch=8, n_cls=4, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                                         n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "            ft_model.load_state_dict(base_state)\n",
    "\n",
    "            # optim + criterio (Î± de este sujeto/split)\n",
    "            opt_ft = make_ft_optimizer(ft_model)\n",
    "            alpha_counts = np.bincount(ytr, minlength=4)\n",
    "            ft_crit = ft_make_criterion_from_counts(alpha_counts)\n",
    "\n",
    "            # loaders FT\n",
    "            ds_tr = TensorDataset(torch.tensor(Xtr_std), torch.tensor(ytr).long())\n",
    "            ds_te = TensorDataset(torch.tensor(Xte_std), torch.tensor(yte_s).long())\n",
    "            ld_tr = DataLoader(ds_tr, batch_size=FT_BATCH, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "            ld_te = DataLoader(ds_te, batch_size=FT_BATCH, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "            # ETAPA 1: freeze backbone\n",
    "            freeze_backbone(ft_model, True)\n",
    "            best_f1_s, best_state_s, wait_s = -1, None, 0\n",
    "            for ep in range(1, FT_FREEZE_EPOCHS+1):\n",
    "                ft_model.train()\n",
    "                for xb, yb in ld_tr:\n",
    "                    xb = xb.to(device); yb = yb.to(device)\n",
    "                    xb = augment_batch_ft(xb)\n",
    "                    opt_ft.zero_grad()\n",
    "                    logits = ft_model(xb)\n",
    "                    loss = ft_crit(logits, yb)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                    opt_ft.step()\n",
    "\n",
    "                # eval fold\n",
    "                acc_s, f1_s = evaluate_tensor(ft_model, Xte_std, yte_s)[:2]\n",
    "                improved = f1_s > best_f1_s + 1e-4\n",
    "                if improved:\n",
    "                    best_f1_s = f1_s\n",
    "                    best_state_s = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                    wait_s = 0\n",
    "                else:\n",
    "                    wait_s += 1\n",
    "                if wait_s >= FT_PATIENCE:\n",
    "                    break\n",
    "\n",
    "            if best_state_s is not None:\n",
    "                ft_model.load_state_dict(best_state_s)\n",
    "\n",
    "            # ETAPA 2: unfreeze (todo entrenable) con early stopping\n",
    "            freeze_backbone(ft_model, False)\n",
    "            best_f1_s2, best_state_s2, wait_s2 = -1, None, 0\n",
    "            for ep in range(1, FT_UNFREEZE_EPOCHS+1):\n",
    "                ft_model.train()\n",
    "                for xb, yb in ld_tr:\n",
    "                    xb = xb.to(device); yb = yb.to(device)\n",
    "                    xb = augment_batch_ft(xb)\n",
    "                    opt_ft.zero_grad()\n",
    "                    logits = ft_model(xb)\n",
    "                    loss = ft_crit(logits, yb)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                    opt_ft.step()\n",
    "\n",
    "                acc_s, f1_s = evaluate_tensor(ft_model, Xte_std, yte_s)[:2]\n",
    "                improved = f1_s > best_f1_s2 + 1e-4\n",
    "                if improved:\n",
    "                    best_f1_s2 = f1_s\n",
    "                    best_state_s2 = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                    wait_s2 = 0\n",
    "                else:\n",
    "                    wait_s2 += 1\n",
    "                if wait_s2 >= FT_PATIENCE:\n",
    "                    break\n",
    "\n",
    "            if best_state_s2 is not None:\n",
    "                ft_model.load_state_dict(best_state_s2)\n",
    "\n",
    "            # mÃ©tricas del fold del sujeto\n",
    "            acc_s, f1_s, pred_s = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "            ft_correct += int(acc_s*len(yte_s)); ft_total += len(yte_s)\n",
    "            all_true.append(yte_s); all_pred.append(pred_s)\n",
    "\n",
    "    # resumen FT por sujeto\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "    ft_acc = accuracy_score(all_true, all_pred)\n",
    "    ft_f1m = f1_score(all_true, all_pred, average='macro')\n",
    "    print(f\"  Fine-tuning PROGRESIVO (por sujeto, {FT_N_FOLDS}-fold CV) acc={ft_acc:.4f}\")\n",
    "    print(f\"  Î”(FT-Global) = {ft_acc - acc:+.4f}\")\n",
    "    cm_ft = confusion_matrix(all_true, all_pred, labels=[0,1,2,3])\n",
    "    print(\"Confusion matrix FT (rows=true, cols=pred):\")\n",
    "    print(cm_ft)\n",
    "    fig = plt.figure(figsize=(4.8,4.2))\n",
    "    plt.imshow(cm_ft, cmap='Greens'); plt.title(f\"Confusion â€” Fold {fold} FT\")\n",
    "    plt.xlabel(\"pred\"); plt.ylabel(\"true\")\n",
    "    plt.colorbar(); plt.tight_layout()\n",
    "    plt.savefig(f\"confusion_ft_fold{fold}.png\", dpi=140); plt.close(fig)\n",
    "    print(f\"â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold{fold}.png\")\n",
    "\n",
    "    return acc, f1m, ft_acc\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    acc_folds, f1_folds, ft_acc_folds = [], [], []\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m, ft_acc = train_one_fold(fold, DEVICE)\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "        ft_acc_folds.append(f\"{ft_acc:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "    ft_acc_mean = float(np.mean([float(a) for a in ft_acc_folds]))\n",
    "    delta_mean = ft_acc_mean - acc_mean\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n",
    "    print(f\"Fine-tune PROGRESIVO folds: {ft_acc_folds}\")\n",
    "    print(f\"Fine-tune PROGRESIVO mean: {ft_acc_mean:.4f}\")\n",
    "    print(f\"Î”(FT-Global) mean: {delta_mean:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de39460",
   "metadata": {},
   "source": [
    "## 2 CLASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto)\n",
      "ðŸ”§ ConfiguraciÃ³n: 2c (L/R), 8 canales, 6s | EPOCHS=60, BATCH=64, LR=0.001 | ZSCORE_PER_EPOCH=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 14.61it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 14.58it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Ã‰poca   1 | train_loss=0.1543 | train_acc=0.5064 | val_acc=0.5825 | val_f1m=0.5682 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.1046 | train_acc=0.6834 | val_acc=0.7063 | val_f1m=0.7060 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.0808 | train_acc=0.7893 | val_acc=0.7429 | val_f1m=0.7428 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.0776 | train_acc=0.8149 | val_acc=0.7587 | val_f1m=0.7587 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.0701 | train_acc=0.8262 | val_acc=0.7333 | val_f1m=0.7309 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.0698 | train_acc=0.8344 | val_acc=0.7730 | val_f1m=0.7729 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.0678 | train_acc=0.8312 | val_acc=0.7619 | val_f1m=0.7619 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.0652 | train_acc=0.8426 | val_acc=0.7190 | val_f1m=0.7131 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.0688 | train_acc=0.8323 | val_acc=0.7651 | val_f1m=0.7650 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.0730 | train_acc=0.8127 | val_acc=0.7476 | val_f1m=0.7458 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.0589 | train_acc=0.8568 | val_acc=0.7619 | val_f1m=0.7608 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.0606 | train_acc=0.8547 | val_acc=0.7667 | val_f1m=0.7665 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.0575 | train_acc=0.8621 | val_acc=0.7683 | val_f1m=0.7681 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.0612 | train_acc=0.8515 | val_acc=0.7778 | val_f1m=0.7776 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.0570 | train_acc=0.8685 | val_acc=0.7651 | val_f1m=0.7651 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.0593 | train_acc=0.8518 | val_acc=0.7619 | val_f1m=0.7610 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.0573 | train_acc=0.8575 | val_acc=0.7889 | val_f1m=0.7887 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.0578 | train_acc=0.8586 | val_acc=0.7667 | val_f1m=0.7665 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.0504 | train_acc=0.8753 | val_acc=0.7746 | val_f1m=0.7740 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.0571 | train_acc=0.8611 | val_acc=0.7571 | val_f1m=0.7566 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.0518 | train_acc=0.8738 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.0475 | train_acc=0.8881 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.0470 | train_acc=0.8952 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.0522 | train_acc=0.8703 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.0457 | train_acc=0.8959 | val_acc=0.7698 | val_f1m=0.7697 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.0437 | train_acc=0.8994 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.0489 | train_acc=0.8881 | val_acc=0.7683 | val_f1m=0.7682 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.0470 | train_acc=0.8856 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.0465 | train_acc=0.8927 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.000710\n",
      "  Early stopping en Ã©poca 29 (mejor val_f1m=0.7887)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.7993\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7882    0.8186    0.8031       441\n",
      "       right     0.8113    0.7800    0.7954       441\n",
      "\n",
      "    accuracy                         0.7993       882\n",
      "   macro avg     0.7998    0.7993    0.7992       882\n",
      "weighted avg     0.7998    0.7993    0.7992       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[361  80]\n",
      " [ 97 344]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold1.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8537\n",
      "  Î”(FT-Global) = +0.0544\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[371  70]\n",
      " [ 59 382]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 16.72it/s]\n",
      "Cargando val fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 16.95it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Ã‰poca   1 | train_loss=0.1262 | train_acc=0.5448 | val_acc=0.6270 | val_f1m=0.6247 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.1055 | train_acc=0.6795 | val_acc=0.7429 | val_f1m=0.7423 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.0851 | train_acc=0.7758 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.0827 | train_acc=0.7772 | val_acc=0.7810 | val_f1m=0.7806 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.0752 | train_acc=0.8063 | val_acc=0.7698 | val_f1m=0.7698 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.0748 | train_acc=0.8109 | val_acc=0.8000 | val_f1m=0.7999 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.0756 | train_acc=0.7950 | val_acc=0.7778 | val_f1m=0.7776 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.0740 | train_acc=0.8042 | val_acc=0.7714 | val_f1m=0.7713 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.0709 | train_acc=0.8227 | val_acc=0.7508 | val_f1m=0.7506 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.0717 | train_acc=0.8223 | val_acc=0.7635 | val_f1m=0.7634 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.0699 | train_acc=0.8230 | val_acc=0.7667 | val_f1m=0.7665 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.0674 | train_acc=0.8365 | val_acc=0.7762 | val_f1m=0.7756 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.0708 | train_acc=0.8316 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.0678 | train_acc=0.8447 | val_acc=0.7778 | val_f1m=0.7776 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.0648 | train_acc=0.8287 | val_acc=0.7698 | val_f1m=0.7691 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.0697 | train_acc=0.8223 | val_acc=0.7603 | val_f1m=0.7603 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.0594 | train_acc=0.8547 | val_acc=0.7952 | val_f1m=0.7950 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.0676 | train_acc=0.8312 | val_acc=0.7794 | val_f1m=0.7792 | LR=0.000935\n",
      "  Early stopping en Ã©poca 18 (mejor val_f1m=0.7999)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.8390\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8315    0.8503    0.8408       441\n",
      "       right     0.8469    0.8277    0.8372       441\n",
      "\n",
      "    accuracy                         0.8390       882\n",
      "   macro avg     0.8392    0.8390    0.8390       882\n",
      "weighted avg     0.8392    0.8390    0.8390       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[375  66]\n",
      " [ 76 365]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold2.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.9025\n",
      "  Î”(FT-Global) = +0.0635\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[399  42]\n",
      " [ 44 397]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:03<00:00, 16.94it/s]\n",
      "Cargando val fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 16.99it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=2814 | n_val=630 | n_test=882)\n",
      "  Ã‰poca   1 | train_loss=0.1298 | train_acc=0.5156 | val_acc=0.6000 | val_f1m=0.5860 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.1162 | train_acc=0.6006 | val_acc=0.7365 | val_f1m=0.7361 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.0930 | train_acc=0.7559 | val_acc=0.7619 | val_f1m=0.7614 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.0809 | train_acc=0.7999 | val_acc=0.7730 | val_f1m=0.7721 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.0843 | train_acc=0.7846 | val_acc=0.7921 | val_f1m=0.7920 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.0759 | train_acc=0.8113 | val_acc=0.8063 | val_f1m=0.8062 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.0734 | train_acc=0.8120 | val_acc=0.7825 | val_f1m=0.7819 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.0696 | train_acc=0.8333 | val_acc=0.8016 | val_f1m=0.8009 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.0709 | train_acc=0.8262 | val_acc=0.7905 | val_f1m=0.7903 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.0666 | train_acc=0.8412 | val_acc=0.8000 | val_f1m=0.7998 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.0697 | train_acc=0.8308 | val_acc=0.7937 | val_f1m=0.7934 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.0649 | train_acc=0.8330 | val_acc=0.8048 | val_f1m=0.8048 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.0646 | train_acc=0.8454 | val_acc=0.7857 | val_f1m=0.7851 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.0631 | train_acc=0.8447 | val_acc=0.8000 | val_f1m=0.7999 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.0604 | train_acc=0.8479 | val_acc=0.7921 | val_f1m=0.7919 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.0629 | train_acc=0.8451 | val_acc=0.7921 | val_f1m=0.7916 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.0578 | train_acc=0.8646 | val_acc=0.7841 | val_f1m=0.7841 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.0580 | train_acc=0.8696 | val_acc=0.7937 | val_f1m=0.7935 | LR=0.000935\n",
      "  Early stopping en Ã©poca 18 (mejor val_f1m=0.8062)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.7937\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7797    0.8186    0.7987       441\n",
      "       right     0.8091    0.7687    0.7884       441\n",
      "\n",
      "    accuracy                         0.7937       882\n",
      "   macro avg     0.7944    0.7937    0.7935       882\n",
      "weighted avg     0.7944    0.7937    0.7935       882\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[361  80]\n",
      " [102 339]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold3.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8515\n",
      "  Î”(FT-Global) = +0.0578\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[377  64]\n",
      " [ 67 374]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:04<00:00, 16.63it/s]\n",
      "Cargando val fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 16.90it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Ã‰poca   1 | train_loss=0.1266 | train_acc=0.5284 | val_acc=0.5857 | val_f1m=0.5583 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.1082 | train_acc=0.6569 | val_acc=0.7063 | val_f1m=0.7043 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.0931 | train_acc=0.7486 | val_acc=0.7603 | val_f1m=0.7597 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.0826 | train_acc=0.7927 | val_acc=0.7524 | val_f1m=0.7512 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.0843 | train_acc=0.7777 | val_acc=0.7825 | val_f1m=0.7825 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.0792 | train_acc=0.8029 | val_acc=0.7476 | val_f1m=0.7422 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.0748 | train_acc=0.8141 | val_acc=0.7698 | val_f1m=0.7691 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.0791 | train_acc=0.7969 | val_acc=0.7857 | val_f1m=0.7857 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.0668 | train_acc=0.8309 | val_acc=0.8143 | val_f1m=0.8142 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.0726 | train_acc=0.8190 | val_acc=0.7540 | val_f1m=0.7482 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.0734 | train_acc=0.8148 | val_acc=0.7794 | val_f1m=0.7783 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.0724 | train_acc=0.8169 | val_acc=0.7762 | val_f1m=0.7761 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.0655 | train_acc=0.8393 | val_acc=0.8016 | val_f1m=0.8014 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.0699 | train_acc=0.8235 | val_acc=0.7841 | val_f1m=0.7840 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.0655 | train_acc=0.8361 | val_acc=0.7873 | val_f1m=0.7869 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.0669 | train_acc=0.8428 | val_acc=0.7619 | val_f1m=0.7601 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.0658 | train_acc=0.8277 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.0611 | train_acc=0.8557 | val_acc=0.7857 | val_f1m=0.7848 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.0619 | train_acc=0.8466 | val_acc=0.7937 | val_f1m=0.7934 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.0593 | train_acc=0.8606 | val_acc=0.7905 | val_f1m=0.7901 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.0608 | train_acc=0.8557 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000887\n",
      "  Early stopping en Ã©poca 21 (mejor val_f1m=0.8142)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.8214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.7885    0.8786    0.8311       420\n",
      "       right     0.8629    0.7643    0.8106       420\n",
      "\n",
      "    accuracy                         0.8214       840\n",
      "   macro avg     0.8257    0.8214    0.8208       840\n",
      "weighted avg     0.8257    0.8214    0.8208       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[369  51]\n",
      " [ 99 321]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold4.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8798\n",
      "  Î”(FT-Global) = +0.0583\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[368  52]\n",
      " [ 49 371]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:04<00:00, 16.64it/s]\n",
      "Cargando val fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 17.03it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=2856 | n_val=630 | n_test=840)\n",
      "  Ã‰poca   1 | train_loss=0.1309 | train_acc=0.5224 | val_acc=0.5635 | val_f1m=0.5252 | LR=0.000125\n",
      "  Ã‰poca   2 | train_loss=0.1096 | train_acc=0.6551 | val_acc=0.6571 | val_f1m=0.6536 | LR=0.000250\n",
      "  Ã‰poca   3 | train_loss=0.0879 | train_acc=0.7749 | val_acc=0.7413 | val_f1m=0.7397 | LR=0.000375\n",
      "  Ã‰poca   4 | train_loss=0.0841 | train_acc=0.7903 | val_acc=0.7444 | val_f1m=0.7422 | LR=0.000500\n",
      "  Ã‰poca   5 | train_loss=0.0771 | train_acc=0.8064 | val_acc=0.7381 | val_f1m=0.7377 | LR=0.000625\n",
      "  Ã‰poca   6 | train_loss=0.0722 | train_acc=0.8204 | val_acc=0.7286 | val_f1m=0.7214 | LR=0.000750\n",
      "  Ã‰poca   7 | train_loss=0.0783 | train_acc=0.8074 | val_acc=0.7413 | val_f1m=0.7406 | LR=0.000875\n",
      "  Ã‰poca   8 | train_loss=0.0726 | train_acc=0.8204 | val_acc=0.7698 | val_f1m=0.7692 | LR=0.001000\n",
      "  Ã‰poca   9 | train_loss=0.0682 | train_acc=0.8368 | val_acc=0.7444 | val_f1m=0.7441 | LR=0.001000\n",
      "  Ã‰poca  10 | train_loss=0.0709 | train_acc=0.8193 | val_acc=0.7587 | val_f1m=0.7585 | LR=0.000999\n",
      "  Ã‰poca  11 | train_loss=0.0695 | train_acc=0.8288 | val_acc=0.7556 | val_f1m=0.7554 | LR=0.000997\n",
      "  Ã‰poca  12 | train_loss=0.0669 | train_acc=0.8309 | val_acc=0.7698 | val_f1m=0.7697 | LR=0.000993\n",
      "  Ã‰poca  13 | train_loss=0.0663 | train_acc=0.8330 | val_acc=0.7571 | val_f1m=0.7571 | LR=0.000987\n",
      "  Ã‰poca  14 | train_loss=0.0651 | train_acc=0.8386 | val_acc=0.7698 | val_f1m=0.7690 | LR=0.000980\n",
      "  Ã‰poca  15 | train_loss=0.0621 | train_acc=0.8400 | val_acc=0.7540 | val_f1m=0.7535 | LR=0.000971\n",
      "  Ã‰poca  16 | train_loss=0.0604 | train_acc=0.8543 | val_acc=0.7603 | val_f1m=0.7601 | LR=0.000960\n",
      "  Ã‰poca  17 | train_loss=0.0632 | train_acc=0.8477 | val_acc=0.7571 | val_f1m=0.7568 | LR=0.000948\n",
      "  Ã‰poca  18 | train_loss=0.0614 | train_acc=0.8519 | val_acc=0.7667 | val_f1m=0.7662 | LR=0.000935\n",
      "  Ã‰poca  19 | train_loss=0.0602 | train_acc=0.8543 | val_acc=0.7873 | val_f1m=0.7871 | LR=0.000920\n",
      "  Ã‰poca  20 | train_loss=0.0585 | train_acc=0.8592 | val_acc=0.7810 | val_f1m=0.7810 | LR=0.000904\n",
      "  Ã‰poca  21 | train_loss=0.0556 | train_acc=0.8610 | val_acc=0.7889 | val_f1m=0.7889 | LR=0.000887\n",
      "  Ã‰poca  22 | train_loss=0.0570 | train_acc=0.8519 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000868\n",
      "  Ã‰poca  23 | train_loss=0.0606 | train_acc=0.8480 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000848\n",
      "  Ã‰poca  24 | train_loss=0.0566 | train_acc=0.8578 | val_acc=0.7746 | val_f1m=0.7746 | LR=0.000828\n",
      "  Ã‰poca  25 | train_loss=0.0554 | train_acc=0.8589 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000806\n",
      "  Ã‰poca  26 | train_loss=0.0545 | train_acc=0.8641 | val_acc=0.7762 | val_f1m=0.7762 | LR=0.000783\n",
      "  Ã‰poca  27 | train_loss=0.0560 | train_acc=0.8659 | val_acc=0.7762 | val_f1m=0.7761 | LR=0.000759\n",
      "  Ã‰poca  28 | train_loss=0.0480 | train_acc=0.8841 | val_acc=0.7794 | val_f1m=0.7793 | LR=0.000735\n",
      "  Ã‰poca  29 | train_loss=0.0456 | train_acc=0.8918 | val_acc=0.7762 | val_f1m=0.7761 | LR=0.000710\n",
      "  Ã‰poca  30 | train_loss=0.0478 | train_acc=0.8915 | val_acc=0.7778 | val_f1m=0.7777 | LR=0.000684\n",
      "  Ã‰poca  31 | train_loss=0.0519 | train_acc=0.8722 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000658\n",
      "  Ã‰poca  32 | train_loss=0.0416 | train_acc=0.8999 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000631\n",
      "  Ã‰poca  33 | train_loss=0.0427 | train_acc=0.9023 | val_acc=0.7810 | val_f1m=0.7809 | LR=0.000604\n",
      "  Early stopping en Ã©poca 33 (mejor val_f1m=0.7889)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.8405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left     0.8373    0.8452    0.8412       420\n",
      "       right     0.8438    0.8357    0.8397       420\n",
      "\n",
      "    accuracy                         0.8405       840\n",
      "   macro avg     0.8405    0.8405    0.8405       840\n",
      "weighted avg     0.8405    0.8405    0.8405       840\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[355  65]\n",
      " [ 69 351]]\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold5.png\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.8679\n",
      "  Î”(FT-Global) = +0.0274\n",
      "Confusion matrix FT (rows=true, cols=pred):\n",
      "[[365  55]\n",
      " [ 56 364]]\n",
      "â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold5.png\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES (2 clases: left/right)\n",
      "============================================================\n",
      "Global folds (ACC): ['0.7993', '0.8390', '0.7937', '0.8214', '0.8405']\n",
      "Global mean ACC: 0.8188\n",
      "F1 folds (MACRO): ['0.7992', '0.8390', '0.7935', '0.8208', '0.8405']\n",
      "F1 mean (MACRO): 0.8186\n",
      "Fine-tune PROGRESIVO folds: ['0.8537', '0.9025', '0.8515', '0.8798', '0.8679']\n",
      "Fine-tune PROGRESIVO mean: 0.8711\n",
      "Î”(FT-Global) mean: +0.0523\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import re, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / '00_folds' / 'Kfold5.json'\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "BASE_LR = 1e-3\n",
    "WARMUP_EPOCHS = 8\n",
    "PATIENCE = 12\n",
    "\n",
    "# Split de validaciÃ³n por fold (por sujetos)\n",
    "VAL_SUBJECT_FRAC = 0.18\n",
    "VAL_STRAT_SUBJECT = True\n",
    "\n",
    "# Prepro global\n",
    "RESAMPLE_HZ = None\n",
    "DO_NOTCH = True\n",
    "DO_BANDPASS = False\n",
    "BP_LO, BP_HI = 4.0, 38.0\n",
    "DO_CAR = False\n",
    "ZSCORE_PER_EPOCH = False\n",
    "\n",
    "# Modelo\n",
    "D_MODEL = 128\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "P_DROP = 0.2\n",
    "P_DROP_ENCODER = 0.3\n",
    "\n",
    "# Ventana temporal\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "\n",
    "# TTA / SUBWINDOW en TEST\n",
    "SW_MODE = 'tta'   # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.075, -0.05, -0.025, 0.0, 0.025, 0.05, 0.075]\n",
    "SW_LEN, SW_STRIDE = 4.5, 1.5\n",
    "COMBINE_TTA_AND_SUBWIN = False\n",
    "\n",
    "# Sampler balanceado\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# EMA (solo GLOBAL). En FT se desactiva.\n",
    "USE_EMA = True\n",
    "EMA_DECAY = 0.9995\n",
    "\n",
    "# Fine-tuning (por sujeto) â€” sigue activo, pero ahora con n_cls=2\n",
    "FT_N_FOLDS = 4\n",
    "FT_FREEZE_EPOCHS = 8\n",
    "FT_UNFREEZE_EPOCHS = 8\n",
    "FT_PATIENCE = 6\n",
    "FT_BATCH = 64\n",
    "FT_LR_HEAD = 1e-3\n",
    "FT_LR_BACKBONE = 2e-4\n",
    "FT_WD = 1e-3\n",
    "FT_AUG = dict(p_jitter=0.25, p_noise=0.25, p_chdrop=0.10, max_jitter_frac=0.02, noise_std=0.02, max_chdrop=1)\n",
    "\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES = ['left', 'right']  # <-- 2 clases\n",
    "\n",
    "# Solo runs de imaginaciÃ³n L/R\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON CNN+Transformer (K-Fold por sujeto)\")\n",
    "print(f\"ðŸ”§ ConfiguraciÃ³n: 2c (L/R), 8 canales, 6s | EPOCHS={EPOCHS}, BATCH={BATCH_SIZE}, LR={BASE_LR} | ZSCORE_PER_EPOCH={ZSCORE_PER_EPOCH}\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in [4, 6, 8, 10, 12, 14]:\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def load_subject_epochs(subject_id: str, resample_hz: int, do_notch: bool, do_bandpass: bool,\n",
    "                        do_car: bool, bp_lo: float, bp_hi: float):\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "\n",
    "        # Usar SOLO runs L/R\n",
    "        if run not in IMAGERY_RUNS_LR:\n",
    "            continue\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "\n",
    "        if do_notch:\n",
    "            raw.notch_filter(freqs=[60.0], picks='all', verbose='ERROR')\n",
    "        if do_bandpass:\n",
    "            raw.filter(l_freq=bp_lo, h_freq=bp_hi, picks='all', verbose='ERROR')\n",
    "        if do_car:\n",
    "            raw.set_eeg_reference('average', projection=False, verbose='ERROR')\n",
    "        if resample_hz is not None and resample_hz > 0:\n",
    "            raw.resample(resample_hz)\n",
    "\n",
    "        sfreq = raw.info['sfreq']\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "        # Mantener solo T1/T2 -> left/right\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data()\n",
    "\n",
    "        if ZSCORE_PER_EPOCH:\n",
    "            X = X.astype(np.float32)\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        # 0=left(T1), 1=right(T2)\n",
    "        y_run = np.array([0 if inv[c] == 'T1' else 1 for c in ev_codes], dtype=int)\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y_run)\n",
    "        sfreq_list.append(sfreq)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0,8,1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0).astype(np.float32)\n",
    "    y_all = np.concatenate(y_list, axis=0).astype(int)\n",
    "\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def standardize_per_channel(train_X, other_X):\n",
    "    C = train_X.shape[1]\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    other_X = other_X.astype(np.float32)\n",
    "    for c in range(C):\n",
    "        mu = train_X[:, c, :].mean()\n",
    "        sd = train_X[:, c, :].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        train_X[:, c, :] = (train_X[:, c, :] - mu) / sd\n",
    "        other_X[:, c, :] = (other_X[:, c, :] - mu) / sd\n",
    "    return train_X, other_X\n",
    "\n",
    "# =========================\n",
    "# MODELO (GroupNorm en conv)\n",
    "# =========================\n",
    "def make_gn(num_channels, num_groups=8):\n",
    "    g = min(num_groups, num_channels)\n",
    "    while num_channels % g != 0 and g > 1:\n",
    "        g -= 1\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s=1, p=0, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n",
    "        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = make_gn(out_ch)\n",
    "        self.act = nn.ELU()\n",
    "        self.dropout = nn.Dropout(p=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.pw(x); x = self.norm(x)\n",
    "        x = self.act(x); x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class EEGCNNTransformer(nn.Module):\n",
    "    def __init__(self, n_ch=8, n_cls=2, d_model=128, n_heads=4, n_layers=2,\n",
    "                 p_drop=0.2, p_drop_encoder=0.3):\n",
    "        super().__init__()\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv1d(n_ch, 32, kernel_size=129, stride=2, padding=64, bias=False),\n",
    "            make_gn(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=p_drop),\n",
    "            DepthwiseSeparableConv(32, 64, k=31, s=2, p=15, p_drop=p_drop),\n",
    "            DepthwiseSeparableConv(64, 128, k=15, s=2, p=7,  p_drop=p_drop),\n",
    "        )\n",
    "        self.proj = nn.Conv1d(128, d_model, kernel_size=1, bias=False)\n",
    "        self.dropout = nn.Dropout(p=p_drop_encoder)\n",
    "        self.pos_encoding = None\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=2*d_model,\n",
    "            batch_first=True, activation='gelu', dropout=0.1, norm_first=False\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, n_cls))\n",
    "\n",
    "    def _positional_encoding(self, L, d):\n",
    "        pos = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n",
    "        i   = torch.arange(0, d, dtype=torch.float32).unsqueeze(0)\n",
    "        angle = pos / torch.pow(10000, (2 * (i//2)) / d)\n",
    "        pe = torch.zeros(L, d, dtype=torch.float32)\n",
    "        pe[:, 0::2] = torch.sin(angle[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angle[:, 1::2])\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv_t(x)           # (B, 128, T')\n",
    "        z = self.proj(z)             # (B, d_model, T')\n",
    "        z = self.dropout(z)\n",
    "        z = z.transpose(1, 2)        # (B, T', d_model)\n",
    "        B, L, D = z.shape\n",
    "        if (self.pos_encoding is None) or (self.pos_encoding.shape[0] != L) or (self.pos_encoding.shape[1] != D):\n",
    "            self.pos_encoding = self._positional_encoding(L, D).to(z.device)\n",
    "        z = z + self.pos_encoding[None, :, :]\n",
    "        cls_tok = self.cls.expand(B, -1, -1)\n",
    "        z = torch.cat([cls_tok, z], dim=1)\n",
    "        z = self.encoder(z)\n",
    "        cls = z[:, 0, :]\n",
    "        return self.head(cls)\n",
    "\n",
    "# =========================\n",
    "# FOCAL LOSS (2 clases)\n",
    "# =========================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 1.5, reduction: str = 'mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha / alpha.sum()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        logp = nn.functional.log_softmax(logits, dim=-1)      # (B,C)\n",
    "        p = logp.exp()\n",
    "        idx = torch.arange(target.shape[0], device=logits.device)\n",
    "        pt = p[idx, target]\n",
    "        logpt = logp[idx, target]\n",
    "        at = self.alpha[target]\n",
    "        loss = - at * ((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS\n",
    "# =========================\n",
    "def augment_batch(\n",
    "    xb,\n",
    "    p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "    max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1\n",
    "):\n",
    "    B, C, T = xb.shape\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T*max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std*torch.randn_like(xb)\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    return xb\n",
    "\n",
    "# VersiÃ³n suave para FT\n",
    "def augment_batch_ft(xb):\n",
    "    return augment_batch(xb, **FT_AUG)\n",
    "\n",
    "# =========================\n",
    "# EMA de pesos (solo global)\n",
    "# =========================\n",
    "class ModelEMA:\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.9995, device=None):\n",
    "        self.ema = self._clone(model).to(device if device is not None else next(model.parameters()).device)\n",
    "        self.decay = decay\n",
    "        self._updates = 0\n",
    "        self.update(model, force=True)\n",
    "\n",
    "    def _clone(self, model):\n",
    "        ema = type(model)()\n",
    "        ema.load_state_dict(model.state_dict())\n",
    "        for p in ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        return ema\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, model: nn.Module, force: bool = False):\n",
    "        d = self.decay\n",
    "        if self._updates < 1000:\n",
    "            d = (self._updates / 1000.0) * self.decay\n",
    "        msd = model.state_dict()\n",
    "        esd = self.ema.state_dict()\n",
    "        for k in esd.keys():\n",
    "            if esd[k].dtype.is_floating_point:\n",
    "                esd[k].mul_(d).add_(msd[k].detach(), alpha=1.0 - d)\n",
    "            else:\n",
    "                esd[k] = msd[k]\n",
    "        self._updates += 1\n",
    "\n",
    "# =========================\n",
    "# INFERENCIA TTA / SUBWINDOW\n",
    "# =========================\n",
    "def subwindow_logits(model, X, sfreq, sw_len, sw_stride, device):\n",
    "    model.eval()\n",
    "    wl = int(round(sw_len * sfreq))\n",
    "    st = int(round(sw_stride * sfreq))\n",
    "    wl = max(1, min(wl, X.shape[-1])); st = max(1, st)\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]; acc = []\n",
    "            for s in range(0, max(1, X.shape[-1]-wl+1), st):\n",
    "                seg = x[:, s:s+wl]\n",
    "                if seg.shape[-1] < wl:\n",
    "                    pad = wl - seg.shape[-1]\n",
    "                    seg = np.pad(seg, ((0,0),(0,pad)), mode='edge')\n",
    "                xb = torch.tensor(seg[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            acc = np.mean(np.stack(acc, axis=0), axis=0) if len(acc) else np.zeros(2, dtype=np.float32)\n",
    "            out.append(acc)\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "def time_shift_tta_logits(model, X, sfreq, shifts_s, device):\n",
    "    model.eval()\n",
    "    T = X.shape[-1]; out = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X.shape[0]):\n",
    "            x0 = X[i]; acc = []\n",
    "            for sh in shifts_s:\n",
    "                shift = int(round(sh * sfreq))\n",
    "                if shift == 0:\n",
    "                    x = x0\n",
    "                elif shift > 0:\n",
    "                    x = np.pad(x0[:, shift:], ((0,0),(0,shift)), mode='edge')[:, :T]\n",
    "                else:\n",
    "                    shift = -shift\n",
    "                    x = np.pad(x0[:, :-shift], ((0,0),(shift,0)), mode='edge')[:, :T]\n",
    "                xb = torch.tensor(x[None, ...], dtype=torch.float32, device=device)\n",
    "                logit = model(xb).detach().cpu().numpy()[0]\n",
    "                acc.append(logit)\n",
    "            out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# Utilidades splits estratificados por sujeto\n",
    "# =========================\n",
    "def build_subject_label_map(subject_ids):\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=2)\n",
    "        y_dom = int(np.argmax(binc))\n",
    "        y_dom_list.append(y_dom)\n",
    "    return np.array(y_dom_list, dtype=int)\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL GLOBAL POR FOLD\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    def load_fold_subjects_local(folds_json: Path, fold: int):\n",
    "        return load_fold_subjects(folds_json, fold)\n",
    "\n",
    "    train_sub, test_sub = load_fold_subjects_local(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # Carga TRAIN/VAL/TEST\n",
    "    X_tr_list, y_tr_list, sub_tr_list = [], [], []\n",
    "    X_val_list, y_val_list, sub_val_list = [], [], []\n",
    "    X_te_list, y_te_list, sub_te_list = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys)\n",
    "        sub_tr_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys)\n",
    "        sub_val_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid, RESAMPLE_HZ, DO_NOTCH, DO_BANDPASS, DO_CAR, BP_LO, BP_HI)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys)\n",
    "        sub_te_list.append(np.full_like(ys, fill_value=subject_id_to_int(sid)))\n",
    "        sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # Concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    sub_tr = np.concatenate(sub_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    sub_val = np.concatenate(sub_val_list, axis=0)\n",
    "    X_te = np.concatenate(X_te_list, axis=0); y_te = np.concatenate(y_te_list, axis=0)\n",
    "    sub_te = np.concatenate(sub_te_list, axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # NormalizaciÃ³n por canal (fit en TRAIN y aplicar a VAL/TEST)\n",
    "    if ZSCORE_PER_EPOCH:\n",
    "        X_tr_std, X_val_std, X_te_std = X_tr, X_val, X_te\n",
    "    else:\n",
    "        X_tr_std, X_val_std = standardize_per_channel(X_tr, X_val)\n",
    "        _,        X_te_std  = standardize_per_channel(X_tr, X_te)\n",
    "\n",
    "    # Datasets\n",
    "    tr_ds  = TensorDataset(torch.tensor(X_tr_std),  torch.tensor(y_tr).long(),  torch.tensor(sub_tr).long())\n",
    "    val_ds = TensorDataset(torch.tensor(X_val_std), torch.tensor(y_val).long(), torch.tensor(sub_val).long())\n",
    "    te_ds  = TensorDataset(torch.tensor(X_te_std),  torch.tensor(y_te).long(),  torch.tensor(sub_te).long())\n",
    "\n",
    "    # Weighted sampler templado: w = (1/ws)^a * (1/wk)^b\n",
    "    def make_weighted_sampler(dataset: TensorDataset):\n",
    "        _Xb, yb, sb = dataset.tensors\n",
    "        yb_np = yb.numpy()\n",
    "        sb_np = sb.numpy()\n",
    "        uniq_s, cnt_s = np.unique(sb_np, return_counts=True)\n",
    "        map_s = {s:c for s,c in zip(uniq_s, cnt_s)}\n",
    "        key = sb_np.astype(np.int64) * 10 + yb_np.astype(np.int64)\n",
    "        uniq_k, cnt_k = np.unique(key, return_counts=True)\n",
    "        map_k = {k:c for k,c in zip(uniq_k, cnt_k)}\n",
    "        a, b = 0.8, 1.0\n",
    "        w = []\n",
    "        for s, y in zip(sb_np, yb_np):\n",
    "            k = int(s)*10 + int(y)\n",
    "            ws = float(map_s[int(s)])\n",
    "            wk = float(map_k[k])\n",
    "            w.append((ws ** (-a)) * (wk ** (-b)))\n",
    "        w = np.array(w, dtype=np.float64)\n",
    "        w = w / (w.mean() + 1e-12)\n",
    "        sampler = WeightedRandomSampler(weights=torch.tensor(w, dtype=torch.double),\n",
    "                                        num_samples=len(yb_np), replacement=True)\n",
    "        return sampler\n",
    "\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        tr_sampler = make_weighted_sampler(tr_ds)\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, sampler=tr_sampler, drop_last=False, worker_init_fn=seed_worker)\n",
    "    else:\n",
    "        tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # Modelo (2 clases)\n",
    "    model = EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                              n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "\n",
    "    # Optimizador + Focal Loss (2 clases)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-2)\n",
    "    class_counts = np.bincount(y_tr, minlength=2).astype(np.float32)\n",
    "    inv = class_counts.sum() / (2.0 * np.maximum(class_counts, 1.0))\n",
    "    alpha = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "    crit = FocalLoss(alpha=alpha, gamma=1.5, reduction='mean')\n",
    "\n",
    "    # LR scheduler Warmup+Cosine\n",
    "    from torch.optim.lr_scheduler import LambdaLR\n",
    "    total_epochs = EPOCHS\n",
    "    warmup_epochs = max(1, int(WARMUP_EPOCHS))\n",
    "    min_factor = 0.1\n",
    "    def lr_lambda(current_epoch):\n",
    "        if current_epoch < warmup_epochs:\n",
    "            return (current_epoch + 1) / warmup_epochs\n",
    "        progress = (current_epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "        progress = min(1.0, max(0.0, progress))\n",
    "        return min_factor + 0.5 * (1.0 - min_factor) * (1.0 + np.cos(np.pi * progress))\n",
    "    scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "\n",
    "    # EMA (solo global)\n",
    "    if USE_EMA:\n",
    "        ema = ModelEMA(model, decay=EMA_DECAY, device=device)\n",
    "    else:\n",
    "        ema = None\n",
    "\n",
    "    # Entrenamiento global con early stopping por F1 macro\n",
    "    best_f1, best_state, wait = 0.0, None, 0\n",
    "    hist = {\"ep\": [], \"tr_loss\": [], \"tr_acc\": [], \"val_acc\": [], \"val_f1m\": [], \"lr\": []}\n",
    "\n",
    "    def evaluate_on(loader, use_ema=True):\n",
    "        mdl = ema.ema if (ema is not None and use_ema) else model\n",
    "        mdl.eval()\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in loader:\n",
    "                xb = xb.to(device)\n",
    "                p = mdl(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "        acc = accuracy_score(gts, preds)\n",
    "        f1m = f1_score(gts, preds, average='macro')\n",
    "        return acc, f1m\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        tr_loss, n_seen, tr_correct = 0.0, 0, 0\n",
    "        for xb, yb, _sb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            xb = augment_batch(xb)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "            if ema is not None:\n",
    "                ema.update(model)\n",
    "\n",
    "            tr_loss += loss.item() * len(yb)\n",
    "            n_seen += len(yb)\n",
    "            tr_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_loss /= max(1, n_seen)\n",
    "        tr_acc = tr_correct / max(1, n_seen)\n",
    "\n",
    "        acc, f1m = evaluate_on(val_ld, use_ema=True)\n",
    "\n",
    "        hist[\"ep\"].append(ep)\n",
    "        hist[\"tr_loss\"].append(tr_loss)\n",
    "        hist[\"tr_acc\"].append(tr_acc)\n",
    "        hist[\"val_acc\"].append(acc)\n",
    "        hist[\"val_f1m\"].append(f1m)\n",
    "        hist[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"  Ã‰poca {ep:3d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_acc={acc:.4f} | val_f1m={f1m:.4f} | LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        improved = f1m > best_f1 + 1e-4\n",
    "        if improved:\n",
    "            best_f1 = f1m\n",
    "            ref_model = ema.ema if ema is not None else model\n",
    "            best_state = {k: v.detach().cpu() for k, v in ref_model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"  Early stopping en Ã©poca {ep} (mejor val_f1m={best_f1:.4f})\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        (ema.ema if (ema is not None) else model).load_state_dict(best_state)\n",
    "\n",
    "    # ---- Guardar curva ----\n",
    "    fig = plt.figure(figsize=(8,4.5))\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_loss\"], label=\"train_loss\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"tr_acc\"], label=\"tr_acc\")\n",
    "    ax1.plot(hist[\"ep\"], hist[\"val_acc\"], label=\"val_acc\")\n",
    "    ax1.set_xlabel(\"Ã‰poca\"); ax1.set_title(f\"Fold {fold} â€” Curva de entrenamiento (2 clases)\")\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "    out_png = f\"training_curve_fold{fold}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.close(fig)\n",
    "    print(f\"â†³ Curva de entrenamiento guardada: {out_png}\")\n",
    "\n",
    "    # ---- EvaluaciÃ³n final en TEST (global) ----\n",
    "    eval_model = ema.ema if (ema is not None) else model\n",
    "    eval_model.eval()\n",
    "\n",
    "    sfreq_used = RESAMPLE_HZ\n",
    "    if sfreq_used is None:\n",
    "        sfreq_used = int(round(X_te_std.shape[-1] / (TMAX - TMIN)))\n",
    "\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        preds, gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _sb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                p = eval_model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p); gts.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    elif SW_MODE in ('subwin', 'tta'):\n",
    "        logits_tta = None\n",
    "        logits_sw  = None\n",
    "        if SW_MODE == 'subwin':\n",
    "            logits_sw = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "        elif SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "\n",
    "        if COMBINE_TTA_AND_SUBWIN:\n",
    "            if logits_tta is None:\n",
    "                logits_tta = time_shift_tta_logits(eval_model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "            if logits_sw is None:\n",
    "                logits_sw  = subwindow_logits(eval_model, X_te_std, sfreq_used, SW_LEN, SW_STRIDE, device)\n",
    "            logits = 0.5 * logits_tta + 0.5 * logits_sw\n",
    "        else:\n",
    "            logits = logits_tta if logits_tta is not None else logits_sw\n",
    "\n",
    "        preds = logits.argmax(axis=1); gts = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc:.4f}\\n\")\n",
    "    print(classification_report(gts, preds, target_names=[c.replace('_',' ') for c in CLASS_NAMES], digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    cm = confusion_matrix(gts, preds, labels=[0,1])\n",
    "    print(cm)\n",
    "    fig = plt.figure(figsize=(4.8,4.2))\n",
    "    plt.imshow(cm, cmap='Blues'); plt.title(f\"Confusion â€” Fold {fold} Global (2 clases)\")\n",
    "    plt.xlabel(\"pred\"); plt.ylabel(\"true\")\n",
    "    plt.colorbar(); plt.tight_layout()\n",
    "    plt.savefig(f\"confusion_global_fold{fold}.png\", dpi=140); plt.close(fig)\n",
    "    print(f\"â†³ Matriz de confusiÃ³n guardada: confusion_global_fold{fold}.png\")\n",
    "\n",
    "    # =========================\n",
    "    # FINE-TUNING PROGRESIVO POR SUJETO (4-fold CV interno) â€” 2 clases\n",
    "    # =========================\n",
    "    subjects = np.unique(sub_te)\n",
    "    subj_to_idx = {s: np.where(sub_te == s)[0] for s in subjects}\n",
    "\n",
    "    def make_ft_optimizer(model):\n",
    "        head_params = list(model.head.parameters())\n",
    "        backbone_params = [p for n,p in model.named_parameters() if not n.startswith('head.')]\n",
    "        return torch.optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': FT_LR_BACKBONE},\n",
    "            {'params': head_params,     'lr': FT_LR_HEAD}\n",
    "        ], weight_decay=FT_WD)\n",
    "\n",
    "    def freeze_backbone(model, freeze=True):\n",
    "        for n,p in model.named_parameters():\n",
    "            if not n.startswith('head.'):\n",
    "                p.requires_grad_(not freeze)\n",
    "\n",
    "    def ft_make_criterion_from_counts(counts):\n",
    "        inv = counts.sum() / (2.0 * np.maximum(counts.astype(np.float32), 1.0))\n",
    "        a = torch.tensor(inv, dtype=torch.float32, device=device)\n",
    "        return FocalLoss(alpha=a, gamma=1.5, reduction='mean')\n",
    "\n",
    "    def evaluate_tensor(model_t, X, y):\n",
    "        model_t.eval()\n",
    "        with torch.no_grad():\n",
    "            xb = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "            p = model_t(xb).argmax(1).cpu().numpy()\n",
    "        return accuracy_score(y, p), f1_score(y, p, average='macro'), p\n",
    "\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    # Base: mejores pesos globales (EMA si existe)\n",
    "    base_state = (ema.ema if (ema is not None) else model).state_dict()\n",
    "\n",
    "    for s in subjects:\n",
    "        idx = subj_to_idx[s]\n",
    "        Xs, ys = X_te_std[idx], y_te[idx]\n",
    "\n",
    "        # Si no hay ambas clases o muy pocos ejemplos, solo eval directa\n",
    "        if len(np.unique(ys)) < 2 or len(ys) < 20:\n",
    "            eval_model = EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                                           n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "            eval_model.load_state_dict(base_state)\n",
    "            _, _, pred_s = evaluate_tensor(eval_model, Xs, ys)\n",
    "            all_true.append(ys); all_pred.append(pred_s)\n",
    "            continue\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=FT_N_FOLDS, shuffle=True, random_state=RANDOM_STATE + fold + int(s))\n",
    "        for tr_idx, te_idx in skf.split(Xs, ys):\n",
    "            Xtr, ytr = Xs[tr_idx].copy(), ys[tr_idx].copy()\n",
    "            Xte_s, yte_s = Xs[te_idx].copy(), ys[te_idx].copy()\n",
    "\n",
    "            # EstandarizaciÃ³n por sujeto (fit en FT-train)\n",
    "            Xtr_std, Xte_std = standardize_per_channel(Xtr, Xte_s)\n",
    "\n",
    "            # Modelo fresh desde el global\n",
    "            ft_model = EEGCNNTransformer(n_ch=8, n_cls=2, d_model=D_MODEL, n_heads=N_HEADS,\n",
    "                                         n_layers=N_LAYERS, p_drop=P_DROP, p_drop_encoder=P_DROP_ENCODER).to(device)\n",
    "            ft_model.load_state_dict(base_state)\n",
    "\n",
    "            # optim + criterio (Î± de este sujeto/split)\n",
    "            opt_ft = make_ft_optimizer(ft_model)\n",
    "            alpha_counts = np.bincount(ytr, minlength=2)\n",
    "            ft_crit = ft_make_criterion_from_counts(alpha_counts)\n",
    "\n",
    "            # loaders FT\n",
    "            ds_tr = TensorDataset(torch.tensor(Xtr_std), torch.tensor(ytr).long())\n",
    "            ds_te = TensorDataset(torch.tensor(Xte_std), torch.tensor(yte_s).long())\n",
    "            ld_tr = DataLoader(ds_tr, batch_size=FT_BATCH, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "            ld_te = DataLoader(ds_te, batch_size=FT_BATCH, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "            # ETAPA 1: freeze backbone\n",
    "            freeze_backbone(ft_model, True)\n",
    "            best_f1_s, best_state_s, wait_s = -1, None, 0\n",
    "            for ep in range(1, FT_FREEZE_EPOCHS+1):\n",
    "                ft_model.train()\n",
    "                for xb, yb in ld_tr:\n",
    "                    xb = xb.to(device); yb = yb.to(device)\n",
    "                    xb = augment_batch_ft(xb)\n",
    "                    opt_ft.zero_grad()\n",
    "                    logits = ft_model(xb)\n",
    "                    loss = ft_crit(logits, yb)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                    opt_ft.step()\n",
    "\n",
    "                acc_s, f1_s = evaluate_tensor(ft_model, Xte_std, yte_s)[:2]\n",
    "                improved = f1_s > best_f1_s + 1e-4\n",
    "                if improved:\n",
    "                    best_f1_s = f1_s\n",
    "                    best_state_s = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                    wait_s = 0\n",
    "                else:\n",
    "                    wait_s += 1\n",
    "                if wait_s >= FT_PATIENCE:\n",
    "                    break\n",
    "\n",
    "            if best_state_s is not None:\n",
    "                ft_model.load_state_dict(best_state_s)\n",
    "\n",
    "            # ETAPA 2: unfreeze (todo entrenable)\n",
    "            freeze_backbone(ft_model, False)\n",
    "            best_f1_s2, best_state_s2, wait_s2 = -1, None, 0\n",
    "            for ep in range(1, FT_UNFREEZE_EPOCHS+1):\n",
    "                ft_model.train()\n",
    "                for xb, yb in ld_tr:\n",
    "                    xb = xb.to(device); yb = yb.to(device)\n",
    "                    xb = augment_batch_ft(xb)\n",
    "                    opt_ft.zero_grad()\n",
    "                    logits = ft_model(xb)\n",
    "                    loss = ft_crit(logits, yb)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(ft_model.parameters(), 1.0)\n",
    "                    opt_ft.step()\n",
    "\n",
    "                acc_s, f1_s = evaluate_tensor(ft_model, Xte_std, yte_s)[:2]\n",
    "                improved = f1_s > best_f1_s2 + 1e-4\n",
    "                if improved:\n",
    "                    best_f1_s2 = f1_s\n",
    "                    best_state_s2 = {k: v.detach().cpu() for k,v in ft_model.state_dict().items()}\n",
    "                    wait_s2 = 0\n",
    "                else:\n",
    "                    wait_s2 += 1\n",
    "                if wait_s2 >= FT_PATIENCE:\n",
    "                    break\n",
    "\n",
    "            if best_state_s2 is not None:\n",
    "                ft_model.load_state_dict(best_state_s2)\n",
    "\n",
    "            # mÃ©tricas del fold del sujeto\n",
    "            _, _, pred_s = evaluate_tensor(ft_model, Xte_std, yte_s)\n",
    "            all_true.append(yte_s); all_pred.append(pred_s)\n",
    "\n",
    "    # resumen FT por sujeto\n",
    "    all_true = np.concatenate(all_true) if len(all_true) else np.array([], dtype=int)\n",
    "    all_pred = np.concatenate(all_pred) if len(all_pred) else np.array([], dtype=int)\n",
    "    if len(all_true) > 0:\n",
    "        ft_acc = accuracy_score(all_true, all_pred)\n",
    "        ft_f1m = f1_score(all_true, all_pred, average='macro')\n",
    "        print(f\"  Fine-tuning PROGRESIVO (por sujeto, {FT_N_FOLDS}-fold CV) acc={ft_acc:.4f}\")\n",
    "        print(f\"  Î”(FT-Global) = {ft_acc - acc:+.4f}\")\n",
    "        cm_ft = confusion_matrix(all_true, all_pred, labels=[0,1])\n",
    "        print(\"Confusion matrix FT (rows=true, cols=pred):\")\n",
    "        print(cm_ft)\n",
    "        fig = plt.figure(figsize=(4.8,4.2))\n",
    "        plt.imshow(cm_ft, cmap='Greens'); plt.title(f\"Confusion â€” Fold {fold} FT (2 clases)\")\n",
    "        plt.xlabel(\"pred\"); plt.ylabel(\"true\")\n",
    "        plt.colorbar(); plt.tight_layout()\n",
    "        plt.savefig(f\"confusion_ft_fold{fold}.png\", dpi=140); plt.close(fig)\n",
    "        print(f\"â†³ Matriz de confusiÃ³n FT guardada: confusion_ft_fold{fold}.png\")\n",
    "    else:\n",
    "        ft_acc = float('nan')\n",
    "        print(\"  Fine-tuning PROGRESIVO: no se generaron splits vÃ¡lidos (sujetos con una sola clase o muy pocos ensayos).\")\n",
    "\n",
    "    return acc, f1m, ft_acc\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    acc_folds, f1_folds, ft_acc_folds = [], [], []\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m, ft_acc = train_one_fold(fold, DEVICE)\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "        ft_acc_folds.append(\"nan\" if (ft_acc != ft_acc) else f\"{ft_acc:.4f}\")  # maneja NaN\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "    valid_ft = [float(a) for a in ft_acc_folds if a != \"nan\"]\n",
    "    ft_acc_mean = float(np.mean(valid_ft)) if len(valid_ft) else float('nan')\n",
    "    delta_mean = (ft_acc_mean - acc_mean) if (ft_acc_mean == ft_acc_mean) else float('nan')\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES (2 clases: left/right)\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n",
    "    print(f\"Fine-tune PROGRESIVO folds: {ft_acc_folds}\")\n",
    "    if ft_acc_mean == ft_acc_mean:\n",
    "        print(f\"Fine-tune PROGRESIVO mean: {ft_acc_mean:.4f}\")\n",
    "        print(f\"Î”(FT-Global) mean: {delta_mean:+.4f}\")\n",
    "    else:\n",
    "        print(\"Fine-tune PROGRESIVO mean: N/A (insuficientes sujetos/conjuntos vÃ¡lidos)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
