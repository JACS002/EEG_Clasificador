{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd0e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Usando dispositivo: cuda\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON EEGNet (mismo Kfold y TTA/Augments que CNN+TF)\n",
      "ðŸ§  INICIANDO EXPERIMENTO CON EEGNet + Augments/TTA estilo CNN+TF (sin balanceo)\n",
      "ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS_GLOBAL=100, BATCH=64, LR=0.01 | ZSCORE_PER_EPOCH=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  7.62it/s]\n",
      "Cargando val fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  7.30it/s]\n",
      "Cargando test fold1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  Ã‰poca   1 | train_acc=0.3520 | val_acc=0.3944 | LR=0.01000\n",
      "  Ã‰poca   5 | train_acc=0.4232 | val_acc=0.4310 | LR=0.00250\n",
      "  Ã‰poca  10 | train_acc=0.4351 | val_acc=0.4246 | LR=0.00854\n",
      "  Ã‰poca  15 | train_acc=0.4531 | val_acc=0.4452 | LR=0.00250\n",
      "  Ã‰poca  20 | train_acc=0.4474 | val_acc=0.4286 | LR=0.00996\n",
      "  Ã‰poca  25 | train_acc=0.4439 | val_acc=0.4349 | LR=0.00854\n",
      "  Early stopping en Ã©poca 25 (mejor val_acc=0.4452)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6461    0.3560    0.4591       441\n",
      "       Right     0.5372    0.4422    0.4851       441\n",
      "  Both Fists     0.3447    0.5283    0.4172       441\n",
      "   Both Feet     0.4357    0.4762    0.4550       441\n",
      "\n",
      "    accuracy                         0.4507      1764\n",
      "   macro avg     0.4909    0.4507    0.4541      1764\n",
      "weighted avg     0.4909    0.4507    0.4541      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[157  39 167  78]\n",
      " [ 22 195 133  91]\n",
      " [ 39  66 233 103]\n",
      " [ 25  63 143 210]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5079 | sujetos=21\n",
      "  Î”(FT-Global) = +0.0573\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:05<00:00, 11.34it/s]\n",
      "Cargando val fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 11.63it/s]\n",
      "Cargando test fold2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  Ã‰poca   1 | train_acc=0.3109 | val_acc=0.3683 | LR=0.01000\n",
      "  Ã‰poca   5 | train_acc=0.3850 | val_acc=0.4484 | LR=0.00250\n",
      "  Ã‰poca  10 | train_acc=0.3984 | val_acc=0.4238 | LR=0.00854\n",
      "  Ã‰poca  15 | train_acc=0.4227 | val_acc=0.4500 | LR=0.00250\n",
      "  Ã‰poca  20 | train_acc=0.4152 | val_acc=0.4444 | LR=0.00996\n",
      "  Ã‰poca  25 | train_acc=0.4129 | val_acc=0.4365 | LR=0.00854\n",
      "  Ã‰poca  30 | train_acc=0.4241 | val_acc=0.4532 | LR=0.00565\n",
      "  Ã‰poca  35 | train_acc=0.4314 | val_acc=0.4492 | LR=0.00250\n",
      "  Ã‰poca  40 | train_acc=0.4456 | val_acc=0.4532 | LR=0.00038\n",
      "  Early stopping en Ã©poca 44 (mejor val_acc=0.4611)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6480    0.4717    0.5459       441\n",
      "       Right     0.6559    0.4626    0.5426       441\n",
      "  Both Fists     0.3901    0.6599    0.4903       441\n",
      "   Both Feet     0.5000    0.4376    0.4667       441\n",
      "\n",
      "    accuracy                         0.5079      1764\n",
      "   macro avg     0.5485    0.5079    0.5114      1764\n",
      "weighted avg     0.5485    0.5079    0.5114      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[208  17 171  45]\n",
      " [ 18 204 137  82]\n",
      " [ 56  28 291  66]\n",
      " [ 39  62 147 193]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5975 | sujetos=21\n",
      "  Î”(FT-Global) = +0.0896\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  9.00it/s]\n",
      "Cargando val fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  9.20it/s]\n",
      "Cargando test fold3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  Ã‰poca   1 | train_acc=0.3264 | val_acc=0.4381 | LR=0.01000\n",
      "  Ã‰poca   5 | train_acc=0.4243 | val_acc=0.4817 | LR=0.00250\n",
      "  Ã‰poca  10 | train_acc=0.4248 | val_acc=0.4810 | LR=0.00854\n",
      "  Ã‰poca  15 | train_acc=0.4471 | val_acc=0.4960 | LR=0.00250\n",
      "  Ã‰poca  20 | train_acc=0.4383 | val_acc=0.4770 | LR=0.00996\n",
      "  Ã‰poca  25 | train_acc=0.4367 | val_acc=0.4825 | LR=0.00854\n",
      "  Early stopping en Ã©poca 25 (mejor val_acc=0.4960)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6026    0.4195    0.4947       441\n",
      "       Right     0.6341    0.4127    0.5000       441\n",
      "  Both Fists     0.3757    0.6032    0.4630       441\n",
      "   Both Feet     0.4242    0.4444    0.4341       441\n",
      "\n",
      "    accuracy                         0.4700      1764\n",
      "   macro avg     0.5092    0.4700    0.4729      1764\n",
      "weighted avg     0.5092    0.4700    0.4729      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[185  23 156  77]\n",
      " [ 24 182 132 103]\n",
      " [ 57  32 266  86]\n",
      " [ 41  50 154 196]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5340 | sujetos=21\n",
      "  Î”(FT-Global) = +0.0641\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00, 11.30it/s]\n",
      "Cargando val fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 11.50it/s]\n",
      "Cargando test fold4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n",
      "  Ã‰poca   1 | train_acc=0.3270 | val_acc=0.4341 | LR=0.01000\n",
      "  Ã‰poca   5 | train_acc=0.4027 | val_acc=0.4683 | LR=0.00250\n",
      "  Ã‰poca  10 | train_acc=0.4210 | val_acc=0.4698 | LR=0.00854\n",
      "  Ã‰poca  15 | train_acc=0.4275 | val_acc=0.4698 | LR=0.00250\n",
      "  Ã‰poca  20 | train_acc=0.4259 | val_acc=0.4635 | LR=0.00996\n",
      "  Ã‰poca  25 | train_acc=0.4272 | val_acc=0.4833 | LR=0.00854\n",
      "  Ã‰poca  30 | train_acc=0.4389 | val_acc=0.4873 | LR=0.00565\n",
      "  Ã‰poca  35 | train_acc=0.4611 | val_acc=0.4802 | LR=0.00250\n",
      "  Ã‰poca  40 | train_acc=0.4582 | val_acc=0.4952 | LR=0.00038\n",
      "  Early stopping en Ã©poca 41 (mejor val_acc=0.4992)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.4857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5932    0.4548    0.5148       420\n",
      "       Right     0.6271    0.4524    0.5256       420\n",
      "  Both Fists     0.3776    0.6429    0.4758       420\n",
      "   Both Feet     0.4853    0.3929    0.4342       420\n",
      "\n",
      "    accuracy                         0.4857      1680\n",
      "   macro avg     0.5208    0.4857    0.4876      1680\n",
      "weighted avg     0.5208    0.4857    0.4876      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[191  19 151  59]\n",
      " [ 30 190 135  65]\n",
      " [ 59  40 270  51]\n",
      " [ 42  54 159 165]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5714 | sujetos=20\n",
      "  Î”(FT-Global) = +0.0857\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:09<00:00,  7.32it/s]\n",
      "Cargando val fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  9.30it/s]\n",
      "Cargando test fold5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n",
      "  Ã‰poca   1 | train_acc=0.3328 | val_acc=0.3937 | LR=0.01000\n",
      "  Ã‰poca   5 | train_acc=0.4090 | val_acc=0.4103 | LR=0.00250\n",
      "  Ã‰poca  10 | train_acc=0.4039 | val_acc=0.4127 | LR=0.00854\n",
      "  Ã‰poca  15 | train_acc=0.4319 | val_acc=0.4278 | LR=0.00250\n",
      "  Early stopping en Ã©poca 19 (mejor val_acc=0.4341)\n",
      "â†³ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6087    0.5333    0.5685       420\n",
      "       Right     0.5455    0.5000    0.5217       420\n",
      "  Both Fists     0.4173    0.5643    0.4798       420\n",
      "   Both Feet     0.5125    0.4381    0.4724       420\n",
      "\n",
      "    accuracy                         0.5089      1680\n",
      "   macro avg     0.5210    0.5089    0.5106      1680\n",
      "weighted avg     0.5210    0.5089    0.5106      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[224  31 123  42]\n",
      " [ 21 210 105  84]\n",
      " [ 76  58 237  49]\n",
      " [ 47  86 103 184]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5667 | sujetos=20\n",
      "  Î”(FT-Global) = +0.0577\n",
      "â†³ Matriz de confusiÃ³n guardada: confusion_global_fold5.png\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4507', '0.5079', '0.4700', '0.4857', '0.5089']\n",
      "Global mean ACC: 0.4846\n",
      "F1 folds (MACRO): ['0.4541', '0.5114', '0.4729', '0.4876', '0.5106']\n",
      "F1 mean (MACRO): 0.4873\n",
      "Fine-tune PROGRESIVO folds: ['0.5079', '0.5975', '0.5340', '0.5714', '0.5667']\n",
      "Fine-tune PROGRESIVO mean: 0.5555\n",
      "Î”(FT-Global) mean: +0.0709\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# EEGNet + (SIN balanceo por sujeto/clase) + Kfold5.json (solo train/test) +\n",
    "# Augments y TTA iguales al CNN+Transformer + Fine-tuning progresivo (igual que antes)\n",
    "\n",
    "import os, re, json, random, copy, itertools\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / '00_folds' / 'Kfold5.json'\n",
    "\n",
    "# Entrenamiento global\n",
    "EPOCHS_GLOBAL   = 100\n",
    "BATCH_SIZE      = 64\n",
    "LR_INIT         = 1e-2\n",
    "SGDR_T0         = 6\n",
    "SGDR_Tmult      = 2\n",
    "GLOBAL_PATIENCE = 10\n",
    "LOG_EVERY       = 5\n",
    "\n",
    "# ValidaciÃ³n desde sujetos de train (igual a tu CNN+TF)\n",
    "VAL_SUBJECT_FRAC   = 0.18\n",
    "VAL_STRAT_SUBJECT  = True\n",
    "\n",
    "# Fine-tuning progresivo\n",
    "CALIB_CV_FOLDS = 4\n",
    "FT_EPOCHS   = 30\n",
    "FT_BASE_LR  = 5e-5\n",
    "FT_HEAD_LR  = 1e-3\n",
    "FT_L2SP     = 1e-4\n",
    "FT_PATIENCE = 5\n",
    "FT_VAL_RATIO = 0.2\n",
    "\n",
    "# Ventana temporal y prepro\n",
    "FS = 160.0\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "NORM_EPOCH_ZSCORE = True   # por-Ã©poca canal-a-canal\n",
    "\n",
    "# Excluir sujetos (igual que antes)\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "# Runs y canales\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES_4C = ['Left','Right','Both Fists','Both Feet']\n",
    "\n",
    "# TTA estilo CNN+TF\n",
    "SW_MODE = 'tta'                     # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.075, -0.05, -0.025, 0.0, 0.025, 0.05, 0.075]\n",
    "SW_LEN, SW_STRIDE = 4.5, 1.5\n",
    "COMBINE_TTA_AND_SUBWIN = False      # mantenemos apagado (como tu comentario)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸš€ Usando dispositivo: {DEVICE}\")\n",
    "print(\"ðŸ§  INICIANDO EXPERIMENTO CON EEGNet (mismo Kfold y TTA/Augments que CNN+TF)\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in sorted(list(IMAGERY_RUNS_LR | IMAGERY_RUNS_BF)):\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def load_subject_epochs(subject_id: str):\n",
    "    \"\"\"Devuelve X (N, T, C) y y (N,) con 8 canales y FS=160 si es necesario.\"\"\"\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0, 1, 1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "        # re-muestreo a FS si hace falta\n",
    "        if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "            raw.resample(FS)\n",
    "        sfreq = raw.info['sfreq']\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data().astype(np.float32)      # (N, C, T)\n",
    "        # z-score por Ã©poca/canal si estÃ¡ activo\n",
    "        if NORM_EPOCH_ZSCORE:\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "        # mapear etiquetas por run\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        # convertimos a (N, T, C) para EEGNet utilidades previas\n",
    "        X_tc = np.transpose(X[mask], (0, 2, 1))   # (N, T, C)\n",
    "        X_list.append(X_tc)\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, 1, 1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def standardize_per_channel_trainfit(X_tr_TxC, X_other_TxC):\n",
    "    \"\"\"Estandariza por canal usando estadÃ­sticas de TRAIN, sobre matrices (N, T, C).\"\"\"\n",
    "    Xtr = X_tr_TxC.astype(np.float32).copy()\n",
    "    Xot = X_other_TxC.astype(np.float32).copy()\n",
    "    C = Xtr.shape[2]\n",
    "    for c in range(C):\n",
    "        mu = Xtr[:, :, c].mean()\n",
    "        sd = Xtr[:, :, c].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        Xtr[:, :, c] = (Xtr[:, :, c] - mu) / sd\n",
    "        Xot[:, :, c] = (Xot[:, :, c] - mu) / sd\n",
    "    return Xtr, Xot\n",
    "\n",
    "def build_subject_label_map(subject_ids):\n",
    "    \"\"\"Etiqueta dominante por sujeto (para estratificar la selecciÃ³n de val).\"\"\"\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=4)\n",
    "        y_dom_list.append(int(np.argmax(binc)))\n",
    "    return np.array(y_dom_list, dtype=int)\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS (estilo CNN+TF) SOBRE (B,1,T,C)\n",
    "# =========================\n",
    "def augment_batch_eegnet(xb_1tC, p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "                         max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1):\n",
    "    \"\"\"\n",
    "    Aplica las mismas ideas de augment que tu CNN+Transformer, pero adaptadas a (B,1,T,C).\n",
    "    Internamente convierte a (B,C,T), aplica, y regresa a (B,1,T,C).\n",
    "    \"\"\"\n",
    "    B, _, T, C = xb_1tC.shape\n",
    "    xb = xb_1tC[:, 0].permute(0, 2, 1).contiguous()   # (B,C,T)\n",
    "    # jitter temporal\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T * max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    # ruido gaussiano\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std * torch.randn_like(xb)\n",
    "    # channel drop\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    # volver a (B,1,T,C)\n",
    "    xb_1tC = xb.permute(0, 2, 1).unsqueeze(1).contiguous()\n",
    "    return xb_1tC\n",
    "\n",
    "# =========================\n",
    "# TTA estilo CNN+TF (time-shifts)\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def time_shift_tta_logits_eegnet(model, X_TxC, sfreq, shifts_s, device):\n",
    "    \"\"\"\n",
    "    X_TxC: (N, T, C) numpy\n",
    "    Genera logits promediados tras desplazar en el tiempo.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N, T, C = X_TxC.shape\n",
    "    out = []\n",
    "    for i in range(N):\n",
    "        x0 = X_TxC[i]  # (T,C)\n",
    "        acc = []\n",
    "        for sh in shifts_s:\n",
    "            shift = int(round(sh * sfreq))\n",
    "            if shift == 0:\n",
    "                x = x0\n",
    "            elif shift > 0:\n",
    "                # desplaza a la derecha, rellena borde\n",
    "                pad = np.tile(x0[:1, :], (shift, 1))\n",
    "                x = np.concatenate([pad, x0[:-shift, :]], axis=0)\n",
    "            else:\n",
    "                # desplaza a la izquierda\n",
    "                shift = -shift\n",
    "                pad = np.tile(x0[-1:, :], (shift, 1))\n",
    "                x = np.concatenate([x0[shift:, :], pad], axis=0)\n",
    "            # a tensor (1,1,T,C)\n",
    "            xb = torch.tensor(x, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
    "            logit = model(xb).detach().cpu().numpy()[0]\n",
    "            acc.append(logit)\n",
    "        out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# MODELO EEGNet\n",
    "# =========================\n",
    "class ChannelDropout(nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p<=0: return x\n",
    "        B,_,T,C = x.shape\n",
    "        mask = (torch.rand(B,1,1,C, device=x.device) > self.p).float()\n",
    "        return x * mask\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Entrada: x de forma (B, 1, T, C)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch: int, n_classes: int,\n",
    "                 F1: int = 24, D: int = 2, kernel_t: int = 64, k_sep: int = 16,\n",
    "                 pool1_t: int = 4, pool2_t: int = 6,\n",
    "                 drop1_p: float = 0.35, drop2_p: float = 0.6,\n",
    "                 chdrop_p: float = 0.10):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.n_classes = n_classes\n",
    "        self.F1 = F1\n",
    "        self.D = D\n",
    "        self.F2 = F1 * D\n",
    "        self.kernel_t = kernel_t\n",
    "        self.k_sep = k_sep\n",
    "        self.pool1_t = pool1_t\n",
    "        self.pool2_t = pool2_t\n",
    "\n",
    "        self.chdrop = ChannelDropout(p=chdrop_p)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "        # Bloque 1: temporal\n",
    "        self.conv_temporal = nn.Conv2d(1, F1, kernel_size=(kernel_t, 1),\n",
    "                                       padding=(kernel_t // 2, 0), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1, momentum=0.99, eps=1e-3)\n",
    "\n",
    "        # Bloque 2: depthwise (espacial)\n",
    "        self.conv_depthwise = nn.Conv2d(F1, self.F2, kernel_size=(1, n_ch),\n",
    "                                        groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F2, momentum=0.99, eps=1e-3)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(pool1_t, 1), stride=(pool1_t, 1))\n",
    "        self.drop1 = nn.Dropout(drop1_p)\n",
    "\n",
    "        # Bloque 3: separable temporal\n",
    "        self.conv_sep_depth = nn.Conv2d(self.F2, self.F2, kernel_size=(k_sep, 1),\n",
    "                                        groups=self.F2, padding=(k_sep // 2, 0), bias=False)\n",
    "        self.conv_sep_point = nn.Conv2d(self.F2, self.F2, kernel_size=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2, momentum=0.99, eps=1e-3)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(pool2_t, 1), stride=(pool2_t, 1))\n",
    "        self.drop2 = nn.Dropout(drop2_p)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Cabeza dinÃ¡mica (se arma en forward segÃºn T)\n",
    "        self.fc = None\n",
    "        self.out = None\n",
    "        self._T_in = None\n",
    "\n",
    "    def _build_head(self, T_in: int, device: torch.device):\n",
    "        T1 = T_in // self.pool1_t\n",
    "        T2 = T1 // self.pool2_t\n",
    "        feat_dim = self.F2 * T2 * 1\n",
    "        self.fc  = nn.Linear(feat_dim, 128, bias=True).to(device)\n",
    "        self.out = nn.Linear(128, self.n_classes, bias=True).to(device)\n",
    "        self._T_in = T_in\n",
    "\n",
    "    def ensure_head(self, T_in: int, device: torch.device):\n",
    "        if (self.fc is None) or (self.out is None) or (self._T_in != T_in):\n",
    "            self._build_head(T_in, device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, _, T, C = x.shape\n",
    "        self.ensure_head(T, x.device)\n",
    "        x = self.chdrop(x)  # ChannelDropout\n",
    "\n",
    "        z = self.conv_temporal(x)\n",
    "        z = self.bn1(z); z = self.act(z)\n",
    "\n",
    "        z = self.conv_depthwise(z)   # (B, F2, T, 1)\n",
    "        z = self.bn2(z); z = self.act(z)\n",
    "        z = self.pool1(z)\n",
    "        z = self.drop1(z)\n",
    "\n",
    "        z = self.conv_sep_depth(z)\n",
    "        z = self.conv_sep_point(z)\n",
    "        z = self.bn3(z); z = self.act(z)\n",
    "        z = self.pool2(z)\n",
    "        z = self.drop2(z)\n",
    "\n",
    "        z = self.flatten(z)\n",
    "        z = self.fc(z); z = self.act(z)\n",
    "        z = self.out(z)\n",
    "        return z\n",
    "\n",
    "# =========================\n",
    "# LOSS (igual que tu EEGNet previo: soft CE ponderada)\n",
    "# =========================\n",
    "class WeightedSoftCrossEntropy(nn.Module):\n",
    "    def __init__(self, class_weights=None, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('w', None if class_weights is None else class_weights.clone().float())\n",
    "        self.ls = float(label_smoothing)\n",
    "    def forward(self, logits, target_probs):\n",
    "        if self.ls > 0:\n",
    "            K = logits.size(1)\n",
    "            target_probs = (1-self.ls)*target_probs + self.ls*(1.0/K)\n",
    "        logp = torch.log_softmax(logits, dim=1)\n",
    "        loss_per_class = -(target_probs * logp)\n",
    "        if self.w is not None:\n",
    "            loss_per_class = loss_per_class * self.w.unsqueeze(0)\n",
    "        loss = loss_per_class.sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "def make_class_weight_tensor(y_indices, n_classes, boost_bfists=1.20, boost_bfeet=1.20, device=DEVICE):\n",
    "    counts = np.bincount(y_indices, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    w = counts.sum() / counts           # inverso de frecuencia\n",
    "    w = w / w.mean()                    # normaliza a media 1\n",
    "    # boosts manuales\n",
    "    w[2] *= float(boost_bfists)         # clase 2: Both Fists\n",
    "    w[3] *= float(boost_bfeet)          # clase 3: Both Feet (NUEVO)\n",
    "    w = w / w.mean()                    # re-normaliza a media 1 (importante)\n",
    "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL HELPERS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def apply_max_norm(model, max_value=2.0, p=2.0):\n",
    "    layers = []\n",
    "    if hasattr(model, 'conv_depthwise'): layers.append(model.conv_depthwise)\n",
    "    if hasattr(model, 'conv_sep_point'): layers.append(model.conv_sep_point)\n",
    "    if hasattr(model, 'fc'):             layers.append(model.fc)\n",
    "    if hasattr(model, 'out'):            layers.append(model.out)\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            w = layer.weight.data\n",
    "            norms = w.view(w.size(0), -1).norm(p=p, dim=1, keepdim=True)\n",
    "            desired = torch.clamp(norms, max=max_value)\n",
    "            w.view(w.size(0), -1).mul_(desired / (1e-8 + norms))\n",
    "\n",
    "def plot_training_curves(history, fname):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history['train_acc'], label='train_acc')\n",
    "    plt.plot(history['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Training curve'); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45, ha='right'); plt.yticks(ticks, classes)\n",
    "    fmt = '.2f'; thresh = cm_norm.max()/2.\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "# =========================\n",
    "# FINE-TUNING PROGRESIVO (igual que antes)\n",
    "# =========================\n",
    "def _freeze_for_mode(model, mode):\n",
    "    for p in model.parameters(): p.requires_grad = False\n",
    "    if mode == 'out':\n",
    "        for p in model.out.parameters(): p.requires_grad = True\n",
    "    elif mode == 'head':\n",
    "        for p in model.fc.parameters():  p.requires_grad = True\n",
    "        for p in model.out.parameters(): p.requires_grad = True\n",
    "    elif mode == 'spatial+head':\n",
    "        for p in model.conv_depthwise.parameters(): p.requires_grad = True\n",
    "        for p in model.bn2.parameters():           p.requires_grad = True\n",
    "        for p in model.conv_sep_depth.parameters():p.requires_grad = True\n",
    "        for p in model.conv_sep_point.parameters():p.requires_grad = True\n",
    "        for p in model.bn3.parameters():           p.requires_grad = True\n",
    "        for p in model.fc.parameters():            p.requires_grad = True\n",
    "        for p in model.out.parameters():           p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "def _class_weights(y_np, n_classes):\n",
    "    counts = np.bincount(y_np, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    weights = counts.sum() / counts\n",
    "    weights = weights / weights.mean()\n",
    "    return torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def _train_one_mode(model, X_cal_TxC, y_cal, n_classes, mode,\n",
    "                    epochs=FT_EPOCHS, batch_size=32,\n",
    "                    head_lr=FT_HEAD_LR, base_lr=FT_BASE_LR,\n",
    "                    l2sp_lambda=FT_L2SP, patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO):\n",
    "    # split interno (sobre ensayos del sujeto)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=RANDOM_STATE)\n",
    "    (tr_idx, va_idx), = sss.split(X_cal_TxC, y_cal)\n",
    "    Xtr, ytr = X_cal_TxC[tr_idx], y_cal[tr_idx]\n",
    "    Xva, yva = X_cal_TxC[va_idx], y_cal[va_idx]\n",
    "\n",
    "    # a tensores (B,1,T,C)\n",
    "    def to_tensor(X_TxC, y_idx):\n",
    "        xb = torch.from_numpy(X_TxC).float().unsqueeze(1)   # (B,1,T,C)\n",
    "        yb = torch.from_numpy(y_idx).long()\n",
    "        return xb, yb\n",
    "\n",
    "    xb_tr, yb_tr = to_tensor(Xtr, ytr)\n",
    "    xb_va, yb_va = to_tensor(Xva, yva)\n",
    "\n",
    "    _freeze_for_mode(model, mode)\n",
    "    if mode == 'spatial+head':\n",
    "        base_params = (list(model.conv_depthwise.parameters()) +\n",
    "                       list(model.bn2.parameters()) +\n",
    "                       list(model.conv_sep_depth.parameters()) +\n",
    "                       list(model.conv_sep_point.parameters()) +\n",
    "                       list(model.bn3.parameters()))\n",
    "        head_params = list(model.fc.parameters()) + list(model.out.parameters())\n",
    "        train_params = base_params + head_params\n",
    "        opt = optim.Adam([\n",
    "            {\"params\": base_params, \"lr\": base_lr},\n",
    "            {\"params\": head_params, \"lr\": head_lr},\n",
    "        ])\n",
    "    else:\n",
    "        train_params = list(model.parameters())  # se respeta freeze por requires_grad\n",
    "        opt = optim.Adam([p for p in train_params if p.requires_grad], lr=head_lr)\n",
    "\n",
    "    # referencia L2SP\n",
    "    ref = [p.detach().clone().to(p.device) for p in [p for p in train_params if p.requires_grad]]\n",
    "    class_w = _class_weights(ytr, n_classes)\n",
    "    crit = nn.CrossEntropyLoss(weight=class_w)\n",
    "\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    best_val = float('inf'); bad = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        # mini-batches\n",
    "        for s in range(0, xb_tr.size(0), batch_size):\n",
    "            xbt = xb_tr[s:s+batch_size].to(DEVICE)\n",
    "            ybt = yb_tr[s:s+batch_size].to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xbt)\n",
    "            loss = crit(logits, ybt)\n",
    "            # L2SP\n",
    "            reg = 0.0\n",
    "            idx = 0\n",
    "            for p in train_params:\n",
    "                if p.requires_grad:\n",
    "                    reg = reg + torch.sum((p - ref[idx])**2)\n",
    "                    idx += 1\n",
    "            loss = loss + l2sp_lambda * reg\n",
    "            loss.backward(); opt.step()\n",
    "            apply_max_norm(model, max_value=2.0, p=2.0)\n",
    "\n",
    "        # validaciÃ³n\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0; nval = 0\n",
    "            for s in range(0, xb_va.size(0), batch_size):\n",
    "                xbv = xb_va[s:s+batch_size].to(DEVICE)\n",
    "                ybv = yb_va[s:s+batch_size].to(DEVICE)\n",
    "                logits = model(xbv)\n",
    "                loss = crit(logits, ybv)\n",
    "                val_loss += loss.item() * xbv.size(0); nval += xbv.size(0)\n",
    "            val_loss /= max(1, nval)\n",
    "\n",
    "        if val_loss + 1e-7 < best_val:\n",
    "            best_val = val_loss; bad = 0\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience: break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_numpy(model, X_np_TxC, device):\n",
    "    model.eval()\n",
    "    xb = torch.from_numpy(X_np_TxC).float().unsqueeze(1).to(device)  # (B,1,T,C)\n",
    "    logits = model(xb)\n",
    "    return logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "def subject_cv_finetune_predict_progressive(model_global, Xs_TxC, ys, device,\n",
    "                                            n_splits=CALIB_CV_FOLDS, n_classes=4):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    y_true_full = np.empty_like(ys); y_pred_full = np.empty_like(ys)\n",
    "    for tr_idx, te_idx in skf.split(Xs_TxC, ys):\n",
    "        Xcal, ycal = Xs_TxC[tr_idx], ys[tr_idx]\n",
    "        Xho,  yho  = Xs_TxC[te_idx], ys[te_idx]\n",
    "\n",
    "        # OUT\n",
    "        m_out = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_out, Xcal, ycal, n_classes, mode='out',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                        patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_out = predict_numpy(m_out, Xho, device); acc_out = (yhat_out == yho).mean()\n",
    "\n",
    "        # HEAD\n",
    "        m_head = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_head, Xcal, ycal, n_classes, mode='head',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                        patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_head = predict_numpy(m_head, Xho, device); acc_head = (yhat_head == yho).mean()\n",
    "\n",
    "        # SPATIAL+HEAD\n",
    "        m_sp = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_sp, Xcal, ycal, n_classes, mode='spatial+head',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, base_lr=FT_BASE_LR,\n",
    "                        l2sp_lambda=FT_L2SP, patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_sp = predict_numpy(m_sp, Xho, device); acc_sp = (yhat_sp == yho).mean()\n",
    "\n",
    "        best_idx = int(np.argmax([acc_out, acc_head, acc_sp]))\n",
    "        yhat_best = [yhat_out, yhat_head, yhat_sp][best_idx]\n",
    "\n",
    "        y_true_full[te_idx] = yho; y_pred_full[te_idx] = yhat_best\n",
    "\n",
    "    return y_true_full, y_pred_full\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL por FOLD (con train/val/test desde Kfold5.json)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    # sujetos del fold (solo usamos listas train/test del JSON)\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # split de validaciÃ³n por sujetos desde train (estratificado por etiqueta dominante como en tu CNN+TF)\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects   = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # cargar datos (SIN balanceo: todos los ensayos)\n",
    "    X_tr_list, y_tr_list = [], []\n",
    "    X_val_list, y_val_list = [], []\n",
    "    X_te_list, y_te_list = [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    X_te  = np.concatenate(X_te_list,  axis=0); y_te  = np.concatenate(y_te_list,  axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # estandarizaciÃ³n por canal con stats de TRAIN\n",
    "    X_tr_std, X_val_std = standardize_per_channel_trainfit(X_tr, X_val)\n",
    "    _,        X_te_std  = standardize_per_channel_trainfit(X_tr, X_te)\n",
    "\n",
    "    # datasets â†’ tensores de entrada (B,1,T,C) para EEGNet\n",
    "    def to_tensor_1tC(X_TxC, y_idx):\n",
    "        xb = torch.tensor(X_TxC, dtype=torch.float32).unsqueeze(1)  # (B,1,T,C)\n",
    "        yb = torch.tensor(y_idx, dtype=torch.long)\n",
    "        return TensorDataset(xb, yb)\n",
    "\n",
    "    tr_ds  = to_tensor_1tC(X_tr_std, y_tr)\n",
    "    val_ds = to_tensor_1tC(X_val_std, y_val)\n",
    "    te_ds  = to_tensor_1tC(X_te_std,  y_te)\n",
    "\n",
    "    tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # modelo + opt + scheduler\n",
    "    n_classes = 4\n",
    "    model = EEGNet(n_ch=8, n_classes=n_classes,\n",
    "                   F1=24, D=2, kernel_t=64, k_sep=16,\n",
    "                   pool1_t=4, pool2_t=6, drop1_p=0.35, drop2_p=0.6,\n",
    "                   chdrop_p=0.10).to(device)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=LR_INIT)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=SGDR_T0, T_mult=SGDR_Tmult)\n",
    "\n",
    "    # criterio suave ponderado (+20% Both Fists) con label smoothing\n",
    "    class_weights = make_class_weight_tensor(y_tr, n_classes, boost_bfists=1.25, boost_bfeet=1.05, device=device)\n",
    "    criterion_soft = WeightedSoftCrossEntropy(class_weights, label_smoothing=0.05)\n",
    "\n",
    "    # mÃ©tricas rÃ¡pidas\n",
    "    @torch.no_grad()\n",
    "    def eval_acc(loader):\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            # TTA en validaciÃ³n? Normalmente NO (dejamos off)\n",
    "            logits = model(xb)\n",
    "            pred = logits.argmax(dim=1).cpu().numpy()\n",
    "            y_true.append(yb.numpy()); y_pred.append(pred)\n",
    "        y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "        return (y_true == y_pred).mean()\n",
    "\n",
    "    # entrenamiento global (con augments estilo CNN+TF)\n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "    best_state = copy.deepcopy(model.state_dict()); best_val = -1.0; bad = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS_GLOBAL + 1):\n",
    "        model.train()\n",
    "        correct, seen = 0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            # AUGMENTS (mismas ideas que CNN+TF)\n",
    "            xb = augment_batch_eegnet(xb,\n",
    "                                      p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "                                      max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1)\n",
    "            # loss suave (one-hot)\n",
    "            yt = torch.nn.functional.one_hot(yb, num_classes=n_classes).float()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion_soft(logits, yt)\n",
    "            loss.backward(); opt.step()\n",
    "            apply_max_norm(model, max_value=2.0, p=2.0)\n",
    "            correct += (logits.argmax(1) == yb).sum().item()\n",
    "            seen += yb.size(0)\n",
    "        scheduler.step(epoch - 1 + 1e-8)\n",
    "\n",
    "        tr_acc = correct / max(1, seen)\n",
    "        va_acc = eval_acc(val_ld)\n",
    "        history['train_acc'].append(tr_acc)\n",
    "        history['val_acc'].append(va_acc)\n",
    "\n",
    "        if (epoch % LOG_EVERY == 0) or epoch in (1, 10, 20, 50, 100):\n",
    "            cur_lr = opt.param_groups[0]['lr']\n",
    "            print(f\"  Ã‰poca {epoch:3d} | train_acc={tr_acc:.4f} | val_acc={va_acc:.4f} | LR={cur_lr:.5f}\")\n",
    "\n",
    "        if va_acc > best_val + 1e-4:\n",
    "            best_val = va_acc; best_state = copy.deepcopy(model.state_dict()); bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= GLOBAL_PATIENCE:\n",
    "                print(f\"  Early stopping en Ã©poca {epoch} (mejor val_acc={best_val:.4f})\")\n",
    "                break\n",
    "\n",
    "    # guardar curva\n",
    "    curve_path = f\"training_curve_fold{fold}.png\"\n",
    "    plot_training_curves(history, curve_path)\n",
    "    print(f\"â†³ Curva de entrenamiento guardada: {curve_path}\")\n",
    "\n",
    "    # cargar mejor estado\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    # ===== EVALUACIÃ“N EN TEST (TTA estilo CNN+TF) =====\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "                pred = logits.argmax(1).cpu().numpy()\n",
    "                y_true.append(yb.numpy()); y_pred.append(pred)\n",
    "        y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "    elif SW_MODE in ('tta', 'subwin'):\n",
    "        sfreq_used = int(round(X_te_std.shape[1] / (TMAX - TMIN)))  # T = X_te_std.shape[1]\n",
    "        logits_tta = None; logits_sw = None\n",
    "        if SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits_eegnet(model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        else:\n",
    "            # subwindow opcional; si quisieras activarlo, implementa anÃ¡logo a tu CNN+TF\n",
    "            raise NotImplementedError(\"SW_MODE='subwin' no implementado aquÃ­ (se pidiÃ³ TTA).\")\n",
    "        logits = logits_tta\n",
    "        y_pred = logits.argmax(axis=1); y_true = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc_global = accuracy_score(y_true, y_pred)\n",
    "    f1m_global = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc_global:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASS_NAMES_4C, digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2,3]))\n",
    "\n",
    "    # ---------- Fine-tuning PROGRESIVO por sujeto (igual que antes) ----------\n",
    "    # agrupamos por sujeto en el TEST\n",
    "    # reconstruimos arrays por sujeto usando las mismas X_te_std/y_te\n",
    "    # Primero necesitamos el vector de sujetos por ensayo:\n",
    "    sub_te = []\n",
    "    for sid in test_sub:\n",
    "        Xs, ys, _ = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        sub_te += [subject_id_to_int(sid)] * len(ys)\n",
    "    sub_te = np.array(sub_te, dtype=int)\n",
    "\n",
    "    y_true_ft_all, y_pred_ft_all = [], []\n",
    "    used_subjects = 0\n",
    "    for sid in np.unique(sub_te):\n",
    "        idx = np.where(sub_te == sid)[0]\n",
    "        Xs_TxC = X_te_std[idx]\n",
    "        ys_sub = y_te[idx]\n",
    "        if len(ys_sub) < CALIB_CV_FOLDS or len(np.unique(ys_sub)) < 2:\n",
    "            continue\n",
    "        y_true_subj, y_pred_subj = subject_cv_finetune_predict_progressive(\n",
    "            model, Xs_TxC, ys_sub, DEVICE, n_splits=CALIB_CV_FOLDS, n_classes=4\n",
    "        )\n",
    "        y_true_ft_all.append(y_true_subj); y_pred_ft_all.append(y_pred_subj)\n",
    "        used_subjects += 1\n",
    "\n",
    "    if len(y_true_ft_all) > 0:\n",
    "        y_true_ft_all = np.concatenate(y_true_ft_all)\n",
    "        y_pred_ft_all = np.concatenate(y_pred_ft_all)\n",
    "        acc_ft = (y_true_ft_all == y_pred_ft_all).mean()\n",
    "        print(f\"  Fine-tuning PROGRESIVO (por sujeto, {CALIB_CV_FOLDS}-fold CV) acc={acc_ft:.4f} | sujetos={used_subjects}\")\n",
    "        print(f\"  Î”(FT-Global) = {acc_ft - acc_global:+.4f}\")\n",
    "    else:\n",
    "        acc_ft = np.nan\n",
    "        print(\"  Fine-tuning PROGRESIVO no ejecutado (sujeto(s) con muestras insuficientes).\")\n",
    "\n",
    "    # matriz de confusiÃ³n global (sin FT)\n",
    "    cm_png = f\"confusion_global_fold{fold}.png\"\n",
    "    plot_confusion(y_true, y_pred, CLASS_NAMES_4C, title=f\"Confusion Matrix - Fold {fold}\", fname=cm_png)\n",
    "    print(f\"â†³ Matriz de confusiÃ³n guardada: {cm_png}\")\n",
    "\n",
    "    return acc_global, f1m_global, acc_ft\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ§  INICIANDO EXPERIMENTO CON EEGNet + Augments/TTA estilo CNN+TF (sin balanceo)\")\n",
    "    print(f\"ðŸ”§ ConfiguraciÃ³n: 4c, 8 canales, 6s | EPOCHS_GLOBAL={EPOCHS_GLOBAL}, BATCH={BATCH_SIZE}, LR={LR_INIT} | ZSCORE_PER_EPOCH={NORM_EPOCH_ZSCORE}\")\n",
    "    acc_folds, f1_folds = [], []\n",
    "    ft_folds = []\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m, acc_ft = train_one_fold(fold, DEVICE)  # <-- recibe acc_ft\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "        # Permite NaN si algÃºn sujeto no tuvo muestras suficientes para FT\n",
    "        ft_folds.append(\"nan\" if (acc_ft is None or (isinstance(acc_ft, float) and np.isnan(acc_ft))) else f\"{acc_ft:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "    # Media de FT ignorando 'nan'\n",
    "    ft_vals = [float(x) for x in ft_folds if x != \"nan\"]\n",
    "    ft_mean = float(np.mean(ft_vals)) if len(ft_vals) > 0 else float(\"nan\")\n",
    "    delta_mean = (ft_mean - acc_mean) if len(ft_vals) > 0 else float(\"nan\")\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n",
    "    # ---- NUEVO BLOQUE RESUMEN FT ----\n",
    "    print(f\"Fine-tune PROGRESIVO folds: {ft_folds}\")\n",
    "    if len(ft_vals) > 0:\n",
    "        print(f\"Fine-tune PROGRESIVO mean: {ft_mean:.4f}\")\n",
    "        print(f\"Î”(FT-Global) mean: {delta_mean:+.4f}\")\n",
    "    else:\n",
    "        print(\"Fine-tune PROGRESIVO mean: nan\")\n",
    "        print(\"Î”(FT-Global) mean: nan\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
