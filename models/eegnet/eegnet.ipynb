{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64483706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Usando dispositivo: cuda\n",
      "üß† INICIANDO EXPERIMENTO CON EEGNet + FINE-TUNING PROGRESIVO (augments + SGDR + tweaks)\n",
      "üîß Configuraci√≥n: 4c, 8 canales, 6s\n",
      "‚öôÔ∏è  FT: epochs=30, base_lr=5e-05, head_lr=0.001, L2SP=0.0001, patience=5, CV=4\n",
      "Sujetos elegibles: 103 ‚Üí [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo dataset (RAW): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:41<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset construido: N=8652 | T=960 | C=8 | clases=4 | sujetos √∫nicos=103\n",
      "Listo para entrenar: N=8652 | T=960 | C=8 | clases=4 | sujetos=103\n",
      "\n",
      "[Fold 1/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n",
      "  √âpoca   1 | train_acc=0.4605 | val_acc=0.4304 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.5138 | val_acc=0.4643 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.5226 | val_acc=0.4744 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.5514 | val_acc=0.4872 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.5371 | val_acc=0.4698 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.5229 | val_acc=0.4799 | LR=0.00854\n",
      "  Early stopping en √©poca 26 (mejor val_acc=0.4881)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5516    0.4603    0.5019       441\n",
      "       Right     0.5642    0.4785    0.5178       441\n",
      "  Both Fists     0.3540    0.5057    0.4164       441\n",
      "   Both Feet     0.4337    0.3855    0.4082       441\n",
      "\n",
      "    accuracy                         0.4575      1764\n",
      "   macro avg     0.4759    0.4575    0.4611      1764\n",
      "weighted avg     0.4759    0.4575    0.4611      1764\n",
      "\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5130 | sujetos=21\n",
      "  Œî(FT-Global) = +0.0556\n",
      "\n",
      "[Fold 2/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n",
      "  √âpoca   1 | train_acc=0.4155 | val_acc=0.4029 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.4707 | val_acc=0.4359 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.5117 | val_acc=0.4560 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.5133 | val_acc=0.4588 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.5312 | val_acc=0.4734 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.5345 | val_acc=0.4762 | LR=0.00854\n",
      "  √âpoca  30 | train_acc=0.5561 | val_acc=0.4808 | LR=0.00565\n",
      "  √âpoca  35 | train_acc=0.5866 | val_acc=0.4881 | LR=0.00250\n",
      "  √âpoca  40 | train_acc=0.5714 | val_acc=0.4597 | LR=0.00038\n",
      "  Early stopping en √©poca 43 (mejor val_acc=0.4908)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6128    0.6281    0.6204       441\n",
      "       Right     0.5934    0.5692    0.5810       441\n",
      "  Both Fists     0.4307    0.5215    0.4718       441\n",
      "   Both Feet     0.5239    0.4218    0.4673       441\n",
      "\n",
      "    accuracy                         0.5351      1764\n",
      "   macro avg     0.5402    0.5351    0.5351      1764\n",
      "weighted avg     0.5402    0.5351    0.5351      1764\n",
      "\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.6173 | sujetos=21\n",
      "  Œî(FT-Global) = +0.0822\n",
      "\n",
      "[Fold 3/5] Entrenando modelo global... (n_train=5796 | n_val=1092 | n_test=1764)\n",
      "  √âpoca   1 | train_acc=0.4432 | val_acc=0.4332 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.5350 | val_acc=0.5165 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.5147 | val_acc=0.5375 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.5336 | val_acc=0.5385 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.5450 | val_acc=0.5375 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.5212 | val_acc=0.5128 | LR=0.00854\n",
      "  Early stopping en √©poca 29 (mejor val_acc=0.5421)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5245    0.5102    0.5172       441\n",
      "       Right     0.5631    0.5261    0.5440       441\n",
      "  Both Fists     0.3818    0.4762    0.4238       441\n",
      "   Both Feet     0.4397    0.3719    0.4029       441\n",
      "\n",
      "    accuracy                         0.4711      1764\n",
      "   macro avg     0.4773    0.4711    0.4720      1764\n",
      "weighted avg     0.4773    0.4711    0.4720      1764\n",
      "\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5323 | sujetos=21\n",
      "  Œî(FT-Global) = +0.0612\n",
      "\n",
      "[Fold 4/5] Entrenando modelo global... (n_train=5880 | n_val=1092 | n_test=1680)\n",
      "  √âpoca   1 | train_acc=0.4437 | val_acc=0.4313 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.5162 | val_acc=0.4853 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.5167 | val_acc=0.4789 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.5304 | val_acc=0.4991 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.5204 | val_acc=0.4927 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.5369 | val_acc=0.4863 | LR=0.00854\n",
      "  Early stopping en √©poca 26 (mejor val_acc=0.5192)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.5107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5940    0.5643    0.5788       420\n",
      "       Right     0.5891    0.4643    0.5193       420\n",
      "  Both Fists     0.4256    0.5786    0.4904       420\n",
      "   Both Feet     0.4828    0.4357    0.4581       420\n",
      "\n",
      "    accuracy                         0.5107      1680\n",
      "   macro avg     0.5229    0.5107    0.5116      1680\n",
      "weighted avg     0.5229    0.5107    0.5116      1680\n",
      "\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5774 | sujetos=20\n",
      "  Œî(FT-Global) = +0.0667\n",
      "\n",
      "[Fold 5/5] Entrenando modelo global... (n_train=5880 | n_val=1092 | n_test=1680)\n",
      "  √âpoca   1 | train_acc=0.4199 | val_acc=0.4167 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.4830 | val_acc=0.4643 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.5071 | val_acc=0.4588 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.5031 | val_acc=0.4835 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.5122 | val_acc=0.4643 | LR=0.00996\n",
      "  Early stopping en √©poca 24 (mejor val_acc=0.4954)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5190\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6141    0.5190    0.5626       420\n",
      "       Right     0.5718    0.4643    0.5125       420\n",
      "  Both Fists     0.4377    0.5524    0.4884       420\n",
      "   Both Feet     0.5000    0.5405    0.5195       420\n",
      "\n",
      "    accuracy                         0.5190      1680\n",
      "   macro avg     0.5309    0.5190    0.5207      1680\n",
      "weighted avg     0.5309    0.5190    0.5207      1680\n",
      "\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5863 | sujetos=20\n",
      "  Œî(FT-Global) = +0.0673\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds: ['0.4575', '0.5351', '0.4711', '0.5107', '0.5190']\n",
      "Global mean: 0.4987\n",
      "Fine-tune PROGRESIVO folds: ['0.5130', '0.6173', '0.5323', '0.5774', '0.5863']\n",
      "Fine-tune PROGRESIVO mean: 0.5653\n",
      "Œî(FT-Global) mean: +0.0666\n",
      "\n",
      "‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_allfolds.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# EEGNet + protocolo global + fine-tuning progresivo por sujeto (augments + SGDR + tweaks)\n",
    "# Cambios clave:\n",
    "# 1) Capacidad ‚Üë: F1=24, fc=128\n",
    "# 2) Loss ponderada por clase (+20% a Both Fists) con soporte para mixup (WeightedSoftCrossEntropy)\n",
    "# 3) Cutout focalizado (30‚Äì60 ms) solo para clases OF (2,3)\n",
    "# 4) SGDR con T0=6, Tmult=2\n",
    "# 5) TTA (n=5, jitter ¬±25 ms) en evaluaci√≥n\n",
    "\n",
    "import os, re, math, random, json, itertools, copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# CONFIGURACI√ìN GENERAL\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "CACHE_DIR = PROJ / 'data' / 'cache'\n",
    "FOLDS_DIR = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dispositivo y semilla\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# Escenario y ventana\n",
    "CLASS_SCENARIO = '4c'\n",
    "WINDOW_MODE = '6s'   # mantienes 6s\n",
    "FS = 160.0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Entrenamiento global\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_GLOBAL = 100\n",
    "LR_INIT = 1e-2\n",
    "SGDR_T0 = 6      # ‚Üì ciclos cortos al inicio\n",
    "SGDR_Tmult = 2\n",
    "\n",
    "# Validaci√≥n/ES global\n",
    "GLOBAL_VAL_SPLIT = 0.15\n",
    "GLOBAL_PATIENCE  = 10\n",
    "LOG_EVERY        = 5\n",
    "\n",
    "# Fine-tuning por sujeto (protocolo robusto)\n",
    "CALIB_CV_FOLDS = 4\n",
    "FT_EPOCHS = 30\n",
    "FT_BASE_LR = 5e-5\n",
    "FT_HEAD_LR = 1e-3\n",
    "FT_L2SP = 1e-4\n",
    "FT_PATIENCE = 5\n",
    "FT_VAL_RATIO = 0.2\n",
    "\n",
    "# Normalizaci√≥n por √©poca canal-a-canal (z-score)\n",
    "NORM_EPOCH_ZSCORE = True\n",
    "\n",
    "# Sujetos excluidos\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "# Runs\n",
    "MI_RUNS_LR = [4, 8, 12]\n",
    "MI_RUNS_OF = [6, 10, 14]\n",
    "BASELINE_RUNS_EO = [1]\n",
    "\n",
    "# Canales (8 con FCz)\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES DE CANALES\n",
    "# =========================\n",
    "def normalize_label(s: str) -> str:\n",
    "    if s is None: return s\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    s = re.sub(r'([A-Za-z])0([0-9])', r'\\1\\2', s)\n",
    "    s = re.sub(r'([A-Za-z])Z$', r'\\1z', s)\n",
    "    s = s.replace('fp', 'Fp').replace('FP', 'Fp')\n",
    "    s = ''.join(ch.upper() if ch != 'z' else 'z' for ch in s)\n",
    "    return s\n",
    "\n",
    "def rename_channels_1010(raw: mne.io.BaseRaw):\n",
    "    mapping = {}\n",
    "    for ch in raw.ch_names:\n",
    "        lab = normalize_label(ch)\n",
    "        lab = lab[:-1] + 'z' if lab.endswith('Z') else lab\n",
    "        lab = re.sub(r'([A-Z])Z$', r'\\1z', lab)\n",
    "        mapping[ch] = lab\n",
    "    mne.rename_channels(raw.info, mapping)\n",
    "\n",
    "def ensure_channels_order(raw: mne.io.BaseRaw, desired_channels=EXPECTED_8):\n",
    "    missing = [ch for ch in desired_channels if ch not in raw.ch_names]\n",
    "    if missing:\n",
    "        print(f\"Warning: faltan canales {missing} en archivo {getattr(raw,'filenames', [''])[0]}\")\n",
    "        return None\n",
    "    raw.reorder_channels([ch for ch in raw.ch_names if ch in desired_channels] +\n",
    "                         [ch for ch in raw.ch_names if ch not in desired_channels])\n",
    "    raw.pick_channels(desired_channels, ordered=True)\n",
    "    return raw\n",
    "\n",
    "# =========================\n",
    "# LECTURA DE EDF y EVENTOS\n",
    "# =========================\n",
    "_re_file = re.compile(r'[Ss](\\d{3}).*?[Rr](\\d{2})')\n",
    "\n",
    "def parse_subject_run(path: Path):\n",
    "    m = _re_file.search(str(path))\n",
    "    if not m: return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def run_kind(run_id:int):\n",
    "    if run_id in MI_RUNS_LR: return 'LR'\n",
    "    if run_id in MI_RUNS_OF: return 'OF'\n",
    "    if run_id in BASELINE_RUNS_EO: return 'EO'\n",
    "    return None\n",
    "\n",
    "# --- Notch adaptativo: lee CSV si existe (subject, run, snr50_db, snr60_db)\n",
    "_SNR_TABLE = None\n",
    "def _load_snr_table():\n",
    "    global _SNR_TABLE\n",
    "    if _SNR_TABLE is not None:\n",
    "        return _SNR_TABLE\n",
    "    csv_path = PROJ / 'reports' / 'psd_mains' / 'psd_mains_summary.csv'\n",
    "    if csv_path.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            _SNR_TABLE = df\n",
    "        except Exception as e:\n",
    "            print(f\"[SNR] No se pudo leer {csv_path}: {e}\")\n",
    "            _SNR_TABLE = None\n",
    "    return _SNR_TABLE\n",
    "\n",
    "def _decide_notch(subject, run, th_db=10.0):\n",
    "    df = _load_snr_table()\n",
    "    if df is None:  # default\n",
    "        return 60.0\n",
    "    row = df[(df['subject']==subject) & (df['run']==run)]\n",
    "    if row.empty:\n",
    "        return 60.0\n",
    "    snr50 = float(row['snr50_db'].iloc[0]); snr60 = float(row['snr60_db'].iloc[0])\n",
    "    if snr60 >= th_db and snr60 >= snr50: return 60.0\n",
    "    if snr50 >= th_db and snr50 >  snr60: return 50.0\n",
    "    return None  # no notch si no sobresale\n",
    "\n",
    "def read_raw_edf(path: Path):\n",
    "    raw = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw.pick(mne.pick_types(raw.info, eeg=True))\n",
    "    rename_channels_1010(raw)\n",
    "    try:\n",
    "        mont = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(mont, on_missing='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "        raw.resample(FS, npad=\"auto\")\n",
    "    raw = ensure_channels_order(raw, EXPECTED_8)\n",
    "    if raw is None:\n",
    "        return None\n",
    "\n",
    "    # Notch adaptativo (por SNR); si no hay CSV, por defecto 60 Hz\n",
    "    sid, rid = parse_subject_run(path)\n",
    "    notch = _decide_notch(sid, rid)\n",
    "    if notch is not None:\n",
    "        raw.notch_filter(freqs=[float(notch)], picks='eeg', method='spectrum_fit', phase='zero')\n",
    "\n",
    "    return raw\n",
    "\n",
    "def collect_events_T1T2(raw: mne.io.BaseRaw):\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return []\n",
    "    def _norm(s): return str(s).strip().upper().replace(' ', '')\n",
    "    res = []\n",
    "    for onset, desc in zip(raw.annotations.onset, raw.annotations.description):\n",
    "        tag = _norm(desc)\n",
    "        if tag in ('T1','T2'):\n",
    "            res.append((float(onset), tag))\n",
    "    res.sort()\n",
    "    dedup = []\n",
    "    last_t1 = last_t2 = -1e9\n",
    "    for t, tag in res:\n",
    "        if tag == 'T1':\n",
    "            if (t - last_t1) >= 0.5: dedup.append((t, tag)); last_t1 = t\n",
    "        else:\n",
    "            if (t - last_t2) >= 0.5: dedup.append((t, tag)); last_t2 = t\n",
    "    return dedup\n",
    "\n",
    "# =========================\n",
    "# CONSTRUCCI√ìN DE DATASETS\n",
    "# =========================\n",
    "def subjects_available():\n",
    "    subs = []\n",
    "    for sdir in sorted(DATA_RAW.glob('S*')):\n",
    "        if not sdir.is_dir(): continue\n",
    "        try: sid = int(sdir.name[1:])\n",
    "        except: continue\n",
    "        if sid in EXCLUDE_SUBJECTS: continue\n",
    "        any_mi = any((sdir / f\"S{sid:03d}R{r:02d}.edf\").exists() for r in (MI_RUNS_LR + MI_RUNS_OF))\n",
    "        if any_mi: subs.append(sid)\n",
    "    return subs\n",
    "\n",
    "def extract_trials_from_run(edf_path: Path, scenario: str, window_mode: str):\n",
    "    subj, run = parse_subject_run(edf_path)\n",
    "    kind = run_kind(run)\n",
    "    if kind not in ('LR','OF','EO'):\n",
    "        return ([], [])\n",
    "\n",
    "    raw = read_raw_edf(edf_path)\n",
    "    if raw is None:\n",
    "        return ([], [])\n",
    "\n",
    "    data = raw.get_data()\n",
    "    fs = raw.info['sfreq']\n",
    "    assert abs(fs - FS) < 1e-6\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if kind in ('LR','OF'):\n",
    "        events = collect_events_T1T2(raw)\n",
    "        if window_mode == '3s':\n",
    "            rel_start, rel_end = 0.0, 3.0\n",
    "        else:\n",
    "            rel_start, rel_end = -1.0, 5.0\n",
    "\n",
    "        for onset_sec, tag in events:\n",
    "            if kind == 'LR':\n",
    "                if tag == 'T1': label = 'L'\n",
    "                elif tag == 'T2': label = 'R'\n",
    "                else: continue\n",
    "            else:\n",
    "                if tag == 'T1': label = 'BFISTS'\n",
    "                elif tag == 'T2': label = 'BFEET'\n",
    "                else: continue\n",
    "\n",
    "            if scenario == '2c' and label not in ('L','R'): continue\n",
    "            if scenario == '3c' and label not in ('L','R','BFISTS'): continue\n",
    "            if scenario == '4c' and label not in ('L','R','BFISTS','BFEET'): continue\n",
    "\n",
    "            s = int(round((raw.first_time + onset_sec + rel_start) * fs))\n",
    "            e = int(round((raw.first_time + onset_sec + rel_end) * fs))\n",
    "            if s < 0 or e > data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            seg = data[:, s:e].T.astype(np.float32)\n",
    "            if NORM_EPOCH_ZSCORE:\n",
    "                seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
    "\n",
    "            if label == 'L':       y = 0\n",
    "            elif label == 'R':     y = 1\n",
    "            elif label == 'BFISTS':y = 2\n",
    "            elif label == 'BFEET': y = 3\n",
    "            else: continue\n",
    "\n",
    "            out.append((seg, y, subj))\n",
    "\n",
    "    elif kind == 'EO':\n",
    "        return ([], raw.ch_names)\n",
    "\n",
    "    return out, raw.ch_names\n",
    "\n",
    "def build_dataset_all(subjects, scenario='4c', window_mode='3s'):\n",
    "    X, y, groups = [], [], []\n",
    "    ch_template = None\n",
    "\n",
    "    for s in tqdm(subjects, desc=\"Construyendo dataset (RAW)\"):\n",
    "        sdir = DATA_RAW / f\"S{s:03d}\"\n",
    "        if not sdir.exists(): continue\n",
    "\n",
    "        trials_L, trials_R, trials_FISTS, trials_FEET = [], [], [], []\n",
    "\n",
    "        for r in MI_RUNS_LR:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 0: trials_L.append(seg)\n",
    "                elif lab == 1: trials_R.append(seg)\n",
    "\n",
    "        for r in MI_RUNS_OF:\n",
    "            p = sdir / f\"S{s:03d}R{r:02d}.edf\"\n",
    "            if not p.exists(): continue\n",
    "            outs, chs = extract_trials_from_run(p, scenario, window_mode)\n",
    "            if ch_template is None and chs: ch_template = chs\n",
    "            for seg, lab, _ in outs:\n",
    "                if lab == 2: trials_FISTS.append(seg)\n",
    "                elif lab == 3: trials_FEET.append(seg)\n",
    "\n",
    "        need_per_class = 21\n",
    "        def pick(trials, n, rng):\n",
    "            if len(trials) < n:\n",
    "                idx = rng.choice(len(trials), size=n, replace=True)\n",
    "                return [trials[i] for i in idx]\n",
    "            rng.shuffle(trials)\n",
    "            return trials[:n]\n",
    "\n",
    "        rng = check_random_state(RANDOM_STATE + s)\n",
    "        if len(trials_L)==0 or len(trials_R)==0 or len(trials_FISTS)==0 or len(trials_FEET)==0:\n",
    "            continue\n",
    "\n",
    "        Lp  = pick(trials_L,     need_per_class, rng)\n",
    "        Rp  = pick(trials_R,     need_per_class, rng)\n",
    "        FIp = pick(trials_FISTS, need_per_class, rng)\n",
    "        FEp = pick(trials_FEET,  need_per_class, rng)\n",
    "\n",
    "        pack = [(Lp, 0), (Rp, 1), (FIp, 2), (FEp, 3)]\n",
    "        for segs, lab in pack:\n",
    "            for seg in segs:\n",
    "                X.append(seg); y.append(lab); groups.append(s)\n",
    "\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    groups = np.asarray(groups, dtype=np.int64)\n",
    "\n",
    "    n, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Dataset construido: N={n} | T={T} | C={C} | clases={n_classes} | sujetos √∫nicos={len(np.unique(groups))}\")\n",
    "    return X, y, groups, ch_template\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS (solo train)\n",
    "# =========================\n",
    "def do_time_jitter(x, max_ms=50, fs=160.0):\n",
    "    # x: (B,1,T,C) torch.float\n",
    "    max_shift = int(round(max_ms/1000.0 * fs))\n",
    "    if max_shift <= 0: return x\n",
    "    B,_,T,C = x.shape\n",
    "    shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=x.device)\n",
    "    out = torch.empty_like(x)\n",
    "    for i,s in enumerate(shifts):\n",
    "        if s==0: out[i] = x[i]; continue\n",
    "        if s>0:\n",
    "            out[i,:,s:,:] = x[i,:,:T-s,:]\n",
    "            out[i,:,:s,:] = 0\n",
    "        else:\n",
    "            s = -s\n",
    "            out[i,:,:T-s,:] = x[i,:,s:,:]\n",
    "            out[i,:,T-s:,:] = 0\n",
    "    return out\n",
    "\n",
    "def do_gaussian_noise(x, sigma=0.01):\n",
    "    if sigma<=0: return x\n",
    "    return x + sigma*torch.randn_like(x)\n",
    "\n",
    "def do_temporal_cutout(x, min_ms=100, max_ms=150, fs=160.0):\n",
    "    B,_,T,C = x.shape\n",
    "    Lmin = int(round(min_ms/1000.0*fs))\n",
    "    Lmax = int(round(max_ms/1000.0*fs))\n",
    "    if Lmin<=0 or Lmax<=0 or Lmin>Lmax: return x\n",
    "    out = x.clone()\n",
    "    for i in range(B):\n",
    "        L = random.randint(Lmin, Lmax)\n",
    "        if L>=T: continue\n",
    "        s = random.randint(0, T-L)\n",
    "        out[i,:,s:s+L,:] = 0\n",
    "    return out\n",
    "\n",
    "def do_temporal_cutout_masked(x, y, classes_mask={2,3}, min_ms=30, max_ms=60, fs=160.0):\n",
    "    # Aplica cutout solo si y pertenece a classes_mask\n",
    "    B,_,T,C = x.shape\n",
    "    if B == 0: return x\n",
    "    Lmin = int(round(min_ms/1000.0*fs))\n",
    "    Lmax = int(round(max_ms/1000.0*fs))\n",
    "    if Lmin<=0 or Lmax<=0 or Lmin>Lmax: return x\n",
    "    out = x.clone()\n",
    "    y_np = y.detach().cpu().numpy()\n",
    "    for i in range(B):\n",
    "        if int(y_np[i]) not in classes_mask: \n",
    "            continue\n",
    "        L = random.randint(Lmin, Lmax)\n",
    "        if L>=T: continue\n",
    "        s = random.randint(0, T-L)\n",
    "        out[i,:,s:s+L,:] = 0\n",
    "    return out\n",
    "\n",
    "def mixup_batch(x, y, n_classes, alpha=0.2):\n",
    "    if alpha<=0:\n",
    "        y_onehot = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "        return x, y_onehot, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    perm = torch.randperm(x.size(0), device=x.device)\n",
    "    x_mix = lam*x + (1-lam)*x[perm]\n",
    "    y_a = torch.nn.functional.one_hot(y, num_classes=n_classes).float()\n",
    "    y_b = y_a[perm]\n",
    "    y_mix = lam*y_a + (1-lam)*y_b\n",
    "    return x_mix, y_mix, lam\n",
    "\n",
    "class WeightedSoftCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross-entropy suave (targets en probas, p.ej. mixup) con pesos por clase.\n",
    "    \"\"\"\n",
    "    def __init__(self, class_weights=None, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('w', None if class_weights is None else class_weights.clone().float())\n",
    "        self.ls = float(label_smoothing)\n",
    "\n",
    "    def forward(self, logits, target_probs):\n",
    "        # label smoothing: mezcla target_probs con uniforme\n",
    "        if self.ls > 0:\n",
    "            K = logits.size(1)\n",
    "            target_probs = (1-self.ls)*target_probs + self.ls*(1.0/K)\n",
    "        logp = torch.log_softmax(logits, dim=1)  # (B,C)\n",
    "        loss_per_class = -(target_probs * logp)  # (B,C)\n",
    "        if self.w is not None:\n",
    "            loss_per_class = loss_per_class * self.w.unsqueeze(0)  # pesar por clase\n",
    "        loss = loss_per_class.sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "# =========================\n",
    "# EEGNet (Lawhern et al., 2018) adaptado a (B,1,T,C) + ChannelDropout\n",
    "# =========================\n",
    "class ChannelDropout(nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p<=0: return x\n",
    "        B,_,T,C = x.shape\n",
    "        mask = (torch.rand(B,1,1,C, device=x.device) > self.p).float()\n",
    "        return x * mask\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Entrada: x de forma (B, 1, T, C)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch: int, n_classes: int,\n",
    "                 F1: int = 24, D: int = 2, kernel_t: int = 64, k_sep: int = 16,\n",
    "                 pool1_t: int = 4, pool2_t: int = 6,\n",
    "                 drop1_p: float = 0.35, drop2_p: float = 0.6,\n",
    "                 chdrop_p: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.n_classes = n_classes\n",
    "        self.F1 = F1\n",
    "        self.D = D\n",
    "        self.F2 = F1 * D\n",
    "        self.kernel_t = kernel_t\n",
    "        self.k_sep = k_sep\n",
    "        self.pool1_t = pool1_t\n",
    "        self.pool2_t = pool2_t\n",
    "\n",
    "        self.chdrop = ChannelDropout(p=chdrop_p)\n",
    "\n",
    "        # Bloque 1: temporal\n",
    "        self.conv_temporal = nn.Conv2d(1, F1, kernel_size=(kernel_t, 1),\n",
    "                                       padding=(kernel_t // 2, 0), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1, momentum=0.99, eps=1e-3)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "        # Bloque 2: depthwise (espacial)\n",
    "        self.conv_depthwise = nn.Conv2d(F1, self.F2, kernel_size=(1, n_ch),\n",
    "                                        groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F2, momentum=0.99, eps=1e-3)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(pool1_t, 1), stride=(pool1_t, 1))\n",
    "        self.drop1 = nn.Dropout(drop1_p)\n",
    "\n",
    "        # Bloque 3: separable temporal\n",
    "        self.conv_sep_depth = nn.Conv2d(self.F2, self.F2, kernel_size=(k_sep, 1),\n",
    "                                        groups=self.F2, padding=(k_sep // 2, 0), bias=False)\n",
    "        self.conv_sep_point = nn.Conv2d(self.F2, self.F2, kernel_size=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2, momentum=0.99, eps=1e-3)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(pool2_t, 1), stride=(pool2_t, 1))\n",
    "        self.drop2 = nn.Dropout(drop2_p)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Cabeza din√°mica\n",
    "        self.fc = None\n",
    "        self.out = None\n",
    "        self._T_in = None\n",
    "\n",
    "    def _build_head(self, T_in: int, device: torch.device):\n",
    "        T1 = T_in // self.pool1_t\n",
    "        T2 = T1 // self.pool2_t\n",
    "        feat_dim = self.F2 * T2 * 1\n",
    "        self.fc  = nn.Linear(feat_dim, 128, bias=True).to(device)\n",
    "        self.out = nn.Linear(128, self.n_classes, bias=True).to(device)\n",
    "        self._T_in = T_in\n",
    "\n",
    "    def ensure_head(self, T_in: int, device: torch.device):\n",
    "        if (self.fc is None) or (self.out is None) or (self._T_in != T_in):\n",
    "            self._build_head(T_in, device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, _, T, C = x.shape\n",
    "        self.ensure_head(T, x.device)\n",
    "\n",
    "        x = self.chdrop(x)  # ChannelDropout\n",
    "\n",
    "        z = self.conv_temporal(x)\n",
    "        z = self.bn1(z); z = self.act(z)\n",
    "\n",
    "        z = self.conv_depthwise(z)   # (B, F2, T, 1)\n",
    "        z = self.bn2(z); z = self.act(z)\n",
    "        z = self.pool1(z)\n",
    "        z = self.drop1(z)\n",
    "\n",
    "        z = self.conv_sep_depth(z)\n",
    "        z = self.conv_sep_point(z)\n",
    "        z = self.bn3(z); z = self.act(z)\n",
    "        z = self.pool2(z)\n",
    "        z = self.drop2(z)\n",
    "\n",
    "        z = self.flatten(z)\n",
    "        z = self.fc(z); z = self.act(z)\n",
    "        z = self.out(z)\n",
    "        return z\n",
    "\n",
    "# =========================\n",
    "# TORCH DATASET\n",
    "# =========================\n",
    "class EEGTrials(Dataset):\n",
    "    def __init__(self, X, y, groups):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.g = groups.astype(np.int64)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        x = np.expand_dims(x, 0)                 # (1, T, C)\n",
    "        return torch.from_numpy(x), torch.tensor(self.y[idx]), torch.tensor(self.g[idx])\n",
    "\n",
    "CLASS_NAMES_4C = ['Left', 'Right', 'Both Fists', 'Both Feet']\n",
    "\n",
    "# =========================\n",
    "# UTIL: MAX-NORM\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def apply_max_norm(model, max_value=2.0, p=2.0):\n",
    "    layers = []\n",
    "    if hasattr(model, 'conv_depthwise'): layers.append(model.conv_depthwise)\n",
    "    if hasattr(model, 'conv_sep_point'): layers.append(model.conv_sep_point)\n",
    "    if hasattr(model, 'fc'):             layers.append(model.fc)\n",
    "    if hasattr(model, 'out'):            layers.append(model.out)\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            w = layer.weight.data\n",
    "            norms = w.view(w.size(0), -1).norm(p=p, dim=1, keepdim=True)\n",
    "            desired = torch.clamp(norms, max=max_value)\n",
    "            w.view(w.size(0), -1).mul_(desired / (1e-8 + norms))\n",
    "\n",
    "# =========================\n",
    "# ENTRENAMIENTO / EVALUACI√ìN\n",
    "# =========================\n",
    "def build_weighted_sampler(y, groups):\n",
    "    # pesos inversos por clase y por sujeto ‚Üí promueve balance en cada batch\n",
    "    y = np.asarray(y); groups = np.asarray(groups)\n",
    "    class_counts = np.bincount(y, minlength=len(np.unique(y))).astype(float)\n",
    "    class_w = 1.0 / class_counts[y]\n",
    "    subj_vals, subj_counts = np.unique(groups, return_counts=True)\n",
    "    subj_map = {s:c for s,c in zip(subj_vals, subj_counts)}\n",
    "    subj_w = np.array([1.0/subj_map[g] for g in groups], dtype=float)\n",
    "    w = class_w * subj_w\n",
    "    w = w / w.mean()\n",
    "    w_t = torch.from_numpy(w).float()\n",
    "    sampler = WeightedRandomSampler(weights=w_t, num_samples=len(w_t), replacement=True)\n",
    "    return sampler\n",
    "\n",
    "def make_class_weight_tensor(y_indices, n_classes, boost_bfists=1.20):\n",
    "    # pesos inversos por clase, normalizados; clase 2 (*Both Fists*) con boost\n",
    "    counts = np.bincount(y_indices, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    w = counts.sum() / counts\n",
    "    w = w / w.mean()\n",
    "    w[2] *= boost_bfists\n",
    "    w = w / w.mean()\n",
    "    return torch.tensor(w, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def train_epoch(model, loader, opt, criterion_soft, n_classes,\n",
    "                do_aug=True, fs=160.0, maxnorm=None):\n",
    "    model.train()\n",
    "    for xb, yb, _ in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "        # ---- AUGMENTS (orden: jitter ‚Üí noise ‚Üí cutout focalizado ‚Üí mixup) ----\n",
    "        if do_aug:\n",
    "            xb = do_time_jitter(xb, max_ms=50, fs=fs)\n",
    "            xb = do_gaussian_noise(xb, sigma=0.01)\n",
    "            xb = do_temporal_cutout_masked(xb, yb, classes_mask={2,3}, min_ms=30, max_ms=60, fs=fs)\n",
    "            xb, yt, _ = mixup_batch(xb, yb, n_classes=n_classes, alpha=0.2)\n",
    "            logits = model(xb)\n",
    "            loss = criterion_soft(logits, yt)\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "            # yb como √≠ndices ‚Üí convertir a one-hot para criterio suave\n",
    "            yt = torch.nn.functional.one_hot(yb, num_classes=n_classes).float()\n",
    "            loss = criterion_soft(logits, yt)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if maxnorm is not None:\n",
    "            apply_max_norm(model, max_value=maxnorm, p=2.0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _predict_tta(model, xb, n=5, fs=160.0):\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        xj = do_time_jitter(xb, max_ms=25, fs=fs)\n",
    "        outs.append(model(xj))\n",
    "    return torch.stack(outs, dim=0).mean(dim=0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_with_preds(model, loader, use_tta=True, tta_n=5):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for xb, yb, _ in loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        if use_tta:\n",
    "            logits = _predict_tta(model, xb, n=tta_n, fs=FS)\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "        pred = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(yb.numpy().tolist())\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    y_pred = np.asarray(y_pred, dtype=int)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    return y_true, y_pred, float(acc)\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm_norm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150, bbox_inches='tight'); plt.close()\n",
    "\n",
    "def plot_training_curves(history, fname):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history['train_acc'], label='train_acc')\n",
    "    plt.plot(history['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Training curve'); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "def print_report(y_true, y_pred, classes):\n",
    "    print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n",
    "\n",
    "# =========================\n",
    "# FINE-TUNING PROGRESIVO por sujeto (con validaci√≥n interna)\n",
    "# =========================\n",
    "def _param_groups(model, mode):\n",
    "    if mode == 'out':\n",
    "        train = list(model.out.parameters())\n",
    "    elif mode == 'head':\n",
    "        train = list(model.fc.parameters()) + list(model.out.parameters())\n",
    "    elif mode == 'spatial+head':\n",
    "        train = (list(model.conv_depthwise.parameters()) +\n",
    "                 list(model.bn2.parameters()) +\n",
    "                 list(model.conv_sep_depth.parameters()) +\n",
    "                 list(model.conv_sep_point.parameters()) +\n",
    "                 list(model.bn3.parameters()) +\n",
    "                 list(model.fc.parameters()) +\n",
    "                 list(model.out.parameters()))\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "    return train\n",
    "\n",
    "def _freeze_for_mode(model, mode):\n",
    "    for p in model.parameters(): p.requires_grad = False\n",
    "    if mode == 'out':\n",
    "        for p in model.out.parameters(): p.requires_grad = True\n",
    "    elif mode == 'head':\n",
    "        for p in model.fc.parameters():  p.requires_grad = True\n",
    "        for p in model.out.parameters(): p.requires_grad = True\n",
    "    elif mode == 'spatial+head':\n",
    "        for p in model.conv_depthwise.parameters(): p.requires_grad = True\n",
    "        for p in model.bn2.parameters():           p.requires_grad = True\n",
    "        for p in model.conv_sep_depth.parameters():p.requires_grad = True\n",
    "        for p in model.conv_sep_point.parameters():p.requires_grad = True\n",
    "        for p in model.bn3.parameters():           p.requires_grad = True\n",
    "        for p in model.fc.parameters():            p.requires_grad = True\n",
    "        for p in model.out.parameters():           p.requires_grad = True\n",
    "\n",
    "def _class_weights(y_np, n_classes):\n",
    "    counts = np.bincount(y_np, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    weights = counts.sum() / counts\n",
    "    weights = weights / weights.mean()\n",
    "    return torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def _train_one_mode(model, X_cal, y_cal, n_classes, mode,\n",
    "                    epochs=FT_EPOCHS, batch_size=32,\n",
    "                    head_lr=FT_HEAD_LR, base_lr=FT_BASE_LR,\n",
    "                    l2sp_lambda=FT_L2SP, patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=RANDOM_STATE)\n",
    "    (tr_idx, va_idx), = sss.split(X_cal, y_cal)\n",
    "    Xtr, ytr = X_cal[tr_idx], y_cal[tr_idx]\n",
    "    Xva, yva = X_cal[va_idx], y_cal[va_idx]\n",
    "\n",
    "    ds_tr = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(Xtr).float().unsqueeze(1),\n",
    "        torch.from_numpy(ytr).long()\n",
    "    )\n",
    "    ds_va = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(Xva).float().unsqueeze(1),\n",
    "        torch.from_numpy(yva).long()\n",
    "    )\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    _freeze_for_mode(model, mode)\n",
    "\n",
    "    if mode == 'spatial+head':\n",
    "        base_params = (list(model.conv_depthwise.parameters()) +\n",
    "                       list(model.bn2.parameters()) +\n",
    "                       list(model.conv_sep_depth.parameters()) +\n",
    "                       list(model.conv_sep_point.parameters()) +\n",
    "                       list(model.bn3.parameters()))\n",
    "        head_params = list(model.fc.parameters()) + list(model.out.parameters())\n",
    "        train_params = base_params + head_params\n",
    "        opt = optim.Adam([\n",
    "            {\"params\": base_params, \"lr\": base_lr},\n",
    "            {\"params\": head_params, \"lr\": head_lr},\n",
    "        ])\n",
    "    else:\n",
    "        train_params = _param_groups(model, mode)\n",
    "        opt = optim.Adam(train_params, lr=head_lr)\n",
    "\n",
    "    ref = [p.detach().clone().to(p.device) for p in train_params]\n",
    "    class_w = _class_weights(ytr, n_classes)\n",
    "    crit = nn.CrossEntropyLoss(weight=class_w)\n",
    "\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    best_val = float('inf'); bad = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in dl_tr:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            reg = 0.0\n",
    "            for p_cur, p_ref in zip(train_params, ref):\n",
    "                reg = reg + torch.sum((p_cur - p_ref)**2)\n",
    "            loss = loss + l2sp_lambda * reg\n",
    "            loss.backward(); opt.step()\n",
    "            apply_max_norm(model, max_value=2.0, p=2.0)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0; nval = 0\n",
    "            for xb, yb in dl_va:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                logits = model(xb)\n",
    "                loss = crit(logits, yb)\n",
    "                val_loss += loss.item() * xb.size(0); nval += xb.size(0)\n",
    "            val_loss /= max(1, nval)\n",
    "\n",
    "        if val_loss + 1e-7 < best_val:\n",
    "            best_val = val_loss; bad = 0\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience: break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_numpy(model, X_np, device):\n",
    "    model.eval()\n",
    "    xb = torch.from_numpy(X_np).float().unsqueeze(1).to(device)\n",
    "    logits = model(xb)\n",
    "    return logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "def subject_cv_finetune_predict_progressive(model_global, Xs, ys, device,\n",
    "                                            n_splits=CALIB_CV_FOLDS, n_classes=4):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    y_true_full = np.empty_like(ys); y_pred_full = np.empty_like(ys)\n",
    "\n",
    "    for tr_idx, te_idx in skf.split(Xs, ys):\n",
    "        Xcal, ycal = Xs[tr_idx], ys[tr_idx]\n",
    "        Xho,  yho  = Xs[te_idx], ys[te_idx]\n",
    "\n",
    "        m_out = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_out, Xcal, ycal, n_classes, mode='out',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                        patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_out = predict_numpy(m_out, Xho, device); acc_out = (yhat_out == yho).mean()\n",
    "\n",
    "        m_head = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_head, Xcal, ycal, n_classes, mode='head',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                        patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_head = predict_numpy(m_head, Xho, device); acc_head = (yhat_head == yho).mean()\n",
    "\n",
    "        m_sp = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_sp, Xcal, ycal, n_classes, mode='spatial+head',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, base_lr=FT_BASE_LR,\n",
    "                        l2sp_lambda=FT_L2SP, patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_sp = predict_numpy(m_sp, Xho, device); acc_sp = (yhat_sp == yho).mean()\n",
    "\n",
    "        best_idx = np.argmax([acc_out, acc_head, acc_sp])\n",
    "        yhat_best = [yhat_out, yhat_head, yhat_sp][best_idx]\n",
    "\n",
    "        y_true_full[te_idx] = yho; y_pred_full[te_idx] = yhat_best\n",
    "\n",
    "    return y_true_full, y_pred_full\n",
    "\n",
    "# =========================\n",
    "# FOLDS JSON helpers\n",
    "# =========================\n",
    "def save_group_folds_json_with_indices(subject_ids_str, groups_array, n_splits, out_json_path,\n",
    "                                       created_by=\"dose_experiment\", description=None):\n",
    "    out_json_path = Path(out_json_path)\n",
    "    unique_subjects_int = sorted(np.unique(groups_array).tolist())\n",
    "    subject_ids = [f\"S{sid:03d}\" for sid in unique_subjects_int]\n",
    "\n",
    "    if len(subject_ids) < n_splits:\n",
    "        raise ValueError(f\"n_splits={n_splits} mayor que n√∫mero de sujetos={len(subject_ids)}\")\n",
    "\n",
    "    groups = np.arange(len(subject_ids))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    folds = []\n",
    "    fold_i = 0\n",
    "    for train_idx_grp, test_idx_grp in gkf.split(groups, groups, groups):\n",
    "        fold_i += 1\n",
    "        train_sids = [subject_ids[int(i)] for i in train_idx_grp]\n",
    "        test_sids  = [subject_ids[int(i)] for i in test_idx_grp]\n",
    "\n",
    "        train_sids_int = [int(s[1:]) for s in train_sids]\n",
    "        test_sids_int  = [int(s[1:]) for s in test_sids]\n",
    "\n",
    "        tr_idx = np.where(np.isin(groups_array, train_sids_int))[0].tolist()\n",
    "        te_idx = np.where(np.isin(groups_array, test_sids_int))[0].tolist()\n",
    "\n",
    "        folds.append({\n",
    "            \"fold\": int(fold_i),\n",
    "            \"train\": train_sids,\n",
    "            \"test\": test_sids,\n",
    "            \"tr_idx\": tr_idx,\n",
    "            \"te_idx\": te_idx\n",
    "        })\n",
    "\n",
    "    payload = {\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"created_by\": created_by,\n",
    "        \"description\": description if description is not None else \"\",\n",
    "        \"n_splits\": int(n_splits),\n",
    "        \"n_subjects\": len(subject_ids),\n",
    "        \"subject_ids\": subject_ids,\n",
    "        \"folds\": folds\n",
    "    }\n",
    "\n",
    "    out_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Folds JSON con √≠ndices guardado ‚Üí {out_json_path}\")\n",
    "    return out_json_path\n",
    "\n",
    "def load_group_folds_json(path_json, expected_subject_ids=None, strict_check=True):\n",
    "    path_json = Path(path_json)\n",
    "    if not path_json.exists():\n",
    "        raise FileNotFoundError(f\"No existe {path_json}\")\n",
    "    with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "\n",
    "    subj_json = payload.get(\"subject_ids\", [])\n",
    "    if expected_subject_ids is not None:\n",
    "        expected = sorted(list(expected_subject_ids))\n",
    "        if subj_json != expected:\n",
    "            msg = (\"Los subject_ids del JSON no coinciden con expected_subject_ids.\\n\"\n",
    "                   f\"JSON has {len(subj_json)} subjects, expected {len(expected)}.\\n\"\n",
    "                   f\"First 10 JSON: {subj_json[:10]}\\nFirst 10 expected: {expected[:10]}\")\n",
    "            if strict_check:\n",
    "                raise ValueError(msg)\n",
    "            else:\n",
    "                print(\"WARNING: \" + msg)\n",
    "    return payload\n",
    "\n",
    "# =========================\n",
    "# EXPERIMENTO\n",
    "# =========================\n",
    "def run_experiment(save_folds_json=True, folds_json_path=FOLDS_DIR, folds_json_description=\"GroupKFold folds for comparison\"):\n",
    "    mne.set_log_level('WARNING')\n",
    "\n",
    "    subs = subjects_available()\n",
    "    print(f\"Sujetos elegibles: {len(subs)} ‚Üí {subs[:10]}{'...' if len(subs)>10 else ''}\")\n",
    "\n",
    "    X, y, groups, chs = build_dataset_all(subs, scenario=CLASS_SCENARIO, window_mode=WINDOW_MODE)\n",
    "    N, T, C = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "    print(f\"Listo para entrenar: N={N} | T={T} | C={C} | clases={n_classes} | sujetos={len(np.unique(groups))}\")\n",
    "\n",
    "    ds = EEGTrials(X, y, groups)\n",
    "\n",
    "    # preparar JSON folds\n",
    "    if folds_json_path is None:\n",
    "        folds_json_path = Path(\"folds\") / f\"group_folds_{N_FOLDS}splits.json\"\n",
    "    else:\n",
    "        folds_json_path = Path(folds_json_path)\n",
    "    folds_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    unique_subs = sorted(np.unique(groups).tolist())\n",
    "    subject_ids_str = [f\"S{s:03d}\" for s in unique_subs]\n",
    "\n",
    "    if not folds_json_path.exists():\n",
    "        if not save_folds_json:\n",
    "            raise FileNotFoundError(f\"Folds JSON no encontrado en {folds_json_path} y save_folds_json=False.\")\n",
    "        save_group_folds_json_with_indices(subject_ids_str, groups, n_splits=N_FOLDS,\n",
    "                                           out_json_path=folds_json_path,\n",
    "                                           created_by=\"Joel_Clasificador\",\n",
    "                                           description=folds_json_description)\n",
    "\n",
    "    payload = load_group_folds_json(folds_json_path, expected_subject_ids=subject_ids_str, strict_check=False)\n",
    "    folds = payload[\"folds\"]\n",
    "\n",
    "    # bucle por folds\n",
    "    global_folds = []\n",
    "    ft_prog_folds = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    for f in folds:\n",
    "        fold = f[\"fold\"]\n",
    "        tr_idx = np.asarray(f.get(\"tr_idx\", []), dtype=int)\n",
    "        te_idx = np.asarray(f.get(\"te_idx\", []), dtype=int)\n",
    "\n",
    "        if tr_idx.size == 0 or te_idx.size == 0:\n",
    "            print(f\"Advertencia: fold {fold} sin √≠ndices tr/te v√°lidos. Saltando.\")\n",
    "            continue\n",
    "\n",
    "        # ===== Split de validaci√≥n por sujetos =====\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=GLOBAL_VAL_SPLIT, random_state=RANDOM_STATE)\n",
    "        tr_subj_idx, va_subj_idx = next(gss.split(tr_idx, groups[tr_idx], groups[tr_idx]))\n",
    "        tr_sub_idx = tr_idx[tr_subj_idx]\n",
    "        va_idx     = tr_idx[va_subj_idx]\n",
    "\n",
    "        # Sampler balanceado para train\n",
    "        sampler = build_weighted_sampler(y[tr_sub_idx], groups[tr_sub_idx])\n",
    "\n",
    "        tr_loader = DataLoader(Subset(ds, tr_sub_idx), batch_size=BATCH_SIZE, sampler=sampler, drop_last=False)\n",
    "        va_loader = DataLoader(Subset(ds, va_idx),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        te_loader = DataLoader(Subset(ds, te_idx),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "        # ===== EEGNet =====\n",
    "        model = EEGNet(n_ch=C, n_classes=n_classes,\n",
    "                       F1=24, D=2, kernel_t=64, k_sep=16,\n",
    "                       pool1_t=4, pool2_t=6, drop1_p=0.35, drop2_p=0.6,\n",
    "                       chdrop_p=0.1).to(DEVICE)\n",
    "\n",
    "        # Opt y scheduler SGDR\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_INIT)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=SGDR_T0, T_mult=SGDR_Tmult)\n",
    "\n",
    "        # M√©trica r√°pida\n",
    "        def _acc(loader):\n",
    "            return evaluate_with_preds(model, loader, use_tta=True, tta_n=5)[2]\n",
    "\n",
    "        # Historia para curvas\n",
    "        history = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "        # ---- Criterio suave con ponderaci√≥n por clase (+20% BFISTS) ----\n",
    "        class_weights = make_class_weight_tensor(y[tr_sub_idx], n_classes, boost_bfists=1.20)\n",
    "        criterion_soft = WeightedSoftCrossEntropy(class_weights, label_smoothing=0.05)\n",
    "\n",
    "        # ===== Entrenamiento global =====\n",
    "        print(f\"\\n[Fold {fold}/{N_FOLDS}] Entrenando modelo global...\"\n",
    "              f\" (n_train={len(tr_sub_idx)} | n_val={len(va_idx)} | n_test={len(te_idx)})\")\n",
    "\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        best_val = -1.0\n",
    "        bad = 0\n",
    "\n",
    "        for epoch in range(1, EPOCHS_GLOBAL + 1):\n",
    "            train_epoch(model, tr_loader, opt, criterion_soft, n_classes=n_classes,\n",
    "                        do_aug=True, fs=FS, maxnorm=2.0)\n",
    "            scheduler.step(epoch-1 + 1e-8)  # tick suave\n",
    "\n",
    "            # eval\n",
    "            tr_acc = _acc(tr_loader)\n",
    "            va_acc = _acc(va_loader)\n",
    "            history['train_acc'].append(tr_acc)\n",
    "            history['val_acc'].append(va_acc)\n",
    "\n",
    "            if (epoch % LOG_EVERY == 0) or epoch in (1, 10, 20, 50, 100):\n",
    "                cur_lr = opt.param_groups[0]['lr']\n",
    "                print(f\"  √âpoca {epoch:3d} | train_acc={tr_acc:.4f} | val_acc={va_acc:.4f} | LR={cur_lr:.5f}\")\n",
    "\n",
    "            if va_acc > best_val + 1e-4:\n",
    "                best_val = va_acc\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= GLOBAL_PATIENCE:\n",
    "                    print(f\"  Early stopping en √©poca {epoch} (mejor val_acc={best_val:.4f})\")\n",
    "                    break\n",
    "\n",
    "        # guardar curva de entrenamiento\n",
    "        curve_path = f\"training_curve_fold{fold}.png\"\n",
    "        plot_training_curves(history, curve_path)\n",
    "        print(f\"‚Ü≥ Curva de entrenamiento guardada: {curve_path}\")\n",
    "\n",
    "        # cargar mejor estado antes de evaluar en test\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # ===== Evaluaci√≥n global (inter-sujeto puro) =====\n",
    "        y_true, y_pred, acc_global = evaluate_with_preds(model, te_loader, use_tta=True, tta_n=5)\n",
    "        global_folds.append(acc_global)\n",
    "        all_true.append(y_true); all_pred.append(y_pred)\n",
    "\n",
    "        print(f\"[Fold {fold}/{N_FOLDS}] Global acc={acc_global:.4f}\")\n",
    "        print_report(y_true, y_pred, CLASS_NAMES_4C)\n",
    "\n",
    "        # ---------- Fine-tuning PROGRESIVO por sujeto con 4-fold CV ----------\n",
    "        X_te, y_te, g_te = X[te_idx], y[te_idx], groups[te_idx]\n",
    "\n",
    "        y_true_ft_all, y_pred_ft_all = [], []\n",
    "        used_subjects = 0\n",
    "        for sid in np.unique(g_te):\n",
    "            idx = np.where(g_te == sid)[0]\n",
    "            Xs, ys = X_te[idx], y_te[idx]\n",
    "\n",
    "            if len(ys) < CALIB_CV_FOLDS or len(np.unique(ys)) < 2:\n",
    "                continue\n",
    "\n",
    "            y_true_subj, y_pred_subj = subject_cv_finetune_predict_progressive(\n",
    "                model, Xs, ys, DEVICE, n_splits=CALIB_CV_FOLDS, n_classes=n_classes\n",
    "            )\n",
    "            y_true_ft_all.append(y_true_subj)\n",
    "            y_pred_ft_all.append(y_pred_subj)\n",
    "            used_subjects += 1\n",
    "\n",
    "        if len(y_true_ft_all) > 0:\n",
    "            y_true_ft_all = np.concatenate(y_true_ft_all)\n",
    "            y_pred_ft_all = np.concatenate(y_pred_ft_all)\n",
    "            acc_ft = (y_true_ft_all == y_pred_ft_all).mean()\n",
    "            print(f\"  Fine-tuning PROGRESIVO (por sujeto, {CALIB_CV_FOLDS}-fold CV) acc={acc_ft:.4f} | sujetos={used_subjects}\")\n",
    "            print(f\"  Œî(FT-Global) = {acc_ft - acc_global:+.4f}\")\n",
    "        else:\n",
    "            acc_ft = np.nan\n",
    "            print(\"  Fine-tuning PROGRESIVO no ejecutado (sujeto(s) con muestras insuficientes).\")\n",
    "\n",
    "        ft_prog_folds.append(acc_ft)\n",
    "\n",
    "    # ---------- resultados finales ----------\n",
    "    if len(all_true) > 0:\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "    else:\n",
    "        all_true = np.array([], dtype=int)\n",
    "        all_pred = np.array([], dtype=int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Global folds:\", [f\"{a:.4f}\" for a in global_folds])\n",
    "    if len(global_folds) > 0:\n",
    "        print(f\"Global mean: {np.mean(global_folds):.4f}\")\n",
    "\n",
    "    print(\"Fine-tune PROGRESIVO folds:\", [(\"nan\" if (a is None or np.isnan(a)) else f\"{a:.4f}\") for a in ft_prog_folds])\n",
    "    if len(ft_prog_folds) > 0:\n",
    "        print(f\"Fine-tune PROGRESIVO mean: {np.nanmean(ft_prog_folds):.4f}\")\n",
    "        print(f\"Œî(FT-Global) mean: {np.nanmean(ft_prog_folds) - np.mean(global_folds):+.4f}\")\n",
    "\n",
    "    if all_true.size > 0:\n",
    "        plot_confusion(all_true, all_pred, CLASS_NAMES_4C,\n",
    "                       title=\"Confusion Matrix - Global Model (All Folds)\",\n",
    "                       fname=\"confusion_global_allfolds.png\")\n",
    "        print(\"\\n‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_allfolds.png\")\n",
    "\n",
    "    return {\n",
    "        \"global_folds\": global_folds,\n",
    "        \"ft_prog_folds\": ft_prog_folds,\n",
    "        \"all_true\": all_true,\n",
    "        \"all_pred\": all_pred,\n",
    "        \"folds_json_path\": str(folds_json_path)\n",
    "    }\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üß† INICIANDO EXPERIMENTO CON EEGNet + FINE-TUNING PROGRESIVO (augments + SGDR + tweaks)\")\n",
    "    print(f\"üîß Configuraci√≥n: {CLASS_SCENARIO}, {len(EXPECTED_8)} canales, {WINDOW_MODE}\")\n",
    "    print(f\"‚öôÔ∏è  FT: epochs={FT_EPOCHS}, base_lr={FT_BASE_LR}, head_lr={FT_HEAD_LR}, L2SP={FT_L2SP}, patience={FT_PATIENCE}, CV={CALIB_CV_FOLDS}\")\n",
    "    run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd0e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Usando dispositivo: cuda\n",
      "üß† INICIANDO EXPERIMENTO CON EEGNet (mismo Kfold y TTA/Augments que CNN+TF)\n",
      "üß† INICIANDO EXPERIMENTO CON EEGNet + Augments/TTA estilo CNN+TF (sin balanceo)\n",
      "üîß Configuraci√≥n: 4c, 8 canales, 6s | EPOCHS_GLOBAL=100, BATCH=64, LR=0.01 | ZSCORE_PER_EPOCH=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:05<00:00, 11.55it/s]\n",
      "Cargando val fold1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00, 11.65it/s]\n",
      "Cargando test fold1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:01<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  √âpoca   1 | train_acc=0.3520 | val_acc=0.3944 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.4232 | val_acc=0.4310 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.4351 | val_acc=0.4246 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.4531 | val_acc=0.4452 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.4474 | val_acc=0.4286 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.4439 | val_acc=0.4349 | LR=0.00854\n",
      "  Early stopping en √©poca 25 (mejor val_acc=0.4452)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold1.png\n",
      "[Fold 1/5] Global acc=0.4507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6461    0.3560    0.4591       441\n",
      "       Right     0.5372    0.4422    0.4851       441\n",
      "  Both Fists     0.3447    0.5283    0.4172       441\n",
      "   Both Feet     0.4357    0.4762    0.4550       441\n",
      "\n",
      "    accuracy                         0.4507      1764\n",
      "   macro avg     0.4909    0.4507    0.4541      1764\n",
      "weighted avg     0.4909    0.4507    0.4541      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[157  39 167  78]\n",
      " [ 22 195 133  91]\n",
      " [ 39  66 233 103]\n",
      " [ 25  63 143 210]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5079 | sujetos=21\n",
      "  Œî(FT-Global) = +0.0573\n",
      "‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_fold1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:05<00:00, 11.44it/s]\n",
      "Cargando val fold2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00, 11.44it/s]\n",
      "Cargando test fold2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:01<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  √âpoca   1 | train_acc=0.3109 | val_acc=0.3683 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.3850 | val_acc=0.4484 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.3984 | val_acc=0.4238 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.4227 | val_acc=0.4500 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.4152 | val_acc=0.4444 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.4129 | val_acc=0.4365 | LR=0.00854\n",
      "  √âpoca  30 | train_acc=0.4241 | val_acc=0.4532 | LR=0.00565\n",
      "  √âpoca  35 | train_acc=0.4314 | val_acc=0.4492 | LR=0.00250\n",
      "  √âpoca  40 | train_acc=0.4456 | val_acc=0.4532 | LR=0.00038\n",
      "  Early stopping en √©poca 44 (mejor val_acc=0.4611)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold2.png\n",
      "[Fold 2/5] Global acc=0.5079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6480    0.4717    0.5459       441\n",
      "       Right     0.6559    0.4626    0.5426       441\n",
      "  Both Fists     0.3901    0.6599    0.4903       441\n",
      "   Both Feet     0.5000    0.4376    0.4667       441\n",
      "\n",
      "    accuracy                         0.5079      1764\n",
      "   macro avg     0.5485    0.5079    0.5114      1764\n",
      "weighted avg     0.5485    0.5079    0.5114      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[208  17 171  45]\n",
      " [ 18 204 137  82]\n",
      " [ 56  28 291  66]\n",
      " [ 39  62 147 193]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5975 | sujetos=21\n",
      "  Œî(FT-Global) = +0.0896\n",
      "‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_fold2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:05<00:00, 11.57it/s]\n",
      "Cargando val fold3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00, 11.54it/s]\n",
      "Cargando test fold3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:01<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3/5] Entrenando modelo global... (n_train=5628 | n_val=1260 | n_test=1764)\n",
      "  √âpoca   1 | train_acc=0.3264 | val_acc=0.4381 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.4243 | val_acc=0.4817 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.4248 | val_acc=0.4810 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.4471 | val_acc=0.4960 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.4383 | val_acc=0.4770 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.4367 | val_acc=0.4825 | LR=0.00854\n",
      "  Early stopping en √©poca 25 (mejor val_acc=0.4960)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold3.png\n",
      "[Fold 3/5] Global acc=0.4700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6026    0.4195    0.4947       441\n",
      "       Right     0.6341    0.4127    0.5000       441\n",
      "  Both Fists     0.3757    0.6032    0.4630       441\n",
      "   Both Feet     0.4242    0.4444    0.4341       441\n",
      "\n",
      "    accuracy                         0.4700      1764\n",
      "   macro avg     0.5092    0.4700    0.4729      1764\n",
      "weighted avg     0.5092    0.4700    0.4729      1764\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[185  23 156  77]\n",
      " [ 24 182 132 103]\n",
      " [ 57  32 266  86]\n",
      " [ 41  50 154 196]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5340 | sujetos=21\n",
      "  Œî(FT-Global) = +0.0641\n",
      "‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_fold3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68/68 [00:05<00:00, 11.38it/s]\n",
      "Cargando val fold4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00, 11.29it/s]\n",
      "Cargando test fold4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n",
      "  √âpoca   1 | train_acc=0.3270 | val_acc=0.4341 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.4027 | val_acc=0.4683 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.4210 | val_acc=0.4698 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.4275 | val_acc=0.4698 | LR=0.00250\n",
      "  √âpoca  20 | train_acc=0.4259 | val_acc=0.4635 | LR=0.00996\n",
      "  √âpoca  25 | train_acc=0.4272 | val_acc=0.4833 | LR=0.00854\n",
      "  √âpoca  30 | train_acc=0.4389 | val_acc=0.4873 | LR=0.00565\n",
      "  √âpoca  35 | train_acc=0.4611 | val_acc=0.4802 | LR=0.00250\n",
      "  √âpoca  40 | train_acc=0.4582 | val_acc=0.4952 | LR=0.00038\n",
      "  Early stopping en √©poca 41 (mejor val_acc=0.4992)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold4.png\n",
      "[Fold 4/5] Global acc=0.4857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.5932    0.4548    0.5148       420\n",
      "       Right     0.6271    0.4524    0.5256       420\n",
      "  Both Fists     0.3776    0.6429    0.4758       420\n",
      "   Both Feet     0.4853    0.3929    0.4342       420\n",
      "\n",
      "    accuracy                         0.4857      1680\n",
      "   macro avg     0.5208    0.4857    0.4876      1680\n",
      "weighted avg     0.5208    0.4857    0.4876      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[191  19 151  59]\n",
      " [ 30 190 135  65]\n",
      " [ 59  40 270  51]\n",
      " [ 42  54 159 165]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5714 | sujetos=20\n",
      "  Œî(FT-Global) = +0.0857\n",
      "‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_fold4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando train fold5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68/68 [00:05<00:00, 11.48it/s]\n",
      "Cargando val fold5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00, 11.55it/s]\n",
      "Cargando test fold5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5/5] Entrenando modelo global... (n_train=5712 | n_val=1260 | n_test=1680)\n",
      "  √âpoca   1 | train_acc=0.3328 | val_acc=0.3937 | LR=0.01000\n",
      "  √âpoca   5 | train_acc=0.4090 | val_acc=0.4103 | LR=0.00250\n",
      "  √âpoca  10 | train_acc=0.4039 | val_acc=0.4127 | LR=0.00854\n",
      "  √âpoca  15 | train_acc=0.4319 | val_acc=0.4278 | LR=0.00250\n",
      "  Early stopping en √©poca 19 (mejor val_acc=0.4341)\n",
      "‚Ü≥ Curva de entrenamiento guardada: training_curve_fold5.png\n",
      "[Fold 5/5] Global acc=0.5089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left     0.6087    0.5333    0.5685       420\n",
      "       Right     0.5455    0.5000    0.5217       420\n",
      "  Both Fists     0.4173    0.5643    0.4798       420\n",
      "   Both Feet     0.5125    0.4381    0.4724       420\n",
      "\n",
      "    accuracy                         0.5089      1680\n",
      "   macro avg     0.5210    0.5089    0.5106      1680\n",
      "weighted avg     0.5210    0.5089    0.5106      1680\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[224  31 123  42]\n",
      " [ 21 210 105  84]\n",
      " [ 76  58 237  49]\n",
      " [ 47  86 103 184]]\n",
      "  Fine-tuning PROGRESIVO (por sujeto, 4-fold CV) acc=0.5667 | sujetos=20\n",
      "  Œî(FT-Global) = +0.0577\n",
      "‚Ü≥ Matriz de confusi√≥n guardada: confusion_global_fold5.png\n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "Global folds (ACC): ['0.4507', '0.5079', '0.4700', '0.4857', '0.5089']\n",
      "Global mean ACC: 0.4846\n",
      "F1 folds (MACRO): ['0.4541', '0.5114', '0.4729', '0.4876', '0.5106']\n",
      "F1 mean (MACRO): 0.4873\n",
      "Fine-tune PROGRESIVO folds: ['0.5079', '0.5975', '0.5340', '0.5714', '0.5667']\n",
      "Fine-tune PROGRESIVO mean: 0.5555\n",
      "Œî(FT-Global) mean: +0.0709\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# EEGNet + (SIN balanceo por sujeto/clase) + Kfold5.json (solo train/test) +\n",
    "# Augments y TTA iguales al CNN+Transformer + Fine-tuning progresivo (igual que antes)\n",
    "\n",
    "import os, re, json, random, copy, itertools\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILIDAD\n",
    "# =========================\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "PROJ = Path('..').resolve().parent\n",
    "DATA_RAW = PROJ / 'data' / 'raw'\n",
    "FOLDS_JSON = PROJ / 'models' / 'folds' / 'Kfold5.json'\n",
    "\n",
    "# Entrenamiento global\n",
    "EPOCHS_GLOBAL   = 100\n",
    "BATCH_SIZE      = 64\n",
    "LR_INIT         = 1e-2\n",
    "SGDR_T0         = 6\n",
    "SGDR_Tmult      = 2\n",
    "GLOBAL_PATIENCE = 10\n",
    "LOG_EVERY       = 5\n",
    "\n",
    "# Validaci√≥n desde sujetos de train (igual a tu CNN+TF)\n",
    "VAL_SUBJECT_FRAC   = 0.18\n",
    "VAL_STRAT_SUBJECT  = True\n",
    "\n",
    "# Fine-tuning progresivo\n",
    "CALIB_CV_FOLDS = 4\n",
    "FT_EPOCHS   = 30\n",
    "FT_BASE_LR  = 5e-5\n",
    "FT_HEAD_LR  = 1e-3\n",
    "FT_L2SP     = 1e-4\n",
    "FT_PATIENCE = 5\n",
    "FT_VAL_RATIO = 0.2\n",
    "\n",
    "# Ventana temporal y prepro\n",
    "FS = 160.0\n",
    "TMIN, TMAX = -1.0, 5.0\n",
    "NORM_EPOCH_ZSCORE = True   # por-√©poca canal-a-canal\n",
    "\n",
    "# Excluir sujetos (igual que antes)\n",
    "EXCLUDE_SUBJECTS = {38, 88, 89, 92, 100, 104}\n",
    "\n",
    "# Runs y canales\n",
    "IMAGERY_RUNS_LR = {4, 8, 12}\n",
    "IMAGERY_RUNS_BF = {6, 10, 14}\n",
    "EXPECTED_8 = ['C3','C4','Cz','CP3','CP4','FC3','FC4','FCz']\n",
    "CLASS_NAMES_4C = ['Left','Right','Both Fists','Both Feet']\n",
    "\n",
    "# TTA estilo CNN+TF\n",
    "SW_MODE = 'tta'                     # 'none'|'subwin'|'tta'\n",
    "SW_ENABLE = True\n",
    "TTA_SHIFTS_S = [-0.075, -0.05, -0.025, 0.0, 0.025, 0.05, 0.075]\n",
    "SW_LEN, SW_STRIDE = 4.5, 1.5\n",
    "COMBINE_TTA_AND_SUBWIN = False      # mantenemos apagado (como tu comentario)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Usando dispositivo: {DEVICE}\")\n",
    "print(\"üß† INICIANDO EXPERIMENTO CON EEGNet (mismo Kfold y TTA/Augments que CNN+TF)\")\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES I/O\n",
    "# =========================\n",
    "def normalize_ch_name(name: str) -> str:\n",
    "    s = re.sub(r'[^A-Za-z0-9]', '', name)\n",
    "    return s.upper()\n",
    "\n",
    "NORMALIZED_TARGETS = [normalize_ch_name(c) for c in EXPECTED_8]\n",
    "\n",
    "def pick_8_channels(raw: mne.io.BaseRaw) -> mne.io.BaseRaw:\n",
    "    chs = raw.info['ch_names']\n",
    "    norm_map = {normalize_ch_name(ch): ch for ch in chs}\n",
    "    picked = []\n",
    "    for target_norm, target_orig in zip(NORMALIZED_TARGETS, EXPECTED_8):\n",
    "        if target_norm in norm_map:\n",
    "            picked.append(norm_map[target_norm])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Canal requerido '{target_orig}' no encontrado. Disponibles: {chs}\")\n",
    "    return raw.pick(picks=picked)\n",
    "\n",
    "def subject_id_to_int(s: str) -> int:\n",
    "    m = re.match(r'[Ss](\\d+)', s)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def list_subject_imagery_edfs(subject_id: str) -> list:\n",
    "    subj_dir = DATA_RAW / subject_id\n",
    "    edfs = []\n",
    "    for r in sorted(list(IMAGERY_RUNS_LR | IMAGERY_RUNS_BF)):\n",
    "        edfs.extend(glob(str(subj_dir / f\"{subject_id}R{r:02d}.edf\")))\n",
    "    return sorted(edfs)\n",
    "\n",
    "def load_fold_subjects(folds_json: Path, fold: int):\n",
    "    with open(folds_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data.get('folds', []):\n",
    "        if int(item.get('fold', -1)) == int(fold):\n",
    "            return list(item.get('train', [])), list(item.get('test', []))\n",
    "    raise ValueError(f\"Fold {fold} not found in {folds_json}\")\n",
    "\n",
    "def load_subject_epochs(subject_id: str):\n",
    "    \"\"\"Devuelve X (N, T, C) y y (N,) con 8 canales y FS=160 si es necesario.\"\"\"\n",
    "    edfs = list_subject_imagery_edfs(subject_id)\n",
    "    if len(edfs) == 0:\n",
    "        return np.empty((0, 1, 1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "    X_list, y_list, sfreq_list = [], [], []\n",
    "    for edf_path in edfs:\n",
    "        m = re.search(r\"R(\\d{2})\", Path(edf_path).name)\n",
    "        run = int(m.group(1)) if m else -1\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "        raw = pick_8_channels(raw)\n",
    "        # re-muestreo a FS si hace falta\n",
    "        if abs(raw.info['sfreq'] - FS) > 1e-6:\n",
    "            raw.resample(FS)\n",
    "        sfreq = raw.info['sfreq']\n",
    "        events, event_id = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        keep = {k: v for k, v in event_id.items() if k in {'T1', 'T2'}}\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=keep, tmin=TMIN, tmax=TMAX,\n",
    "                            baseline=None, preload=True, verbose='ERROR')\n",
    "        X = epochs.get_data().astype(np.float32)      # (N, C, T)\n",
    "        # z-score por √©poca/canal si est√° activo\n",
    "        if NORM_EPOCH_ZSCORE:\n",
    "            eps = 1e-6\n",
    "            mu = X.mean(axis=2, keepdims=True)\n",
    "            sd = X.std(axis=2, keepdims=True) + eps\n",
    "            X = (X - mu) / sd\n",
    "        # mapear etiquetas por run\n",
    "        ev_codes = epochs.events[:, 2]\n",
    "        inv = {v: k for k, v in keep.items()}\n",
    "        y_run = []\n",
    "        for code in ev_codes:\n",
    "            lab = inv[code]\n",
    "            if run in IMAGERY_RUNS_LR:\n",
    "                y_run.append(0 if lab == 'T1' else 1)\n",
    "            elif run in IMAGERY_RUNS_BF:\n",
    "                y_run.append(2 if lab == 'T1' else 3)\n",
    "            else:\n",
    "                y_run.append(-1)\n",
    "        y_run = np.array(y_run, dtype=int)\n",
    "        mask = y_run >= 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        # convertimos a (N, T, C) para EEGNet utilidades previas\n",
    "        X_tc = np.transpose(X[mask], (0, 2, 1))   # (N, T, C)\n",
    "        X_list.append(X_tc)\n",
    "        y_list.append(y_run[mask])\n",
    "        sfreq_list.append(sfreq)\n",
    "    if len(X_list) == 0:\n",
    "        return np.empty((0, 1, 1), dtype=np.float32), np.empty((0,), dtype=int), None\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "    if len(set([int(round(s)) for s in sfreq_list])) != 1:\n",
    "        raise RuntimeError(f\"Sampling rates inconsistentes: {sfreq_list}\")\n",
    "    return X_all, y_all, sfreq_list[0]\n",
    "\n",
    "def standardize_per_channel_trainfit(X_tr_TxC, X_other_TxC):\n",
    "    \"\"\"Estandariza por canal usando estad√≠sticas de TRAIN, sobre matrices (N, T, C).\"\"\"\n",
    "    Xtr = X_tr_TxC.astype(np.float32).copy()\n",
    "    Xot = X_other_TxC.astype(np.float32).copy()\n",
    "    C = Xtr.shape[2]\n",
    "    for c in range(C):\n",
    "        mu = Xtr[:, :, c].mean()\n",
    "        sd = Xtr[:, :, c].std()\n",
    "        sd = sd if sd > 1e-6 else 1.0\n",
    "        Xtr[:, :, c] = (Xtr[:, :, c] - mu) / sd\n",
    "        Xot[:, :, c] = (Xot[:, :, c] - mu) / sd\n",
    "    return Xtr, Xot\n",
    "\n",
    "def build_subject_label_map(subject_ids):\n",
    "    \"\"\"Etiqueta dominante por sujeto (para estratificar la selecci√≥n de val).\"\"\"\n",
    "    y_dom_list = []\n",
    "    for sid in subject_ids:\n",
    "        Xs, ys, _ = load_subject_epochs(sid)\n",
    "        if len(ys) == 0:\n",
    "            y_dom_list.append(-1)\n",
    "            continue\n",
    "        binc = np.bincount(ys, minlength=4)\n",
    "        y_dom_list.append(int(np.argmax(binc)))\n",
    "    return np.array(y_dom_list, dtype=int)\n",
    "\n",
    "# =========================\n",
    "# AUGMENTS (estilo CNN+TF) SOBRE (B,1,T,C)\n",
    "# =========================\n",
    "def augment_batch_eegnet(xb_1tC, p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "                         max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1):\n",
    "    \"\"\"\n",
    "    Aplica las mismas ideas de augment que tu CNN+Transformer, pero adaptadas a (B,1,T,C).\n",
    "    Internamente convierte a (B,C,T), aplica, y regresa a (B,1,T,C).\n",
    "    \"\"\"\n",
    "    B, _, T, C = xb_1tC.shape\n",
    "    xb = xb_1tC[:, 0].permute(0, 2, 1).contiguous()   # (B,C,T)\n",
    "    # jitter temporal\n",
    "    if np.random.rand() < p_jitter:\n",
    "        max_shift = int(max(1, T * max_jitter_frac))\n",
    "        shifts = torch.randint(low=-max_shift, high=max_shift+1, size=(B,), device=xb.device)\n",
    "        for i in range(B):\n",
    "            xb[i] = torch.roll(xb[i], shifts=int(shifts[i].item()), dims=-1)\n",
    "    # ruido gaussiano\n",
    "    if np.random.rand() < p_noise:\n",
    "        xb = xb + noise_std * torch.randn_like(xb)\n",
    "    # channel drop\n",
    "    if np.random.rand() < p_chdrop and max_chdrop > 0:\n",
    "        k = min(max_chdrop, C)\n",
    "        for i in range(B):\n",
    "            idx = torch.randperm(C, device=xb.device)[:k]\n",
    "            xb[i, idx, :] = 0.0\n",
    "    # volver a (B,1,T,C)\n",
    "    xb_1tC = xb.permute(0, 2, 1).unsqueeze(1).contiguous()\n",
    "    return xb_1tC\n",
    "\n",
    "# =========================\n",
    "# TTA estilo CNN+TF (time-shifts)\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def time_shift_tta_logits_eegnet(model, X_TxC, sfreq, shifts_s, device):\n",
    "    \"\"\"\n",
    "    X_TxC: (N, T, C) numpy\n",
    "    Genera logits promediados tras desplazar en el tiempo.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N, T, C = X_TxC.shape\n",
    "    out = []\n",
    "    for i in range(N):\n",
    "        x0 = X_TxC[i]  # (T,C)\n",
    "        acc = []\n",
    "        for sh in shifts_s:\n",
    "            shift = int(round(sh * sfreq))\n",
    "            if shift == 0:\n",
    "                x = x0\n",
    "            elif shift > 0:\n",
    "                # desplaza a la derecha, rellena borde\n",
    "                pad = np.tile(x0[:1, :], (shift, 1))\n",
    "                x = np.concatenate([pad, x0[:-shift, :]], axis=0)\n",
    "            else:\n",
    "                # desplaza a la izquierda\n",
    "                shift = -shift\n",
    "                pad = np.tile(x0[-1:, :], (shift, 1))\n",
    "                x = np.concatenate([x0[shift:, :], pad], axis=0)\n",
    "            # a tensor (1,1,T,C)\n",
    "            xb = torch.tensor(x, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
    "            logit = model(xb).detach().cpu().numpy()[0]\n",
    "            acc.append(logit)\n",
    "        out.append(np.mean(np.stack(acc, axis=0), axis=0))\n",
    "    return np.stack(out, axis=0)\n",
    "\n",
    "# =========================\n",
    "# MODELO EEGNet\n",
    "# =========================\n",
    "class ChannelDropout(nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p<=0: return x\n",
    "        B,_,T,C = x.shape\n",
    "        mask = (torch.rand(B,1,1,C, device=x.device) > self.p).float()\n",
    "        return x * mask\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Entrada: x de forma (B, 1, T, C)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_ch: int, n_classes: int,\n",
    "                 F1: int = 24, D: int = 2, kernel_t: int = 64, k_sep: int = 16,\n",
    "                 pool1_t: int = 4, pool2_t: int = 6,\n",
    "                 drop1_p: float = 0.35, drop2_p: float = 0.6,\n",
    "                 chdrop_p: float = 0.10):\n",
    "        super().__init__()\n",
    "        self.n_ch = n_ch\n",
    "        self.n_classes = n_classes\n",
    "        self.F1 = F1\n",
    "        self.D = D\n",
    "        self.F2 = F1 * D\n",
    "        self.kernel_t = kernel_t\n",
    "        self.k_sep = k_sep\n",
    "        self.pool1_t = pool1_t\n",
    "        self.pool2_t = pool2_t\n",
    "\n",
    "        self.chdrop = ChannelDropout(p=chdrop_p)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "        # Bloque 1: temporal\n",
    "        self.conv_temporal = nn.Conv2d(1, F1, kernel_size=(kernel_t, 1),\n",
    "                                       padding=(kernel_t // 2, 0), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1, momentum=0.99, eps=1e-3)\n",
    "\n",
    "        # Bloque 2: depthwise (espacial)\n",
    "        self.conv_depthwise = nn.Conv2d(F1, self.F2, kernel_size=(1, n_ch),\n",
    "                                        groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F2, momentum=0.99, eps=1e-3)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(pool1_t, 1), stride=(pool1_t, 1))\n",
    "        self.drop1 = nn.Dropout(drop1_p)\n",
    "\n",
    "        # Bloque 3: separable temporal\n",
    "        self.conv_sep_depth = nn.Conv2d(self.F2, self.F2, kernel_size=(k_sep, 1),\n",
    "                                        groups=self.F2, padding=(k_sep // 2, 0), bias=False)\n",
    "        self.conv_sep_point = nn.Conv2d(self.F2, self.F2, kernel_size=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2, momentum=0.99, eps=1e-3)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(pool2_t, 1), stride=(pool2_t, 1))\n",
    "        self.drop2 = nn.Dropout(drop2_p)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Cabeza din√°mica (se arma en forward seg√∫n T)\n",
    "        self.fc = None\n",
    "        self.out = None\n",
    "        self._T_in = None\n",
    "\n",
    "    def _build_head(self, T_in: int, device: torch.device):\n",
    "        T1 = T_in // self.pool1_t\n",
    "        T2 = T1 // self.pool2_t\n",
    "        feat_dim = self.F2 * T2 * 1\n",
    "        self.fc  = nn.Linear(feat_dim, 128, bias=True).to(device)\n",
    "        self.out = nn.Linear(128, self.n_classes, bias=True).to(device)\n",
    "        self._T_in = T_in\n",
    "\n",
    "    def ensure_head(self, T_in: int, device: torch.device):\n",
    "        if (self.fc is None) or (self.out is None) or (self._T_in != T_in):\n",
    "            self._build_head(T_in, device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, _, T, C = x.shape\n",
    "        self.ensure_head(T, x.device)\n",
    "        x = self.chdrop(x)  # ChannelDropout\n",
    "\n",
    "        z = self.conv_temporal(x)\n",
    "        z = self.bn1(z); z = self.act(z)\n",
    "\n",
    "        z = self.conv_depthwise(z)   # (B, F2, T, 1)\n",
    "        z = self.bn2(z); z = self.act(z)\n",
    "        z = self.pool1(z)\n",
    "        z = self.drop1(z)\n",
    "\n",
    "        z = self.conv_sep_depth(z)\n",
    "        z = self.conv_sep_point(z)\n",
    "        z = self.bn3(z); z = self.act(z)\n",
    "        z = self.pool2(z)\n",
    "        z = self.drop2(z)\n",
    "\n",
    "        z = self.flatten(z)\n",
    "        z = self.fc(z); z = self.act(z)\n",
    "        z = self.out(z)\n",
    "        return z\n",
    "\n",
    "# =========================\n",
    "# LOSS (igual que tu EEGNet previo: soft CE ponderada)\n",
    "# =========================\n",
    "class WeightedSoftCrossEntropy(nn.Module):\n",
    "    def __init__(self, class_weights=None, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('w', None if class_weights is None else class_weights.clone().float())\n",
    "        self.ls = float(label_smoothing)\n",
    "    def forward(self, logits, target_probs):\n",
    "        if self.ls > 0:\n",
    "            K = logits.size(1)\n",
    "            target_probs = (1-self.ls)*target_probs + self.ls*(1.0/K)\n",
    "        logp = torch.log_softmax(logits, dim=1)\n",
    "        loss_per_class = -(target_probs * logp)\n",
    "        if self.w is not None:\n",
    "            loss_per_class = loss_per_class * self.w.unsqueeze(0)\n",
    "        loss = loss_per_class.sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "def make_class_weight_tensor(y_indices, n_classes, boost_bfists=1.20, boost_bfeet=1.20, device=DEVICE):\n",
    "    counts = np.bincount(y_indices, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    w = counts.sum() / counts           # inverso de frecuencia\n",
    "    w = w / w.mean()                    # normaliza a media 1\n",
    "    # boosts manuales\n",
    "    w[2] *= float(boost_bfists)         # clase 2: Both Fists\n",
    "    w[3] *= float(boost_bfeet)          # clase 3: Both Feet (NUEVO)\n",
    "    w = w / w.mean()                    # re-normaliza a media 1 (importante)\n",
    "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL HELPERS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def apply_max_norm(model, max_value=2.0, p=2.0):\n",
    "    layers = []\n",
    "    if hasattr(model, 'conv_depthwise'): layers.append(model.conv_depthwise)\n",
    "    if hasattr(model, 'conv_sep_point'): layers.append(model.conv_sep_point)\n",
    "    if hasattr(model, 'fc'):             layers.append(model.fc)\n",
    "    if hasattr(model, 'out'):            layers.append(model.out)\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            w = layer.weight.data\n",
    "            norms = w.view(w.size(0), -1).norm(p=p, dim=1, keepdim=True)\n",
    "            desired = torch.clamp(norms, max=max_value)\n",
    "            w.view(w.size(0), -1).mul_(desired / (1e-8 + norms))\n",
    "\n",
    "def plot_training_curves(history, fname):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history['train_acc'], label='train_acc')\n",
    "    plt.plot(history['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Training curve'); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes, title, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45, ha='right'); plt.yticks(ticks, classes)\n",
    "    fmt = '.2f'; thresh = cm_norm.max()/2.\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
    "\n",
    "# =========================\n",
    "# FINE-TUNING PROGRESIVO (igual que antes)\n",
    "# =========================\n",
    "def _freeze_for_mode(model, mode):\n",
    "    for p in model.parameters(): p.requires_grad = False\n",
    "    if mode == 'out':\n",
    "        for p in model.out.parameters(): p.requires_grad = True\n",
    "    elif mode == 'head':\n",
    "        for p in model.fc.parameters():  p.requires_grad = True\n",
    "        for p in model.out.parameters(): p.requires_grad = True\n",
    "    elif mode == 'spatial+head':\n",
    "        for p in model.conv_depthwise.parameters(): p.requires_grad = True\n",
    "        for p in model.bn2.parameters():           p.requires_grad = True\n",
    "        for p in model.conv_sep_depth.parameters():p.requires_grad = True\n",
    "        for p in model.conv_sep_point.parameters():p.requires_grad = True\n",
    "        for p in model.bn3.parameters():           p.requires_grad = True\n",
    "        for p in model.fc.parameters():            p.requires_grad = True\n",
    "        for p in model.out.parameters():           p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "def _class_weights(y_np, n_classes):\n",
    "    counts = np.bincount(y_np, minlength=n_classes).astype(np.float32)\n",
    "    counts[counts == 0] = 1.0\n",
    "    weights = counts.sum() / counts\n",
    "    weights = weights / weights.mean()\n",
    "    return torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def _train_one_mode(model, X_cal_TxC, y_cal, n_classes, mode,\n",
    "                    epochs=FT_EPOCHS, batch_size=32,\n",
    "                    head_lr=FT_HEAD_LR, base_lr=FT_BASE_LR,\n",
    "                    l2sp_lambda=FT_L2SP, patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO):\n",
    "    # split interno (sobre ensayos del sujeto)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=RANDOM_STATE)\n",
    "    (tr_idx, va_idx), = sss.split(X_cal_TxC, y_cal)\n",
    "    Xtr, ytr = X_cal_TxC[tr_idx], y_cal[tr_idx]\n",
    "    Xva, yva = X_cal_TxC[va_idx], y_cal[va_idx]\n",
    "\n",
    "    # a tensores (B,1,T,C)\n",
    "    def to_tensor(X_TxC, y_idx):\n",
    "        xb = torch.from_numpy(X_TxC).float().unsqueeze(1)   # (B,1,T,C)\n",
    "        yb = torch.from_numpy(y_idx).long()\n",
    "        return xb, yb\n",
    "\n",
    "    xb_tr, yb_tr = to_tensor(Xtr, ytr)\n",
    "    xb_va, yb_va = to_tensor(Xva, yva)\n",
    "\n",
    "    _freeze_for_mode(model, mode)\n",
    "    if mode == 'spatial+head':\n",
    "        base_params = (list(model.conv_depthwise.parameters()) +\n",
    "                       list(model.bn2.parameters()) +\n",
    "                       list(model.conv_sep_depth.parameters()) +\n",
    "                       list(model.conv_sep_point.parameters()) +\n",
    "                       list(model.bn3.parameters()))\n",
    "        head_params = list(model.fc.parameters()) + list(model.out.parameters())\n",
    "        train_params = base_params + head_params\n",
    "        opt = optim.Adam([\n",
    "            {\"params\": base_params, \"lr\": base_lr},\n",
    "            {\"params\": head_params, \"lr\": head_lr},\n",
    "        ])\n",
    "    else:\n",
    "        train_params = list(model.parameters())  # se respeta freeze por requires_grad\n",
    "        opt = optim.Adam([p for p in train_params if p.requires_grad], lr=head_lr)\n",
    "\n",
    "    # referencia L2SP\n",
    "    ref = [p.detach().clone().to(p.device) for p in [p for p in train_params if p.requires_grad]]\n",
    "    class_w = _class_weights(ytr, n_classes)\n",
    "    crit = nn.CrossEntropyLoss(weight=class_w)\n",
    "\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    best_val = float('inf'); bad = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        # mini-batches\n",
    "        for s in range(0, xb_tr.size(0), batch_size):\n",
    "            xbt = xb_tr[s:s+batch_size].to(DEVICE)\n",
    "            ybt = yb_tr[s:s+batch_size].to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xbt)\n",
    "            loss = crit(logits, ybt)\n",
    "            # L2SP\n",
    "            reg = 0.0\n",
    "            idx = 0\n",
    "            for p in train_params:\n",
    "                if p.requires_grad:\n",
    "                    reg = reg + torch.sum((p - ref[idx])**2)\n",
    "                    idx += 1\n",
    "            loss = loss + l2sp_lambda * reg\n",
    "            loss.backward(); opt.step()\n",
    "            apply_max_norm(model, max_value=2.0, p=2.0)\n",
    "\n",
    "        # validaci√≥n\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0; nval = 0\n",
    "            for s in range(0, xb_va.size(0), batch_size):\n",
    "                xbv = xb_va[s:s+batch_size].to(DEVICE)\n",
    "                ybv = yb_va[s:s+batch_size].to(DEVICE)\n",
    "                logits = model(xbv)\n",
    "                loss = crit(logits, ybv)\n",
    "                val_loss += loss.item() * xbv.size(0); nval += xbv.size(0)\n",
    "            val_loss /= max(1, nval)\n",
    "\n",
    "        if val_loss + 1e-7 < best_val:\n",
    "            best_val = val_loss; bad = 0\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience: break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_numpy(model, X_np_TxC, device):\n",
    "    model.eval()\n",
    "    xb = torch.from_numpy(X_np_TxC).float().unsqueeze(1).to(device)  # (B,1,T,C)\n",
    "    logits = model(xb)\n",
    "    return logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "def subject_cv_finetune_predict_progressive(model_global, Xs_TxC, ys, device,\n",
    "                                            n_splits=CALIB_CV_FOLDS, n_classes=4):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    y_true_full = np.empty_like(ys); y_pred_full = np.empty_like(ys)\n",
    "    for tr_idx, te_idx in skf.split(Xs_TxC, ys):\n",
    "        Xcal, ycal = Xs_TxC[tr_idx], ys[tr_idx]\n",
    "        Xho,  yho  = Xs_TxC[te_idx], ys[te_idx]\n",
    "\n",
    "        # OUT\n",
    "        m_out = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_out, Xcal, ycal, n_classes, mode='out',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                        patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_out = predict_numpy(m_out, Xho, device); acc_out = (yhat_out == yho).mean()\n",
    "\n",
    "        # HEAD\n",
    "        m_head = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_head, Xcal, ycal, n_classes, mode='head',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, l2sp_lambda=FT_L2SP,\n",
    "                        patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_head = predict_numpy(m_head, Xho, device); acc_head = (yhat_head == yho).mean()\n",
    "\n",
    "        # SPATIAL+HEAD\n",
    "        m_sp = copy.deepcopy(model_global)\n",
    "        _train_one_mode(m_sp, Xcal, ycal, n_classes, mode='spatial+head',\n",
    "                        epochs=FT_EPOCHS, head_lr=FT_HEAD_LR, base_lr=FT_BASE_LR,\n",
    "                        l2sp_lambda=FT_L2SP, patience=FT_PATIENCE, val_ratio=FT_VAL_RATIO)\n",
    "        yhat_sp = predict_numpy(m_sp, Xho, device); acc_sp = (yhat_sp == yho).mean()\n",
    "\n",
    "        best_idx = int(np.argmax([acc_out, acc_head, acc_sp]))\n",
    "        yhat_best = [yhat_out, yhat_head, yhat_sp][best_idx]\n",
    "\n",
    "        y_true_full[te_idx] = yho; y_pred_full[te_idx] = yhat_best\n",
    "\n",
    "    return y_true_full, y_pred_full\n",
    "\n",
    "# =========================\n",
    "# TRAIN/EVAL por FOLD (con train/val/test desde Kfold5.json)\n",
    "# =========================\n",
    "def train_one_fold(fold:int, device):\n",
    "    # sujetos del fold (solo usamos listas train/test del JSON)\n",
    "    train_sub, test_sub = load_fold_subjects(FOLDS_JSON, fold)\n",
    "    train_sub = [s for s in train_sub if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "    test_sub  = [s for s in test_sub  if subject_id_to_int(s) not in EXCLUDE_SUBJECTS]\n",
    "\n",
    "    # split de validaci√≥n por sujetos desde train (estratificado por etiqueta dominante como en tu CNN+TF)\n",
    "    rng = np.random.RandomState(RANDOM_STATE + fold)\n",
    "    tr_subjects = sorted(train_sub)\n",
    "    if VAL_STRAT_SUBJECT and len(tr_subjects) > 1:\n",
    "        y_dom = build_subject_label_map(tr_subjects)\n",
    "        if np.any(y_dom < 0):\n",
    "            mask = y_dom >= 0\n",
    "            moda = int(np.bincount(y_dom[mask]).argmax()) if mask.sum() > 0 else 0\n",
    "            y_dom[~mask] = moda\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects) * VAL_SUBJECT_FRAC)))\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_val_subj, random_state=RANDOM_STATE + fold)\n",
    "        idx = np.arange(len(tr_subjects))\n",
    "        _, val_idx = next(sss.split(idx, y_dom))\n",
    "        val_subjects = sorted([tr_subjects[i] for i in val_idx])\n",
    "        train_subjects = [s for s in tr_subjects if s not in val_subjects]\n",
    "    else:\n",
    "        tr_subjects_shuf = tr_subjects.copy()\n",
    "        rng.shuffle(tr_subjects_shuf)\n",
    "        n_val_subj = max(1, int(round(len(tr_subjects_shuf) * VAL_SUBJECT_FRAC)))\n",
    "        val_subjects   = sorted(tr_subjects_shuf[:n_val_subj])\n",
    "        train_subjects = sorted(tr_subjects_shuf[n_val_subj:])\n",
    "\n",
    "    # cargar datos (SIN balanceo: todos los ensayos)\n",
    "    X_tr_list, y_tr_list = [], []\n",
    "    X_val_list, y_val_list = [], []\n",
    "    X_te_list, y_te_list = [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for sid in tqdm(train_subjects, desc=f\"Cargando train fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        X_tr_list.append(Xs); y_tr_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(val_subjects, desc=f\"Cargando val fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        X_val_list.append(Xs); y_val_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    for sid in tqdm(test_sub, desc=f\"Cargando test fold{fold}\"):\n",
    "        Xs, ys, sf = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        X_te_list.append(Xs); y_te_list.append(ys); sfreq = sf if sfreq is None else sfreq\n",
    "\n",
    "    # concatenar\n",
    "    X_tr = np.concatenate(X_tr_list, axis=0); y_tr = np.concatenate(y_tr_list, axis=0)\n",
    "    X_val = np.concatenate(X_val_list, axis=0); y_val = np.concatenate(y_val_list, axis=0)\n",
    "    X_te  = np.concatenate(X_te_list,  axis=0); y_te  = np.concatenate(y_te_list,  axis=0)\n",
    "\n",
    "    print(f\"[Fold {fold}/5] Entrenando modelo global... (n_train={len(y_tr)} | n_val={len(y_val)} | n_test={len(y_te)})\")\n",
    "\n",
    "    # estandarizaci√≥n por canal con stats de TRAIN\n",
    "    X_tr_std, X_val_std = standardize_per_channel_trainfit(X_tr, X_val)\n",
    "    _,        X_te_std  = standardize_per_channel_trainfit(X_tr, X_te)\n",
    "\n",
    "    # datasets ‚Üí tensores de entrada (B,1,T,C) para EEGNet\n",
    "    def to_tensor_1tC(X_TxC, y_idx):\n",
    "        xb = torch.tensor(X_TxC, dtype=torch.float32).unsqueeze(1)  # (B,1,T,C)\n",
    "        yb = torch.tensor(y_idx, dtype=torch.long)\n",
    "        return TensorDataset(xb, yb)\n",
    "\n",
    "    tr_ds  = to_tensor_1tC(X_tr_std, y_tr)\n",
    "    val_ds = to_tensor_1tC(X_val_std, y_val)\n",
    "    te_ds  = to_tensor_1tC(X_te_std,  y_te)\n",
    "\n",
    "    tr_ld  = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False, worker_init_fn=seed_worker)\n",
    "    val_ld = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "    te_ld  = DataLoader(te_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False, worker_init_fn=seed_worker)\n",
    "\n",
    "    # modelo + opt + scheduler\n",
    "    n_classes = 4\n",
    "    model = EEGNet(n_ch=8, n_classes=n_classes,\n",
    "                   F1=24, D=2, kernel_t=64, k_sep=16,\n",
    "                   pool1_t=4, pool2_t=6, drop1_p=0.35, drop2_p=0.6,\n",
    "                   chdrop_p=0.10).to(device)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=LR_INIT)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=SGDR_T0, T_mult=SGDR_Tmult)\n",
    "\n",
    "    # criterio suave ponderado (+20% Both Fists) con label smoothing\n",
    "    class_weights = make_class_weight_tensor(y_tr, n_classes, boost_bfists=1.25, boost_bfeet=1.05, device=device)\n",
    "    criterion_soft = WeightedSoftCrossEntropy(class_weights, label_smoothing=0.05)\n",
    "\n",
    "    # m√©tricas r√°pidas\n",
    "    @torch.no_grad()\n",
    "    def eval_acc(loader):\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            # TTA en validaci√≥n? Normalmente NO (dejamos off)\n",
    "            logits = model(xb)\n",
    "            pred = logits.argmax(dim=1).cpu().numpy()\n",
    "            y_true.append(yb.numpy()); y_pred.append(pred)\n",
    "        y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "        return (y_true == y_pred).mean()\n",
    "\n",
    "    # entrenamiento global (con augments estilo CNN+TF)\n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "    best_state = copy.deepcopy(model.state_dict()); best_val = -1.0; bad = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS_GLOBAL + 1):\n",
    "        model.train()\n",
    "        correct, seen = 0, 0\n",
    "        for xb, yb in tr_ld:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            # AUGMENTS (mismas ideas que CNN+TF)\n",
    "            xb = augment_batch_eegnet(xb,\n",
    "                                      p_jitter=0.35, p_noise=0.35, p_chdrop=0.15,\n",
    "                                      max_jitter_frac=0.03, noise_std=0.03, max_chdrop=1)\n",
    "            # loss suave (one-hot)\n",
    "            yt = torch.nn.functional.one_hot(yb, num_classes=n_classes).float()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion_soft(logits, yt)\n",
    "            loss.backward(); opt.step()\n",
    "            apply_max_norm(model, max_value=2.0, p=2.0)\n",
    "            correct += (logits.argmax(1) == yb).sum().item()\n",
    "            seen += yb.size(0)\n",
    "        scheduler.step(epoch - 1 + 1e-8)\n",
    "\n",
    "        tr_acc = correct / max(1, seen)\n",
    "        va_acc = eval_acc(val_ld)\n",
    "        history['train_acc'].append(tr_acc)\n",
    "        history['val_acc'].append(va_acc)\n",
    "\n",
    "        if (epoch % LOG_EVERY == 0) or epoch in (1, 10, 20, 50, 100):\n",
    "            cur_lr = opt.param_groups[0]['lr']\n",
    "            print(f\"  √âpoca {epoch:3d} | train_acc={tr_acc:.4f} | val_acc={va_acc:.4f} | LR={cur_lr:.5f}\")\n",
    "\n",
    "        if va_acc > best_val + 1e-4:\n",
    "            best_val = va_acc; best_state = copy.deepcopy(model.state_dict()); bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= GLOBAL_PATIENCE:\n",
    "                print(f\"  Early stopping en √©poca {epoch} (mejor val_acc={best_val:.4f})\")\n",
    "                break\n",
    "\n",
    "    # guardar curva\n",
    "    curve_path = f\"training_curve_fold{fold}.png\"\n",
    "    plot_training_curves(history, curve_path)\n",
    "    print(f\"‚Ü≥ Curva de entrenamiento guardada: {curve_path}\")\n",
    "\n",
    "    # cargar mejor estado\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    # ===== EVALUACI√ìN EN TEST (TTA estilo CNN+TF) =====\n",
    "    if (not SW_ENABLE) or SW_MODE == 'none':\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in te_ld:\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "                pred = logits.argmax(1).cpu().numpy()\n",
    "                y_true.append(yb.numpy()); y_pred.append(pred)\n",
    "        y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "    elif SW_MODE in ('tta', 'subwin'):\n",
    "        sfreq_used = int(round(X_te_std.shape[1] / (TMAX - TMIN)))  # T = X_te_std.shape[1]\n",
    "        logits_tta = None; logits_sw = None\n",
    "        if SW_MODE == 'tta':\n",
    "            logits_tta = time_shift_tta_logits_eegnet(model, X_te_std, sfreq_used, TTA_SHIFTS_S, device)\n",
    "        else:\n",
    "            # subwindow opcional; si quisieras activarlo, implementa an√°logo a tu CNN+TF\n",
    "            raise NotImplementedError(\"SW_MODE='subwin' no implementado aqu√≠ (se pidi√≥ TTA).\")\n",
    "        logits = logits_tta\n",
    "        y_pred = logits.argmax(axis=1); y_true = y_te\n",
    "    else:\n",
    "        raise ValueError(f\"SW_MODE desconocido: {SW_MODE}\")\n",
    "\n",
    "    acc_global = accuracy_score(y_true, y_pred)\n",
    "    f1m_global = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"[Fold {fold}/5] Global acc={acc_global:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASS_NAMES_4C, digits=4))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2,3]))\n",
    "\n",
    "    # ---------- Fine-tuning PROGRESIVO por sujeto (igual que antes) ----------\n",
    "    # agrupamos por sujeto en el TEST\n",
    "    # reconstruimos arrays por sujeto usando las mismas X_te_std/y_te\n",
    "    # Primero necesitamos el vector de sujetos por ensayo:\n",
    "    sub_te = []\n",
    "    for sid in test_sub:\n",
    "        Xs, ys, _ = load_subject_epochs(sid)\n",
    "        if len(ys) == 0: continue\n",
    "        sub_te += [subject_id_to_int(sid)] * len(ys)\n",
    "    sub_te = np.array(sub_te, dtype=int)\n",
    "\n",
    "    y_true_ft_all, y_pred_ft_all = [], []\n",
    "    used_subjects = 0\n",
    "    for sid in np.unique(sub_te):\n",
    "        idx = np.where(sub_te == sid)[0]\n",
    "        Xs_TxC = X_te_std[idx]\n",
    "        ys_sub = y_te[idx]\n",
    "        if len(ys_sub) < CALIB_CV_FOLDS or len(np.unique(ys_sub)) < 2:\n",
    "            continue\n",
    "        y_true_subj, y_pred_subj = subject_cv_finetune_predict_progressive(\n",
    "            model, Xs_TxC, ys_sub, DEVICE, n_splits=CALIB_CV_FOLDS, n_classes=4\n",
    "        )\n",
    "        y_true_ft_all.append(y_true_subj); y_pred_ft_all.append(y_pred_subj)\n",
    "        used_subjects += 1\n",
    "\n",
    "    if len(y_true_ft_all) > 0:\n",
    "        y_true_ft_all = np.concatenate(y_true_ft_all)\n",
    "        y_pred_ft_all = np.concatenate(y_pred_ft_all)\n",
    "        acc_ft = (y_true_ft_all == y_pred_ft_all).mean()\n",
    "        print(f\"  Fine-tuning PROGRESIVO (por sujeto, {CALIB_CV_FOLDS}-fold CV) acc={acc_ft:.4f} | sujetos={used_subjects}\")\n",
    "        print(f\"  Œî(FT-Global) = {acc_ft - acc_global:+.4f}\")\n",
    "    else:\n",
    "        acc_ft = np.nan\n",
    "        print(\"  Fine-tuning PROGRESIVO no ejecutado (sujeto(s) con muestras insuficientes).\")\n",
    "\n",
    "    # matriz de confusi√≥n global (sin FT)\n",
    "    cm_png = f\"confusion_global_fold{fold}.png\"\n",
    "    plot_confusion(y_true, y_pred, CLASS_NAMES_4C, title=f\"Confusion Matrix - Fold {fold}\", fname=cm_png)\n",
    "    print(f\"‚Ü≥ Matriz de confusi√≥n guardada: {cm_png}\")\n",
    "\n",
    "    return acc_global, f1m_global, acc_ft\n",
    "\n",
    "# =========================\n",
    "# LOOP 5 FOLDS + RESUMEN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üß† INICIANDO EXPERIMENTO CON EEGNet + Augments/TTA estilo CNN+TF (sin balanceo)\")\n",
    "    print(f\"üîß Configuraci√≥n: 4c, 8 canales, 6s | EPOCHS_GLOBAL={EPOCHS_GLOBAL}, BATCH={BATCH_SIZE}, LR={LR_INIT} | ZSCORE_PER_EPOCH={NORM_EPOCH_ZSCORE}\")\n",
    "    acc_folds, f1_folds = [], []\n",
    "    ft_folds = []\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        acc, f1m, acc_ft = train_one_fold(fold, DEVICE)  # <-- recibe acc_ft\n",
    "        acc_folds.append(f\"{acc:.4f}\")\n",
    "        f1_folds.append(f\"{f1m:.4f}\")\n",
    "        # Permite NaN si alg√∫n sujeto no tuvo muestras suficientes para FT\n",
    "        ft_folds.append(\"nan\" if (acc_ft is None or (isinstance(acc_ft, float) and np.isnan(acc_ft))) else f\"{acc_ft:.4f}\")\n",
    "\n",
    "    acc_mean = float(np.mean([float(a) for a in acc_folds]))\n",
    "    f1_mean  = float(np.mean([float(f) for f in f1_folds]))\n",
    "    # Media de FT ignorando 'nan'\n",
    "    ft_vals = [float(x) for x in ft_folds if x != \"nan\"]\n",
    "    ft_mean = float(np.mean(ft_vals)) if len(ft_vals) > 0 else float(\"nan\")\n",
    "    delta_mean = (ft_mean - acc_mean) if len(ft_vals) > 0 else float(\"nan\")\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"RESULTADOS FINALES\")\n",
    "    print(\"============================================================\")\n",
    "    print(f\"Global folds (ACC): {acc_folds}\")\n",
    "    print(f\"Global mean ACC: {acc_mean:.4f}\")\n",
    "    print(f\"F1 folds (MACRO): {f1_folds}\")\n",
    "    print(f\"F1 mean (MACRO): {f1_mean:.4f}\")\n",
    "    # ---- NUEVO BLOQUE RESUMEN FT ----\n",
    "    print(f\"Fine-tune PROGRESIVO folds: {ft_folds}\")\n",
    "    if len(ft_vals) > 0:\n",
    "        print(f\"Fine-tune PROGRESIVO mean: {ft_mean:.4f}\")\n",
    "        print(f\"Œî(FT-Global) mean: {delta_mean:+.4f}\")\n",
    "    else:\n",
    "        print(\"Fine-tune PROGRESIVO mean: nan\")\n",
    "        print(\"Œî(FT-Global) mean: nan\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
