# Proyecto EEG MI ‚Äî Primer Avance

Este repositorio contiene el trabajo inicial de an√°lisis y preprocesamiento de se√±ales EEG de **imaginaci√≥n motora (MI)**, as√≠ como la implementaci√≥n del primer modelo base **FBCSP + LDA**.  

A continuaci√≥n se describen las fases clave desarrolladas hasta el momento.

---

## 1. EDA de datos RAW

Antes de cualquier limpieza se realiz√≥ un **an√°lisis exploratorio de los datos crudos** (`data/raw`) con los siguientes objetivos:

- **Inventario de archivos:** verificaci√≥n de sujetos disponibles y runs por sujeto.
- **Conteo de eventos por clase:** Left, Right, Both Fists, Both Feet, Rest.
- **Amplitud extrema:** c√°lculo de percentil 99 (`p99_uV`) y desviaci√≥n est√°ndar por canal (`std_uV`) para detectar outliers.
- **Artefactos musculares (EMG):** estimados mediante la **relaci√≥n de potencia 20‚Äì40 Hz** en los canales motores.
- **PSD (densidad espectral de potencia):** inspecci√≥n en C3, Cz, C4.
- **Separabilidad inicial:** an√°lisis con **t-SNE** sobre log-varianza de las √©pocas.

**Hallazgos importantes en RAW:**
- Gran variabilidad inter-sujetos en amplitud (50‚Äì300 ŒºV).
- Presencia de ruido y artefactos musculares en varios sujetos.
- La mayor√≠a de sujetos muestran **silhouette score negativo** ‚Üí baja separabilidad entre clases en el estado crudo.
- Dataset heterog√©neo, requiere un pipeline de preprocesamiento robusto.

---

## 2. Pipeline de Preprocesamiento

El preprocesamiento busca limpiar los EEG y asegurar que las features extra√≠das representen la actividad neuronal y no artefactos.


### Explicaci√≥n paso a paso

1. **Normalizaci√≥n de nombres y montaje**  
   - Estandarizaci√≥n de canales y asignaci√≥n al sistema 10‚Äì20.  
   - Permite localizar f√°cilmente C3, Cz y C4, fundamentales en MI.

2. **Filtro Notch**  
   - Remueve interferencia el√©ctrica de 50/60 Hz.  
   - Evita que el ruido de la red contamine las bandas mu y beta.

3. **Clipping de amplitud**  
   - **Softclip:** aten√∫a valores extremos sin descartarlos.  
   - **Hardclip:** elimina √©pocas con amplitudes fuera de rango.  
   - Previene que outliers extremos dominen el entrenamiento.

4. **Filtro Bandpass (8‚Äì30 Hz)**  
   - A√≠sla las bandas mu (8‚Äì12 Hz) y beta (13‚Äì30 Hz).  
   - Son las m√°s asociadas a imaginaci√≥n motora.

5. **ICA (FastICA / Picard)**  
   - Separa fuentes independientes y elimina componentes de artefactos:  
     - Oculares (EOG),  
     - Musculares (EMG),  
     - Cardiacos (ECG).  
   - Esencial para mejorar la pureza de las se√±ales.

6. **Segmentaci√≥n en epochs**  
   - Ventana de **0.5‚Äì4.5 s post-est√≠mulo**.  
   - Captura la actividad cortical durante la tarea, evitando ruido al inicio/final.

7. **Rechazo autom√°tico de √©pocas**  
   - Se eliminan ensayos con amplitudes excesivas (peak-to-peak).  
   - Garantiza un set final m√°s balanceado y limpio.

8. **Exportaci√≥n en formato FIF**  
   - Archivos por sujeto (`Sxxx_MI-epo.fif`).  
   - Estandariza y permite reutilizar f√°cilmente con MNE y modelos posteriores.

**Resultados del preprocesamiento:**
- Reducci√≥n significativa de amplitudes extremas.  
- Menor presencia de artefactos EMG.  
- Balance de clases m√°s uniforme por sujeto.  
- Mejora en separabilidad en varios sujetos (Œî silhouette > 0).  

---

## 3. EDA de datos POST

Una vez aplicado el pipeline, se evaluaron nuevamente los datos procesados (`data/processed`) con m√©tricas y visualizaciones:

- **Conteo de √©pocas por sujeto y clase** ‚Üí para verificar balance.
- **PSD en C3, Cz, C4 por clase** ‚Üí confirmaci√≥n de la actividad en bandas mu/beta.
- **Topomapas de potencia** en bandas mu y beta ‚Üí patrones espaciales de activaci√≥n.
- **QA autom√°tico:** detecci√≥n de sujetos problem√°ticos (muy pocas √©pocas, EMG residual alto, silhouette muy negativo).
- **Comparaci√≥n RAW vs POST**:  
  - Œî silhouette ‚Üí mejora en separabilidad de clases.  
  - Œî amplitud extrema (`p99_uV`) ‚Üí reducci√≥n de outliers.  
  - EMG ratio ‚Üí ca√≠da en la mayor√≠a de sujetos.

**Hallazgos importantes en POST:**
- Disminuci√≥n clara en amplitudes extremas y ruido.  
- Aumento en la calidad de √©pocas disponibles.  
- Mejor diferenciaci√≥n de clases en varios sujetos.  
- Sin embargo, algunos sujetos siguen presentando problemas de EMG o baja separabilidad, que deber√°n manejarse con **flags de QA** en futuras iteraciones.

---

## Conclusi√≥n preliminar

El **pipeline de preprocesamiento** aplicado transforma un dataset crudo, heterog√©neo y ruidoso, en un conjunto m√°s limpio y balanceado. Esto sienta las bases para los experimentos con modelos como **FBCSP + LDA** y, en fases posteriores, comparaciones con **SVM, Riemannianos y redes profundas**.

--- 

## 4. FBCSP + LDA

**Objetivo:** clasificar EEG de *Motor Imagery* (Œº/Œ≤) usando **Filter-Bank CSP (FBCSP)** + **LDA con shrinkage**.  
Se eval√∫a en dos configuraciones: **INTRA-subject** (K-Fold por ensayos) y **INTER-subject** (folds predefinidos por sujetos desde JSON, con **validaci√≥n interna por sujetos** y opci√≥n de **calibraci√≥n**).

### Pipeline
1. **Carga y recorte** de √©pocas MNE (`.fif`) con ventana fija `crop_window` (p. ej., 0.5‚Äì3.5 s).
2. **Selecci√≥n de canales motores** (opcional): `C3, CZ, C4, FC3, FC4, CP3, CPZ, CP4`; alineaci√≥n de canales en VAL/TEST con `reorder_channels`.
3. **Banco de filtros** (Œº/Œ≤): subbandas densas de 2 Hz entre 8‚Äì30 Hz (11 bandas).
4. **CSP por subbanda**: `n_csp` componentes, `reg='ledoit_wolf'`, `log=True` (devuelve vectores de varianzas proyectadas).  
   - **Fit** con **solo TRAIN** del fold; **transform** en VAL/TEST.
5. **Concatenaci√≥n de features** de todas las subbandas.
6. **Estandarizaci√≥n** (z-score de features) con `StandardScaler` (fit en TRAIN).
7. **Clasificador**: `LDA(solver='lsqr', shrinkage='auto')`.

### FBCSP + LDA (features)
Para cada sub-banda (8‚Äì30 Hz, pasos de 2 Hz):
1) Filtramos; 
2) Ajustamos **CSP** en TRAIN y transformamos VAL/TEST;  
3) Calculamos **log-varianzas** de las `n_csp` componentes;  
4) **Concatenamos** features de todas las sub-bandas.  
Luego estandarizamos y clasificamos con **LDA (shrinkage)**.

### Evaluaciones
- **INTRA-subject** (`run_intra_all`):
  - `StratifiedKFold(k)` por sujeto (split por ensayos).
  - M√©tricas: Accuracy y F1-macro por fold; promedio ¬± DE por sujeto; fila **GLOBAL**.
  - Artefactos: CSV, TXT, figuras de matrices de confusi√≥n (mosaicos).

- **INTER-subject** (`run_inter_subject_cv_from_json`):
  - Folds desde JSON (`train/test` por sujetos).
  - **Validaci√≥n interna por sujetos**: fracci√≥n `val_ratio_subjects` dentro de TRAIN para ajuste/selecci√≥n.
  - Calibraci√≥n per-subject (k-shots): Para cada sujeto de test, tomamos **k=5** √©pocas por clase como **calibraci√≥n** y evaluamos en el resto de sus √©pocas. Durante la calibraci√≥n se re-ajustan **FBCSP** (fit con TRAIN + k-shots del propio sujeto) y **LDA** (tras estandarizaci√≥n). Este esquema refleja el uso real de BCI: una **breve sesi√≥n inicial** de calibraci√≥n por usuario mejora sustancialmente la transferencia inter-sujeto.
  - M√©tricas: VAL (acc, F1-macro) y TEST (acc, F1-macro) por fold + **GLOBAL**.
  - Artefactos: CSV consolidado, TXT de m√©tricas, TXT con `classification_report` por fold, figuras de confusi√≥n por fold y **GLOBAL**.

### Antileakage y reproducibilidad
- CSP, scaler y LDA se ajustan **exclusivamente** con TRAIN del fold (o TRAIN+CALIB si la calibraci√≥n est√° activa).  
- VAL/TEST s√≥lo se **transforman**.  
- Canales de VAL/TEST se **reordenan** para coincidir con TRAIN.  
- Se generan logs con timestamp y par√°metros para auditor√≠a.

### Principales hiperpar√°metros
- `crop_window=(0.5, 3.5)` s  
- `motor_only=True | False`  
- `zscore_epoch=True | False` (z-score por √©poca previo a CSP)  
- `fb_bands`: denso (2 Hz) de 8‚Äì30 Hz  
- `n_csp`: t√≠picamente 4‚Äì8 (p. ej., 4 √≥ 6)  
- `val_ratio_subjects‚âà0.16`, `calibrate_n` (s√≥lo INTER)

### Salidas
- **Tablas** (`/models/fbcsp_lda/tables`): CSV de m√©tricas con fila GLOBAL.
- **Logs** (`/models/fbcsp_lda/logs`): TXT de m√©tricas y `classification_reports_by_fold_*.txt`.
- **Figuras** (`/models/fbcsp_lda/figures`): matrices de confusi√≥n por sujeto/fold y GLOBAL.

> **Nota:** El mapeo de clases usa `LabelEncoder` para asegurar etiquetas consistentes. No influye en la se√±al ni en par√°metros del modelo.

## 5. Modelo Riemanniano para MI-EEG (MDM / FgMDM)

**Resumen.** Cada √©poca se representa por su **matriz de covarianza SPD** (SPD significa Symmetric Positive Definite) por sub-banda (8‚Äì30 Hz), y se clasifica por **distancia geod√©sica** a las medias de clase en la geometr√≠a Riemanniana (pyRiemann). Usamos **OAS** como estimador de covarianza y **normalizaci√≥n por traza** para estabilizar escala. Dos variantes:
- **MDM**: Minimum Distance to Mean sobre un **bloque-diagonal** que apila las covariancias de todas las bandas.
- **FgMDM**: Filter-geodesic MDM, que **agrega en el manifold** la informaci√≥n multi-banda.

**Preprocesado.**
- Ventana temporal: `crop_window=(0.5, 3.5)` (configurable).
- Canales: `motor_only=True` (C3, Cz, C4, FC3/4, CP3/z/4).
- Banco de bandas: denso 8‚Äì30 Hz, paso 2 Hz.
- Covarianza: `Covariances(estimator='oas')` + normalizaci√≥n por traza.

**Validaciones.**
- **INTRA-sujeto (k-fold)**: 5 folds estratificados dentro de cada sujeto; m√©tricas por sujeto + GLOBAL.
- **INTER-sujeto (folds JSON)**: split de **validaci√≥n por sujetos** dentro de TRAIN; ajuste del espacio **solo con TRAIN**; m√©tricas en VALID y TEST; **matriz de confusi√≥n global** y `classification_report` por fold.

**Calibraci√≥n per-subject (k-shots, recomendada).**
Para cada sujeto de TEST, tomamos **k=5** √©pocas por clase como **calibraci√≥n**, recomputamos el espacio con `TRAIN + CALIB_del_sujeto` y **evaluamos en el resto** de sus √©pocas. Refleja el uso real de BCI con una **breve sesi√≥n inicial** de calibraci√≥n por usuario. (Alternativamente, se puede calibrar con **n sujetos completos** del TEST si el escenario lo requiere.)

**Features (Riemann).** Cada √©poca se representa por **matrices de covarianza SPD** por sub-banda (estimador OAS + normalizaci√≥n por traza).  
**Geometr√≠a.** Las SPD viven en un manifold; usamos **distancia geod√©sica Riemanniana** (afin-invariante) para comparar.  
**Clasificadores.**  
- **MDM**: calcula la **media Riemanniana** por clase y predice por **distancia al centroide**. Multi-banda v√≠a **bloque diagonal**.  
- **FgMDM**: mantiene **una SPD por banda** y **agrega geod√©sicamente** la info multi-banda; suele rendir mejor.  
**En este repo:** `model='fgmdm'` (por defecto en inter-sujeto) ‚áí el clasificador activo es **FgMDM**.


---

# üß† EEGNet (4 clases, 8 canales) con Augmentaciones, TTA y Fine-Tuning Progresivo

Este proyecto implementa un clasificador EEGNet en PyTorch para se√±ales EEG de imaginaci√≥n motora (MI-EEG), con:
- Entrenamiento global (5 folds) sobre datos sin balancear por sujeto/clase.
- **Augmentaciones (jitter, ruido, channel-drop)** inspiradas en CNN+Transformer.
- **SGDR (CosineAnnealingWarmRestarts)** para ajustar la tasa de aprendizaje.
- **Label smoothing**, **pesos por clase** y **max-norm** como regularizaciones.
- **Test-Time Augmentation (TTA)** por desplazamientos temporales.
- **Fine-Tuning progresivo** por sujeto con penalizaci√≥n L2SP.

---

## üì¶ Estructura general

| Bloque | Descripci√≥n |
|:--|:--|
| **Carga de datos** | Lectura de archivos EDF, extracci√≥n de epochs `[-1,5]s`, selecci√≥n de 8 canales, z-score por √©poca. |
| **Normalizaci√≥n** | Estandarizaci√≥n por canal usando estad√≠sticas del conjunto de entrenamiento. |
| **Modelo** | EEGNet con filtros temporales y espaciales separables, salida lineal para 4 clases. |
| **Entrenamiento global** | Augments + SGDR + label smoothing + pesos por clase + max-norm. |
| **Evaluaci√≥n (Test)** | TTA por *time-shifts* y m√©tricas (ACC, F1, matriz de confusi√≥n). |
| **Fine-tuning progresivo** | Adaptaci√≥n por sujeto con L2SP y congelamiento progresivo de capas. |

---

## ‚öôÔ∏è Configuraci√≥n global (hiperpar√°metros)

| Categor√≠a | Par√°metro | Valor | Explicaci√≥n |
|:--|:--|:--|:--|
| Datos | FS | 160 Hz | Frecuencia de muestreo objetivo |
| | TMIN/TMAX | -1.0 / 5.0 s | Ventana temporal de cada ensayo |
| | EXPECTED_8 | C3,C4,Cz,CP3,CP4,FC3,FC4,FCz | Canales usados |
| | NORM_EPOCH_ZSCORE | True | Z-score por √©poca y canal |
| Split | VAL_SUBJECT_FRAC | 0.18 | % de sujetos usados como validaci√≥n |
| | VAL_STRAT_SUBJECT | True | Validaci√≥n estratificada por etiqueta dominante |
| Train | EPOCHS_GLOBAL | 100 | √âpocas m√°ximas |
| | BATCH_SIZE | 64 | Tama√±o de batch |
| | LR_INIT | 1e-2 | Tasa inicial de aprendizaje |
| | SGDR_T0 / SGDR_Tmult | 6 / 2 | Ciclos coseno: 6, 12, 24‚Ä¶ |
| | GLOBAL_PATIENCE | 10 | Early stopping |
| EEGNet | F1 / D | 24 / 2 | Filtros temporales y multiplicador depthwise |
| | kernel_t / k_sep | 64 / 16 | Kernels temporal y separable |
| | pool1_t / pool2_t | 4 / 6 | Reducci√≥n temporal por bloque |
| | drop1_p / drop2_p | 0.35 / 0.6 | Dropout |
| | chdrop_p | 0.10 | Channel dropout |
| Loss | label_smoothing | 0.05 | Suavizado de etiquetas |
| | boost (clase 2/3) | 1.25 / 1.05 | Pesos extra para clases raras |
| Augments | p_jitter / p_noise / p_chdrop | 0.35 / 0.35 / 0.15 | Probabilidad de aplicar cada tipo |
| | max_jitter_frac / noise_std | 0.03 / 0.03 | Magnitud del jitter y ruido |
| TTA | shifts_s | ¬±0.075,‚Ä¶,0 s | Desplazamientos en inferencia |
| FT | CALIB_CV_FOLDS | 4 | Folds internos por sujeto |
| | FT_EPOCHS | 30 | √âpocas por modo |
| | FT_HEAD_LR / FT_BASE_LR | 1e-3 / 5e-5 | LR para cabeza y base |
| | FT_L2SP | 1e-4 | Penalizaci√≥n de alejamiento de pesos globales |
| | FT_PATIENCE / FT_VAL_RATIO | 5 / 0.2 | Early stopping y validaci√≥n interna |

---

## üß† Arquitectura EEGNet

### Estructura general
Entrada: `(B, 1, T, C)` ‚Üí Salida: `(B, 4)`  
(`B`: batch, `T`: tiempo ‚âà 960, `C`: canales=8)

1. **ChannelDropout (p=0.10)**  
   Apaga canales completos aleatoriamente (simula fallos de electrodos).

2. **Bloque temporal**
   ```python
   Conv2d(1 ‚Üí F1, kernel=(64,1)) ‚Üí BN ‚Üí ELU
   ```
   Extrae patrones de oscilaci√≥n y filtros pasa-banda temporales.

3. **Bloque espacial (depthwise)**
   ```python
   Conv2d(F1 ‚Üí F1*D, kernel=(1, n_ch), groups=F1)
   AvgPool2d(4,1) ‚Üí Dropout(0.35)
   ```
   Aprende combinaciones espaciales (proyecciones de canales) por cada filtro temporal.

4. **Bloque separable temporal**

   ```python
   Conv2d(F2 ‚Üí F2, kernel=(16,1), groups=F2)
   Conv2d(F2 ‚Üí F2, kernel=(1,1))
   AvgPool2d(6,1) ‚Üí Dropout(0.6)
   ```
   Refina din√°micas temporales espec√≠ficas con pocos par√°metros.

5. **Head**

   ```python
   Flatten ‚Üí Linear(1920‚Üí128) ‚Üí ELU ‚Üí Linear(128‚Üí4)
   ```
   Proyecci√≥n final a clases.

## üß© Entrenamiento global

- **Optimizador:** Adam (`LR inicial = 1e-2`)
- **Scheduler:** CosineAnnealingWarmRestarts (SGDR)  
  - Ciclos: 6, 12, 24, 48 √©pocas‚Ä¶  
  - Cada reinicio restablece el LR alto para explorar nuevos m√≠nimos.
- **Augmentaciones:** jitter temporal, ruido gaussiano, channel-drop
- **P√©rdida:** Weighted Soft CrossEntropy con *label smoothing* (0.05)
- **Regularizaciones:**
  - Max-norm = 2.0 (filtros espaciales y FC)
  - Dropout + ChannelDropout
  - Label smoothing + pesos por clase

## üîÑ CosineAnnealingWarmRestarts (SGDR)

Controla la **tasa de aprendizaje (LR)** de forma c√≠clica, alternando fases de exploraci√≥n y refinamiento.

### üß† Intuici√≥n
- **Grandes saltos** ‚Üí explora nuevos m√≠nimos.  
- **LR peque√±o** ‚Üí refina soluciones locales.  
- **Reinicios** ‚Üí permite escapar de m√≠nimos sub√≥ptimos.

### ‚öôÔ∏è Par√°metros
- **T‚ÇÄ = 6** ‚Üí duraci√≥n del primer ciclo (√©pocas).  
- **T_mult = 2** ‚Üí cada ciclo siguiente dura el doble: 6, 12, 24, 48, ‚Ä¶

El LR se reinicia al valor inicial en cada ciclo, generando una curva coseno decreciente dentro de cada fase.

### üí° Consejos pr√°cticos
| Situaci√≥n | Ajuste recomendado |
|:--|:--|
| `val_acc` oscila mucho | Aumenta **T‚ÇÄ** o reduce **LR_INIT** |
| Entrenamiento estancado | Sube **LR_INIT** o acorta **T‚ÇÄ** |

‚ú® **Idea clave:** equilibrar exploraci√≥n (LR alto) y refinamiento (LR bajo) para alcanzar mejores m√≠nimos sin sobreentrenar.

## üåà Augmentaciones (entrenamiento)

Tres transformaciones principales se aplican por batch (B, 1, T, C):

### 1Ô∏è‚É£ Jitter temporal
Desplaza la se√±al unos milisegundos (roll en el eje temporal).  
**max_jitter_frac = 0.03**  ‚Üí ¬±180 ms para 6 s (T‚âà960)  

**Motivo:** simula peque√±as desincronizaciones del inicio del ensayo (onset).  
**Rango t√≠pico:** 0.02‚Äì0.05 (¬±120‚Äì300 ms).  

---

### 2Ô∏è‚É£ Ruido gaussiano
**noise_std = 0.03**  

**Motivo:** mejora la robustez frente a ruido fisiol√≥gico y electr√≥nico.  
**Rango recomendado:** œÉ = 0.01‚Äì0.05 para se√±ales EEG normalizadas (z-scoreadas).  

---

### 3Ô∏è‚É£ Channel-drop
**p_chdrop = 0.15**, **max_chdrop = 1**  

**Motivo:** incrementa la robustez espacial ante la p√©rdida o mal contacto de electrodos.  
**Recomendaci√≥n:** apagar 1‚Äì2 canales cuando se trabaja con 8 canales totales.  

## üß± Regularizaciones

### üß© Label Smoothing (Œµ=0.05)
Suaviza las etiquetas para evitar sobreconfianza:

**F√≥rmula:**
\[
\tilde{y} = (1 - \varepsilon) \cdot \text{one\_hot} + \frac{\varepsilon}{K}
\]

Esto reduce la probabilidad de que el modelo se vuelva demasiado confiado en una sola clase, mejorando la **calibraci√≥n** de las predicciones.

---

### ‚öñÔ∏è Pesos por clase
Para corregir el desbalance de clases en el entrenamiento se asignan pesos distintos a las clases minoritarias:

- **Clase 2 (Both Fists):** √ó1.25  
- **Clase 3 (Both Feet):** √ó1.05  

Esto aumenta la contribuci√≥n de las clases menos frecuentes en la funci√≥n de p√©rdida y ayuda a equilibrar el rendimiento entre categor√≠as.

---

### üßÆ Max-Norm
Se aplica un l√≠mite **L2 m√°ximo (2.0)** sobre los pesos de los filtros.  
Este m√©todo evita la explosi√≥n de pesos y mejora la **estabilidad del entrenamiento**.  
Si el modelo sobreajusta, se puede reducir el l√≠mite a 1.8; si no aprende bien, puede aumentarse a 2.5‚Äì3.0.

---

## üîÆ Inferencia: Test-Time Augmentation (TTA)

Durante la fase de inferencia, cada se√±al EEG se **desplaza ligeramente en el tiempo** y se promedian las predicciones (logits) para mejorar la robustez.

**Desplazamientos usados (en segundos):**  
[-0.075, -0.05, -0.025, 0, +0.025, +0.05, +0.075]

**Prop√≥sito:**  
Aumentar la resistencia a peque√±as desalineaciones temporales entre ensayos.

**Costo:**  
Proporcional al n√∫mero de desplazamientos (m√°s TTA = m√°s tiempo de inferencia).

**Recomendaciones:**
- M√°ximo rendimiento: usar 5‚Äì7 desplazamientos.  
- Cuando el tiempo sea cr√≠tico: usar 3 desplazamientos ([-0.05, 0, +0.05]).

---

## üîß Fine-Tuning progresivo por sujeto

Cada sujeto de test se adapta mediante **fine-tuning** interno (4 folds por sujeto), ajustando partes espec√≠ficas del modelo sin olvidar el conocimiento global.

**Modos de ajuste:**
- **out:** solo la capa de salida  
- **head:** capa totalmente conectada + salida  
- **spatial+head:** bloque espacial + cabeza del modelo  

**Par√°metros clave:**
- LR base: 5e-5  
- LR cabeza: 1e-3  
- L2SP: 1e-4  
- Patience (early stopping): 5  
- Validaci√≥n interna: 20%  

El objetivo es **personalizar el modelo a cada sujeto** preservando las representaciones generales aprendidas.

---

## üìä M√©tricas y salidas

- **Accuracy global** y **F1 macro** promedio.  
- Curvas de entrenamiento: `training_curve_foldX.png`  
- Matrices de confusi√≥n: `confusion_global_foldX.png`  
- Resultados del fine-tuning: `acc_global`, `acc_ft` y diferencia `Œî(FT-Global)`.

---

## üí° Cheatsheet de ajuste

| Problema | Causa posible | Soluci√≥n sugerida |
|:--|:--|:--|
| **Overfitting (Train‚Üë, Val‚Üì)** | Modelo muy complejo o augmentaciones suaves | Subir dropout, aumentar Œµ de Label Smoothing, reducir F1 |
| **Underfitting (Train‚Üì, Val‚Üì)** | LR demasiado bajo o augmentaciones muy fuertes | Aumentar LR, reducir ruido/jitter |
| **Oscilaciones en validaci√≥n** | LR alto o ciclos SGDR muy cortos | Aumentar T‚ÇÄ o reducir LR inicial |
| **Mala precisi√≥n en clases 2/3** | Pocas muestras o sin boost | Subir pesos (1.4 / 1.2) |
| **Modelo inestable** | Max-norm demasiado alto | Bajar a 1.8‚Äì2.0 |

---


## üßÆ Flujo resumido del pipeline
```bash
raw EDF ‚îÄ‚ñ∫ selecci√≥n de 8 canales
        ‚îî‚ñ∫ epoch [-1, 5] s @160 Hz
            ‚îî‚ñ∫ z-score por √©poca
                ‚îî‚ñ∫ split Kfold5 (train/val/test)
                    ‚îî‚ñ∫ estandarizaci√≥n canal-fit(train)
                        ‚îî‚ñ∫ EEGNet + Augments
                            ‚îî‚ñ∫ Train con SGDR
                                ‚îî‚ñ∫ Test con TTA
                                    ‚îî‚ñ∫ Fine-tuning por sujeto (L2SP)
```

---

# üß† Arquitectura CNN + Transformer para EEG Motor Imagery

Este documento describe detalladamente la arquitectura h√≠brida **CNN + Transformer** usada para clasificar se√±ales EEG (motor imagery), los **hiperpar√°metros**, la **estrategia de entrenamiento**, y t√©cnicas como **EMA**, **warmup scheduler** y **fine-tuning por sujeto**.

---

## ‚öôÔ∏è 1. Flujo general del pipeline

```text
EEG EDF Files
   ‚îÇ
   ‚îú‚îÄ‚îÄ Preprocesamiento (notch, filtro, zscore)
   ‚îÇ
   ‚îú‚îÄ‚îÄ Divisi√≥n por sujetos (train / val / test)
   ‚îÇ
   ‚îú‚îÄ‚îÄ CNN temporal ‚Üí Extracci√≥n de patrones locales
   ‚îÇ
   ‚îú‚îÄ‚îÄ Proyecci√≥n ‚Üí tokens (d_model)
   ‚îÇ
   ‚îú‚îÄ‚îÄ Transformer Encoder ‚Üí atenci√≥n temporal
   ‚îÇ
   ‚îú‚îÄ‚îÄ Token CLS ‚Üí Head lineal
   ‚îÇ
   ‚îú‚îÄ‚îÄ Entrenamiento con Focal Loss + Warmup + EMA
   ‚îÇ
   ‚îî‚îÄ‚îÄ Fine-tuning por sujeto (4-fold CV)
```

---

## üß± 2. Arquitectura de la CNN

La parte convolucional del modelo extrae **patrones espacio-temporales** del EEG.  

### Flujo de capas
```mermaid
graph TD
    A[EEG 8xT] --> B[Conv1D 8‚Üí32, k=129, s=2]
    B --> C[DepthwiseSepConv 32‚Üí64]
    C --> D[DepthwiseSepConv 64‚Üí128]
    D --> E[Conv1D 128‚Üíd_model (1x1)]
    E --> F[Feature Map (d_model x T‚Ä≤)]
```

### Detalles
| Capa | Descripci√≥n |
|:--|:--|
| **Conv1D 8‚Üí32** | Captura patrones largos (~1 s). Reduce T a la mitad (stride=2). |
| **Depthwise Separable Conv** | Divide la convoluci√≥n en ‚Äúpor canal‚Äù y ‚Äúmezcla de canales‚Äù para reducir par√°metros. |
| **GroupNorm + ELU** | Normaliza por grupos y usa activaci√≥n ELU para estabilidad. |
| **Dropout (p_drop)** | Evita sobreajuste. |
| **Conv1D 1√ó1 ‚Üí d_model** | Proyecta las features al espacio de embedding del Transformer. |

El n√∫mero de filtros crece (32‚Üí64‚Üí128) para permitir que capas m√°s profundas aprendan representaciones m√°s abstractas y ricas.  
Mientras tanto, la longitud temporal `T` se reduce con strides (`T‚Ä≤ ‚âà T / 8`).

---

## üî∫ 3. Arquitectura del Transformer Encoder

El Transformer modela dependencias **de largo alcance** en el tiempo entre los tokens de EEG.

### Flujo de procesamiento
```mermaid
graph TD
    A[Feature Map + PosEnc] --> B[Add CLS Token]
    B --> C[Multi-Head Self-Attention]
    C --> D[Add & Norm]
    D --> E[Feedforward Network 2√ód_model]
    E --> F[Add & Norm]
    F --> G[Repeat N_LAYERS]
    G --> H[CLS ‚Üí Linear Head ‚Üí Probabilidades]
```

### M√≥dulos internos
| Componente | Descripci√≥n |
|:--|:--|
| **Positional Encoding** | Suma se√±ales sinusoidales para indicar posici√≥n temporal. |
| **Token [CLS]** | Representaci√≥n global que resume toda la secuencia. |
| **Multi-Head Attention (MHA)** | Cada cabeza aprende relaciones distintas entre tiempos. |
| **Feedforward Network (FFN)** | Dos capas lineales (2√ód_model) con GELU y Dropout. |
| **LayerNorm + Residuals** | Aumenta estabilidad y flujo del gradiente. |
| **N_LAYERS** | Controla cu√°ntas veces se repite el bloque completo. |

---

## ‚öôÔ∏è 4. Hiperpar√°metros explicados

### üß© Entrenamiento
| Par√°metro | Descripci√≥n |
|:--|:--|
| `EPOCHS` | √âpocas m√°ximas de entrenamiento. |
| `BATCH_SIZE` | Cu√°ntas muestras se procesan por iteraci√≥n. |
| `BASE_LR` | Tasa de aprendizaje inicial. |
| `WARMUP_EPOCHS` | √âpocas donde el LR aumenta gradualmente (warmup). |
| `PATIENCE` | N√∫mero de √©pocas sin mejora antes de detener. |

### ‚ö° Preprocesamiento EEG
| Par√°metro | Funci√≥n |
|:--|:--|
| `DO_NOTCH` | Aplica filtro notch (60 Hz). |
| `DO_BANDPASS`, `BP_LO`, `BP_HI` | Filtro pasa banda entre 4‚Äì38 Hz (motor imagery). |
| `DO_CAR` | Referencia com√∫n. |
| `ZSCORE_PER_EPOCH` | Normaliza cada √©poca individualmente. |
| `RESAMPLE_HZ` | Nueva frecuencia de muestreo (si se usa). |

### üß† Modelo CNN + Transformer
| Par√°metro | Significado |
|:--|:--|
| `D_MODEL` | Dimensi√≥n interna de embeddings. |
| `N_HEADS` | N√∫mero de cabezas en MHA. |
| `N_LAYERS` | Capas Transformer Encoder. |
| `P_DROP` | Dropout en capas CNN. |
| `P_DROP_ENCODER` | Dropout dentro del Transformer. |

### üîÅ Entrenamiento avanzado
| Par√°metro | Funci√≥n |
|:--|:--|
| `USE_EMA` | Usa Exponential Moving Average de pesos. |
| `EMA_DECAY` | Factor de suavizado (0.9995). |
| `USE_WEIGHTED_SAMPLER` | Balancea sujetos y clases. |

### üß¨ Fine-Tuning (por sujeto)
| Par√°metro | Explicaci√≥n |
|:--|:--|
| `FT_N_FOLDS` | Cross-validation interna por sujeto. |
| `FT_FREEZE_EPOCHS` | √âpocas congelando backbone. |
| `FT_UNFREEZE_EPOCHS` | √âpocas entrenando todo. |
| `FT_LR_HEAD` | LR para la capa de salida. |
| `FT_LR_BACKBONE` | LR para el backbone (menor). |
| `FT_PATIENCE` | Early stopping en FT. |
| `FT_WD` | Weight decay. |
| `FT_AUG` | Probabilidades de augmentaci√≥n. |

---

## üßÆ 5. Conceptos clave

| Concepto | Significado |
|:--|:--|
| **Batch size** | N√∫mero de ejemplos procesados por actualizaci√≥n. |
| **d_model** | Tama√±o del vector de embedding (dimensi√≥n del token). |
| **T‚Ä≤** | Longitud temporal reducida tras convoluciones (por stride). |
| **Warmup scheduler** | Aumenta el LR suavemente al inicio y lo reduce con coseno al final. |
| **EMA** | Mantiene una versi√≥n suavizada de los pesos para evaluaci√≥n estable. |
| **Fine-tuning** | Adapta el modelo global a cada sujeto con aprendizaje incremental. |

---

## üî• 6. Estrategias de entrenamiento

### üß© Warmup + Cosine Scheduler
Durante las primeras `WARMUP_EPOCHS`, el LR aumenta gradualmente desde un valor peque√±o hasta el `BASE_LR`.  
Despu√©s, decrece siguiendo una curva coseno hasta llegar a un m√≠nimo (10 % del valor base).

**Ventajas:**
- Evita inestabilidad al inicio.  
- Permite convergencia m√°s suave.  
- Refina los √∫ltimos pasos con actualizaciones peque√±as.

**Visualizaci√≥n:**
```
LR
‚îÇ        /\
‚îÇ       /  \
‚îÇ      /    \______
‚îÇ_____/            √âpoca
    ‚Üë warmup     ‚Üë decay
```

---

### ‚öôÔ∏è Exponential Moving Average (EMA)
EMA mantiene una copia ‚Äúpromediada‚Äù de los pesos que evoluciona lentamente:

```
Œ∏_ema ‚Üê decay * Œ∏_ema + (1 - decay) * Œ∏_model
```

**Ventajas:**
- Reduce el ruido en los pesos.  
- Mejora la estabilidad y generalizaci√≥n.  
- Se usa el modelo EMA para evaluaci√≥n.

---

### üß† Fine-Tuning progresivo
Despu√©s del entrenamiento global (multi-sujeto), cada sujeto pasa por un ajuste personalizado:

1. **Congelar backbone:** se entrena solo la cabeza (aprende r√°pido sin olvidar).  
2. **Descongelar todo:** se entrena el modelo completo con LR bajo.  
3. **4-Fold CV:** cada sujeto se valida en 4 divisiones internas.

**Beneficios:**
- El modelo se adapta a las variaciones individuales del EEG.  
- Evita sobreajuste manteniendo conocimiento general.

---

## üìä 7. Resumen estructural

| Bloque | Funci√≥n | Output |
|:--|:--|:--|
| CNN | Extrae patrones locales del EEG. | (B, C‚Ä≤, T‚Ä≤) |
| Proyecci√≥n 1√ó1 | Convierte a espacio de embedding. | (B, d_model, T‚Ä≤) |
| Transformer Encoder | Modela dependencias temporales largas. | (B, L, D) |
| Token [CLS] + Head | Predicci√≥n binaria (izq./der.). | (B, 2) |

---

## üßæ 8. Resumen final de conceptos

- La **CNN** act√∫a como extractor jer√°rquico local.  
- El **Transformer** modela relaciones temporales globales.  
- El **warmup scheduler** suaviza el aprendizaje.  
- El **EMA** estabiliza los pesos.  
- El **fine-tuning** personaliza por sujeto.  

Con este pipeline, el modelo logra una **alta robustez y generalizaci√≥n inter-sujeto**, adapt√°ndose luego individualmente.

---


---

## ‚öôÔ∏è Entrenamiento

- **Optimizaci√≥n:** AdamW (lr=1e-3), scheduler Warmup + Cosine decay.
- **P√©rdida:** Focal Loss (Œ≥=1.5, Œ± balanceado).
- **Regularizaci√≥n:** Dropout, EMA (decay=0.9995), Early stopping.
- **Aumentaciones:** jitter temporal, ruido aditivo, channel dropout.
- **Weighted Sampler:** balanceo por clase y sujeto.
- **Cross-validation:** 5 folds por sujeto (train/val/test).

---

## üßÆ Robustez con Pocas Muestras

El modelo logra buen desempe√±o a pesar del n√∫mero reducido de √©pocas (~45 por sujeto) gracias a:

1. **Extracci√≥n jer√°rquica (CNN):** aprende patrones reutilizables entre sujetos.
2. **Eficiencia param√©trica:** depthwise separable convs reducen la cantidad de pesos entrenables.
3. **Regularizaci√≥n y data augmentation.**
4. **Atenci√≥n global:** el Transformer aprende relaciones invariantes al sujeto.
5. **Fine-tuning individual:** refina el modelo global con datos de cada sujeto.

---

## üîç Interpretabilidad

- **Attention Maps:** muestran qu√© regiones temporales fueron m√°s relevantes.
- **Grad-CAM++ 1D:** identifica segmentos EEG que influyeron en la decisi√≥n.
- **Visualizaciones por sujeto:** se generan autom√°ticamente en test (solo aciertos).

---

## üìä M√©tricas

- Accuracy global por fold.
- F1 Macro (balance entre clases).
- Matrices de confusi√≥n.
- Especificidad y sensibilidad promedio.



---


# üß† Comparaci√≥n de Modelos CNN+Transformer ‚Äî EEG PhysioNet

---

## ‚öôÔ∏è Modelos evaluados

| Modelo | Configuraci√≥n | Capas Transformer | Par√°metros | FLOPs | Enfoque |
|:--|:--|--:|--:|--:|:--|
| `nb2_h4_optimized_ligero` | d=128, L=1 | 1 | 195 k | 19.6 M | Modelo eficiente (low-power) |
| `nb2_h4_optimized_medio` | d=128, L=3 | 3 | 460 k | 58.8 M | Modelo balanceado (mejor F1) |
| `nb2_h4` | d=144, L=2 | 2 | 400 k | 48.6 M | Modelo base (referencia) |

---

## üìä Resultados globales

| Modelo | ACC (mean) | F1_macro (mean) | FT_ACC (mean) | FLOPs | Latencia | Par√°metros |
|:--|--:|--:|--:|--:|--:|--:|
| **nb2_h4_optimized_medio** | **0.8305 ¬± 0.0188** | **0.8298 ¬± 0.0188** | 0.8623 ¬± 0.0154 | 58.8 M | 2.81 ms | 460k |
| **nb2_h4_optimized_ligero** | 0.8211 ¬± 0.0167 | 0.8211 ¬± 0.0167 | **0.8731 ¬± 0.0133** | **19.6 M** | **1.31 ms** | **195k** |
| **nb2_h4 (base)** | 0.8203 ¬± 0.0112 | 0.8203 ¬± 0.0112 | 0.8596 ¬± 0.014 | 48.6 M | 1.76 ms | 400k |

---

## üß© An√°lisis de rendimiento

### ü•á `nb2_h4_optimized_medio`
- M√°ximo F1 (‚âà0.83).  
- 3 capas Transformer ‚Üí mejor estabilidad inter-fold.  
- Costo computacional medio-alto (‚âà58M FLOPs).

### ü•à `nb2_h4_optimized_ligero`
- F1 ‚âà 0.82, con solo 1 capa Transformer.  
- 3√ó m√°s r√°pido que el medio.  
- Ideal para tiempo real o dispositivos embebidos.

### ü•â `nb2_h4` (base)
- F1 ‚âà 0.82, sin mejora clara frente al ligero.  
- FLOPs intermedios (48M), sin ganancia significativa.

---

## ‚öñÔ∏è Trade-off general

| Modelo | F1_macro | FLOPs | Latencia | F1 / Costo (relativo) | Recomendaci√≥n |
|:--|--:|--:|--:|--:|:--|
| ü•á `nb2_h4_optimized_medio` | **0.8298** | 58.8 M | 2.8 ms | 1.0√ó | Mejor F1 absoluto |
| ü•à `nb2_h4_optimized_ligero` | 0.8211 | **19.6 M** | **1.3 ms** | **2.5√ó m√°s eficiente** | Mejor costo-beneficio |
| ü•â `nb2_h4` (base) | 0.8203 | 48.6 M | 1.76 ms | 1.5√ó | Equilibrado, sin ganancia clara |

---

## üí° Conclusiones

- **Ganancia F1:** El modelo medio supera al ligero solo +1‚ÄØ%, pero triplica su costo computacional.  
- **Robustez:** Los tres modelos muestran varianza baja ‚Üí pipeline estable y reproducible.  
- **Fine-Tuning:** mejora promedio de 4‚Äì5‚ÄØ% adicional en accuracy por sujeto.  
- **Uso recomendado:**  
  - **Entrenamiento offline / m√°xima precisi√≥n:** `nb2_h4_optimized_medio`.  
  - **Despliegue en tiempo real / eficiencia:** `nb2_h4_optimized_ligero`.

---



