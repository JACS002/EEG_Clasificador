# Proyecto EEG MI ‚Äî Primer Avance

Este repositorio contiene el trabajo inicial de an√°lisis y preprocesamiento de se√±ales EEG de **imaginaci√≥n motora (MI)**, as√≠ como la implementaci√≥n del primer modelo base **FBCSP + LDA**.  

A continuaci√≥n se describen las fases clave desarrolladas hasta el momento.

---

## 1. EDA de datos RAW

Antes de cualquier limpieza se realiz√≥ un **an√°lisis exploratorio de los datos crudos** (`data/raw`) con los siguientes objetivos:

- **Inventario de archivos:** verificaci√≥n de sujetos disponibles y runs por sujeto.
- **Conteo de eventos por clase:** Left, Right, Both Fists, Both Feet, Rest.
- **Amplitud extrema:** c√°lculo de percentil 99 (`p99_uV`) y desviaci√≥n est√°ndar por canal (`std_uV`) para detectar outliers.
- **Artefactos musculares (EMG):** estimados mediante la **relaci√≥n de potencia 20‚Äì40 Hz** en los canales motores.
- **PSD (densidad espectral de potencia):** inspecci√≥n en C3, Cz, C4.
- **Separabilidad inicial:** an√°lisis con **t-SNE** sobre log-varianza de las √©pocas.

**Hallazgos importantes en RAW:**
- Gran variabilidad inter-sujetos en amplitud (50‚Äì300 ŒºV).
- Presencia de ruido y artefactos musculares en varios sujetos.
- La mayor√≠a de sujetos muestran **silhouette score negativo** ‚Üí baja separabilidad entre clases en el estado crudo.
- Dataset heterog√©neo, requiere un pipeline de preprocesamiento robusto.

---

## 2. Pipeline de Preprocesamiento

El preprocesamiento busca limpiar los EEG y asegurar que las features extra√≠das representen la actividad neuronal y no artefactos.


### Explicaci√≥n paso a paso

1. **Normalizaci√≥n de nombres y montaje**  
   - Estandarizaci√≥n de canales y asignaci√≥n al sistema 10‚Äì20.  
   - Permite localizar f√°cilmente C3, Cz y C4, fundamentales en MI.

2. **Filtro Notch**  
   - Remueve interferencia el√©ctrica de 50/60 Hz.  
   - Evita que el ruido de la red contamine las bandas mu y beta.

3. **Clipping de amplitud**  
   - **Softclip:** aten√∫a valores extremos sin descartarlos.  
   - **Hardclip:** elimina √©pocas con amplitudes fuera de rango.  
   - Previene que outliers extremos dominen el entrenamiento.

4. **Filtro Bandpass (8‚Äì30 Hz)**  
   - A√≠sla las bandas mu (8‚Äì12 Hz) y beta (13‚Äì30 Hz).  
   - Son las m√°s asociadas a imaginaci√≥n motora.

5. **ICA (FastICA / Picard)**  
   - Separa fuentes independientes y elimina componentes de artefactos:  
     - Oculares (EOG),  
     - Musculares (EMG),  
     - Cardiacos (ECG).  
   - Esencial para mejorar la pureza de las se√±ales.

6. **Segmentaci√≥n en epochs**  
   - Ventana de **0.5‚Äì4.5 s post-est√≠mulo**.  
   - Captura la actividad cortical durante la tarea, evitando ruido al inicio/final.

7. **Rechazo autom√°tico de √©pocas**  
   - Se eliminan ensayos con amplitudes excesivas (peak-to-peak).  
   - Garantiza un set final m√°s balanceado y limpio.

8. **Exportaci√≥n en formato FIF**  
   - Archivos por sujeto (`Sxxx_MI-epo.fif`).  
   - Estandariza y permite reutilizar f√°cilmente con MNE y modelos posteriores.

**Resultados del preprocesamiento:**
- Reducci√≥n significativa de amplitudes extremas.  
- Menor presencia de artefactos EMG.  
- Balance de clases m√°s uniforme por sujeto.  
- Mejora en separabilidad en varios sujetos (Œî silhouette > 0).  

---

## 3. EDA de datos POST

Una vez aplicado el pipeline, se evaluaron nuevamente los datos procesados (`data/processed`) con m√©tricas y visualizaciones:

- **Conteo de √©pocas por sujeto y clase** ‚Üí para verificar balance.
- **PSD en C3, Cz, C4 por clase** ‚Üí confirmaci√≥n de la actividad en bandas mu/beta.
- **Topomapas de potencia** en bandas mu y beta ‚Üí patrones espaciales de activaci√≥n.
- **QA autom√°tico:** detecci√≥n de sujetos problem√°ticos (muy pocas √©pocas, EMG residual alto, silhouette muy negativo).
- **Comparaci√≥n RAW vs POST**:  
  - Œî silhouette ‚Üí mejora en separabilidad de clases.  
  - Œî amplitud extrema (`p99_uV`) ‚Üí reducci√≥n de outliers.  
  - EMG ratio ‚Üí ca√≠da en la mayor√≠a de sujetos.

**Hallazgos importantes en POST:**
- Disminuci√≥n clara en amplitudes extremas y ruido.  
- Aumento en la calidad de √©pocas disponibles.  
- Mejor diferenciaci√≥n de clases en varios sujetos.  
- Sin embargo, algunos sujetos siguen presentando problemas de EMG o baja separabilidad, que deber√°n manejarse con **flags de QA** en futuras iteraciones.

---

## Conclusi√≥n preliminar

El **pipeline de preprocesamiento** aplicado transforma un dataset crudo, heterog√©neo y ruidoso, en un conjunto m√°s limpio y balanceado. Esto sienta las bases para los experimentos con modelos como **FBCSP + LDA** y, en fases posteriores, comparaciones con **SVM, Riemannianos y redes profundas**.

--- 

## 4. FBCSP + LDA

**Objetivo:** clasificar EEG de *Motor Imagery* (Œº/Œ≤) usando **Filter-Bank CSP (FBCSP)** + **LDA con shrinkage**.  
Se eval√∫a en dos configuraciones: **INTRA-subject** (K-Fold por ensayos) y **INTER-subject** (folds predefinidos por sujetos desde JSON, con **validaci√≥n interna por sujetos** y opci√≥n de **calibraci√≥n**).

### Pipeline
1. **Carga y recorte** de √©pocas MNE (`.fif`) con ventana fija `crop_window` (p. ej., 0.5‚Äì3.5 s).
2. **Selecci√≥n de canales motores** (opcional): `C3, CZ, C4, FC3, FC4, CP3, CPZ, CP4`; alineaci√≥n de canales en VAL/TEST con `reorder_channels`.
3. **Banco de filtros** (Œº/Œ≤): subbandas densas de 2 Hz entre 8‚Äì30 Hz (11 bandas).
4. **CSP por subbanda**: `n_csp` componentes, `reg='ledoit_wolf'`, `log=True` (devuelve vectores de varianzas proyectadas).  
   - **Fit** con **solo TRAIN** del fold; **transform** en VAL/TEST.
5. **Concatenaci√≥n de features** de todas las subbandas.
6. **Estandarizaci√≥n** (z-score de features) con `StandardScaler` (fit en TRAIN).
7. **Clasificador**: `LDA(solver='lsqr', shrinkage='auto')`.

### FBCSP + LDA (features)
Para cada sub-banda (8‚Äì30 Hz, pasos de 2 Hz):
1) Filtramos; 
2) Ajustamos **CSP** en TRAIN y transformamos VAL/TEST;  
3) Calculamos **log-varianzas** de las `n_csp` componentes;  
4) **Concatenamos** features de todas las sub-bandas.  
Luego estandarizamos y clasificamos con **LDA (shrinkage)**.

### Evaluaciones
- **INTRA-subject** (`run_intra_all`):
  - `StratifiedKFold(k)` por sujeto (split por ensayos).
  - M√©tricas: Accuracy y F1-macro por fold; promedio ¬± DE por sujeto; fila **GLOBAL**.
  - Artefactos: CSV, TXT, figuras de matrices de confusi√≥n (mosaicos).

- **INTER-subject** (`run_inter_subject_cv_from_json`):
  - Folds desde JSON (`train/test` por sujetos).
  - **Validaci√≥n interna por sujetos**: fracci√≥n `val_ratio_subjects` dentro de TRAIN para ajuste/selecci√≥n.
  - Calibraci√≥n per-subject (k-shots): Para cada sujeto de test, tomamos **k=5** √©pocas por clase como **calibraci√≥n** y evaluamos en el resto de sus √©pocas. Durante la calibraci√≥n se re-ajustan **FBCSP** (fit con TRAIN + k-shots del propio sujeto) y **LDA** (tras estandarizaci√≥n). Este esquema refleja el uso real de BCI: una **breve sesi√≥n inicial** de calibraci√≥n por usuario mejora sustancialmente la transferencia inter-sujeto.
  - M√©tricas: VAL (acc, F1-macro) y TEST (acc, F1-macro) por fold + **GLOBAL**.
  - Artefactos: CSV consolidado, TXT de m√©tricas, TXT con `classification_report` por fold, figuras de confusi√≥n por fold y **GLOBAL**.

### Antileakage y reproducibilidad
- CSP, scaler y LDA se ajustan **exclusivamente** con TRAIN del fold (o TRAIN+CALIB si la calibraci√≥n est√° activa).  
- VAL/TEST s√≥lo se **transforman**.  
- Canales de VAL/TEST se **reordenan** para coincidir con TRAIN.  
- Se generan logs con timestamp y par√°metros para auditor√≠a.

### Principales hiperpar√°metros
- `crop_window=(0.5, 3.5)` s  
- `motor_only=True | False`  
- `zscore_epoch=True | False` (z-score por √©poca previo a CSP)  
- `fb_bands`: denso (2 Hz) de 8‚Äì30 Hz  
- `n_csp`: t√≠picamente 4‚Äì8 (p. ej., 4 √≥ 6)  
- `val_ratio_subjects‚âà0.16`, `calibrate_n` (s√≥lo INTER)

### Salidas
- **Tablas** (`/models/fbcsp_lda/tables`): CSV de m√©tricas con fila GLOBAL.
- **Logs** (`/models/fbcsp_lda/logs`): TXT de m√©tricas y `classification_reports_by_fold_*.txt`.
- **Figuras** (`/models/fbcsp_lda/figures`): matrices de confusi√≥n por sujeto/fold y GLOBAL.

> **Nota:** El mapeo de clases usa `LabelEncoder` para asegurar etiquetas consistentes. No influye en la se√±al ni en par√°metros del modelo.

## 5. Modelo Riemanniano para MI-EEG (MDM / FgMDM)

**Resumen.** Cada √©poca se representa por su **matriz de covarianza SPD** (SPD significa Symmetric Positive Definite) por sub-banda (8‚Äì30 Hz), y se clasifica por **distancia geod√©sica** a las medias de clase en la geometr√≠a Riemanniana (pyRiemann). Usamos **OAS** como estimador de covarianza y **normalizaci√≥n por traza** para estabilizar escala. Dos variantes:
- **MDM**: Minimum Distance to Mean sobre un **bloque-diagonal** que apila las covariancias de todas las bandas.
- **FgMDM**: Filter-geodesic MDM, que **agrega en el manifold** la informaci√≥n multi-banda.

**Preprocesado.**
- Ventana temporal: `crop_window=(0.5, 3.5)` (configurable).
- Canales: `motor_only=True` (C3, Cz, C4, FC3/4, CP3/z/4).
- Banco de bandas: denso 8‚Äì30 Hz, paso 2 Hz.
- Covarianza: `Covariances(estimator='oas')` + normalizaci√≥n por traza.

**Validaciones.**
- **INTRA-sujeto (k-fold)**: 5 folds estratificados dentro de cada sujeto; m√©tricas por sujeto + GLOBAL.
- **INTER-sujeto (folds JSON)**: split de **validaci√≥n por sujetos** dentro de TRAIN; ajuste del espacio **solo con TRAIN**; m√©tricas en VALID y TEST; **matriz de confusi√≥n global** y `classification_report` por fold.

**Calibraci√≥n per-subject (k-shots, recomendada).**
Para cada sujeto de TEST, tomamos **k=5** √©pocas por clase como **calibraci√≥n**, recomputamos el espacio con `TRAIN + CALIB_del_sujeto` y **evaluamos en el resto** de sus √©pocas. Refleja el uso real de BCI con una **breve sesi√≥n inicial** de calibraci√≥n por usuario. (Alternativamente, se puede calibrar con **n sujetos completos** del TEST si el escenario lo requiere.)

**Features (Riemann).** Cada √©poca se representa por **matrices de covarianza SPD** por sub-banda (estimador OAS + normalizaci√≥n por traza).  
**Geometr√≠a.** Las SPD viven en un manifold; usamos **distancia geod√©sica Riemanniana** (afin-invariante) para comparar.  
**Clasificadores.**  
- **MDM**: calcula la **media Riemanniana** por clase y predice por **distancia al centroide**. Multi-banda v√≠a **bloque diagonal**.  
- **FgMDM**: mantiene **una SPD por banda** y **agrega geod√©sicamente** la info multi-banda; suele rendir mejor.  
**En este repo:** `model='fgmdm'` (por defecto en inter-sujeto) ‚áí el clasificador activo es **FgMDM**.


## 6. EEGNet + Fine-Tuning Progresivo por Sujeto (MI-EEG, 4 clases)

**Objetivo:**  
Clasificar imaginaci√≥n motora (MI) en 4 clases (`Left`, `Right`, `Both Fists`, `Both Feet`) usando solo **8 canales motores de EEG**, mediante una red **EEGNet** y un protocolo realista de **calibraci√≥n/fine-tuning progresivo por sujeto**.

---

### ¬øQu√© problema resolvemos?

Cuando intentamos usar un **BCI (interfaz cerebro-computador)** con personas nuevas, el modelo suele bajar rendimiento porque cada cerebro es distinto (morfolog√≠a, impedancias, atenci√≥n, fatiga, etc.).

Nuestra estrategia:
1. **Aprender un modelo global** con muchos sujetos (para captar patrones generales).  
2. **Personalizarlo ligeramente** con pocos ensayos etiquetados del nuevo usuario (**fine-tuning progresivo**), de forma r√°pida y estable.

---

### ¬øQu√© es EEG y qu√© entrada ve la red?

- **EEG:** voltajes medidos en el cuero cabelludo.  
- **Canales usados (motores):** `C3, Cz, C4, FC3, FC4, CP3, CPz, CP4`.

**Procesamiento de entrada:**
- Para cada evento (T1/T2), extraemos una **ventana de 3 segundos**, muestreada a **160 Hz**.  
- Normalizamos cada √©poca (z-score por canal) para estabilizar amplitudes.  

**Cada ejemplo:**  
Matriz de tama√±o `(Tiempo √ó Canales)`  
**Etiquetas:**  
`0=Left`, `1=Right`, `2=Both Fists`, `3=Both Feet`.

---

### ¬øQu√© es una red neuronal y c√≥mo decide una clase?

Una red neuronal transforma la entrada a trav√©s de capas hasta llegar a una **representaci√≥n √∫til para clasificar**.  
La √∫ltima capa produce **4 n√∫meros** (uno por clase).  
Aplicamos **softmax** ‚Üí obtenemos probabilidades.  

Entrenamos la red para maximizar la probabilidad de la clase correcta con:  
- **Funci√≥n de p√©rdida:** *Cross-Entropy*  
- **Optimizador:** *Adam*

---

### Arquitectura: EEGNet

EEGNet est√° dise√±ada espec√≠ficamente para EEG.  
La entrada tiene forma `(Batch, 1, Tiempo, Canales)` y pasa por **3 bloques convolucionales + cabeza densa**:

Entrada (B, 1, T, C)
‚îÇ
‚îú‚îÄ Bloque 1: Convoluci√≥n Temporal ‚Üí aprende filtros en el tiempo
‚îÇ + BatchNorm + ELU
‚îÇ
‚îú‚îÄ Bloque 2: Convoluci√≥n Depthwise Espacial ‚Üí patrones espaciales
‚îÇ + BN + ELU + AvgPool + Dropout
‚îÇ
‚îú‚îÄ Bloque 3: Convoluci√≥n Separable Temporal ‚Üí refina patrones
‚îÇ + BN + ELU + AvgPool + Dropout
‚îÇ
‚îî‚îÄ Cabeza: Flatten ‚Üí Dense(80) ‚Üí Dense(4) + Softmax


**Intuici√≥n:**
- **Temporal:** aprende ritmos relevantes (Œº/beta).  
- **Espacial (depthwise):** combina canales como una CSP aprendida.  
- **Separable temporal:** refina patrones con pocos par√°metros.  
- **Cabeza:** traduce caracter√≠sticas a probabilidades por clase.

---

### Evaluaci√≥n: c√≥mo evitamos *data leakage*

Validaci√≥n **inter-sujeto (K=5 folds):**
- Cada *fold* tiene sujetos **no vistos** en test.  
- Dentro del *train*, se reserva un **15% de sujetos para validaci√≥n** (early stopping).  
- As√≠, el modelo no ve nunca el test antes de tiempo.

---

### Entrenamiento Global (Inter-Sujeto)

**Dataset:**  
Hasta **21 ensayos por clase y sujeto** (con reposici√≥n si faltan) ‚Üí dataset balanceado.

**Entrenamiento:**
- Modelo: EEGNet  
- Optimizador: Adam  
- √âpocas: 100 (m√°ximo)  
- *Early stopping* por `val_acc`

**Evaluaci√≥n:**
- `accuracy` y `classification report` en sujetos no vistos.

---

### Fine-Tuning Progresivo por Sujeto (Calibraci√≥n r√°pida)

Cuando llega un **nuevo sujeto (de test)**:

1. Hacemos **4-fold CV interno** con solo sus datos (‚âà 75% calibraci√≥n / 25% hold-out).  
2. Entrenamos **tres modos** con *early stopping* + penalizaci√≥n **L2-SP**:

| Modo | Capas entrenadas | Descripci√≥n |
|------|------------------|-------------|
| `out` | Solo salida | Ajusta el clasificador final |
| `head` | FC + salida | Personaliza la cabeza entera |
| `spatial+head` | Convs espaciales + separables + cabeza | Congela filtros temporales globales |

Elegimos el modo con mejor `accuracy` en el *hold-out* del sujeto ‚Üí se usa para predecir todo su set.

**Por qu√© funciona:**  
Con pocos ensayos del usuario, ajustar pocas capas + L2-SP (penaliza alejarse del modelo global) evita sobreajuste y personaliza la fisiolog√≠a.

---

### Hiperpar√°metros

#### Generales
| Par√°metro | Valor | Descripci√≥n |
|------------|--------|-------------|
| `FS` | 160 Hz | Frecuencia de muestreo |
| `WINDOW_MODE` | '3s' | Duraci√≥n de ventana |
| `EXPECTED_8` | 8 canales | C3, Cz, C4, FC3, FC4, CP3, CPz, CP4 |

#### Entrenamiento Global
| Par√°metro | Valor | Descripci√≥n |
|------------|--------|-------------|
| `N_FOLDS` | 5 | CV por sujeto |
| `BATCH_SIZE` | 16 | Tama√±o de lote |
| `EPOCHS_GLOBAL` | 100 | M√°ximo de √©pocas |
| `LR` | 1e-3 | Tasa de aprendizaje |
| `GLOBAL_VAL_SPLIT` | 0.15 | Validaci√≥n por sujeto |
| `GLOBAL_PATIENCE` | 10 | Early stopping |
| `LOG_EVERY` | 5 | Log cada 5 √©pocas |

#### Fine-Tuning
| Par√°metro | Valor | Descripci√≥n |
|------------|--------|-------------|
| `CALIB_CV_FOLDS` | 4 | CV interno del sujeto |
| `FT_EPOCHS` | 30 | M√°x. √©pocas por etapa |
| `FT_BASE_LR` | 5e-5 | LR para capas base |
| `FT_HEAD_LR` | 1e-3 | LR para cabeza |
| `FT_L2SP` | 1e-4 | Penalizaci√≥n L2-SP |
| `FT_PATIENCE` | 5 | Early stopping FT |
| `FT_VAL_RATIO` | 0.2 | Validaci√≥n interna del sujeto |

**Regla pr√°ctica:**  
- Si tienes **pocos ensayos**, usa `out` o `head`.  
- Si tienes **m√°s datos**, prueba `spatial+head`.  
- Si ves sobreajuste ‚Üí sube `FT_L2SP` o baja `LR`.

---

### M√©tricas y Salidas

- **Global accuracy por fold** (inter-sujeto puro).  
- **Fine-tuning accuracy** y **Œî(FT - Global)** (mejora por personalizaci√≥n).  
- **Classification reports:** precisi√≥n, recall, F1 por clase.  
- **Matriz de confusi√≥n global** acumulada (todos los folds).

---

## Evaluaci√≥n INTRA-Sujeto (Fine-Tuning Progresivo dentro del mismo sujeto)

En el modo **INTRA**, evaluamos el rendimiento **dentro del mismo sujeto**.  
Para cada persona, realizamos una **validaci√≥n cruzada k-fold** con sus propias √©pocas.

En cada fold:
- Partimos de un **modelo global** (pre-entrenado con todos los sujetos).
- Lo **ajustamos ligeramente** a ese sujeto mediante **fine-tuning progresivo**.
- Elegimos la etapa (`out`, `head` o `spatial+head`) que mejor rinde en validaci√≥n.
- Probamos esa etapa en el **test del fold**.

---

### Flujo de INTRA (paso a paso)

#### Pre-entrenamiento global (pretrain)

- Mezclamos **todas las √©pocas de todos los sujetos** (sin limitar a 21 por clase).  
- Entrenamos un modelo **EEGNet global** durante hasta **100 √©pocas** (por defecto).  
- Este modelo sirve como **base inicial** para todos los fine-tuning posteriores.

---

#### k-Fold por sujeto

Para cada sujeto `Sxyz`:

1. **Divisi√≥n interna (k-fold estratificado):**  
   - Dividimos solo las √©pocas de ese sujeto en `k` folds (por ejemplo, `k=5`),  
     manteniendo las clases balanceadas en cada fold.

2. **En cada fold:**

   **a) Calibraci√≥n / Validaci√≥n**  
   - Dentro del conjunto de *train* del fold, hacemos un split adicional (p. ej. 20% para validaci√≥n).

   **b) Fine-Tuning Progresivo**  
   - Clonamos el **modelo global pre-entrenado**.  
   - Entrenamos tres configuraciones diferentes:

     | Modo | Capas entrenadas | Descripci√≥n |
     |------|------------------|-------------|
     | `out` | Solo la capa de salida | R√°pido y seguro con pocos datos |
     | `head` | FC + salida | M√°s capacidad de adaptaci√≥n |
     | `spatial+head` | Convoluciones espaciales + separables + cabeza | Congela los filtros temporales globales |

   - En todos los modos se aplica **L2-SP**, una regularizaci√≥n que penaliza desviarse del modelo global ‚Üí reduce el sobreajuste.

   **c) Selecci√≥n de modelo**
   - Elegimos la etapa con **mayor `val_acc`** (accuracy en validaci√≥n dentro del fold).

   **d) Prueba**
   - Evaluamos esa etapa elegida en el **test del fold** (√©pocas del mismo sujeto, nunca vistas en ese fold).

---

#### Agregaci√≥n de resultados

- **Por sujeto:**  
  Promediamos `accuracy` y `F1-macro` sobre sus `k` folds.

- **Global INTRA:**  
  Promedio de las m√©tricas de todos los sujetos ‚Üí mide el rendimiento medio de personalizaci√≥n dentro del sujeto.

---

> üß† **Resumen:**  
> El protocolo INTRA eval√∫a la capacidad del modelo global de adaptarse a cada sujeto con pocos datos.  
> Combina transferencia de aprendizaje, regularizaci√≥n L2-SP y validaci√≥n cruzada interna para medir un rendimiento realista de calibraci√≥n personalizada.


> üîç **Resumen:**  
> EEGNet + Fine-Tuning Progresivo permite transferir un modelo global a nuevos sujetos con m√≠nima calibraci√≥n, manteniendo estabilidad y mejorando la personalizaci√≥n en escenarios de BCI realistas.
